t comparison id backpropag english texttospeech map a perform error backpropag bp id learn algorithm compar task map english text phonem stress distribut output code develop sejnowski rosenberg shown bp consist outperform id task sever percentag point three hypothes explain differ explor a id overfit train data b bp abl share hidden unit across sever output unit henc learn output unit better c bp captur statist inform id not conclud hypothesi c correct augment id simpl statist learn procedur perform bp close match complex statist procedur improv perform bp id substanti domain b introduct univers learn algorithm take sampl train exampl arbitrari unknown function f produc good approxim f see dietterich instead everi learn algorithm embodi assumpt or bia natur learn problem appli algorithm exampl assum small number featur describ data relev algorithm assum everi featur make small independ contribut determin classifi cation mani algorithm order hypothes accord syntact simplic represent attempt find simplest hypothesi consist train exampl unfortun mani popular learn algorithm assumpt embodi entir knownor known state term difficult check given applic domain exampl quinlan decisiontre algorithm id assum unknown function f repres small decis tree howev given new learn problem difficult know whether assumpt hold without first run id algorithm result good understand rang problem id appropri similarli backpropag algorithm rumelhart hinton william assum minimum unknown function f repres multilay feedforward network sigmoid unit although mani success applic backpropag touretzki still lack understand situat appropri furthermor clear statement assumpt made id backpropag unavail understand relationship two algorithm investig even suggest algorithm make similar assumpt lorien pratt person commun henc confront two relat question first assumpt embodi id backpropag or equival situat algorithm appli second id backpropag relat one conceiv two differ approach answer question theoret approach could analyz algorithm attempt articul assumpt experiment approach could test two algorithm nontrivi problem compar behavior paper take experiment approach appli id backpropag task map english word pronunci task pioneer sejnowski rosenberg famou nettalk sy tem employ backpropag rosenberg doctor dissert includ analysi experi domain replic work discov backpropag outperform id task demonstr id backpropag make ident assumpt go investig differ id backpropag formul three hypothes explain differ conduct experi test hypothes experi show id combin simpl statist learn procedur nearli match perform bp also present data show perform id backpropag highli correl collect binari concept learn problem data also show id bp tend agre concept easi difficult given bp substanti awkward timeconsum appli result suggest follow methodolog appli algorithm problem similar nettalk task first id combin statist learn procedur appli perform adequ need appli backpropag howev id perform inadequ still use estim perform backpropag much expens backpropag procedur employ see yield better classifi id backpropag task conduct comparison id backpropag chosen task map english text speech complet texttospeech system involv mani stage process ideal sentenc pars identifi word sens part speech individu word and sens map string phonem stress final phonem stress combin variou techniqu gener sound wave excel review see klatt phonem equival class basic sound exampl phonem p individu occurr p slightli differ consid p sound exampl two ps lollypop pronounc differ member equival class phonem p use phonem see appendix a stress perceiv weight given syllabl word exampl first syllabl lollypop receiv primari stress third syllabl receiv secondari stress middl syllabl unstress stress inform code assign one six possibl stress symbol letter conson gener receiv one symbol indic princip vowel syllabl left right respect conson vowel gener mark code none primari secondari indic degre stress lastli silent stress assign blank let l set symbol compris letter az comma space period in data set comma period appear let p set english phonem set stress employ sejnowki rosenberg task learn map f specif f map word length k string phonem length k string stress length k exampl notic letter phonem stress align silent letter map silent phonem defin f complex discret map larg rang assum word contain letter the length antidisestablishmen tarian rang would contain element exist learn algorithm focu primarili learn boolean conceptsthat is function whose rang set f g algorithm cannot appli directli learn f fortun sejnowski rosenberg develop techniqu convert complex learn problem task learn collect boolean concept begin reformul f map g sevenlett window singl phonem singl stress exampl word lollypop would convert separ sevenlett window function g appli window result concaten obtain phonem stress string map function g rang possibl phonemestress pair substanti improv final sejnowski rosenberg code possibl phonemestress pair bit string bit phonem bit stress bit code correspond properti phonem stress convert g separ boolean function h function h map seven letter window set f g assign phonem stress window function evalu produc bit string string map nearest bit string repres legal phonemestress pair use ham distanc two string measur distanc sejnowski rosenberg use angl two string measur distanc report euclidean distanc metric gave similar result test euclidean metric obtain result ident report paper reformul possibl appli boolean concept learn method learn h howev individu h must learn extrem well order obtain good perform level entir word error aggreg exampl h learn well correct error among h independ bit string correct time averag word letter whole word correct time far discuss represent output map learn input repres straightforward fashion use approach recommend sejnowski rosenberg sevenlett window repres concaten seven bit string bit string repres letter one bit letter period comma blank henc one bit set bit string produc string bit window bit provid input featur learn algorithm id backpropag algorithm id id simpl decisiontre learn algorithm develop ross quinlan b construct decis tree recurs start root node select featur test node featur whose mutual inform output classif greatest thi sometim call inform gain criterion train exampl partit exampl algorithm invok recurs two subset train exampl algorithm halt exampl node fall class point leaf node creat label class question basic oper id quit similar cart algorithm develop breiman friedman olshen stone treegrow method develop lucassen mercer algorithm extend handl featur valu featur continu valu well implement id employ window quinlan chisquar forward prune quinlan a kind revers prune quin lan appli one simpl kind forward prune handl inconsist train data remain featur zero inform gain growth tree termin leaf class train exampl chosen label leaf in case tie leaf assign class appli id task algorithm must execut timesonc map h execut produc separ decis tree backpropag error backpropag method rumelhart hinton william wide appli train artifici neural network howev standard form algorithm requir substanti assist user specif user must specifi transfer function artifici neuron unit network architectur number layer interconnect number hidden unit layer learn rate momentum term initi weight valu target threshold furthermor user must decid termin train make comparison id backpropag fair necessarili transform bp userassist method algorithm involv user assist develop transform call result algorithm bpcv backpropag crossvalid defin bpcv fix userspecifi properti set remain paramet via crossvalid use method introduc lang waibel hinton explain below bpcv one hidden layer fulli connect input layer output layer everi unit hidden output layer implement take dot product vector weight w vector incom activ x ad bia appli logist function continu differenti approxim linear threshold function use perceptron sever paramet given fix valu learn rate alway momentum term target threshold use criterion minim sum squar error sse basic paramet except target threshold use sejnowski rosenberg conduct crossvalid found perform insensit paramet choic remain parametersnumb hidden unit random start weight stop total sum squar error tssear set follow crossvalid procedur given set exampl s subdivid three set train set s tr crossvalid set s cv test set s test execut backpropag sever time train set tr vari number hidden unit random start weight pass train data test perform network cv goal search paramet space find paramet give peak perform crossvalid set paramet use train backpropag union tr cv good estim gener perform obtain test test advantag crossvalid train inform test set employ train henc observ error rate test set fair estim true error rate learn network contrast common unsound practic adjust paramet optim perform test set one advantag bpcv nettalk task that unlik id necessari appli bpcv onc output bit learn simultan inde output share set hidden unit may allow output learn accur howev id batch algorithm process entir train set onc bp increment algorithm make repeat pass data complet pass call epoch epoch train exampl inspect oneatatim weight network adjust reduc squar error output use implement provid mcclelland rumelhart output bp float point number adapt ham distanc measur map nearest legal phonemestress pair use follow distanc measur dx reduc ham distanc x boolean vector id backpropag tabl optim network size via crossvalid number letter number hidden unit correct tsse epoch data set sejnowski rosenberg provid us dictionari word correspond phonem stress string dictionari drew random and without replac train set word crossvalid set word test set word result crossvalid train present result studi first discuss result crossvalid procedur bpcv perform seri run systemat vari number hidden unit random start weight four set random weight gener net work perform crossvalid set evalu complet pass train data epoch network train except case train continu epoch ensur peak perform found tabl show peak perform percent letter correctli pronounc network size total sum squar error on tr gave peak perform tsse number appropri adjust number train exampl use decid termin train entir train set s tr cv base run best network size hidden unit complet crossvalid train proceed merg train set crossvalid set form word train set crossvalid train store snapshot weight valu first complet epoch random network gener henc perform train entir train set use best store hidden unit snapshot start point origin train set tr contain sevenlett window percent letter correct epoch figur train curv best hidden unit network vertic bar indic point maximum perform full train set tr s cv contain sevenlett window henc target tsse full train set surpris figur shown tabl sinc expect reason small network eg hidden unit would give good fit data howev tabl clearli show gener steadili improv qualiti fit train data improv furthermor figur show train network continu past point peak perform perform declin appreci previou work sejnowski rosenberg rosenberg use network hidden unit howev knowledg one previous conduct systemat studi relationship network size perform nettalk task similar result show larger network give improv perform publish martin pittman perform comparison tabl show percent correct over word test set word letter phonem stress letter consid correct phonem stress correctli predict after map nearest legal phonem id backpropag tabl percent correct word test set level aggreg correct method word letter phonem stress bit mean id bpcv differ cell signific disagre agre backpropag incorrect correct incorrect correct stress word correct letter correct virtual everi differ tabl word letter phonem stress level statist signific use onetail test differ two proport base normal approxim binomi distribut henc conclud substanti differ perform id bpcv task note although test set contain disjoint word sevenlett window test set also appear train set specifi calli window test set appear word train set repres distinct window henc perform letter phonem stress level artifici high one concern abil learn method handl unseen case correctli howev one interest probabl letter or phonem stress unseen word correctli classifi number provid right measur take closer look perform differ studi exactli sevenlett window test set handl algorithm tabl categor window accord whether correctli classifi algorithm one algorithm neither one tabl show window correctli learn bpcv form superset learn id instead two algorithm share correct window algorithm correctli classifi sever window algorithm get wrong overal result bpcv classifi window tabl averag percent correct word test set five trial level aggreg correct method word letter phonem stress bit mean id bp differ cell signific correctli id show two algorithm overlap substanti learn fairli differ texttospeech map inform tabl summar correl coeffici specif let x id xbpcv random variabl id bpcv respect make correct predict letter level case correl x id xbpcv four cell tabl equal correl coeffici would zero for refer independ run bpcv train set differ random start state correl coeffici weak tabl show perform valu one particular choic train test set replic studi four time for total independ trial trial randomli drew without replac two set word dictionari word note mean overlap among five train set and among five test set tabl show averag perform run differ signific level use ttest pair differ anoth weak tabl show perform valu word train set might rel perform differ id bpcv might chang size train set chang tabl show case row tabl give result run id bpcv sever differ size train set case bpcv train use crossvalid train methodolog outlin four run network hidden unit differ methodolog outlin train tr determin peak gener perform test word cv retrain union tr cv sinc would creat train set larg instead simpli test best network word test conclud consist differ id bpcv that perform algorithm increas size train set differ still observ remaind paper attempt understand natur differ bpcv id main approach experi modif two algorithm enhanc elimin differ id backpropag tabl percent correct word test set sampl level aggreg correct size method word letter phonem stress bit mean bpcv id id bpcv id bpcv id bpcv id bpcv differ cell signific tabl result appli three overfittingprevent techniqu level aggreg correct method data set word letter phonem stress bit mean a id as abov test b id cutoff test c id prune test d id rule test them unless state otherwis experi perform use word train set word test set tabl three hypothes caus differ id bpcv three hypothes hypothesi overfit id overfit train data seek complet consist caus make error test set hypothesi share abil bpcv share hidden unit among h allow reduc aggreg problem bit level henc perform better hypothesi statist numer paramet network allow captur statist inform captur id hypothes neither mutual exclus exhaust follow three subsect present experi perform test hypothes test hypothesi overfit tendenc id overfit train data well establish case data contain nois three basic strategi develop address problem a criteria earli termin treegrow process b techniqu prune tree remov overfit branch c techniqu convert decis tree collect rule implement test one method strategi tabl summar result first row repeat basic id result given abov comparison purpos second row show effect appli test at confid level decid whether growth decis tree statist justifi quin lan a author report mooney et al hurt perform nettalk domain third row show effect appli quinlan techniqu reduceerror prune quinlan minger id backpropag provid evid one best prune techniqu row decis tree built use word tr set prune use cv crossvalid set final fourth row show effect appli method convert decis tree collect rule quinlan describ threestep method convert decis tree rule first path root leaf convert conjunct rule second rule evalu remov unnecessari condit third rule combin unnecessari rule elimin experi perform first two step third step expens execut rule set contain rule none techniqu improv perform id task suggest hypothesi incorrect id overfit data domain make sens sinc sourc nois domain limit size sevenlett window exist small number word like read one correct pronunci sevenlett window suffici correctli classifi word word dictionari may also explain observ overfit excess train crossvalid run backpropag either test hypothesi share second hypothesi claim key bpcv superior perform fact output unit share singl set hidden unit one obviou way test share hypothesi would develop version id permit share among separ decis tree learn could see sharedid improv perform altern remov share backpropag train independ network one output unit learn h map hypothesi correct then share among separ network see drop perform compar singl network share hidden unit furthermor decreas perform decreas differ bpcv id measur correl error call singl network hidden unit share output unit bp call separ network bp delic issu aris train bp ideal want train collect network differ bp result lack share hidden unit mean total sum squar error on train set bp bp goal train procedur find among bp network collect whose perform crossvalid set maxim henc use follow procedur first measur sum squar error over train set bit learn bp second train bp network follow crossvalid procedur tri altern random seed number hidden unit time alway dietterich hild bakiri termin train individu network attain squar error observ larg network crossvalid tri network hidden unit with four random seed network size final select network whose sum squar error minimum word crossvalid test set s cv surprisingli unabl train success separ network target error level word train set explor smaller subset word train set word found train succeed train set contain word word train set exampl individu network often converg local minima even though bp network avoid minima specif bit could train criterion even epoch bit word train set conduct detail studi attempt understand train problem perform hundr run vari number hidden unit learn rate momentum term initi random weight attempt find configur could learn singl bit level bp none run succeed run bp train converg error hand train exampl error remain train exampl contrast error bp extrem tabl show collect sevenlett window test set squar error window nine differ train run first train run bp unit train epoch next four column show run bp hiddenunit network four differ random start seed these train learn rate momentum initi random valu rang last four column show run bp hiddenunit network four differ random start seed these train learn rate momentum initi random valu rang demonstr even share hidden unit aid classif per formanc certainli aid learn process consequ train problem abl report result word train set crossvalid train bp see abov determin best network train set contain hidden unit train sumsquar error tabl summar train process output bit bp row give number hidden unit best bp network squar error obtain bp network squar error obtain bp network number epoch requir train bp notic individu bit slightli overtrain compar bp program accumul squar error epoch stop fall target error level perform improv epoch final squar error somewhat lower tabl show perform network train test set perform train set virtual ident hiddenunit id backpropag tabl comparison individu error bit window bp bp austr sot breadwi bucksaw moi cinnamo figurat lawyer muumuu pettifo ilton valu shown tabl train statist independ network bit number squar error squar error number hidden unit bp network bp network epoch tabl perform separ network compar singl network share hidden unit train word train set test word test set level aggreg correct method data set word letter phonem stress bit mean a id test b bp separ net train test c bp hidden unit train test differ bc train test gamma gamma gamma gamma differ ac test gamma gamma gamma gamma differ signific id backpropag tabl correl coeffici replic x id xbp x id xbp c averag decreas network show train regim success perform test set howev show loss perform share hidden unit among output unit henc suggest hypothesi least partial correct howev examin correl id bpcv indic wrong correl x id xbp ie bp singl network wherea correl x id xbp replic comparison time differ train test set use less rigor effici uncrossvalid train procedur tabl show result correl coeffici pair differ ttest show differ correl coeffici signific level henc remov share hidden unit actual made id bp less similar rather similar hypothesi claim conclus share backpropag import improv train perform explain id bpcv perform differ test hypothesi statist perform three experi test third hypothesi continu paramet bpcv network abl captur statist inform id fail captur first experi took output backpropag network threshold valu map valu map map nearest legal phonemestress pair threshold valu chang distanc measur output legal phonem stress pattern tabl present result word train set result show threshold significantli drop perform back propag inde phonem level decreas enough push bpcv id level aggreg bpcv still outperform id tabl perform backpropag threshold output valu train word train set test word test set level aggreg correct method data set word letter phonem stress bit mean a id legal test b bpcv legal test c bpcv threshold test differ cb test gamma gamma gamma gamma gamma differ signific id backpropag result support hypothesi continu output neural network aid perform bpcv howev threshold output bpcv caus behav substanti like id correl x id xbpcv thresh as compar xbpcv thi small increas close examin data show sevenlett window lost ie incorrectli classifi bpcv threshold includ window correctli classifi id window incorrectli classifi id henc mistak introduc threshold nearli independ mistak made id experi demonstr import continu output tell us kind inform captur continu output reveal anyth role continu weight insid network thi must turn two experi second experi modifi method use map output bit string one legal phonemestress pair instead consid possibl legal phonemestress pair restrict attent phonemestress pair observ train data specif construct list everi phonemestress pair appear train set along frequenc occurr appendix a show frequenc inform word train set test element vector produc either id bpcv map closest phonemestress pair appear list tie broken favor frequent phonemestress pair call observ decod method sensit phonemestress pair and frequenc observ train set tabl present result word train set compar previou techniqu legal decod nearest legal phonemestress pair key point notic decod method leav perform bpcv virtual unchang substanti improv perform id inde elimin substanti part differ id bpcvthe two method statist indistinguish word phonem level mooney et al compar studi id bpcv task employ version decod techniqu with random tie break obtain similar result train set word dictionari occur frequent english text examin correl coeffici show observ decod increas slightli similar id bpcv correl idobserv xbpobserv as compar legal decod ing furthermor observ decod almost alway monoton better ie window incorrectli classifi legal decod becom correctli classifi observ decod vice versa tabl show result four replic paireddiffer ttest conclud correl coeffici increas observ decod with signific level better result conclud bpcv alreadi captur inform frequenc occurr phonemestress pair tabl effect observ decod learn perform level aggreg correct method data set word letter phonem stress bit mean a id legal test b bpcv legal test c id observ test d bpcv observ test id improv ca test differ cell signific tabl correl id bpcv observ decod data set legal observ c e averag increas id backpropag id captur nearli much henc experi strongli support hypothesi drawback observ strategi never decod window phonemestress pair seen befor henc certainli make mistak test set howev phonemestress pair observ train set make small fraction window test set exampl phonemestress pair appear word test set appear word train set test set account window train word dictionari appear word test set would one phonemestress pair present test set would appear train set would appear one window final experi concern hypothesi focus extract addit statist inform train set motiv klatt view ultim lettertophonem rule need identifi exploit morphem ie commonlyoccur letter sequenc appear within word there fore analyz train data find letter sequenc length k retain b mostfrequentlyoccur sequenc length paramet b determin crossvalid describ below retain letter sequenc form list phonemestress string sequenc map train set and frequenc exampl five pronunci letter sequenc ation train set hphonem stringi hstress stringi hfrequencyi esxn sxn decod word scan from left right see contain one top b letter sequenc length l vari l k word contain sequenc letter correspond sequenc process follow first l window center letter sequenc evalu ie decis tree feedforward network obtain bit string string concaten produc bit string length l delta then observ pronunci sequenc convert l delta bit string accord code given appendix a final unknown string map nearest observ bit string decod block control skip end match lletter sequenc resum scan anoth top b letter sequenc length l scan complet part word yet match rescan look block length l gamma everi letter word eventu process everi individu letter block length call techniqu block decod dietterich hild bakiri tabl effect block decod learn perform level aggreg correct method data set word letter phonem stress bit mean a id legal test b bpcv legal test c id block test d bpcv block test id improv ca test differ cell signific agre disagre id backpropag incorrect correct incorrect correct employ crossvalid determin maximum block length k number block b store evalu differ valu train word test word crossvalid test set tri valu k valu b id peak perform attain bpcv peak perform attain case perform much sensit k b tabl show perform result word test set block decod significantli improv id bpcv again id improv much especi word level inde two method cannot distinguish statist level aggreg furthermor correl coeffici x idblock xbpblock substanti increas compar legal decod henc block decod also make perform id bpcv much similar tabl show sevenlett window test set handl id bpcv tabl show correl coeffici along four replic paireddiffer ttest conclud correl coeffici increas block decod with signific level better id backpropag tabl correl id bpcv block decod tabl classif test set window id bpcv block decod data set legal block c e averag increas note method suppli addit inform id bpcv could expect improv correl algorithm some what furthermor sourc new inform would probabl benefit poorer perform algorithm id better perform algorithm nonetheless fact block decod elimin differ id bpcv provid strong evid identifi import caus differ two method hypothesi correct experi also suggest block decod techniqu use adjunct learn algorithm appli domain discuss improv algorithm mani direct explor improv algorithm pursu sever direct order develop highperform texttospeech system effort report detail elsewher bakiri one approach design better output code phonemestress pair experi shown bch error correct code provid better output code output code use paper randomlygener bitstr produc similar perform improv see dietterich bakiri anoth approach widen sevenlett window introduc context lucassen mercer employ letter window also includ input phonem stress four letter left letter center window phonem stress obtain execut letter alreadi pronounc scan lefttoright experi with letter window indic produc substanti perform gain well howev find work better word scan righttoleft instead third techniqu improv perform suppli addit input featur program one featur letter help bit indic whether letter vowel conson featur phonem help whether phonem tens lax fourth techniqu pursu refin block decod method block chosen care consider statist confid decod consid overlap block fifth direct pursu implement buntin method obtain class probabl estim decis tree algorithm produc fairli accur probabl estim leav decis tree use estim map nearest phonemestress pair curiou know whether approach would captur statist inform provid observ block decod experi show howev observ block decod superior simpli use legal decod or even observ decod class probabl tree id backpropag tabl correct code sevenlett phonem stress context domainspecif input featur observ decod simplifi stress level aggreg correct train set word letter phonem stress bit mean word word combin errorcorrect output code wider window right toleft scan includ phonem stress context domainspecif featur obtain excel perform word train test set tabl show bestperform configur train word train word detail configur describ bakiri unabl test similar configur bpcv huge comput resourc would requir bakiri describ studi human judg compar output system output dectalk klatt lettertosound rule base result show system and two machin learn approach significantli outperform dectalk appli id aid bpcv interest observ studi perform id bpcv highli correl suggest methodolog use id aid bpcv even domain bpcv outperform id mani realworld applic induct learn substanti vocabulari engin requir order obtain high perform vocabulari engin process typic involv iter select test promis featur test featur necessari train bpcv network use themwhich timeconsum perform id correl bpcv use instead test featur set good set featur identifi bpcv network train examin idea detail consid tabl show perform id bpcv individu bit ie without decod all each algorithm train word train set test word test set hidden unit network employ bpcv correl coeffici signific well level henc conclud gener perform id good predictor gener perform bpcv dietterich hild bakiri tabl perform complex difficulti learn word train set word test set id bp id backpropag conclus rel perform id backpropag texttospeech task depend decod techniqu employ convert bit se jnowskirosenberg code phonemestress pair decod nearest legal phonemestress pair the obviou approach reveal substanti differ perform two algorithm experi investig three hypothes concern caus perform differ first hypothesisthat id overfit train datawa shown incorrect three techniqu avoid overfit appli none improv id perform second hypothesisthat abil backpropag share hidden unit factorwa shown partial correct share hidden unit improv classif perform backpropag andperhap importantlyth converg gradient descent search howev analysi kind error made id backpropag with without share hidden unit demonstr differ kind error henc elimin share hidden unit produc algorithm behav like id suggest develop share id algorithm could learn multipl concept simultan unlik produc perform similar bpcv third hypothesisthat backpropag captur statist inform mechan perhap continu output activationswa demonstr primari differ id bpcv ad ob serv decod techniqu algorithm level perform two algorithm classifi test case becom statist indistinguish at word phonem level ad block decod techniqu differ algorithm statist insignific given block decod two algorithm perform equival given bpcv much awkward appli timeconsum train result suggest task similar texttospeech task id block decod clearli algorithm choic applic bpcv id play extrem valuabl role exploratori studi determin good set featur predict difficulti learn task paper also introduc new method experiment analysi comput error correl measur effect algorithm modif shown method appli discov way algorithm relat broader applic methodolog improv understand assumpt bias underli mani induct learn algorithm dietterich hild bakiri acknowledg author thank terri sejnowski provid nettalk phonem dictionari without work would imposs correspond jude shavlik ray mooney geoffrey towel help clarifi possibl kind decod strategi discuss lorien pratt aid design crossvalid studi research support nsf grant number ccr iri presidenti young investig award match support sun microsystem r convert english text speech machin learn approach classif regress tree theori learn classif rule school comput scienc limit induct learn compar studi id backpropag english texttospeech map review texttospeech convers english inform theoret approach automat determin phonem base form explor parallel distribut process empir comparison prune method decis tree induct experiment comparison symbol connectionist learn algorithm learn effici classif procedur applic chess endgam simplifi decis tree learn intern represent error propag learn connect spell sound network model oral read parallel network learn pronounc english text advanc neural inform process system advanc neural inform process system tr ctr thoma g dietterich approxim statist test compar supervis classif learn algorithm neural comput v n p oct kang keysun choi two approach resolut word mismatch problem caus english word foreign word korean inform retriev proceed fifth intern workshop inform retriev asian languag p septemb octob hong kong china john case sanjay jain matthia ott arun sharma frank stephan robust learn aid context proceed eleventh annual confer comput learn theori p juli madison wisconsin unit state miroslav kubat robert c holt stan matwin machin learn detect oil spill satellit radar imag machin learn v n p feb march melodi y kiang compar assess classif method decis support system v n p juli rich caruana virginia r de sa benefit variabl variabl select discard journal machin learn research rich caruana multitask learn machin learn v n p juli walter daeleman antal van den bosch jakub zavrel forget except harm languag learn machin learn v n p feb sreerama k murthi automat construct decis tree data multidisciplinari survey data mine knowledg discoveri v n p decemb