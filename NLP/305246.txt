t parallel hierarch solver precondition boundari element method a method moment import tool solv boundari integr equat aris varieti applic transform physic problem dens linear system due larg number variabl associ comput requir system solv iter use method gmre cg variant core oper iter solver applic system matrix vector requir thetan oper memori use accur dens method comput complex reduc on log n memori requir thetan use hierarch approxim techniqu algorithm speedup approxim combin parallel yield fast dens solver paper present effici parallel formul dens iter solver base hierarch approxim solv potenti integr equat first kind studi impact variou paramet accuraci perform parallel solver demonstr parallel formul incur minim parallel process overhead scale larg number processor present two precondit techniqu acceler converg iter solver techniqu base innerout scheme blockdiagon scheme base truncat green function present detail experiment result processor cray td code achiev raw comput speed gflop compar accur solver correspond speed approxim gflop b introduct method moment popular method solv integr equat extens applic comput electromagnet wave propag heat transfer transform physic problem defin integr equat dens linear system integr equat term volum boundari integr equat depend whether variabl defin volum surfac model object paper address solut boundari integr equat complex d object model arbitrarili complex d object may requir larg number boundari el ement object boundari element method result dens linear system hundr thousand unknown memori comput requir solv system formid iter solut techniqu gener minim residu gmre method choic memori comput requir solver grow thetan per iter solv system k variabl manner challeng current supercomput memori requir method reduc form coeffici matrix ex plicitli addit hierarch algorithm fast multipol method fmm relat particl dynam method allow us reduc comput complex iter approxim hierarch techniqu receiv lot attent context particl simul given system n particl particl influenc everi particl system total n interact must comput howev physic system influenc particl anoth diminish distanc system possibl aggreg singl express impact sever particl anoth distant particl use approach total number interact system reduc significantli form basi hierarch method method provid systemat way aggreg entiti comput interact control overal error model algorithm base hierarch techniqu includ barneshut fast multipol appel algorithm approxim long rang interact manner reduc sequenti complex typic simul involv n particl on on log n on clearli reduc comput complex hierarch method repres signific reduct time solv system howev model hundr thousand boundari element still take inordin larg amount time convent serial comput parallel process offer tool effect speed comput enabl us solv problem larg number element increas accuraci simul incorpor higher precis approxim hierarch matvec parallel formul hierarch method involv partit domain among variou processor combin object optim commun balanc load particl densiti uniform across domain object easili met irregular distribut object hard achiev highli unstructur natur comput commu nicat singh et al warren salmon present scheme irregular distribut tri meet object present altern scheme irregular distribut improv perform earlier scheme use parallel hierarch techniqu comput dens matrixvector product studi impact variou paramet accuraci perform import aspect use iter solver solv larg system use effect precondit techniqu acceler converg use hierarch method comput matrixvector product parallel process signific implic choic precondition sinc system matrix never explicitli construct precondition must deriv hierarch domain represent furthermor precondit strategi must highli paralleliz sinc earli work rokhlin rel littl work done dens hierarch solver even serial context paper investig accuraci converg gmre solver built around parallel hierarch matrixvector product investig impact variou paramet accuraci perform propos two precondit strategi acceler converg solver precondition base innerout scheme truncat green function demonstr excel parallel effici perform solver processor cray td rest paper organ follow section present brief overview hierarch method use solv integr equat section describ parallel formul hierarch method section describ precondit techniqu section present experiment result cray td section draw conclus outlin ongo research hierarch method solv integr equat boundari element method bem solv integr equat use potenti theori method discret boundari domain panel use associ green function potenti panel repres sum contribut everi panel appli dirichlet boundari condit yield larg scale linear system equat n basi boundari discret n theta n linear system aris approach dens iter solut system requir applic system matrix vector iter process facilit fact coupl coeffici two boundari element the green function integr equat diminish function distanc r element instanc laplac equat green function r three dimens logr two dimens function decreas function distanc r allow us aggreg impact sever boundari element singl express appli constant time similar principl singl iter nbodi algorithm integr boundari element perform use gaussian quadratur nearbi element higher number gauss point use desir accuraci comput coupl coeffici distant basi function fewer gauss point may use simplest scenario far field evalu use singl gauss point assum triangular surfac element process involv comput mean basi function triangl scale area triangl comput matrixvector product manner involv follow step construct hierarch represent domain particl simul method particl inject empti domain everi time number particl subdomain exce preset constant partit eight oct manner oct tree structur comput boundari element method element center correspond particl coordin octtre therefor construct base element center node tree store extrem along x y z dimens subdomain correspond node number particl tree correspond boundari element method equal product number boundari element number gauss point far field case singl gauss point far field multipol expans comput center triangl particl coordin mean basi function scale triangl area charg in addit singl gauss point code also support three gauss point far field comput matrixvector product need comput potenti n basi function done use variant barneshut method hierarch tree travers boundari element boundari element fall within near field observ element integr perform use direct gaussian quadratur code provid support integr use gauss point near field invok base distanc sourc observ element contribut basi function observ element accru farfield contribut comput use multipol expans ff criterion barneshut method slightli modifi size subdomain defin extrem boundari element correspond node tree unlik origin barneshut method use size oct comput ff criterion parallel gmre use hierarch matrixvector product implement parallel formul restart gmre algorithm critic compon algorithm are product system matrix vector x n dot product vector distribut across processor first np element vector go processor p next np processor p on matrixvector product comput use parallel hierarch treecod parallel treecod compris two major step tree construct the hierarch represent domain tree travers start distribut panel processor processor construct local tree set node highest level tree describ exclus subdomain assign processor refer branch node processor commun branch node tree form global consist imag tree processor proce comput potenti panel assign travers tree encount node local avail two possibl scenario panel coordin commun remot processor evalu interact node commun request processor refer former function ship latter data ship parallel formul base function ship paradigm discuss advantag function ship loadbalanc techniqu effici implement costzon scheme messagepass comput node tree contain variabl store number boundari element interact comput previou matvec comput first matvec variabl sum along tree valu load node store number interact node root subtre load balanc inord travers tree assign equal load processor figur illustr parallel formul barneshut method sinc discret assum static load need balanc onc parallel formul assign boundari element and associ basi func tion processor two implic multipl processor may contribut element matrixvector product and map basi function processor may match partit assum gmre algorithm problem solv hash vector element processor design gmre partit destin processor job accru vector element ad necessari commun perform use singl alltoal person commun variabl messag size alltoal broadcast insert branch node recomput top part travers local tree need insert remot processor buffer send buffer correspond broadcast branch node processor full messag process forc comput tree construct aggreg load local tree period check pend branch node broadcast load node local tree aggreg toplevel load after thi root node processor total load w within processor domain locat node correspond load wp wp left thi determin destin point commun point use alltoal person commun insert load branch assum initi particl distribut construct local tree branch node balanc load move particl b balanc load commun particl particl a schemat parallel algorithm figur schemat parallel treecod formul load balanc techniqu precondit techniqu iter solver section present precondit techniqu iter solver sinc coeffici matrix never explicitli comput precondition must construct hierarch represent domain limit explicit represent coeffici matrix form basi two precondition innerout scheme hierarch represent domain provid us conveni approxim coeffici matrix increas accuraci matrixvector product increas number direct interact and thu runtim convers reduc accuraci reduc runtim therefor possibl visual two level scheme outer solv to desir accuraci precondit inner solv base lower resolut matrixvector product accuraci inner solv control ff criterion matrixvector product multipol degre sinc top node tree avail processor matrixvector product requir rel littl commun degre diagon domin determin method control accuraci coeffici matrix highli diagon domin as case mani applic high valu ff desir ensur minimum commun overhead howev matrix diagon domin desir use lower valu ff correspondingli lower valu multipol degre fact possibl improv accuraci inner solv increas multipol degre reduc valu ff inner solv solut converg use flexibl precondit gmre solver howev paper present precondit result constant resolut inner solv truncat green function primari drawback two level scheme inner iter still poorli condi tion diagon domin mani problem allow us approxim system truncat green function leaf node hierarch tree coeffici matrix explicitli construct assum truncat green function done use criteria similar ff criterion barneshut method follow let constant fi defin truncat spread green function boundari element travers barneshut tree appli multipol accept criteria constant fi node tree use thi determin near field boundari element correspond constant fi construct coeffici matrix correspond near field precondition comput direct invers matrix approxim solv basi function comput dotproduct specif row correspond basi function near field element number element near field control preset constant k closest k element near field use comput invers number element near field less k correspond matrix assum smaller easi see precondit strategi variant block diagon precondition simplif scheme deriv follow assum leaf node barneshut tree hold element coeffici matrix correspond element explicitli comput invers matrix use precondit solv perform precondition howev expect wors gener scheme describ abov hand comput precondition requir commun sinc data correspond node local avail paper report perform gener precondit techniqu base truncat green function and simplif experiment result object experiment studi follow ffl studi error parallel perform iter solver base hierarch matrixvector product ffl studi impact ff criterion multipol degre accuraci perform solver ffl studi impact number gauss point far field perform ffl studi precondit effect iter count solut time precondition impact parallel perform section report perform gmre solver precondit techniqu cray td processor varieti test case highli irregular geometri use evalu perform solver precondition test sphere k unknown bent plate k unknown experiment result organ three categori perform raw parallel effici solver accuraci stabil solver precondit techniqu problem runtim eff mflop runtim eff mflop pscan tabl runtim in second effici comput rate td differ problem perform matrixvector product comput intens part gmre method applic coeffici matrix vector remain dot product comput take neglig amount time therefor raw comput speed matvec good approxim overal speed solver two import aspect perform raw comput speed in term flop count parallel effici addit sinc hierarch method result signific save comput larger problem use determin comput speed dens solver not use hierarch metvec requir solv problem time present parallel runtim raw comput speed effici four differ problem instanc imposs run instanc singl processor memori requir therefor use forc evalu rate serial parallel version comput effici comput mflop rate code count number float point oper insid forc comput routin appli mac intern node use number mac forc comput determin total number float point oper execut code divid total time obtain mflop rate code tabl present runtim effici comput rate four problem valu ff paramet case degre multipol expans effici comput determin sequenti time mac forc comput sequenti time larger problem instanc project use valu effici comput code achiev peak perform gflop although may appear high must note code littl structur data access result poor cach perform furthermor divid squareroot instruct take significantli larger number processor cycl hand perform achiev hierarch code correspond gflop dens matrixvector product clearli loss accuraci accept applic use hierarch method result two order magnitud improv perform combin speedup processor parallel treecod provid power tool solv larg dens system loss parallel effici result commun overhead residu load imbal also exist minor variat raw comput rate across differ problem instanc ident runtim differ percentag mac comput near field interact farfield interact comput instanc farfield interact comput use particleseri interac tion involv evalu complex polynomi length degre multipol seri comput good local properti yield good flop count convent risc processor alpha contrast nearfield interact mac comput exhibit good data local involv divid squar root instruct result vari raw comput speed across problem instanc detail studi impact variou paramet accuraci matrixvector product present author parallel perform unprecondit gmre solver one import metric perform code time solut investig solut time differ number processor differ accuraci paramet object follow show speedup fast matvec translat scalabl solut time larg number processor studi impact ff criterion multipol degre solut time case assum desir solut reach residu norm reduc factor gamma choic reduct residu norm lower accuraci matvec may becom unstabl beyond point first set experi studi impact ff criterion solut time degre multipol expans fix parallel runtim reduc residu norm factor gamma note time present tabl the cap second therefor one miss entri tabl number use infer drawn tabl ffl case rel speedup processor around more correspond rel effici demonstr parallel solver highli scalabl ffl given number processor multipol degre increas accuraci matvec reduc ff result higher solut time lower effici former increas number interact comput near field result higher comput load loss effici processor tabl time reduc rel residu norm gamma degre multipol expans fix time second processor degre tabl time reduc rel residu norm gamma valu ff fix time second increas commun overhead increas number interact need perform lower tree sinc local avail element coordin need commun processor farther away consist observ comput matvec studi impact increas multipol degre solut time parallel perform valu ff fix multipol degre vari tabl record solut time reduc residu norm factor gamma processor expect increas multipol degre result increas solut time modulo parallel process overhead serial comput increas squar multipol degre sinc commun overhead high trend visibl parallel runtim also increas multipol degre also result better parallel effici raw comput speed commun overhead remain constant comput increas furthermor longer polynomi evalu conduc cach perform tabl lead us believ desir accuraci point identifi better use higher degre multipol oppos tighter ff criterion achiev accuraci approx accur figur rel residu norm accur approxim iter scheme accuraci gmre solver use approxim hierarch matvec sever implic iter solver import cours error solut often possibl comput accur solut due excess memori comput requir therefor difficult comput error solut howev norm axgammab good measur close current solut desir solut unfortun possibl comput sinc never explicitli assembl comput correspond approxim matvec valu match ax close say measur confid approxim solut math real solut examin norm vector iter studi stabil unprecondit gmre iter converg accuraci iter solver section demonstr possibl get nearaccur converg signific save comput time use hierarch method fix valu ff multipol degre compar reduct error norm iter tabl present log rel residu norm gmre variou degre approxim execut processor td follow infer drawn experiment data ffl iter method base hierarch matvec stabl beyond residu norm reduct gamma also illustr figur plot reduct residu norm iter accur worst case most inaccur matvec seen even worst case accuraci residu norm near agreement rel residu norm gamma mani problem accuraci adequ ffl increas accuraci matvec result closer agreement accur hierarch solver also accompani increas solut time therefor desir oper desir accuraci rang ffl parallel runtim indic hierarch method capabl yield signific save time expens slight loss accuraci iter accur time tabl converg log rel error norm runtim in second gmre solver processor cray td problem consist unknown impact number gauss point far field comput farfield interact code allow flexibl use either point gaussian quadratur singl point gaussian quadratur here investig impact comput farfield potenti use overal runtim error tabl present converg solver two case case valu ff fix multipol degre near point interact comput ident manner either case depend distanc boundari element code allow point gaussian quadratur nearfield follow infer drawn experiment result ffl use larger number gauss point yield higher accuraci also requir comput consist understand fix ff criterion comput complex increas number gauss point far field ffl singl gauss point integr farfield extrem fast adequ approxim solut iter gauss time tabl converg log rel error norm runtim in second gmre solver processor cray td problem consist unknown valu ff multipol degre unprecondit block diag innerout block diag innerout unprecondit figur rel residu norm accur approxim iter scheme perform precondit gmre section examin effect blockdiagon innerout precondit scheme fix valu ff multipol degre effect precondition judg number iter comput time reduc residu norm fix factor although certain precondition may yield excel iter count may difficult comput vice versa third perhap equal import aspect parallel process overhead incur precondition tabl present reduct error norm iter unprecondit innerout blockdiagon precondit scheme figur illustr converg two problem graphic easi see innerout scheme converg small number outer iter howev runtim fact block diagon scheme number inner iter innerout scheme rel high drawback innerout scheme sinc attempt improv condit inner solv we current investig techniqu solv thi hand sinc block diagon matrix factor onc commun overhead high block diagon precondition provid effect lightweight precondit techniqu reflect slightli higher iter count lower solut time iter unprecon innerout block diag unprecon innerout block diag time tabl rel error norm runtim in second precondit gmre solver processor cray td conclud remark paper present dens iter solver base approxim hierarch matrixvector product use solver demonstr possibl solv larg problem hundr thousand unknown extrem fast problem cannot even gener let alon solv use tradit method memori comput requir show possibl achiev scalabl high perform solver term raw comput speed parallel effici processor cray td combin improv use hierarch techniqu parallel repres speedup four order magnitud solut time reason size problem also examin effect variou accuraci paramet solut time parallel effici overal error present two precondit techniqu innerout scheme blockdiagon scheme evalu perform precondition term iter count solut time although innerout scheme requir fewer iter iter inner solv may expens hand due diagon domin mani system blockdiagon scheme provid us effect lightweight precondition treecod develop highli modular natur provid gener framework solv varieti dens linear system even serial context rel littl work done sinc initi work rokhlin promin piec work area includ best knowledg treecod present paper among first parallel multilevel solverprecondition toolkit current extend hierarch solver scatter problem electromagnet freespac green function field integr equat depend wave number incid radiat high wave number boundari discret must fine correspond larg number unknown applic hierarch method particularli suitabl desir level accuraci high r effici program manybodi simul hierarch on log n forc calcul algorithm guidelin use fast multipol method calcul rc larg object acceler molecular dynam fast multipol algorithm effici parallel formul hierarch method applic scalabl parallel formul barneshut method nbodi simul parallel matrixvector product use hierarch method parallel version fast multipol method fast algorithm particl simul field comput method moment matrix method field problem map adapt fast multipol algorithm mimd system multipol acceler precondit iter method threedimension potenti integr equat first kind rapid solut integr equat classic potenti theori rapid solut integr equat scatter theori two dimens gmre gener minim residu algorithm solv nonsymmetr linear system implement fast multipol method three dimen sion load balanc data local hierarch nbodi method fast multipol method solut use parametr geometri multilevel fast multipol algorithm solv combin field integr equat electromagnet scatter astrophys nbodi simul use hierarch tree data structur parallel hash oct tree nbodi algorithm parallel multipol method connect machin tr ctr vivek sarin ananth grama ahm sameh analyz error bound multipolebas treecod proceed acmiee confer supercomput cdrom p novemb san jose ca sreekanth r sambavaram vivek sarin ahm sameh ananth grama multipolebas precondition larg spars linear system parallel comput v n p septemb ananth y grama vivek sarin impact farfield interact perform multipolebas precondition spars linear system proceed th annual intern confer supercomput june juli malo franc hariharan sriniva aluru balasubramaniam shanker scalabl parallel fast multipol method analysi scatter perfect electr conduct surfac proceed acmiee confer supercomput p novemb baltimor maryland qian xi wang variabl order revis binari treecod journal comput physic v n p octob