t data squash empir likelihood a data squash introduc w dumouchel c volinski t johnson c cort d pregibon proceed th intern confer kdd idea scale data set smaller repres sampl instead scale algorithm larg data set report success learn model coeffici squash data paper present form data squash base empir likelihood method reweight random sampl data match certain expect valu popul comput requir rel easi convex optim also theoret basi predict produc larg gain credit score exampl empir likelihood weight also acceler rate coeffici learn also investig extent benefit translat improv accuraci consid reweight conjunct boost decis tree b introduct stapl problem data mine construct classic rule data data warehous larg becom impract train classic rule use avail data instead sampl avail data may select train instanc enterpris miner sa institut featur semma process acronym lead s stand sampl dumouchel et al introduc data squash improv upon sampl instead scale algorithm larg data set one scale data suit exist algorithm instead rel passiv sampl larg data set construct data set way make suitabl train algorithm on suppos origin data consist n pair x x vector predictor variabl variabl predict x data squash one construct much smaller data set assign weight w necessarili connect point like x x index inde valu like x might correspond x i idea train algorithm n weight much faster train n origin data point larg speed gain may expect squash data main memori outlin paper section describ data squash present version use empir likelihood weight point connect data squash numer integr varianc reduct techniqu use mont carlo simul survey sampl find empir likelihood weight reduc tractabl convex optim problem empir likelihood squash also theoret underpin predict work outlin section section describ credit score problem data valu simul distort obfusc transform variabl name data sourc hidden condenti assur remain good test case algorithm section appli logist regress small data sampl without empir likelihood reweight reweight acceler rate coecient learn section replac logist regress boost decis tree section present conclus less pleas result squash dumouchel et al though describ sort problem expect squash add valu dierent conclus could due dierenc algorithm dierenc way result assess simpli data set dierent conclud section refer madigan raghavan dumouchel nason poss ridgeway oer likelihood base form squash gear exploit userspeci statist model bradley fayyad reina goal similar dumouchel et al madigan et al instead repres data weight set point employ mixtur model element mixtur includ gaussian distribut multinomi distribut product thereof row describ earlier work direct recent cite work much ambiti bet greater comput power avail today data squash begin outlin data squash method dumouchel et al cast older method new light special case data squash notat dier somewhat origin dumouchel et al distinguish predictor respons squash defer distinct train stage allow squash data set use multipl predict problem also choos weight w averag weight train algorithm aect scale case simpl altern convent dumouchel et al choos w outlin here rst step group x vector region suggest sever way construct region simplest method point x region share valu everi discret variabl also share valu discret version everi continu variabl point region low order moment noncategor variabl comput region set point correspond weight w chosen weight moment squash data match nearli match unweight moment origin data function x pair moment within region correspond take g product power noncategor variabl multipli function one insid region zero outsid it let z weight would provid perfect match withn given enough moment region ideal weight possibl dumouchel et al minim m zm instead m larger valu lower order moment valu minim w x n scalar valu variabl like person age number children household squash data valu need match sampl valu allow go outsid rang data thu squash data may record children record children sampl squash issu data mine echo sampl two good refer sampl cochran lohr simpl random sampl cast trivial version squash let subset n distinct simpl random sampl without replac them take strati sampl popul partit strata sampl n h valu taken stratum h weight nn h nn h make hold function g indic strata regress estim use sampl theori incorpor known valu popul mean suppos n zm known form weight z zs z regress weight satisfi regress estim shown subsum stratic introduc indic variabl z regress stratic also combin sever way regress estim also wide use mont carlo simul known method control variat two gener refer bratley fox schrage ripley hesterberg good present reweight approach control variat empir likelihood squash problem regress weight take neg valu may unus train algorithm one insist w either solut els n dimension famili solut solut one might either increas n remov moment consider suppos n dimension famili solut natur pick one somehow closest equal weight empir likelihood weight maxim subject z owen describ comput weight reduc minim convex function convex domain taken dimension euclidean space splu function avail httpwwwstatstanfordeduowen comput empir likelihood weight empir likelihood provid one way pick weight w closest equal one also use distanc measur kullbackliebl distanc helling distanc w empir likelihood weight advantag comput slightli simpler altern minim euclidean distanc simpler still reduc regress weight may neg owen benet weight stratic gener regress weight advantag reduc varianc associ estim let hx function data case let simpl random sampl estim h h varianc approxim h n main error approxim multipl factor nn take virtual one data squash eect regress weight reduc varianc h n correl hx reduct factor r r proport varianc explain linear regress z show empir likelihood reduc asymptot varianc estim mean factor regress estim do train method estim mean accur often shown predict accur simplest case like linear regr sion predict construct smooth function sampl moment complic set like maximum likelihood estim paramet vector dene equationsn log estim solv equationsn log fx qin lawless show empir likelihood weight produc varianc reduct compar unweight estim extent reduct depend well z correl deriv averag baggerli show reduct hold distanc measur kullbackliebl helling diminish return better paramet estim translat directli better predict rule gener diminish return exampl consid logist regress paramet vector simplic logist regress fact accur know mean know bay rule ordinari sampl estim approach error order n weight misclass loss loss use typic on bay loss wol stork owen reason bay rule deriv respect expect misclass zero expect error approxim form b squash use approxim form b empir likelihood squash use xed list function gener expect a bay error b domin estim error regress empir likelihood squash bring small benet logist model fail hold instead take b bay error take best error rate avail within logist famili squash method dumouchel et al adjust weight also estim new valu x sinc sampl cannot quot result like empir likelihood squash suppos search x w eect match or approxim match mani function valu n similar way gauss quadratur rule adjust locat weight numer integr davi rabinowitz integr higher order polynomi one adjust weight locat match function valu possibl come closer bay error rate cours reduc bay error rate thu could reason expect error form thu expect squash variou form eectiv case bay error domin sampl approxim error particular set zero bay error may benet enorm squash expect benet reason expect better model coecient squash albeit eventu diminish gain predict accuraci order realiz gain coecient must relat quantiti correl valu g x precis vector log fx well approxim linear combin g x expect improv estim help distinguish local global featur data logist regress use global featur data reason expect featur could highli correl judici chosen global featur nearest neighbor method use local featur averag small region determin x valu reason expect one local averag correl global featur data therefor squash global featur g help nearest neighbor much improv one must consid way employ larg number local function g method like classic tree would seem priori intermedi rst split global featur data nal split made least larg tree local featur thu squash global g help rst split later one exampl data data set inspir real commerci problem problem disguis from me order preserv condenti train data row column data aris credit score problem sourc known data set transform obfusc describ below row data describ one credit case row present random order column contain one variabl respons variabl column describ bad good credit outcom respect may possibl attribut dollar valu bad good outcom dollar valu data receiv inde may exist data roughli good case although necessarili percentag good popul variabl predictor variabl describ credit histori case origin data valu transform origin valu given predictor put vector v element transform valu z v minvmaxv minv p power p chosen random independ predictor variabl miss valu remain miss transform contribut minv maxv column score variabl use predict respons construct knowledg input variabl mean unknown possibl proprietari algorithm use gener column custombuilt score serv benchmark compar perform train method miss valu origin data store miss valu interpret not avail not believ miss valu predictor valu column almost miss drop column column miss left data miss valu valu imput miss entri describ below result remain predictor prior build predict model data transform appli column predictor valu nonmiss valu replac x ij rais power p chosen among valu g valu p chosen maxim normal separ mean mean varianc pair x nonmiss x ij n yj number ij miss miss valu x p ij simpli replac imput valu idea replac miss valu one neutral possibl regard classic hand observ one imput valu logist regress rst classic method appli simpl logist regress train data contain case random order therefor simpl random sampl obtain take x rst n case weight unweight logist regress run weight make weight unweight analys ident weight chosen f g weight mean x ij match unweight mean x ij y reason choic follow simpl global classier base sole respons group condit mean varianc covari predictor reason expect condit mean carri relev inform mani predictor variabl allow use condit second moment condit moment match impos equat take weight shown figur smallest weight largest n increas weight becom nearli equal one possibl reweight data match condit moment use posit weight smallest sampl size use figur show euclidean distanc estim coecient vector full data coecient vector decreas n increas decreas faster empir likelihood weight estim term accuraci estim coecient empir likelihood weight increas eectiv sampl size roughli figur shown empir likelihood weight credit score data increas accuraci coecient estim lead increas accuraci classic diminish return figur show receiv oper characterist roc curv sever classier describ below data roc curv plot classier produc score function x predictor interpret score figur shown distanc logist regress coecient sampl point base subsampl lower line weight logist regress use empir likelihood weight function larger valu x make like point classi x threshold chosen trade error rate fals posit fals neg predict roc curv plot proport good versu proport bad decreas roc curv arc top roc curv figur correspond custom score vector suppli data solid line correspond empir likelihood weight logist regress n point line increas increas n dash line correspond unweight logist regress weight unweight roc curv same refer point describ hypothet classic rule accept good case bad one custom rule nearli good roc curv tend make perform dierenc among classier look small part reason underli probabl plot rang import distinct among real cla sier much smaller thi exampl dierenc accept good case small plot like thi like practic import despit thi clear diminish return n increas whether weight unweight logist regress case produc roc curv essenti overlap logist regress figur shown roc curv logist regress proprietari score percent good case classi good plot percent bad case classi good exampl point describ unreal set good case would accept along bad case solid curv top bottom for proprietari score empir likelihood weight logist regress sampl size dash curv top bottom unweight logist regress case curv overlap signicantli describ text case empir likelihood weight produc overlap smaller sampl perhap although coecient keep get better perform tend converg limit reason expect better squash techniqu would get logist regress good full data logist regress even smaller sampl size empir likelihood weight logist regress doe roc curv figur comput n point includ point use train but littl risk overt here sampl size n either larg compar small compar or both evid logist regress overt notic logist regress case produc roc curv much better one case boost tree logist regress fairli old classic techniqu modern classic method also make use observ weight also consid boost classic tree boost classic tree make predict combin larg number typic small classic tree extrem individu tree one split take weight sum stump produc addit model friedman a friedman b describ multipl addit regress tree mart model construct boost tree classier build earlier work friedman hasti tibshirani built turn freund schapir roc curv obtain mart use sampl size use empir likelihood weight unweight analys plot roc curv tend hard distinguish well logist regress custom method figur curv separ visual interv horizont axi rang roughli parallel cross among close curv custom mart logist mart mart mart w mart w mart w mart w tabl roc valu boost tree shown height roc curv correspond method describ text roc curv evalu horizont valu given top row tabl show numer valu roc curv valu smaller given signic place valu close given dierenc may comput signic place region weight unweigh mart model tend better larger sampl size use weight sometim help sometim hurt seem make much dierenc mart model respond global local featur data anticip weight might help global portion local one appear weight greatli acceler mart also investig boost tree use evalu copi mineset unabl obtain result better logist regress data appear benet use empir likelihood weight even boost stump which global natur discuss result empir likelihood base data squash encourag origin paper dumouchel et al outlin dierenc describ posit result might expect first base comparison primarili qualiti estim logist regress coecient like them get good result coe cient nd diminish return classic perform also compar predict probabl squash model predict probabl full data set probabl determinist function coecient show diminish return way mi classic rate do second dierenc report result local method addit global one found littl benet there area ambiti squash describ dumouchel et al might abl make big improv thirdli reason expect optimist result entir appropri one data set anoth data set need investig data set predictor use consequ abl look interact consid sampl size larg enough that reason match interact moment case data set compar total size record compar point origin motiv squash speed although much articl stress accuraci reason essenti speed gain achiev sampl squash repres gain sampl accur n diminish return suggest small n squash could much better sampl larger n practic valu disappear suggest squash use problem even one ll comput memori data one undersampl set maxim promis squash first problem near zero bay error might benet squash secondli classic one need comput score right side threshold problem one must predict numer valu eg prot versu protabl diminish return might set much later third record predictor larg n memori record mani thousand million predictor much smaller valu n memori could gain form squash final squash describ dumouchel et al might serv good data obfusc devic organ could releas squash train data set squash test set research evalu learn method without ever releas singl condenti data record acknowledg thank bruce hoadley valuabl discuss data mine jerom friedman make avail earli version mart code work support nsf grant dm dm r scale cluster algorithm larg databas guid simul second edit method numer integr nd squash addit logist regress statist view boost stochast simul tr