t effect cach prefetch busbas multiprocessor a compilerdirect cach prefetch potenti hide much high memori latenc seen current futur highperform processor howev prefetch without cost particularli sharedmemori multiprocessor prefetch neg affect bu util overal cach miss rate memori latenc data share simul effect compilerdirect prefetch algorithm run rang busbas multiprocessor show that despit high memori latenc architectur necessarili support prefetch well case actual caus perform degrad pinpoint sever problem prefetch sharedmemori architectur addit conflict miss reduct datashar traffic associ latenc multiprocessor greater sensit memori util sensit cach hit rate prefetch distanc measur effect perform solv problem architectur techniqu heurist prefetch could easili incorpor compil victim cach elimin cach conflict miss caus prefetch directmap cach special prefetch algorithm share data significantli improv abil basic prefetch algorithm prefetch individu miss compilerbas shareddata restructur elimin mani invalid miss basic prefetch algorithm predict combin effect improv make prefetch effect much wider rang memori architectur b introduct sever factor contribut increas need processor toler high memori latenc particularli multiprocessor system certainli widen gap speed cpu memori increas memori latenc uniprocessor multiprocessor alik fast processor also increas content multiproc sor lengthen actual latenc seen cpu cpu queu interconnect second parallel workload exhibit interconnect oper caus data share among processor result research support onr grant no nj nsf pyi award no mip author address depart comput scienc engin fr univers washington seattl wa delay greater memori subsystem content final processor memori becom physic distribut memori latenc necessarili increas softwarecontrol cach prefetch techniqu design make processor speed toler memori latenc softwarecontrol cach prefetch cpu execut special prefetch instruct data load point near futur best case data arriv cach need cpu cpu see load hit lockupfre cach allow cpu continu execut prefetch hide prefetch latenc cpu paper address issu prefetch busbas share memori multiprocessor goal work gaug impact perform architectur pinpoint factor respons experi simul parallel workload busbas multiprocessor coupl prefetch algorithm repres ideal current compilerdirect prefetch technolog oracl predict cach miss apart miss caus data share use identifi architectur workload prefetch improv perform perform degrad result give us insight particular problem multiprocessor pose prefetch allow us introduc chang memori subsystem prefetch algorithm share data alloc solv them although studi close model busbas system extend multiprocessor architectur memori content issu show prefetch busbas multiprocessor unlik uniprocessor need done care univers win issu increas pressur cach parallel machin greater sensit memori subsystem util interact prefetch data share effect caus perform improv prefetch less expect even nonexist basic prefetch scheme observ speedup higher degrad high address issu variou architectur compilerbas techniqu victim cach compilerbas share data restructur two special prefetch algorithm share data end result prefetch shown effect much wider rang memori architectur effect region alreadi viabl combin techniqu achiev speedup prefetch simul memori speed rang remaind paper organ follow section describ relat work compilerdirect prefetch multiprocessor prefetch section describ methodolog justifi choic simul environ section present result basic prefetch strategi use conjunct highli effici cach miss predictor highlight drawback prefetch strategi follow three section explor detail issu prevent better multiprocessor prefetch perform present architectur compil techniqu make prefetch effect section examin problem prefetch complet time section cach conflict miss caus prefetch section data share issu princip difficulti predict invalid miss section show effect combin techniqu conclus appear section relat work work build previou studi pinpoint problem prefetch share memori machin addit conflict miss data share traffic multiprocessor greater sensit memori util determin best prefetch distanc measur effect perform paper show that despit high memori latenc mani busbas multiprocessor support prefetch well case prefetch actual caus perform degrad paper extend work sever way first examin conflict miss detail use new memori architectur altern a victim cach virtual elimin caus prefetch section second present new prefetch strategi make effect use exclus prefetch in section third make use sophist share data restructur techniqu in section make prefetch viabl fourth improv methodolog previou studi sever respect exampl trace differ region pverifi applic captur parallel also model hardwar barrier accur increas accuraci shortterm share activ topopt the applic make frequent use barrier although need make processor toler high memori latenc much sever multiprocessor uniprocessor studi cach prefetch concentr uniprocessor architectur dash hardwar support cach prefetch date publish result microbenchmark throughput test noteworthi except work mowri gupta simul driven three parallel program provid analysi potenti speedup programm direct cach prefetch howev multiprocessor architectur examin sixteen dash cluster connect highthroughput interconnect network one processor per cluster avoid type content interfer wish studi result includ full effect content share bu found effect crucial prefetch perform architectur examin addit provid detail analysi multiprocessor cach miss identifi key compon affect perform scheme deal programmerdirect prefetch emul compilerdirect simul sharedmemori refer simul share privat interfer two cach key element studi mowri et al detail compilerbas prefetch algorithm uniprocessor model simul prefetch algorithm emul use sever techniqu select prefetch target memori access like miss cach simul environ prefetch studi use tracedriven simul trace gener coarsegrain explicitli parallel workload prefetch instruct insert trace simul sever type busbas multiprocessor differ extent content affect memori latenc ie vari bu speed also examin cach architectur without in section victim cach sever prefetch strategi use differ when often prefetch done section detail simul environ prefetch algorithm softwaredirect prefetch scheme either cach prefetch which bring data data cach closest processor prefetch data separ prefetch buffer prefetch studi concern cachebas prefetch baselin prefetch algorithm contain optim prefetch nonshar ie uniprocessor data miss those depend cach configur accur predict nonshar cach hit miss never prefetch data use emul algorithm ad prefetch instruct address trace gener share memori multiprocessor candid prefetch identifi run processor address stream uniprocessor cach filter mark data miss prefetch instruct place instruct stream distanc ahead access miss number cpu instruct prefetch actual access refer prefetch distanc sinc offlin algorithm techniqu repres ideal current prefetch algorithm ie one prefetch scalar array refer accur identifi lead refer first access cach line capac conflict miss mowri et al shown compil algorithm approxim well alreadi predict compulsori capac miss array refer and exist algorithm improv get closer ideal use prefetch ideal respect nonshar miss enabl us pinpoint exact caus remain miss observ cpu prefetch explain section baselin algorithm strive emul compilerbas algorithm of mowri et al best exampl rather programmerdirect approach such mowri gupta feel prefetch predominantli domain compil rather programm mowri gupta show prefetch insert programm intim familiar applic effect methodolog necessarili indic compilerdirect prefetch would do mowri et al despit target uniprocessor repres best avail compilerdirect prefetch algorithm architectur unreason expect would perform well larg number multiprocessor architectur without enhanc overhead associ prefetch simul rel low singl instruct prefetch access itself continu assum exist effect effici prefetch algorithm mowri et al report overhead uniprocessor compil algorithm typic less in increas instruct count impact total execut time typic half that mowri gupta programmerdirect scheme experienc overhead total execut time chen baer implement mowri et al compil algorithm multiprocessor includ two bench mark mpd water experienc prefetch instruct overhead total execut time simul overhead never instruct count total execut time multiprocessor writeinvalid cach coher protocol data prefetch either share mode in case subsequ write might requir extra invalid bu oper exclus mode which would caus cach copi cach line invalid latter refer exclus prefetch simul support type prefetch mowri gupta specifi otherwis howev prefetch share mode workload address trace gener mptrace sequent symmetri run follow coars grain explicitli parallel applic written c see tabl topopt perform topolog optim vlsi circuit use parallel simul anneal algorithm pverifi determin whether two boolean circuit function ident statist amount share data program found locusrout commerci qualiti vlsi standard cell router mpd solv problem involv particl flow extrem low densiti water evalu forc potenti system water molecul liquid state latter three part stanford splash benchmark which contrast two applic optim programm processor local share number dynam data data percent percent program data set data process set size refer read privat pverifi cberk kb kb million topopt aplalomim kb kb million locusrout primari mb kb million mpd molecul mb kb million water molecul kb kb million tabl workload use experi restrict practic limit trace length multiprocessor tracedriven simul balanc must struck desir larg data set fit cach trace reason portion program larg data structur one could easili end trace singl loop may may indic rest program attempt solv scale back data set local cach size singl order magnitud rel might consid reason configur current moder parallel multiprocessor thu maintain realist ratio data set offchip cach size ensur case neither critic data structur dynam cach work set fit simul cach except topopt still interest high degre write share larg number conflict miss even small share data set size applic begin collect trace right parallel execut begin initi simul without collect statist data refer avoid coldstart effect simul least million data refer applic tabl share data column give total amount share data alloc applic dynam data set size column show total amount privat share data touch trace portion program number refer simul statist kept given refer colum last two column show percent data refer read percent privat data benchmark multiprocessor simul prefetch access ad trace run charli multiprocessor simul modifi handl prefetch lockupfre cach splittransact bu protocol victim cach besid model cpu cach bu hardwar low level charli carri lock barrier synchron therefor interleav access differ processor chang behavior memori subsystem charli ensur legal interleav maintain so instanc processor vie lock may acquir order trace run still acquir legal order enter critic section one processor time model data cach assum instruct cach insignificantli low miss rate cach direct map writeback one per processor simul present kbyte simul includ privat share data order includ effect interfer two cach cach coher scheme illinoi coher protocol invalidationbas protocol import featur purpos privateclean state exclus prefetch simul deep buffer hold pend prefetch processor suffici larg almost alway prevent processor stall buffer full bu use roundrobin arbitr scheme favor block load prefetch consid system high memori latenc prefetch less use possibl harm littl latenc hide processor execut singl cycl per instruct cycl data load coupl memori subsystem latenc cycl given latenc examin spectrum memori architectur high low memori bandwidth result rang bu util memoryinterconnect model splittransact bu protocol system enough parallel memori bankscontrol make address bu memori access rel conflict free data bu transfer bottleneck vari speed data bu then vari maximum throughput memori subsystem way abl model spectrum valu ratio bu latenc bu bandwidth sinc factor mani phenomena describ sensit without vari minimum latenc thu prevent result domin larg chang memori latenc sinc effect prefetch obvious highli sensit paramet specif model splittransact bu result reflect memori architectur potenti satur also ran simul larger block size result present here add great deal insight alreadi present essenti larger block size increas amount share traffic due fals share thu increas import techniqu use deal share otherwis impact effect prefetch aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa total miss rate aa aa cpu miss rate adj cpu miss rate miss rate prefetch strategi locusrout water topopt pverifi mpd figur total cpu miss rate five workload cycl data bu latenc simul paper data transfer portion memori latenc vari cycl total cycl split transact bu architectur describ abov data transfer latenc cycl would make address transmiss memori lookup cycl processor cycl speed mhz would model memori subsystem memori latenc nanosecond peak throughput gbytessecond cycl latenc correspond memori throughput mbytessecond cycl latenc correspond transfer bit across bu everi cpu cycl also section add victim cach architectur hit victim cach take cycl longer hit main cach much less memori access save least one bu oper basic prefetch simul memori architectur basic prefetch algorithm prefetch serv baselin calcul speedup prefetch algorithm execut time experi given rel prefetch memori architectur cach configur basic prefetch algorithm prefetch instruct insert trace potenti cach miss identifi cach filter algorithm prefetch distanc instruct mean that bar cpu stall code prefetch associ load would execut cycl given processor model give memori subsystem minimum latenc cycl time complet prefetch content delay larg processor otherwis slow down thi basic prefetch strategi identifi figur pref compar basic prefetch strategi prefetch identifi np result kbyte cach byte cach line shown figur tabl effect prefetch miss rate figur terminolog becom ambigu presenc prefetch use follow term miss or total miss rate refer prefetch nonprefetch access hit cach cpu miss cpu miss rate miss nonprefetch access thu observ cpu prefetch miss occur prefetch access onli access prefetch still progress sinc cpu must stall count cpu miss refer prefetchinprogress miss often compris nonneglig portion cpu miss rate adjust cpu miss rate includ them therefor adjust cpu miss rate includ access caus cpu stall entir memori latenc cpu miss rate adjust cpu miss rate plu prefetchinprogress miss rate total miss rate cpu miss rate plu prefetch miss rate miss rate cumul figur total miss rate combin height three bar cpu miss rate combin height black diagon stripe bar without prefetch total miss rate cpu miss rate adjust cpu miss rate ident data figur cycl datatransf latenc compon miss rate vari significantli across memori throughput prefetchinprogress the differ cpu miss rate adjust cpu miss rate rise data bu get slower sever observ made miss rate result first cpu miss rate fell significantli adjust result shown figur use oracl prefetch one might naiv expect even miss cover three reason happen first prefetchinprogress miss account signific part cpu miss rate applic second prefetch actual introduc addit cach conflict miss last importantli data share among processor produc invalid miss case largest singl compon cpu miss rate oracl prefetch predict miss result invalid total miss rate increas simul prefetch previou studi uniprocessor multiprocessor focus cpu miss rate uniprocessor like memori interconnect bandwidth absorb extra memori traffic increas total miss rate signific rel decreas cpu miss rate multiprocessor system total miss rate import metric indic demand bottleneck compon machin particularli true busbas multiprocessor also multiprocessor content memori interconnect signific bu becom satur system perform track throughput bu speed cpu benefici effect sinc bu demand function total miss rate rather cpu miss rate total miss rate better indic perform architectur bu memori bottleneck system then prefetch reduc cpu miss rate expens total miss rate may hurt perform tabl see miss rate affect databu util memori architectur vari bu util number cycl bu use divid total cycl simul bu util result mislead interpret correctli two reason bu util increas one workload produc bu oper second number bu oper occur shorter time period so instanc bu util increas prefetch cycl pverifi simul total miss rate increas execut time reduc pref data transfer latenc program alg cycl cycl locu np mpd np pverifi np topopt np water np tabl select bu util workload np pref locusrout mpd pverifi topopt water tabl bu demand per access bdpa cycl data bu latenc result prefetch success overlap memori access instruct execut order see bu demand independ execut speed tabl give bu demand per access bdpa total number bu cycl use divid total number memori access both cach hit miss bdpa unlik bu util independ execut time thu give better indic addit demand place memori subsystem prefetch result tabl indic that applic bu demand increas prefetch expect given total miss rate figur data tabl cycl data transfer latenc data bu speed shown practic purpos scale linearli bu speed figur see effect prefetch execut time differ memori subsystem figur execut time prefetch bu speed normal execut time prefetch memori architectur examin tabl figur see whenev bu util greater without prefetch use prefetch result increas execut time region enough spare bu bandwidth absorb extra demand prefetch place it increas execut time bu satur dramat howev total miss rate rise small amount prefetch increasingli posit effect execut time bu load becom lighter as bu get faster gener perform improv larg two reason thi first alreadi discuss prefetch caus increas memori latenc due increas content processor bu addit overhead prefetch cpu execut time although rel small experi no execut time pref scheme summari data bu latenc data bu latenc data bu latenc data bu latenc data bu latenc rel execut time rel execut time topopt water locusrout mpd pverifi figur rel execut time five workload prefetch pref normal prefetch execut time result indic benefit prefetch busbas multiprocessor margin except case high bandwidth memori subsystem even use highli effici cach miss predictor largest gain execut time observ speedup largest degrad order gain insight much improv actual possibl prefetch look processor util without prefetch instanc averag processor util water fastest bu slowest bu sinc best memorylat hide techniqu bring processor util best speedup could achiev water hand processor util mpd rang room speedup fast bu slow bu ignor overhead prefetch instruct so mpd best speedup fall far short maximum potenti workload averag processor util without prefetch locusrout rang pverifi rang topopt topopt make use hardwar barrier much low processor util due synchron delay aaa aaaaaa aaa aaa aaaaaa aaa aaa aaaaaa aaa aaa aaaaaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa top src data nonshar prefetch aa aa nonshar prefetch invalid prefetch aa aa invalid prefetch prefetch progress number prefetch strategi mpd pverifi topopt figur sourc cpu miss mpd pverifi topopt cycl data bu latenc also note predict effect prefetch particular workload difficult workload achiev largest improv largest degrad depend upon memori subsystem architectur applic put heavi load memori system see larger memori latenc due content benefit hide latenc applic howev first enter bu satur begin degrad prefetch simul exemplifi mpd pverifi high bu util one reason result prefetch disappoint anoth larg number cpu miss despit use oracl miss predictor order understand variou sourc magnitud remain cpu miss analyz differ type cpu miss figur show breakdown cpu miss three applic topopt pverifi mpd cycl data transfer latenc miss shown fall follow categori either invalid miss the tag match state mark invalid nonshar miss thi first use data replac cach miss type either prefetch and disappear cach use prefetch the miss predict fifth type miss prefetchinprogress mean prefetch access present memori subsystem complet time cpu request data sum total five type miss the combin height five bar cpu miss rate compon total miss rate for pref prefetch miss shown here prefetch miss miss effect hidden turn hit perspect cpu prefetch access goal prefetch turn mani miss np prefetch miss possibl hope without incur mani addit cach miss use oracl predict nonshar miss allow us categor nonshar miss precis imperfect prefetch would necessarili clear whether miss caus prefetch permut memori refer pattern imperfect prefetch result observ remain signific portion nonshar cpu miss cover prefetch sinc oracl prefetch perfectli predict nonshar miss absenc prefetch remain either caus prefetch access replac data still use nonshar prefetch figur prefetch cach line replac use nonshar prefetch figur impli degre conflict prefetch data current work set signific two compon cpu miss rate particularli import repres cach miss cover prefetch also result bu access necessari without prefetch nonshar prefetch miss requir extra bu access prefetch access wast nonshar prefetch miss without prefetch access cach hit therefor remain nonshar miss repres increas demand bu due prefetch prefetchinprogress miss repres much cpu miss figur slowest data bu cycl much total contribut observ memori latenc less that howev prefetchinprogress miss latenc typic much less entir memori access latenc see section perhap conspicu result figur prefetch algorithm affect invalid miss one concern motiv studi hypothesi that increas interv cach seek hold cach line prefetch would exacerb data share problem result invalid oper invalid miss result bear pref prefetch strategi seen prefetch reduc number invalid cpu miss all clearli limit effect prefetch address invalid miss may true prefetch exacerb data share problem expos perform applic effect data share much greater extent result present far suggest three primari opportun improv multiprocessor prefetch larg number prefetchinprogress miss conflict miss and addit bu load introduc prefetch inabl hide reduc latenc due data share area investig follow section reduc prefetchinprogress miss pref prefetch distanc rel close bestcas memori latenc cycl content caus real latenc much higher howev reason mowri et al suggest use larger prefetch distanc ensur prefetch data time arriv section examin effect increas prefetch distanc instruct label prefetch strategi lpd lpd strategi want prefetch distanc high enough caus prefetchinprogress miss insignific impact execut time bu speed without necessarili remov aaa aaaaaa aaa aaa aaaaaa aaa aaa aaaaaa aaa aaa aaa aaaaaa aaa aaa aaaaaa aaa aaa aaaaaa aaa aaa pver src data aa aa aa aa aa aa aa aa aaa aaa aaa aaa aaa nonshar prefetch aaa aaa nonshar prefetch invalid prefetch aaa aaa aaa invalid prefetch prefetch progress number prefetch strategi mpd pverifi topopt figur sourc cpu miss mpd pverifi topopt long prefetch distanc strategi lpd data bu latenc cycl all lower valu prefetch distanc quit achiev thi figur present effect longer prefetch distanc individu compon miss rate figur show effect execut time figur sake consist given data bu latenc cycl prefetchinprogress miss seriou problem cycl bu number prefetchinprogress miss increas applic least factor four shown increas prefetch distanc success elimin major prefetchinprogress miss for bu speed shown virtual elimin worst case cycl bu lpd strategi elimin averag prefetchinprogress miss cost conflict miss earlier prefetch begun like replac data still use also longer prefetch data sit cach use like replac number pverifi topopt indic latter particularli critic trade prefetchinprogress miss conflict miss wise prefetchinprogress miss cheapest type miss processor wait access progress complet instead entir access time mpd exampl prefetchinprogress miss repres cpu miss cycl bu add total execut time also incur prefetchinprogress miss increas load bu prefetchinduc conflict miss repres extra bu oper as compar prefetch even mpd lpd add least number conflict miss improv execut time lpd pref result indic increas prefetch distanc point virtual prefetch complet pay off argu prefetch algorithm strive receiv prefetch data exactli time penalti cycl late small processor must stall cycl much less time full access penalti cycl earli also small chanc lose data use slight period mowri et al also studi prefetch distanc note one program degrad data bu latenc data bu latenc data bu latenc data bu latenc data bu latenc locusrout mpd water pverifi topopt rel execut time rel execut time lpd figur rel execut time long prefetch distanc strategi increas prefetch distanc manual restructur four other avoid conflict caus phenomenon inabl long prefetch distanc improv prefetch perform close tie gener problem prefetchinduc conflict miss therefor reexamin lpd strategi next section look one cach architectur design reduc conflict miss victim cach reduc conflict miss shown prefetch increas number replac miss cach due conflict current work set part futur work set prefetch result base directmap cach section investig modifi cach organ reduc magnitud conflict consequ whether improv effect prefetch order see effect altern cach organ magnitud prefetchinduc conflict simul configur addit small entri fullyassoci victim cach aa aaaa aa aa aa aa aa aa aaaa aa aa aaaa aa aaa aaaaaa aaa np pref npvict prefvict lpdvict top src data aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa np pref npvict prefvict lpdvict nonshar prefetch aaa aaa aaa nonshar prefetch invalid prefetch aaa aaa aaa invalid prefetch prefetch progress number mpd pverifi topopt prefetch strategi aaa aaaaaa aaa aaa aaa aaa aaa aaa aaaaaa aaa aa aaaa aa aa aaaa aa np pref npvict prefvict lpdvict figur sourc cpu miss mpd pverifi topopt victim cach although cach higher level associ greater one also lessen impact prefetch induc conflict chose examin victim cach seem repres less costli approach in term criticalpath cach access time size complex appear ideal suit problem prefetchinduc conflict chen show victim cach match perform way setassoci cach context hardwar prefetch test actual show line victim cach wa gener somewhat less effect way setassoci cach reduc number conflict miss suffici elimin particular problem prefetchinduc conflict section show victim cach small cach block recent replac main cach good match prefetchinduc conflict target conflict miss data recent replac cach incur prefetchinduc conflict miss number instruct time block replac cach access result conflict miss bound prefetch distanc victim cach may case requir hardwar ad way setassoci cach exampl case line victim cach requir line data tag state on order x bit byte line size bit address way setassoci cach requir one extra tag bit per cach line lru bit per set bit configur howev cach configur kbyte larger would requir increasingli storag line victim cach cachecoher multiprocessor victim cach slightli complex uniprocessor need hardwar support snoop victim cach tag victim cach distinct advantag add delay critic path cach lookup directmap cach true convent associ cach victim cach lookup occur main cach miss access victim cach take longer access main cach also tie cach longer for swap main victim cach much less costli main data bu latenc data bu latenc data bu latenc data bu latenc data bu latenc lpdvict prefvict npvict locusrout mpd water pverifi topopt rel execut time rel execut time figur execut time rel prefetch victim cach five workload victim cach memori access requir bu oper figur see victim cach inde signific impact number replac miss caus prefetch exampl pref strategi victim cach prefetchinduc conflict miss that combin prefetch nonprefetch nonshar miss repres cpu miss rate topopt cycl result strategi victim cach account cpu miss rate figur show execut time result victim cach result normal np result without victim cach result make sever observ first although still see small perform degrad prefetch much smaller without victim cach fact worst case prefvict npvict perhap small enough allow us ignor prefetch induc conflict problem architectur support appropri cach configur eg setassoci cach directmap victim cach level second observ nearli case combin effect speedup prefetch victim cach togeth greater sum individu contribut effect prefetch benefit victim cach without exampl topopt cycl bu pref provid speedup np prefvict provid speedup npvict two reason occur alreadi discuss victim cach elimin neg sideeffect prefetch the addit conflict miss previous detract potenti speedup prefetch also victim cach lower overal miss rate decreas load bu mean configur less sensit bu content effect shown limit effect prefetch exampl region without victim cach satur bu pverifi cycl case point thu saw benefit prefetch may victim cach longer bu satur would expect increas prefetch effect due victim cach would even greater real prefetch system without oracl determin potenti cach miss sinc conflict miss difficult compil identifi capac miss third observ increas prefetch distanc longer clearli harm one applic topopt lpdvict notic inferior prefvict victim cach catch addit conflict caus increas prefetch distanc one case locusrout increas prefetch distanc effect compar lpdvict prefvict effect high bu util but short satur number delay associ prefetchinprogress miss greatest case lpdvict clearli better wors prefvict perform loss due prefetchinprogress miss never great perhap import aspect result then allow compil place prefetch earlier perform prefetch less sensit exact placement prefetch cach strictli direct map allow compil much flexibl prefetch placement result line victim cach line cach found suffici elimin enough prefetchinduc conflict applic studi pref still visibl outperform lpd applic lastli observ although elimin drawback which result occasion perform degrad prefetch victim cach prefetch still provid signific speedup bu satur the bu util npvict pverifi cycl mpd cycl so although cach organ forgiv cach conflict mitig drawback prefetch memorybottleneck system prefetch still attack problem bottleneck componentthat is total number interconnectmemori oper victim cach also fail help largest singl compon cpu miss rate invalid miss dealt follow section reduc share data latenc current know avail compilerbas prefetch algorithm deal invalid miss show section simpl heurist simpler instanc data flow analysi across process recogn writeshar data blindli prefetch often prefetch write differ read recogn readmodifywrit pattern improv perform sever opportun reduc impact share traffic observ pref scheme certainli better job predict prefetch invalid miss achiev much better miss coverag clear figur current miss predictor although extrem effici predict nonshar miss inadequ predict invalid miss prefetch algorithm emul tailor uniprocessor even better algorithm appear predict invalid miss remain much difficult problem predict nonshar miss due nondeterminist natur invalid traffic investig two mechan make prefetch effect presenc data share traffic section examin better heurist prefetch invalid miss section studi effect prefetch perform compil algorithm reduc invalid miss restructur share data addit prefetch increas share traffic way obviou data shown far success prefetch write miss share data increas bu traffic even caus cpu miss caus unnecessari invalid oper section show exclus prefetch solv problem also gener problem unnecessari invalid oper prefetch invalid miss saw section figur clear limit effect prefetch invalid miss share data none tradit uniprocessorbas prefetch strategi look far success reduc less predict invalid miss largest compon cpu miss workload fact effect prefetch nonshar miss invalid miss becom critic perform applic prefetch exampl seen figur without prefetch invalid miss repres cpu miss rate mpd prefetch repres cpu miss rate adjust cpu miss rate word prefetch made applic much sensit data share problem improv coverag extern caus therefor less predict miss introduc redund prefetch cach line known writeshar redund uniprocessor sens ie issu data would resid cach invalid emul prefetch algorithm prefetch writeshar data exhibit poor tempor local under premis longer share cach line resid cach without access like invalid ran writeshar data trace line associ cach filter get firstord approxim tempor local select miss prefetch prefetch addit prefetch identifi pref strategi label pw increas prefetch instruct overhead but still less improv coverag invalid miss compil algorithm could obtain effect use mowri et al algorithm assum much smaller cach size deal data known write share aaa aaaaaa aaa aaa aaa aaa aaa aa aa aa aa aaa aaaaaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa top src data nonshar prefetch aaa aaa aaa aaa aaa aaa aaa aaa aa aa aa aa aa aa aa nonshar prefetch invalid prefetch aa aa aa invalid prefetch prefetch progress mpd pverifi topopt prefetch strategi number figur sourc cpu miss enhanc writeshar data prefetch see figur coverag invalid miss improv consider pw invalid portion cpu miss rate drop significantli on averag drop result rang bu util data transfer latenc prefetch alreadi viabl improv execut time achiev workload seen figur fastest bu cycl result allow us see benefit improv prefetch writeshar data clearli isol memori content effect architectur speedup pw rel pref rang water pverifi pref faster prefetch pw achiev speedup prefetch cpu miss rate pw lower pref one reason consist reduct cpu miss writeshar algorithm that although pw increas number prefetch significantli increas number prefetchinduc cpu conflict miss restructur share data nondeterminist behavior interprocessor share predict invalid miss multiprocessor difficult predict nonshar miss algorithm uniprocessor multiprocessor section investig extent reduc share traffic compilerbas share data restructur elimin reduc need multiprocessor specif prefetch algorithm share traffic consist true fals share amount true share inher algorithm use program fals share elimin improv processor local share data fals share occur cach line share two processor cach access differ data it one processor modifi data locat caus invalid other cach cach coher maintain cach block basi record fals share miss invalid miss caus write anoth processor word local cach line local processor access tabl duboi et al definit fals share calcul fals share lifetim cach line accur data bu latenc data bu latenc data bu latenc data bu latenc data bu latenc et data locu pw locusrout mpd water pverifi topopt rel execut time rel execut time figur execut time rel prefetch five workload enhanc writeshar data prefetch show benchmark half invalid miss could attribut fals share even splash benchmark handtun processor local although total amount fals share benchmark rather low show result byte cach line previou work demonstr fals share goe significantli larger block size algorithm present restructur share data reduc fals share techniqu promis improv overal perform purpos studi interest whether make prefetch viabl tabl figur show result prefetch strategi restructur topopt pverifi program improv less significantli alreadi optim processor local programmerbas restructur restructur program certainli run faster origin program evidenc definit use howev measur small differ definit our here rate less concern exactli much fals share exist measur mani share miss elimin total total invalid total fals workload miss rate miss rate share miss rate pverifi topopt locu mpd water tabl total invalid fals share miss rate prefetch prefetch cpu total total total workload disciplin mr mr inval mr fs mr pverifi np pref pw topopt np tabl miss rate restructur program data transfer latenc cycl decreas total miss rate pverifi decreas topopt reduct total miss rate achiev part signific reduct fals share miss rate pverifi reduct offset somewhat increas nonshar miss rate topopt increas data local achiev side effect data restructur caus nonshar miss rate also decreas use tracedriven simul difficult accur compar execut time differ trace sinc alway clear exactli fraction total execut time captur mean cannot calcul raw perform improv restructur howev measur increment perform prefetch program restructur exactli make restructur interest research sinc invalid miss shown limit factor perform prefetch strategi particularli pref figur show perform pref pw strategi appli two restructur program figur result normal execut time restructur program without prefetch despit fact restructur program less sensit memori latenc due lower total miss rate experienc gener greater improv prefetch origin program seen compar figur figur exampl pverifi cycl experi speedup pref strategi without restructur pref rel np prefrestr rel nprestr pw strategi without restructur valid assert invalid miss limit effect prefetch algorithm although prefrestr pwsrestr show improv nprestr pref pw show np program improv much signific prefrestr consequ distinct pref pw almost nonexist restructur program surpris data bu latenc data bu latenc rel execut time pverifi topopt pwsrestr prefrestr rel execut time figur execut time rel prefetch restructur program pverifi topopt appli two prefetch strategi restructur program pw algorithm restructur attempt attack problem conclud restructur effect significantli reduc invalid miss rate simpler uniprocessorbas prefetch algorithm use place one tune multiprocessor data share exclus prefetch prefetch strategi simul thu far prefetch look bu like read illinoi coher protocol line read cach exclus mode cach current hold line otherwis cach share mode read case prefetch write miss would fetch share data share mode write now like hit would requir invalid oper bu turn one bu oper read intent modifi load data invalid one oper two avoid exclus prefetch prefetch data cach exclus mode invalid copi cach migratori share where one processor time typic access cach line exclus prefetch save bu oper howev interprocessor content cach line exclus prefetch writeshar data caus mani invalid miss problem unnecessari invalid oper limit sharedmod prefetch gener problem parallel applic wrex prefetch strategi target extra invalid caus sharedmod prefetch rdex strategi also target gener problem wrex prefetch strategi expect miss write algorithm issu exclus prefetch line prefetch miss line brought cach exclus mode invalid copi cach prefetch hit cach bu oper initi even cach line share state illinoi protocol read cach line current anoth cach enter exclus state immedi differ pref wrex miss occur line share among cach figur see wrex prefetch strategi ineffect reduc execut time pref data bu latenc data bu latenc data bu latenc data bu latenc data bu latenc rdex_pw locusrout mpd water pverifi topopt rel execut time rel execut time figur execut time rel prefetch five workload exclus prefetch four five applic with topopt execut time drop primari reason write miss mani write preced short distanc read locat word specif problem unnecessari invalid oper caus prefetch write access evid one applic aggress use exclus prefetch attack gener problem unnecessari invalid unnecessari invalid oper occur readmodifywrit pattern result read miss follow write hit cach line current share anoth cach result two bu oper a share read follow invalid preced exclus prefetch write hit requir second bu oper long interven access anoth processor cach line prefetch write compil recogn readmodifywrit pattern short span instruct issu exclus prefetch lead read miss mowri gupta take advantag programmerdirect prefetch studi therefor rdex prefetch strategi modifi wrex algorithm also exclus prefetch read miss follow write word within instruct chose recogn read aa aa aa aa aa aaaa aa aa aaaa aa aa aaaa aa aa aaaa aa aaa aaa aaa aaa aaaaaa aaa aaa aaa aaaaaa aaa aaa aaa aaaaaa aaa aaa aaa aaaaaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa nonshar prefetch aaa aaa nonshar prefetch invalid prefetch aaa aaa invalid prefetch prefetch progress mpd pverifi topopt number prefetch strategi figur sourc cpu miss exclus prefetch modifywrit pattern word rather cach line felt access pattern complex would difficult compil recogn pattern cach line basi access pattern simpl eg uniform access array element result analysi word cach line would ident figur see rdex like wrex reduc miss rate surpris sinc goal elimin invalid oper which shown miss rate graph effect reduc invalid traffic seen fact execut time decreas without reduct miss rate rdex strategi significantli increas invalid miss rate either signific cost issu invalid earli term addit invalid miss guarante alway true howev exclus prefetch need done caution particular avoid interprocessor content cach line expect high workload np pref wrex rdex rdex pw locusrout mpd pverifi topopt water tabl bu demand per access cycl data bu latenc first applic prefetch paper actual decreas number bu oper rel prefetch see tabl figur bu demand improv aggress exclus prefetch strategi consequ improv execut time bu speed signific result show prefetch win even memorysatur multiprocessor data bu latenc data bu latenc data bu latenc locusrout mpd water pverifi topopt rel execut time rel execut data bu latenc data bu latenc rdex_pwsvict normal np rdex_pwsvict normal npvict pref normal np figur execut time appli rdex pw prefetch strategi system victim cach also see figur rdex strategi use conjunct pw made write share algorithm significantli effect two work well togeth two reason first exclus prefetch lower bu demand thu make pw which use bu satur effect wider rang bu speed second pw allow rdex attack compon miss respons vast major unnecessari invalid operationsinvalid miss so instanc see rdex pw provid speedup high rdex alon up pw alon combin provid speedup high pref fact five applic rdex pw notic outperform strategi even slowest memori subsystem put togeth demonstr sever architectur compilerori techniqu increas effect prefetch section want see far weve come word use techniqu togeth effect prefetch rang memori architectur applic studi figur appli sever but all techniqu particular appli combin pw rdex prefetch strategi architectur victim cach figur pref result normal np first rdex pwsvict result normal npvict allow us see overal increas effect enhanc prefetch strategi independ benefit victim cach combinationrdex pwsvict achiev speedup due prefetch much signific origin basic prefetch pref high addit perform degrad minimum speedup result indic right cach architectur care applic prefetch compil perform improv extens cover wide rang memori bandwidth and case signific third line figur show absolut perform gain achiev combin use victim cach composit prefetch algorithm appli architectur prefetch techniqu achiev speedup base architectur oppos maximum speedup slowdown much base uniprocessorstyl prefetch see then none individu solut provid dramat improv taken togeth total solut signific due fact differ techniqu attack differ aspect prefetch problem case actual synergi differ approach interpret result rememb oraclebas prefetch algorithm like underestim prefetch instruct overhead overestim abil identifi nonshar miss latter mix effectmor prefetch minim cpu miss rate also maxim bu demand due cach conflict nonetheless result give us high confid combin techniqu prefetch made profit across wide array multiprocessor memori architectur summari conclus multiprocessor system limit memori bandwidth compilerdirect prefetch algorithm guarante improv perform even success reduc cpuobserv miss rate increas load memori subsystem through prefetchinduc cach conflict unnecessari invalid oper difficulti hide invalid miss slowdown possibl perform unpredict found applic benefit prefetch applic suffer architectur vari chang bu speed also show prefetch effect reduc effect nonshar cach miss make applic sensit data share problem assort architectur compil techniqu howev drawback prefetch allevi cach design forgiv cach conflict directmap cach case addit victim cach elimin prefetchinduc conflict miss increas cpu miss rate load bu memori increas effect prefetch make applic less sensit prefetch distanc allow compil freedom prefetch placement prefetch algorithm target invalid miss well nonshar miss greatli increas coverag prefetch sharedmemori multiprocessor prefetch algorithm make effect use exclus prefetch significantli reduc number invalid oper thu reduc load memori subsystem restructur share data increas processor local and thu reduc number invalid miss effect make prefetch effect allow use simpler uniprocessorori prefetch algorithm two techniqu a victim cach architectur improv restructur share data compil algorithm shown elsewher improv perform independ prefetch also make prefetch effect appli although individu contribut one techniqu dramat combin effect sever techniqu signific combin techniqu then prefetch made viabl across much wider rang parallel applic memori subsystem architectur even memori subsystem repres bottleneck multiprocessor system acknowledg author would like thank jeanloup baer insight comment paper sever stage work review journal provid mani insight comment improv present paper tor jeremiassen provid execut trace restructur execut r softwar prefetch data prefetch highperform processor reduc memori latenc via nonblock prefetch cach perform studi softwar hardwar data prefetch scheme effici architectur loop base data preload data access microarchitectur superscalar processor compilerassist data prefetch topolog optim multipl level array logic detect elimin useless miss multiprocessor simul analysi data share share memori multiprocessor simplic versu accuraci model cach coher overhead elimin fals share techniqu inlin trace sharedmemori multiprocessor comput technolog architectur evolv interact comput perprocess summari sideeffect inform static analysi barrier synchron explicitli parallel program improv directmap cach perform addit small fullyassoci cach prefetch buffer dash proto type logic overhead perform symmetri multiprocessor system logic verif algorithm parallel implement toler latenc softwarecontrol prefetch sharedmemori multiprocessor design evalu compil algorithm prefetch splash stanford parallel applic sharedmemori share data placement optim reduc multiprocessor cach miss rate limit cach prefetch busbas multiprocessor tr logic verif algorithm parallel implement techniqu effici inlin trace sharedmemori multiprocessor lockupfre cach highperform multiprocessor softwar prefetch highbandwidth data memori system superscalar processor toler latenc softwarecontrol prefetch sharedmemori multiprocessor data access microarchitectur superscalar processor compilerassist data prefetch comput technolog architectur simplic versu accuraci model cach coher overhead reduc memori latenc via nonblock prefetch cach design evalu compil algorithm prefetch effici architectur loop base data preload detect elimin useless miss multiprocessor limit cach prefetch busbas multiprocessor perform studi softwar hardwar data prefetch scheme data prefetch highperform processor microprocessor user manual fals share spatial local multiprocessor cach dash prototyp comput perprocess summari sideeffect inform static analysi barrier synchron explicitli parallel program lockupfre instruct fetchprefetch cach organ lowoverhead coher solut multiprocessor privat cach memori splash stanford parallel applic sharedmemori simul analysi data share share memori multiprocessor ctr john mellorcrummey david whalley ken kennedi improv memori hierarchi perform irregular applic use data comput reorder intern journal parallel program v n p june aleksandar milenkov achiev high perform busbas sharedmemori multiprocessor ieee concurr v n p juli pablo ibez vctor vial jo l briz mara j garzarn character improv loadstor cachebas prefetch proceed th intern confer supercomput p juli melbourn australia john mellorcrummey david whalley ken kennedi improv memori hierarchi perform irregular applic proceed th intern confer supercomput p june rhode greec parthasarathi ranganathan vijay s pai hazim abdelshafi sarita v adv interact softwar prefetch ilp processor sharedmemori system acm sigarch comput architectur new v n p may