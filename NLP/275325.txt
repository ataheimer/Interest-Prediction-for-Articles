t compil blockabl dens matrix factor a goal lapack project provid effici portabl softwar dens numer linear algebra comput recast mani fundament dens matrix comput term call effici implement bla basic linear algebra subprogram lapack project ha larg part achiev goal unfortun effici implement bla result often machinespecif code portabl across multipl architectur without signific loss perform signific effort reoptim them articl examin wheter hand optim perform matrix factor code unnecessari and should perform compil believ better programm express algorithm machineindepend form allow compil handl machinedepend detail give algorithm portabl across architectur remov errorpron expens tediou process hand optim although current exist product compil perform loop transform discuss articl descript current research compil technolog provid prove benefici numer linear algebra commun show choleski optim automaticlali compil effici handoptim version found lapack also show qr factor may optim compil perform compar handoptim lapack version modest matrix size approach allow us conclud advent compil optim dicuss articl matrix factor may effici implement blasless form b introduct process power microprocessor supercomput increas dramat continu so time demand memori system comput increas dramat size due cost restrict typic workstat cannot use memori chip latenc bandwidth requir today processor instead main memori construct cheaper slower technolog result delay may hundr cycl singl memori access allevi memori speed problem machin architect construct hierarchi memori highest level regist smallest fastest lower level larger research support nsf grant ccr nsf grant ccr second author also support us depart energi contract defgfer weng depart comput scienc michigan technolog univers houghton mi carrcsmtuedu z mathemat comput scienc divis argonn nation laboratori argonn il lehoucqmcsanlgov httpwwwmcsanlgovhomelehoucqindexhtml slower bottom hierarchi purpos main memori typic one two level cach memori fall regist main memori cach memori faster main memori often fraction size cach memori serv buffer recent access data program the work set cach becom ineffect work set program larger size three factor consid paper lu choleski qr among frequent use numer linear algebra applic first two use solv linear system equat last typic use linear least squar problem squar matric order n three factor involv order n float point oper data need n memori locat advent vector parallel supercomput effici factor seen depend dramat upon algorithm form chosen implement studi conclud manag memori hierarchi singl import factor govern effici softwar implement comput factor motiv lapack project recast algorithm eispack linpack softwar librari block one block form algorithm restructur algorithm term matrix oper attempt minim amount data move within memori hierarchi keep arithmet unit machin occupi lapack block mani dens matrix algorithm restructur use level bla motiv basic linear algebra subprogram bla provid set commonli use vector oper programm could invok subprogram instead write code directli level bla follow matrixvector matrixmatrix oper respect often necessari high effici across broad rang high perform comput higher level bla better util underli memori hierarchi level bla respons optim higher level bla left machin vendor anoth interest parti studi investig whether compil abil block matrix factor although compil transform techniqu may appli directli bla interest draw comparison appli directli factor benefit possibl blasless linear algebra packag nearli effici lapack exampl demonstr comput best lu factor inlin approach even highli optim set bla avail deem algorithm blockabl compil automat deriv effici block algorithm for studi one found lapack correspond machineindepend point algorithm particular show lu choleski factor blockabl algo rithm unfortun qr factor household transform blockabl how ever show altern block algorithm qr deriv use compil method use lu choleski factor studi yield two major result first detail anoth paper reveal hand loop unrol perform optim level bla often unnecessari bla use hand optim requir obtain good perform particular architectur may left compil experi show that case compil automat unrol loop effect hand optim second result discuss paper reveal possibl block matrix factor automat result show block algorithm deriv compil competit lapack modest size matric on order less compilerderiv variant often superior begin present review background materi relat compil optimiza tion then describ studi applic compil analysi deriv three block algorithm lapack consid correspond point algorithm present experi compar perform handoptim lapack algorithm compil deriv algorithm attain use techniqu also briefli discuss relat approach final summar result provid draw gener conclus background transform use creat block version matrix factor correspond point version well known mathemat softwar commun section introduc fundament tool compil need perform transform automat compil optim point version matrix factor analysi array access pattern rather linear algebra depend vector parallel compil depend critic compil tool perform transform improv memori perform loop depend necessari determin legal compil transform creat block version matrix factor give partial order statement within loop nest depend exist two statement exist control flow path first statement second statement refer memori locat ffl first statement write locat second read it true depend also call flow depend ffl first statement read locat second write it antid pendenc ffl statement write locat output depend ffl statement read locat input depend depend carri loop refer sourc sink begin end depend differ iter loop depend carri outer loop loop below true depend aij aij carri iloop true depend aij aij carri jloop input depend aij aij carri iloop enhanc depend inform section analysi use describ portion array access particular refer set refer section describ common substructur array element row column diagon exampl section analysi consid follow loop declar theta section access loop would shown shade portion figur matrix factor code requir us enhanc basic depend inform portion matrix involv block updat compil use section analysi reveal portion matrix block updat section discuss detail figur section automat block dens matrix factor section show deriv block algorithm lu choleski factor use current compil technolog section analysi enhanc depend inform also show qr factor household transform blockabl how ever present performancecompetit version qr factor deriv compil lu factor lu decomposit factor nonsingular matrix product two matric l u lu l unit lower triangular matrix u upper triangular matrix factor obtain multipli matrix seri elementari lower a pivot matric use make lu factor numer stabl process first examin blockabl lu factor sinc pivot creat difficulti first show block lu factor without pivot show handl pivot pivot consid follow algorithm lu factor point algorithm refer unblock rightlook algorithm exhibit poor cach perform larg matric transform point algorithm block algorithm compil must perform stripmineandinterchang kloop transform use creat block updat a appli transform first strip kloop fix size section thi size depend upon target architectur cach characterist beyond scope paper shown below ks machinedepend strip size relat cach size complet transform kkloop must distribut around loop surround statement around loop nest surround statement interchang innermost posit loop surround statement distribut yield unfortun loop longer correct loop scale number valu updat them depend analysi allow compil detect avoid chang semant recogn depend cycl aikk statement aij statement carri kkloop use basic depend analysi onli appear compil would prevent block lu factor due cycl howev enhanc depend analysi section inform reveal cycl exist portion data access statement figur show section array access entir execut kkloop section access aikk statement subset section access aij statement sinc recurr exist portion iter space loop surround statement split jloop two loop one loop iter portion depend cycl exist one loop iter portion cycl exist use transform call indexset split j split point creat two loop shown below figur section lu factor depend cycl exist statement statement longer cycl stripmineandinterchang continu distribut kkloop around two new loop shown below finish stripmineandinterchang need move kkloop innermost posit nest surround statement howev lower bound iloop contain refer kk creat triangular iter space shown figur interchang kk loop intersect line ikk iter space point kk must handl therefor interchang loop requir kkloop iter trapezoid region upper bound i i kk see wolf carr kennedi detail transform nonrectangular loop nest give follow loop nest kk figur iter space lu factor point rightlook block algorithm obtain therefor lu factor blockabl loop nest surround statement matrixmatrix multipli optim depend upon architectur superscalar architectur whose perform bound cach outer loop unrol nonrectangular loop appli j iloop improv perform vector architectur differ loop optim strategi may benefici mani transform use obtain block version lu factor well known compil commun exist mani commerci compil eg hp dec sgi one contribut studi compil research show addit section analysi allow compil block matrix factor note none aforement compil use section analysi purpos ad partial pivot although compil discov potenti block lu decomposit without pivot use indexset split section analysi cannot said partial pivot ad see figur lu decomposit partial pivot partial pivot algorithm new recurr exist fit form handl indexset split consid follow section code appli indexset split algorithm figur refer aimaxj statement refer aij statement access section distribut kkloop around jloop would convert true depend aij aimaxj antidepend revers direct rule preserv data depend prohibit revers depend direct would seem preclud exist block analogu similar nonpivot case howev block algorithm ignor prevent recurr distribut kkloop still mathemat deriv consid follow gammam result show postpon applic elimin applic permut matrix p also permut row elimin extend equat entir formul implement block algorithm p cannot comput step point algorithm p depend upon first column a allow comput k p s block factor block applic c pick pivot imax figur lu decomposit partial pivot instal result compil examin implic data depend viewpoint point version row interchang follow wholecolumn updat row element updat independ block version multipl row interchang may occur particular column updat comput column updat perform point block version comput may occur differ locat row array key concept compil understand row interchang wholecolumn updat commut oper data depend alon suffici understand thi data depend relat map valu memori locat reveal sequenc valu pass particular locat block version lu decomposit sequenc valu pass locat differ point version although final valu ident unless compil understand row interchang column updat commut lu decomposit partial pivot blockabl fortun compil equip understand oper whole column commut row permut upgrad compil one would instal pattern match recogn row permut wholecolumn updat prove recurr involv statement indexset split code could ignor form pattern match alreadi done commerci avail compil vector compil pattern match special comput search vector particular condit preprocessor pattern match recogn matrix multipl and turn output predetermin solut optim particular machin so reason believ pivot recogn implement commerci compil import emphas choleski factor matrix symmetr posit definit lu factor may written diagon matrix consist main diagon u decomposit product triangular matrix transpos call choleski factor thu need work lower triangular half essenti depend analysi appli lu factor without pivot may use note respect float point comput choleski factor differ lu two regard first n squar root choleski second lower half matrix need updat strip mine version choleski factor shown below case lu factor recurr aij statement aikk statement carri kkloop data access pattern choleski factor ident lu factor see figur indexset split appli jloop kk allow kkloop distribut achiev lapack block algorithm qr factor section examin blockabl qr factor first show algorithm lapack blockabl then give altern algorithm blockabl lapack version lapack point algorithm comput qr factor consist form sequenc initi matrix row n column studi assum n elementari reflector updat k order first k column k form upper triangular matrix updat accomplish perform matrix vector multipl w follow rank one updat effici implement level bla subroutin determin rate factor comput detail discuss qr factor see book golub van loan lapack block qr factor attempt recast algorithm term call level bla level bla handtun particular architectur block qr algorithm may perform significantli better point version larg matrix size those caus work set much larger cach size unfortun block qr algorithm lapack automat deriv compil block applic number elementari reflector involv comput storag exist origin point algorithm block number elimin togeth follow comput compil cannot deriv gamma v tv origin point algorithm use depend infor mation illustr consid block two elementari reflector comput matrix part origin algorithm henc lapack version block qr factor differ algorithm point version rather reshap point algorithm better perform compil reshap algorithm but cannot deriv new algorithm data depend inform case compil would need understand linear algebra deriv block algorithm next section compilerderiv block algorithm qr factor present algorithm give compar perform lapack version small matric retain machin independ compilerderiv qr factor consid applic j matric v k k compil deriv algorithm henceforth call cdqr form column k k kj updat remaind matrix j elementari reflector final updat trail column rich float point oper compil organ best suit underli hardwar code optim techniqu stripmin andinterchang unrollandjam left compil deriv algorithm depend upon compil effici contrast lapack algorithm depend hand optim bla cdqr obtain point algorithm qr decomposit use array section analysi refer segment code point algorithm strip mine outer loop shown figur complet transform code figur obtain cdqr iloop must distribut around loop surround comput v around updat interchang jloop howev recurr definit use akj within updat section definit use aji comput recurr carri iloop appear prevent distribut gener elementari reflector vi enddo updat aimin vi enddo enddo enddo enddo enddo figur stripmin point qr decomposit ii ii figur region access qr decomposit figur show section array a access entir execut iloop section access aji akj examin legal partial distribut iloop reveal note similar lu choleski factor section access aji the black region subset section access akj both black gray region indexset j split point creat new loop execut iter space memori locat access akj disjoint access aji new loop iter disjoint region optim compil depend upon target architectur comparison two qr factor algorithm cdqr exhibit much cach reus lapack version larg matric reason lapack algorithm abl take advantag level bla routin dgemm highli optim cdqr use oper closer level bla wors cach reus characterist therefor would expect lapack algorithm perform better larger matric could possibl take advantag highli tune matrixmatrix multipli kernel summari transform summari tabl list analys transform must use compil block matrix factor item discuss section item discuss section item discuss compil literatur item discuss section mani commerci compil eg ibm hp dec sgi contain item howev note item like found today commerci compil tabl summari compil transform necessari block matrix factor depend analysi section array section analysi section stripmineandinterchang section unrollandjam section measur perform block factor algorithm four differ architectur ibm power model hp model dec alpha sgi model indigo mip r tabl summar characterist machin architectur chosen repres typic highperform workstat tabl machin characterist machin clock speed peak mflop cach size associ line size dec alpha mhz kb machin use vendor optim bla exampl ibm power sgi indigo link librari lessl engin scientif subroutin librari lbla respect compileroptim version obtain hand use algorithm literatur reason process could fulli autom current defici depend analyz tool tabl list fortran compil flag use compil factor tabl fortran compil switch machin compil flag hp f v o dec alpha f v o sgi indigo f v o mip tabl perform report doubl precis megaflop number float point oper lu qr choleski factor n respect n number row column respect use lapack subroutin dgetrfdgeqrf dpotrf lu qr choleski factor respect factor routin run block size tabl column interpret follow lablk best block factor lapack algorithm lamf best megaflop rate lapack algorithm correspond lablk cblk best block factor compilerderiv algorithm cmf best megaflop rate compilerderiv algorithm correspond cblk order explicitli set block size lapack factor modifi lapack integ function ilaenv includ common block benchmark run comput system free comput intens job benchmark typic run two time differ time within lu factor tabl show perform compilerderiv version lu factor pivot versu lapack version tabl lu perform ibm hp dec sgi size lablk lamf cblk cmf speedup labk lamf cblk cmf speedup x x x dec alpha sgi indigo size lablk lamf cblk cmf speedup labk lamf cblk cmf speedup x x x x although compil effect choos block factor automat implement avail algorithm ibm power result show size matrix increas compil deriv algorithm edg lapack diminish remain matrix size compil deriv algorithm stay within lapack one clearli fortran compil ibm power abl nearli achiev perform hand optim bla avail essl librari block matrix factor hp tabl indic unexpect trend compilerderiv version perform better matrix size except x dramat improv matrix size increas indic handoptim dgemm effici use cach optim cach perform compil deriv algorithm evid size matric exce size cach signific perform degrad x case interest matrix small cach perform factor believ perform differ come way code gener superscalar architectur like hp code gener scheme call softwar pipelin use gener highli parallel code howev softwar pipelin requir lot regist success code perform unrollandjam improv cach perform howev unrollandjam significantli increas regist pressur caus softwar pipelin fail version lu decomposit hp compil diagnost reveal softwar pipelin fail main comput loop due high regist pressur given handoptim version highli softwar pipelin result would highli parallel handoptim loop notasparallel compilerderiv loop matrix size x enough loop iter expos differ matrix size x differ signific matrix size x greater cach perform becom factor time known compil algorithm deal tradeoff unrollandjam softwar pipelin import area futur research dec alpha tabl show algorithm perform well better lapack version matric order less size x secondlevel cach alpha k begin overflow compilerderiv version block multipl level cach lapack version block level cach thu compil deriv algorithm suffer mani cach miss level cach lapack version possibl compil perform extra block multipl level cach know compil current thi addit bla algorithm util follow architectur featur ffl use temporari array elimin conflict level directmap cach translat lookasid buffer ffl use memoryprefetch featur alpha hide latenc cach memori although optim could done dec product compil not optim would give addit perform algorithm use temporari buffer may provid small improv prefetch provid signific perform improv latenc main memori order cycl prefetch cannot issu sourc code unabl tri optim result sgi roughli similar dec alpha difficult us determin exactli perform lower smaller matric diagnost tool could softwar pipelin architectur featur awar note code gener sgi compil wors expect addit level cach come play larger matric compar result ibm power multilevel cach hierarchi system dec sgi show compilerderiv version effect singlelevel cach evid work need done optim updat portion factor obtain rel perform singlelevel cach system multilevel cach system choleski factor tabl show perform compilerderiv version choleski factor versu version ibm power result show size matrix increas compil deriv algorithm edg lapack diminish remain matrix size compil deriv algorithm stay within lapack one case lu factor compil version perform well larg matrix size highli tune bla use lapack factor caus lapack faster tabl show slightli irregular pattern block size use compil deriv algorithm remark matrix size mflop rate two block size nearli equival hp observ pattern lu factor cach perform critic outperform lapack version cach perform critic lapack version give better result except matrix small algorithm perform much better x matrix like due high overhead associ softwar pipelin short loop sinc choleski factor fewer oper lu factor updat portion code would expect high overhead associ small matric also effect cach seen larger matrix size compar lu factor due smaller updat portion factor tabl choleski perform ibm hp dec sgi size lablk lamf cblk cmf speedup lablk lamf cblk cmf speedup x x x x dec outperform lapack version x matrix pattern seen lu factor except take longer appear due smaller size updat portion factor result sgi show compil deriv version perform better lapack matrix size matrix size increas compil deriv algorithm perform decreas compar lapack factor believ level cach hierarchi final remark although tabl show similar pattern tabl differ recal explain x choleski factor approxim half float point oper lu sinc neglect strict abov diagon upper triangular portion matrix updat phase moreov comput squar root diagon element n iter qr factor tabl show perform compilerderiv version qr factor versu lapack version sinc compilerderiv algorithm block qr factor wors cach perform lapack algorithm on less comput expect wors perform cach perform becom critic plain word lapack algorithm use level bla matrix multipli kernel dgemm compil deriv algorithm util oper similar level bla hp see pattern befor howev sinc cach perform algorithm good lapack version see much smaller improv algorithm superior perform again also see matrix size stay within limit cach lapack outperform algorithm tabl qr perform ibm hp size lablk lamf cblk cmf speedup lablk lamf cblk cmf speedup x three machin see pattern previou factor except degrad much larger larg matric again due inferior cach perform cdqr interest trend reveal tabl ibm power slightli irregular block size pattern matrix size increas remark matrix size less equal interest behavior first two matrix size optim block size larger dimens matrix impli block perform level bla use lapack algorithm matrix size rate achiev lapack algorithm block size within unblock factor relat work briefli review summar investig parallel our evid activ amount work remov substanti hand code associ effici dens linear algebra comput block gemm base approach sinc lapack depend upon set highli tune bla effici remain practic question optim discuss introduct effici set bla requir nontrivi effort softwar engin see discuss softwar effort provid optim implement level bla approach effici practic gemmbas one propos kagstrom ling van loan recent studi approach advoc optim gener matrix multipli add kernel gemm rewrit remaind level bla term call kernel benefit approach kernel need optim whether hand compil thorough analysi highlight mani issu must consid attempt construct set highli tune bla moreov provid high qualiti implement bla gener use well perform evalu benchmark emphas studi examin whether necessari optim may left compil and also whether appli directli matrix factor themselv beyond abil compil recast level bla term call gemm phipac anoth recent approach methodolog express develop portabl highperform matrixvector libari ansi c phipac project motiv mani reason outlin introduct major differ approach make parallel studi gemm base approach seek support bla aim effici vendor suppli bla howev unlik studi gemm one phipac assum ansi c program languag variou c semant phipac instead seek provid parameter gener produc optim code see report discuss inhibitor c prevent optim compil gener effici code autoblock matrix multipl fren wise present altern algorithm matrixmatrix multipli base upon quadtre represent matric solut recurs suffer lack interprocedur optim commerci compil result show page becom problem sgi multiprocessor system quadtre algorithm superior perform bla smaller problem quadtre algorithm inferior perform relat work could expect compil replac bla quadtre approach appropri chang algorithm rather reshap addit special storag layout use fren wise call question effect entir program summari set determin whether compil automat restructur matrix factor well enough avoid need hand optim end examin collect implement lapack program determin whether plausibl compil technolog could succeed obtain block version point algorithm result studi encourag demonstr exist implement compil method automat block matrix factor code achiev algorithm competit lapack result show modests matric advanc microprocessor compilerderiv variant often superior matrix size typic workstat given futur machin design certain increasingli complex memori hierarchi compil need adopt increasingli sophist memorymanag strategi programm remain free concentr program logic given potenti perform attain automat techniqu believ possibl user express machineindepend point matrix factor algorithm without bla still get good perform compil adopt enhanc alreadi exist method acknowledg ken kennedi richard hanson provid origin motiv work ken kennedi keith cooper danni sorensen provid financi support research begun rice univers also wish thank toma lofgren john pieper dec help obtain dxml librari diagnos compil perform respect also thank per ling univers umea ken stanley univers california berkeley help benchmark discuss r automat translat fortran program vector form portabl parallel program environ analysi interprocedur side effect parallel program environ improv softwar pipelin unrollandjam compil blockabl numer algorithm improv ratio memori oper floatingpoint oper loop tile size select use cach organ set level basic linear algebra subprogram extend set fortran basic linear algebra subprogram solv linear system vector share memori comput solv linear system vector sharedmemori comput implement linear algebra algorithm dens matric vector pipelin machin parallel algorithm dens linear algebra comput practic depend test matrix comput implement interprocedur bound regular section analysi structur comput comput volum softwar pipelin effect schedul techniqu vliw machin cach perform optim block algorithm basic linear algebra subprogram fortran usag implement effici portabl dens matrix factor compar studi automat vector compil introduct parallel vector solut linear system regist alloc softwar pipelin loop automat select high order transform ibm xl fortran compil data local optim algorithm advanc loop interchang iter space tile memori hierarchi tr automat translat fortran program vector form extend set fortran basic linear algebra subprogram softwar pipelin effect schedul techniqu vliw machin introduct parallel myampersandamp vector solut linear system analysi interprocedur side effect parallel program environ parallel algorithm dens linear algebra comput set level basic linear algebra subprogram cach perform optim block algorithm practic depend test data local optim algorithm regist alloc softwar pipelin loop compil blockabl numer algorithm memoryhierarchi manag improv ratio memori oper floatingpoint oper loop tile size select use cach organ data layout matrix comput rd ed autoblock matrixmultipl track bla perform sourc code automat select highord transform ibm xl fortran compil basic linear algebra subprogram fortran usag solv linear system vector share memori comput structur comput comput implement interprocedur bound regular section analysi iter space tile memori hierarchi implement effici portabl dens matrix factor improv softwar pipelin unrollandjam ctr mahmut kandemir j ramanujam alok choudhari improv cach local combin loop data transform ieee transact comput v n p februari nikolay mateev vijay menon keshav pingali fractal symbol analysi proceed th intern confer supercomput p june sorrento itali kgstrm per ling charl van loan gemmbas level bla highperform model implement perform evalu benchmark acm transact mathemat softwar tom v n p sept steve carr soner nder case workingsetbas memori hierarchi proceed nd confer comput frontier may ischia itali jeremi d fren david s wise autoblock matrixmultipl track bla perform sourc code acm sigplan notic v n p juli qing yi vikram adv ken kennedi transform loop recurs multilevel memori hierarchi acm sigplan notic v n p may qing yi ken kennedi haihang keith seymour jack dongarra automat block qr lu factor local proceed workshop memori system perform june washington dc vijay menon keshav pingali nikolay mateev fractal symbol analysi acm transact program languag system topla v n p novemb qing yi ken kennedi vikram adv transform complex loop nest local journal supercomput v n p march