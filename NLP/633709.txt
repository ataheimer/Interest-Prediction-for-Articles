t featur select neural network a present neural network base approach identifi salient featur classif feedforward neural network approach involv neural network train augment crossentropi error function augment error function forc neural network keep low deriv transfer function neuron learn classif task approach reduc output sensit input chang featur select base reaction crossvalid data set classif error due remov individu featur demonstr use propos approach one artifici three realworld classif problem compar approach five featur select method bank differ concept algorithm develop outperform method achiev higher classif accuraci problem test b introduct learn system primari sourc inform data numer system like neural network nn data usual repres vector subspac r k whose compon featur may correspond exampl measur perform physic system inform gather observ phenomenon usual featur equal inform may noisi meaningless correl irrelev task featur select aim select subset featur relev given problem often import issu amount data gather process may reduc train may easier better estim obtain use relev featur case small data set sophist process method may use smaller dimension space origin measur space perform may increas non relev inform interfer etc featur select subject intens research statist applic domain like pattern recognit process identif time seri model econometr recent began investig machin learn commun develop method whatev domain is featur select remain difficult problem time non monoton problem ie best subset p variabl alway contain best subset q variabl q p also best subset variabl depend model use process data usual two step treat sequenti method variabl select reli heurist perform limit explor whole set variabl combin field nn featur select studi last ten year classic well origin method employ discuss problem featur select specif nn review origin method develop field certainli exhaust sinc literatur domain alreadi import main idea propos describ describ section basic ingredi featur select method notat briefli present section statist method use regress classif use baselin techniqu describ section famili method develop specif neural network may easili implement either regress classif task repres method compar differ test problem section basic ingredi featur select method featur select techniqu typic requir follow ingredi featur evalu criterion compar variabl subset use select one subset search procedur explor subspac possibl variabl combin stop criterion model select strategi featur evalu depend task eg predict classif model linear logist neural network sever evalu criteria base either statist ground heurist propos measur import variabl subset classif classic criteria use probabilist distanc entropi measur often replac practic simpl interclass distanc measur regress classic candid predict error measur survey classic statist method may found thomson regress mclachlan classif method reli data comput relev variabl take consider model use process data select step may reli hypothesi data distribut parametr method non parametr method method take account simultan model data usual case nn variabl select search gener sinc evalu criteria non monoton comparison featur subset amount combinatori problem there k possibl subset k variabl rapidli becom comput unfeas even moder input size branch bound explor narendra fukunaga allow reduc search monoton criteria howev complex procedur still prohibit case due limit algorithm base upon heurist perform measur evalu suboptim search suboptim search method follow one follow sequenti search techniqu see eg kittler start empti set variabl add variabl alreadi select variabl set forward method start full set variabl elimin variabl select variabl set backward method start empti set altern forward backward step stepwis method plu l take away r algorithm generalis basic stepwis method altern l forward select r backward delet subset select stop criterion let given featur subset evalu criterion search procedur sever method examin subset provid search eg k exhaust search k simpl backward search select relev accord evalu criterion empir distribut evalu measur relat statist known test may perform irrelev hypothesi input variabl classic sequenti select procedur use stop criterion examin variabl sequenti stop soon variabl found irrelev accord statist test classic parametr method distribut characterist eg estim evalu measur varianc easili deriv see section non parametr flexibl method like nn distribut difficult obtain confid interv would allow perform signific test might comput via mont carlo simul bootstrap extrem prohibit practic use except particular case eg baxt white hypothesi test thu seldom use model mani author use instead heurist stop criteria better methodolog whose complex still reason applic comput success variabl subset provid search algorithm estim gener error or predict risk obtain subset select variabl give best perform gener error estim may comput use valid set crossvalid algebra method although latter easi obtain non linear model note strategi involv retrain nn subset notat denot k g realiz random variabl pair xy probabl distribut p x th compon x x l l th pattern given data set cardin n follow restrict one hidden layer nn number input output unit denot respect k g transfer function network denot f train perform accord mean squar error criterion mse although restrict consid select method classif regress task model independ featur select introduc method perform select classif regress step sequenti ie take account classif regress model select method nn orient use experiment comparison nn specif select techniqu section first two basic statist techniqu aim respect regress classif method well fit nn sinc hypothesi reli correspond situat nn might use howev sinc nn specif method heurist use baselin comparison third one develop recent gener select techniqu data hypothesi free might use system either regress classif base probabilist depend measur two set variabl featur select linear regress consid linear regress approach describ may trivial extend multipl regress let x x x k real variabl suppos center let us denot current approxim p select variabl the x renumb p first select variabl correspond number p residu x assum ident independ distribut let us denot l l forward select choic p th variabl usual base r p partial correl coeffici tabl regressor f p adjust coeffici coeffici repres proport total varianc explain regressor f p p th variabl select one f p maxim coeffici import new variabl usual measur via fisher test thompson compar model p p variabl fsp forward tabl select stop adjust coeffici r often use instead r p fsp forward fnpa fisher statist np degre freedom confid level a choic stop y l n backward ssr l tabl choic stop criteria use statist forward backward method note f could also use place r p choic criterion forward p variabl alreadi select r p constant valu maxim f similar maxim r p equat select variabl order r p doe backward elimin variabl elimin remain p less signific term fisher test ie one smallest valu ssr p equival fsp backward tabl select stop backward fnpa featur select classif classif shall select variabl subset allow best separ data variabl select usual perform consid class separ criterion choic criterion associ ftest stop criterion regress forward backward stepwis method may use data separ usual comput interclass distanc measur kittler frequent discrimin measur wilk lambda wilk l sv p defin follow w intraclass matrix dispers correspond select variabl set sv p b correspond interclass matrix m determin matrix m determin covari matrix measur volum occupi data w measur mean volum differ class wb volum whole data set quantiti comput select variabl good discrimin power correspond small valu l sv p differ class repres compact cluster well separ criterion well suit case multinorm distribut equal covari class meaningless eg multimod distribut clearli restrict hypothesi measur statist f defin below fgngpa distribut mclachlan use wilk lambda estim discrimin power variabl stop select forward backward habbema herman stepwis method comparison section use stepdisc stepwis method base confid level mutual inform data consid realiz random process probabilist inform measur may use order comput relev set two quantiti defin x l class j g number class n j number sampl class j j mean class j global mean variabl respect variabl mutual inform measur defin as ab b two variabl probabl densiti pa pb mutual inform independ invers differenti transform variabl measur uncertainti reduct b known also known kullbakleibl distanc joint distribut pab margin distribut product papb method describ make use restrict assumpt data therefor gener attract one describ section especi hypothesi correspond data process model usual case nn may use either regress discrimin hand non parametr method comput intens main practic difficulti estim joint densiti pab margin densiti pa pb non parametr densiti estim method costli high dimens necessit larg amount data algorithm present use shannon entropi denot h comput mutual inform possibl use entropi measur like quadrat cubic entropi kittler battiti propos use mutual inform forward select algorithm call mif mutual inform base featur select pab estim fraser algorithm fraser swinney recurs partit space use c test data distribut algorithm comput mutual inform two variabl order comput mutual inform x p select variabl set sv p belong sv p battiti use simplifi assumpt moreov number variabl select fix select algorithm use forward search variabl x p one maximis valu sv p set p alreadi select variabl bonnland weigend use epanechnikov kernel densiti estim hrdle branchbound bb algorithm search narendra fukunaga bb warrant optim search criterion use monoton less comput intens exhaust search search algorithm one also consid suboptim float search techniqu propos pudil et al offer good compromis sequenti method simplic rel comput cost branchbound algorithm comparison section use epanechnikov kernel densiti estim forward search select stop mi increas fall fix threshold model depend featur select neural network model depend featur select attempt perform simultan select process data featur select process part train process featur sought optim model select criterion global optim look attract modelindepend select adequaci two step user howev sinc valu choic criterion depend model paramet might necessari train nn differ set variabl select procedur altern variabl select retrain model paramet forbid use sophist search strategi would comput prohibit specif nn also taken consider deriv featur select algorithm nn usual non linear model sinc mani parametr modelindepend techniqu base hypothesi inputoutput variabl depend linear input variabl redund well measur linear correl variabl method clearli ill fit nn search space usual mani local minima relev measur depend minimum nn converg to measur averag sever run applic prohibit consid here except white deriv result weight distribut work nn commun might use hypothesi test nn featur select algorithm choic criteria mainli base heurist individu featur evalu function sever propos literatur made attempt classifi accord similar distinguish between zero order method use network paramet valu first order method use first deriv network paramet second order method use second deriv network paramet featur evalu criteria allow rank variabl given time valu criterion non inform howev see method work reason well featur select method neural network use mostli backward search although forward method also propos moodi goutt sever method use individu evalu featur rank take consider depend correl may problemat select minim relev set variabl use correl simpl depend measur enough sinc nn captur non linear relationship variabl hand measur non linear depend trivial author simpli ignor problem other propos select one variabl time retrain network new select set evalu relev remain variabl allow take account depend network discov among variabl critic difficulti defin sound stop criterion model choic mani method use crude techniqu stop select eg threshold choic criterion valu rank differ subset use estim gener error latter expect error perform futur data defin as case rxi euclidean error desir comput output estim comput use valid set crossvalid algebra approxim risk like final predict sever estim propos statist gustafson hajlmarsson nn moodi larsen hansen literatur comparison section use simpl threshold author gave indic stop criterion valid set approxim risk otherwis zero order method linear regress model partial correl coeffici express simpl function weight although sound non linear model attempt use input weight valu comput variabl relev observ ineffici heurist weight cannot easili interpret model sophist heurist propos yacoub bennani exploit weight valu network structur multilay perceptron deriv follow criterion i h denot respect input hidden output layer better understand measur let us suppos hidden output unit incom weight vector unitari l norm equat written as inner term product weight input hidden unit j j output o import variabl output sum absolut valu product path in nn unit unit o import variabl defin sum valu output denomin oper normal factor import use squash function sinc function limit effect weight magnitud note measur depend magnitud input differ variabl similar rang two weight layer differ role mlp reflect exampl output linear normal suppress inner summat use backward search nn retrain variabl delet stop criterion base evolut perform valid set elimin stop soon perform decreas first order method sever method propos evalu relev variabl deriv error output respect variabl evalu criteria easi comput lead similar result deriv measur local chang output wrt given input input fix sinc deriv constant like linear model must averag train set measur fulli meaning input independ sinc measur averag local sensit valu train set repres input space salienc base prune sbp backward method moodi utan use evalu criterion variat learn error variabl x replac empir mean sinc variabl assum center mse x l l l l l direct measur use variabl comput output larg valu n comput costli linear approxim may use f x l l l l l x variabl elimin increas order featur set nn train estim gener error gener final predict error criterion comput model minimum gener error select chang mse ambigu input correl variabl relev comput here method take account possibl correl variabl relev could comput success nn sequenc comput extracost ok comput instead ok present method method use comput output deriv linear model output deriv wrt input constant case non linear nn sever author propos measur sensit network transfer function respect input x comput mean valu output deriv respect x whole train set case multilay perceptron deriv comput progress learn hashem sinc deriv may take posit neg valu may compens produc averag near zero measur use averag squar absolut deriv tenth measur base deriv propos mani other could defin thu give repres sampl measur sum deriv absolut valu use eg ruck et al l classif priddi et al remark sinc error decis j x may estim f j x may interpret absolut valu error probabl deriv averag decis output data squar deriv may use instead absolut valu refen et al exampl propos regress normal sum x f f x l l x x var hold varianc also propos seri relat criteria among normal standard deviat deriv f x f x f x l l l l x weight averag deriv absolut valu weight reflect rel magnitud x fx f x x f l l l x x measur sensit input space repres sampl set sever author propos use subset sampl order increas signific relev measur order obtain robust method nonpatholog train exampl discard regress radial basi function network dorizzi et al propos use percentil deriv absolut valu f aberr point elimin contribut robust measur note idea could use relev measur propos paper follow line czernichow propos heurist criterion regress estim set non patholog exampl whose cardin n propos choic criterion is f l f l classif rossi follow proposit made priddi et al consid pattern near class frontier propos follow relev measur f x f x l frontier l x x x frontier defin set point x l f x e e fix threshold sever author also consid rel contribut partial deriv gradient method use simpl backward search stop criteria author use heurist rule except refen et al defin statist test relev measur non linear nn necessit estim relev measur distribut costli opinion usual prohibit approach even look attract link method method use simpl relev measur depend upon gradient network output respect input variabl difficult rank differ criteria said wise use reason rule like discard aberr point robust retrain nn discard variabl comput new relev measur nn sequenc order take account depend variabl practic method give similar result shown section summar tabl main characterist relev measur differ method deriv use task cr data use moodi f cr refen f cr dorizzi f cr non patholog data refen f cr czernichow f cr non patholog data refen f ruck rossi c frontier class tabl comput relev variabl differ method use deriv network function c r denot respect classif regress task second order method sever method propos evalu relev variabl comput weight prune criteria set weight input node present three method first one bayesian approach comput weight varianc two use hessian cost function comput cost function depend upon input unit weight automat relev determin ard method propos mackay framework bayesian learn approach weight consid random variabl regular term take account input includ cost function assum prior probabl distribut group weight th input gaussian input posterior varianc estim with help hessian matrix ard success time seri predict learn regular term improv predict perform howev ard realli use featur select method sinc variabl prune train optim cell damag sever neural select method inspir weight prune techniqu latter decis prune weight made accord relev criterion often name weight salienc weight prune salienc low similarli salienc input cell usual defin sum weight salienc fanouti set weight input i optim cell damag ocd propos ciba et al a similar method also propos mao et al featur select method inspir optim brain damag obd weight prune techniqu develop lecun obd connect salienc defin order two taylor expans mse variat around local minimum hessian matrix h easili comput use gradient descent may comput intens larg network obd author use diagon approxim hessian comput on salienc input variabl defin accordingli as ciba et al propos use choic criterion elimin variabl nn train reach local minimum variabl whose salienc given threshold elimin threshold valu fix cross valid process repeat variabl found threshold method test sever problem gave satisfi result again difficulti lie select adequ threshold furthermor sinc sever variabl elimin simultan wherea individu variabl pertin measur use signific set depend variabl may elimin stop gener perform nn sequenc estim via valid set variabl set correspond nn best perform chosen hessian diagon approxim question sever author hassibi stork exampl propos weight prune algorithm optim brain surgeon ob similar obd use whole hessian comput weight salienc stahlberg riedmil propos featur select method similar ocd except take account non diagon term hessian method salienc comput use perform measur error variat train set weight estim model select use data set optim pedersen et al propos two weight prune method gobd gob comput weight salienc accord estim gener error final predict error akaik similarli obd ob method could also transform featur select method earli cell damag ecd use second order taylor expans obd famili method justifi local minimum reach cost local quadrat minimum hypothesi bare met practic tresp et al propos two weight prune techniqu famili coin ebd earli brain damag eb earli brain surgeon use heurist justif take account earli stop ad new term salienc comput method extend featur rank call ecd earli cell damag ebd extens ecd salienc input defin as algorithm propos slightli differ ocd one variabl elimin time nn retrain delet choos best set variabl use variat select accord estim gener error method estim comput use valid set sinc perform may oscil significantli differ sever subset may perform see eg figur use fisher test compar model perform best model select set network whose perform similar best one choos among network one smallest number input variabl experiment comparison present compar perform differ featur select method compar method difficult task uniqu measur character import input select accuraci also depend search techniqu variabl subset choic criterion case nn differ step reli heurist could exchang one method other nn use multilay perceptron one hidden layer neuron comparison provid intend definit rank differ method illustr gener behavior method describ befor use two synthet classif problem illustr differ difficulti variabl select first one frontier nearli linear depend variabl well pure nois variabl second problem non linear frontier variabl chosen independ correl first problem origin propos breiman et al three class waveform classif problem noisi depend featur also use variat problem pure nois variabl ad initi variabl there input variant train set pattern test set descript problem provid appendix perform optim bay classifi estim test set correct classif perform comparison appear tabl two instanc method p select variabl perf stepdisc bonnland moodi ruck dorizzi czernichow ciba leray tabl perform comparison differ variabl select noisi wave problem noisi problem method elimin pure nois variabl except two method bottom tabl give slightli lower perform select fewer variabl give similar valu around correct stepdisc also give good perform sinc problem data unimod distribut frontier nearli linear non noisi problem perform method order chang two techniqu bottom tabl give slightli better perform method p select variabl perf none stepdisc bonnland moodi ruck dorizzi czernichow ciba leray tabl perform comparison differ variabl select method origin wave problem number remain variabl ecd ocd figur perform comparison two variabl select method ocd ecd accord number remain variabl noisi wave problem figur show perform curv two method ocd ecd estim valid set sinc use singl valid set small fluctuat perform form cross valid use order get better estim test strategi propos ecd look also attract case seen problem perform less similar backward elimin they slightli rise quickli drop relev variabl remov none yacoub moodi ciba leray ruck stepdisc bonnland czernichow figur perform comparison differ variabl select method vs percentag select variabl origin wave problem x axi percentag variabl select axi percentag correct classif figur give repartit differ variabl select method origin wave problem accord perform y axi percentag select variabl x axi best method best perform lower number variabl problem leray satisfi see figur yacoub delet enough variabl bonnland delet much variabl second problem two class problem dimension space class distribut accord two gaussian respect a chosen problem variabl relev order accord index x useless x i relev x method p select variabl perf stepdisc bonnland moodi ruck dorizzi czernichow ciba leray tabl perform comparison differ variabl select method two gaussian problem uncorrel variabl none yacoub stepdisc leray ciba dorizzi ruck czernichow moodi bonnland figur perform comparison differ variabl select method vs percentag select variabl two gaussian problem uncorrel variabl x axi percentag variabl select axi percentag correct classif tabl show stepdisc adapt non linear frontier method select x useless problem remark figur bonnland method delet mani variabl wherea yacoub stop criterion rough delet enough variabl experi replac matrix block diagon matrix block x four group five success correl variabl new problem method p select variabl perf stepdisc bonnland ruck leray tabl perform comparison differ variabl select method two gaussian problem correl variabl tabl give result repres method problem stepdisc still give model good perform select mani correl variabl bonnland method select variabl give significantli lower result ruck method obtain good perform select correl variabl leray method thank retrain variabl delet find model good perform variabl compar ruck stepdisc conclus review variabl select method develop field neural network main difficulti nn non linear system make use explicit parametr hypothesi consequ select method reli heavili heurist three step variabl select relev criterion search procedur nn variabl select use mainli backward search choic final model first discuss main difficulti develop step introduc differ famili method discuss strength weak believ variabl select method must remain comput feasibl use consid techniqu reli comput intens method like eg bootstrap step select instead propos seri rule could use order enhanc sever method describ reason extra comput cost eg retrain nn sequenc comput relev nn allow take account correl variabl simpl estim gener error may use evalu variabl subset simpl test estim allow choos minim variabl set section final perform comparison repres nn select techniqu synthet problem r statist predictor identif use mutual inform select featur supervis neural net learn bootstrap confid interv clinic input variabl effect network train identifi presenc acut myocardi infract select input variabl use mutual inform nonparametr densiti evalu classif regress tree fogelman souli fogelman souli architectur select statist sensit analysi independ coordin strang attractor mutual inform extract relev decay time seri model gustafson hajlmarsson select variabl discrimin analysi fstatist error rate appli nonparametr regress econometr societi monograph n sensit analysi feedforward artifici neural network differenti activ function second order deriv network prune featur select extract gener perform regular neural network model bayesian nonlinear model energi predict competit discrimin analysi statist pattern recognit note generl principl architectur select neural network applic corpor bond rate predict predict risk architectur select neural network statist neural network theori pattern recognit applic branch bound algorithm featur subset select float search method featur select pattern recognit letter attribut suppress multilay perceptron fast network prune featur extract use unitob algorithm select variabl multipl regress learn artifici neural network mathemat statist hv heurist variabl select multilay artifici neural network classifi tr featur select automat classif nongaussian data imag enhanc threshold optim fuzzi compact introduct statist pattern recognit nd ed float search method featur select merg backpropag hebbian learn rule robust classif featur select neural network pattern recognit ctr e gasca j s snchez r alonso rapid brief commun elimin redund irrelev use new mlpbase featur select method pattern recognit v n p februari rajen b bhatt m gopal fuzzyrough set approach featur select pattern recognit letter v n p may m bacauskien a verika select salient featur classif base neural network committe pattern recognit letter v n p decemb chaoton su longsheng chen tailin chiang neural network base inform granul approach shorten cellular phone test process comput industri v n p june d franoi f rossi v wertz m verleysen resampl method parameterfre robust featur select mutual inform neurocomput v n p march r e abdela gmdhbase featur rank select improv classif medic data journal biomed informat v n p decemb