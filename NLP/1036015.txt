t commun lower bound distributedmemori matrix multipl a present lower bound amount commun matrix multipl algorithm must perform distributedmemori parallel comput denot number processor ipi dimens squar matric ini show wide use class algorithm socal twodimension d algorithm optim sens algorithm use ioiinisupsupipi word memori per processor least one processor must send receiv inisupsupipisupsup word also show algorithm anoth class socal threedimension d algorithm also optim algorithm use replic reduc commun show algorithm use ioiinisupsupipisupsup word memori per processor least one processor must send receiv inisupsupipisupsup word furthermor show continu tradeoff size local memori amount commun must perform bound essenti instanti tradeoff also show input distribut across local memori multipl node without replic inisupsup word must cross bisect cut machin bound appli convent inisupsup algorithm appli strassen algorithm ioiinisupsup algorithm b introduct although commun bottleneck mani comput run distributedmemori parallel comput cluster workstat server commun lower bound prove know great deal amount commun specic algorithm perform know littl much commun must perform present lower bound amount commun requir multipli matric convent algorithm distributedmemori parallel comput analysi use uni framework also appli analysi capac cach miss sequenti matrixmultipl algorithm use simpl yet realist comput model prove lower bound model parallel comput collect p processormemori node connect commun network is memori distribut among node commun across network analysi bound number word must sent receiv least one node bound appli even processormemori node includ sever processor fairli common today machin rang cluster dualprocessor workstat sgi origin ibm sp aggarw chandra snir present lower bound amount commun matrix multipl number comput bound howev assum sharedmemori comput model model well exist comput lpram model assum p processor privat cach connect larg share memori furthermor assum comput begin cach empti comput end output must return main memori analysi bound amount data must transfer share main memori privat cach bound matrix multipl essenti quanti number compulsori capac cach miss sharedmemori multiprocessor lpram model model well system memori physic distribut among process node eg cluster worksta tion parallel comput sgi origin ibm sp distinct lpram model model highli relev matrix multipl lower bound matrix multipl nearli alway subroutin larger comput distribut memori machin mul tiplicand alreadi distribut manner matrix multipl subroutin call product must left distribut processor local memori return thu lpram bound essenti show processor must access irrelev distributedmemori machin sinc element may alreadi resid processor mem ori lpram lower bound depend amount local memori data allow store perhap replic local memori comput begin end commun may necessari all contrast lower bound allow initi data distribut input ma trice includ data distribut replic input element algorithm do is lower bound even count commun necessari perform replic input element except section explicitli forbid replic analyz commun across bisect machin is lower bound hold even data allow replic prior invoc algorithm bound also allow distribut use standard asymptot notat paper specic use denit gn set function fn exist posit constant c c c gn fn c gn n n ogn dene similarli use weaker condit fn c gn gn dene condit c gn fn set ogn consist function fn c exist constant n fn c gn n n commun lower bound matrix multipl output matrix c constraint place algorithm upon complet everi element c must resid processor local memori possibl sever state prove lower bound paper use concret constant rather asymptot notat sinc bound amount commun depend three paramet size matric n number processor p size local memori asymptot notat make less clear paramet must grow order function show asymptot behavior also use concret constant clari depend amount commun three paramet constant appear statement lemma theorem howev chosen make proof simpl possibl chosen tight possibl bound assum matric involv squar wherea other appli matric shape restrict matric squar shape feel bound rectangular matric would complic statement result proof unnecessarili analysi appli convent matrix multipl algorithm appli strassen algorithm on algorithm lower bound commun complex strassen nonconvent algorithm beyond scope paper rest paper organ follow section present technic tool underli uni approach commun cachetrac lower bound section present basic memorycommun tradeo show lack memori increas commun section use provabl tradeo analyz socal twodimension d matrixmultipl algorithm algorithm use n p word memori per processor constant factor requir store input output some algorithm use word per processor dror ironi sivan toledo alexand tiskin minim amount requir store input output without compr sion show amount commun perform per processor asymptot optim amount memori section use sophist argument show socal threedimension d algorithm also optim algorithm replic input matric need n word memori per processor allow reduc amount commun n p per processor show amount commun optim amount memori use argument case somewhat complex sinc continu tradeo prove section appli amount local memori per processor n p section prove replic input element allow must cross bisect machin final section use basic lemma underli result prove wellknown lower bound number cach miss sometim refer page fault io lowerbound literatur main point section show kind lower bound deriv use uni approach io commun lower bound relat basic lemma section present technic lemma underli lower bound paper lemma show processor access n element a n element b contribut comput n element product perform on use arithmet oper hong kung prove weaker form lemma lemma consid access element b contribut element c weak use proof distributedmemori lower bound commun lower bound matrix multipl also hong kung state result use asymptot notat wherea state prove use concret constant formal prove follow lemma we dene formal matrixmultipl model below hong kung use similar directedacyclicgraph model lemma hong kung consid convent matrix multipl c r processor local memori cach size word must read write least word secondari memori comput product state prove lemma must dene precis kind algorithm appli to inform want deal algorithm use element addit multipl comput element c ik explicit sum product ij b jk thu rule eg strassen algorithm save comput use element subtract furthermor must assum comput involv valu ij b jk c ik take place thu rule eg boolean matrix multipl algorithm comput explicit sum still save commun memori use intermedi compact represent matric definit convent matrix multipl b n r c r dene direct acycl graph dag mn nr input node repres element ij b jk matric a b mr output node repres element c ik matrix c mnr comput node repres elementari multipl v arc repres data depend particular input node unbound outdegre correspond replic input output node unbound indegre correspond combin partial sum output thu denit cover whole class algorithm may perform replic combin dierent order readi prove basic lemma note hold matric shape long shape allow multipl lemma consid convent matrix multipl mn b n r c r processor contribut nc element c access na element nb element b perform multipl proof lemma immedi corollari discret loomiswhitney inequ relat cardin nite set z cardin ddimension orthogon project d applic discret loomiswhitney inequ matrixmultipl lower bound suggest paterson see also let v nite set point z let va vb vc orthogon project v onto coordin plane discret loomiswhitney inequ state notat number elementari multipl perform processor therefor nanbnc lemma main tool prove commun lower bound fact import would like restat dierent form new commun lower bound matrix multipl version slightli weaker lemma allow direct proof feel may benet reader lemma assumpt lemma processor perform min elementari multipl proof statement follow lemma arithmeticgeometr mean inequ give altern direct proof base idea similar denot sa set element index pair processor access sb set element b processor access sc set element c processor contribut to rst show nb nc n bound number elementari multipli cation partit row two set set contain row least n element sa fa contain rest row n row sinc row c product correspond row b nbn elementari multipl involv row sinc element c product row column b sinc row fa less n element sa ncn elementari multipl involv row fa similar argument show na nc n b bound number elementari multipl partit column b set mb consist column least n b element sb set fb contain rest column sinc column c product correspond column b nan elementari multipl involv column mb sinc element c product row column b ncn elementari multipl involv row fb final show na nb n c bound number elementari mul tiplic partit row c set mc fc a row c product row b c elementari multipl involv row mc element use comput element one row c row c contain less n c element sc element us use less n cation henc number elementari multipl involv row c fc less nan c memorycommun tradeoff section prove tradeo memori commun matrix multipl algorithm analysi show reduc amount memori forc algorithm perform commun shall use provabl tradeo next section prove matrixmultipl algorithm asymptot optim amount memori use algorithm use littl extra memori beyond storag requir store matri ce henc lie extrem end memorycommun tradeo section shall extend tradeo deal larger memori size enabl us prove algorithm also asymptot optim amount memori use lemma consid convent matrix multipl mn b n r c r p processor distributedmemori parallel commun lower bound matrix multipl comput consid processor word local memori perform elementari multipl processor must send receiv least wp word proof decompos schedul comput processor phase phase begin total number word sent receiv far processor exactli m thu phase except perhap last phase processor send receiv exactli word number na element processor may access phase sinc one element must resid processor memori phase begin els must receiv anoth processor phase argument show nb dene element c ik product c live phase if processor comput ij b jk j phase partial sum contain ij b jk either resid processor memori end phase sent anoth processor phase number nc live element c phase sinc live element either use one word memori end phase sent anoth processor lemma show number elementari multipl phase nanbnc total number elementari multipl algorithm w therefor number full phase that phase exactli word sent receiv least wp wp total amount commun least wp wp conclud proof note proof allow input valu ij b jk pre distribut multipl copi dierent processor memori free input replica tion also ignor need collect add togeth individu processor contribut output valu c ik free output combin also note lower bound degener zero w inevit sinc commun inde zero eg input output local memori gener commun requir input replic output com bine account proof howev latter case w therefor threshold constant factor away best achiev lemma prove concentr singl processor next theorem take global view run time typic determin heavili load processor therefor show least one processor must perform lot commun deriv lower bound amount time whole algorithm must spend commun theorem memorycommun tradeoff consid convent matrix multipl c r p processor distributedmemori parallel comput word local memori per processor total number word sent receiv least one processor least proof least one processor must perform mnrp multipl result follow appli lemma commun lower bound matrix multipl lower bound degener zero eg commun lower bound almostinplac algorithm among mani exist parallel matrix multipl algorithm recent algorithm mccoll tiskin is knowledg one whose perform match asymptot lower bound memorycommun tradeo valu howev two class earlier algorithm match lower bound specic valu one end spectrum socal algorithm use littl extra memori beyond requir store matric end spectrum socal algorithm use extra memori replic input matric reduc com munic special theorem algorithm section analyz algorithm use extra memori rst distributedmemori parallel matrixmultipl algorithm probabl one due cannon cannon origin propos algorithm parallel comput connect twodimension mesh gener cannon algorithm larger blockdistribut matric due dekel nassimi sahni algorithm also gener hypercub interconnect topolog fox otto hey describ dierent algorithm which unlik cannon algorithm use broadcast anoth algorithm propos agarw gustavson zubair independ almost simultan van de geijn watt algorithm call summa use mani broadcast rel small matrix piec allow broadcast pipelin occur concurr comput storag requir algorithm proport size matric squar matric amount memori per processor proport n p clearli n p word per processor necessari store dror ironi sivan toledo alexand tiskin multiplicand product algorithm eg summa need storag beyond storag requir matric simpler algorithm block implement cannon algorithm requir addit word per processor order store two block two block b thi reduc on p break commun phase mani small messag possibl result increas commun overhead next theorem show algorithm asymptot optim amount commun per processor algorithm use word memori per processor must perform per processor order keep theorem simpl state prove squar matric theorem d commun lower bound consid convent multipl two n n matric p processor distributedmemori parallel comput processor n p word local memori least one processor must send receiv least word proof theorem amount commun least one processor bound commun lower bound matrix multipl inequ reli fact p extend tradeoff n p tradeo section fail provid meaning bound n p regim may even singl full phase sens proof lemma sinc proof lemma take account either amount commun last phase commun necessari input replic output combin provid use bound case section analyz amount commun must perform includ commun necessari output combin but still input replic show regim amount commun per processor bound match asymptot upper bound achiev algorithm use input replic algorithm reduc commun tradit algorithm although dekel nassimi sahni perhap rst propos algorithm algorithm communicationeci total number word commun n communicationeci algorithm rst propos berntsen aggarw chandra snir time berntsen paper submit public paper aggarw chandra snir present confer essenti algorithm propos later independ gupta kumar johnsson berntsen algorithm somewhat complex rest aggarw chandra snir also prove amount commun per processor matrix multipl algorithm must perform sharedmemori parallel comput explain introduct bound appli matrix multipl distribut memori machin bound reli privat cach processor empti comput begin contrast distributedmemori machin matric typic alreadi distribut matrix multipl subroutin invok main result section hing follow lemma lemma consid convent multipl two n n matric p processor distributedmemori parallel comput consid processor word local memori perform least n p elementari multipli cation let processor must send receiv least word proof na theorem statement hold sinc element resid processor local memori comput begin rest must receiv processor argument hold nb theorem statement hold again sinc processor must send contribut least n p element c processor na nb nc less claim three quantiti must greater commun lower bound matrix multipl let w number multipl processor perform use lemma notat fact na nb less therefor ident argument show express also bound na nb number element c processor comput without contribut processor small everi c ik processor must access entir ith row entir kth column b na nb less processor comput n n element c own suppos processor particip comput c ik comput own c ik resid processor end comput processor must receiv contribut c ik least one processor c ik resid anoth processor processor must sent contribut processor either way one word data must either receiv sent c ik therefor processor must send receiv least word particip comput element c subtract hypothes p rst two inequ true sinc third hold sinc p impli p turn impli show number word must sent receiv least claim state main result section proof essenti theorem omit theorem d commun lower bound consid convent multipl two n n matric p processor distributedmemori parallel comput processor n p word local memori least one processor must send receiv least min word commun lower bound matrix multipl bisectionbandwidth bound section analyz amount data must cross bisect distributedmemori parallel comput partit memoryprocessor node two subset establish lower bound amount data must cross cut separ subset commun network comput assum element input matric store exactli distribut memori machin input evenli split subset inde allow replic input matric output comput without commun across bisect exampl algorithm perform commun across bisect cut network follow initi data replic phase anoth way deriv lower bound commun across cut appli lower bound section group processor bound also bound amount commun group p processor must perform p p processor machin commun must transmit edg cut commun network two processor group henc bound amount commun must travers cut network techniqu howev unlik provid use bound larg p say gener memorycommun tradeo degener special bound theorem hold larg p therefor need specic bound commun across bisect cut theorem assum matric b evenli distribut proof easili modi show asymptot bound also appli two processor subset initi store n element n element b constant complex proof would requir theorem consid convent multipl two n n matric p processor distributedmemori parallel comput input element initi store local memori exactli one processor least word must transfer across cut split input distribut multiplicand b evenli proof let consid cut commun network split node two subset hold exactli n element n element b n element n element b transfer across cut theorem statement hold otherwis claim subset machin comput element c that is sum product ij b jk comput local comput element requir access entir row entir column b n element b cross cut subset access n row column b comput element c own henc commun lower bound matrix multipl element c must comput two subset machin togeth mean least mani word must cross cut sinc theorem statement hold io lower bound section use lemma bound number compulsori capac cach miss matrix multipl establish lower bound number word must transfer slow memori fast cach arithmet instruct access data cach result new show proof techniqu use parallel commun bound appli analysi cach miss specic bound prove asymptot prove hong kung toledo bound howev specifi constant unlik hong kung result state use asymptot notat constant slightli stronger given proof techniqu similar eect use toledo proof techniqu use lemma simpli structur proof lower bound use lax memorysystem model equival hong kung redblu pebbl game therefor appli cach organiza tion lower bound also match asymptot perform recurs matrix multipl block matrix multipl assum block size chosen appropri cach fulli associ use lru replac polici matrix multipl algorithm whose asymptot perform match lower bound old comput rutledg rubinstein describ librari block matrix subroutin design togeth herbert f mitchel implement univac rstgener comput dror ironi sivan toledo alexand tiskin becam oper mckeller coman provid rst rigor analysi data reus matrix comput includ matrix multipli cation show block algorithm transfer fewer word fast slow memori algorithm oper row column highqual implement ioecient matrixmultipl algorithm wide avail frequent use proof next theorem similar proof lemma theorem consid convent multipl two n n matric comput larg slow memori fast cach contain word arithmet oper perform word cach number word move slow memori fast cach least proof decompos schedul comput phase phase begin total number word move memori cach exactli m thu phase except perhap last phase exactli word transfer memori cach number na element processor may oper upon phase sinc one element must either resid cach phase begin must read cach phase argument show nb dene element c ik product c live phase processor comput ij b jk k phase partial sum contain ij b jk either resid cach end phase written slow memori phase number nc live element c phase commun lower bound matrix multipl sinc live element either use one word cach end phase written slow memori lemma show number elementari multipl phase nanbnc total number elementari multipl algorithm n therefor number full phase that is phase exactli word transfer least total number word transfer least conclud proof next corollari show matric sever time larger cach number cach miss proport n m constant corollari essenti exampl pick stronger bound size matric rel cach could prove stronger bound number cach miss corollari the io lower bound condit theorem assum n number word must transfer cach least proof n number word must transfer least n pd r f februari conclus present rigor lower bound amount commun distributedmemori parallel matrix multipl algorithm must perform bound hold directedacyclicgraph dag model convent matrix multipl nari summat that is dag allow summat order bound hold on matrix multipl algorithm strassen hold case arbitrari comput matrix element allow even elementari product comput explicitli main signic result rigor valid algorithmdesign long suspect algorithm asymptot optim littl replic allow algorithm asymptot optim replic allow therefor search ecient algorithm must concentr improv constant involv eort design nonconvent algorithm specic domain use compress nondag techniqu anoth import conclus research algorithm somewhat unlik becom competit bound show asymptot reduct commun rel algorithm cannot exceed factor p typic machin size valu unlik high enough make replic protabl note although author found algorithm faster algorithm practic nearli wide use exist commun lower bound matrix multipl librari implement algorithm also note eort rst two author design factor algorithm suggest constant algorithm high the constant higher triangular factor matrix multipl acknowledg thank two anonym refere help comment suggest sivan toledo support part ibm faculti partnership award grant israel scienc foundat found israel academi scienc human r threedimension approach parallel matrix multipl exploit function parallel power design highperform numer algorithm improv perform linear algebra algorithm dens matric use algorithm prefetch commun complex pram commun ecient matrix multipl hypercub optim matrix multipli use phipac portabl geometr inequ cellular comput implement kalman parallel matrix graph algorithm matrix algorithm hypercub scalabl matrix multipl algorithm parallel comput perform intel tflop supercomput io complex redblu pebbl game trade replic commun parallel distributedmemori dens solver minim commun time matrix multipl mul tiprocessor local basic linear algebra subroutin lbla connect machin system cm local basic linear algebra subroutin lbla cme inequ relat isoperimetr inequ privat commun high order matrix comput univac matrix algebra program univac gaussian elimin optim bulksynchron parallel random access machin survey outofcor algorithm numer linear algebra robert van de geijn jerrel watt automat tune linear algebra softwar tr commun complex pram minim commun time matrix multipl multiprocessor improv perform linear algebra algorithm dens matric use algorithm prefetch exploit function parallel power design highperform numer algorithm highperform matrixmultipl algorithm distributedmemori parallel comput use overlap commun threedimension approach parallel matrix multipl optim matrix multipli use phipac bulksynchron parallel random access machin survey outofcor algorithm numer linear algebra organ matric matrix oper page memori system introduct algorithm high order matrix comput univac bulksynchron parallel multipl boolean matric io complex automat tune linear algebra softwar cellular comput implement kalman filter algorithm