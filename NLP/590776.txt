t overcom myopia induct learn algorithm relieff a current induct machin learn algorithm typic use greedi search limit lookahead prevent detect signific condit depend attribut describ train object instead myopic impur function lookahead propos use relieff extens relief develop kira rendel lsqb rsqb heurist guidanc induct learn algorithm reimplement assist system top induct decis tree use relieff estim attribut select step algorithm test sever artifici sever real world problem result compar well known machin learn algorithm excel result artifici data set two real world problem show advantag present approach induct learn b introduct induct learn algorithm typic use greedi search strategi overcom combinatori explos search good hy pothes heurist function estim potenti successor current state search space major role greedi search current induct learn algorithm use variant impur function like inform gain gain ratio giniindex distanc ever measur assum attribut condit independ given class therefor domain strong condit depend attribut greedi search poor chanc reveal good hypothesi kira rendel develop algorithm call seem power estim qualiti attribut exampl pariti problem variou degre signific number irrelev ran dom addit attribut relief abl correctli estim relev attribut time proport number attribut squar number train instanc thi reduc limit number iter relief origin relief deal discret continu at tribut deal incomplet data limit twoclass problem onli develop extens relief call relieff improv origin algorithm estim probabl reliabl extend handl incomplet multiclass data set complex remain same relieff seem promis heurist function may overcom myopia current induct learn algorithm kira rendel use relief preprocessor elimin irrelev attribut data descript learn ing relieff gener rel effici reliabl enough guid search learn process paper reimplement assist learn algorithm top induct decis tree describ name assist r instead inform gain assistantr use relieff heurist function estim attribut qualiti step tree gener experi seri artifici realworld data set describ result obtain use relieff select criterion compar result ap proach follow approach compar ffl use inform gain select criterion ffl lfc tri overcom myopia inform gain limit lookahead ffl naiv bayesian classifi assum condit independ attribut ffl knearest neighbor algorithm paper organ follow next section origin relief briefli describ along interpret extend version relieff section present reimplement assist call assistantr section briefli describ algorithm use experi section describ experiment methodolog section describ experi compar result differ algorithm show assistantr perform least well assist sometim much better conclus potenti breakthrough discuss basi excel result artifici data set final integr compar algorithm propos relieff relief key idea relief estim attribut accord well valu distinguish among instanc near other purpos given instanc relief set weight wa n begin randomli select instanc r find nearest hit h nearest miss m all attribut wa wa diffarhn end figur basic algorithm relief search two nearest neighbor one class call nearest hit differ class call nearest miss origin algorithm relief randomli select n train instanc n userdefin paramet algorithm given figur function diffattributeinstanceinst calcul differ valu attribut two instanc discret attribut differ either the valu differ the valu equal continu attribut differ actual differ normal interv normal n guarante weight w a interv gamma howev normal n unnecessari step w a use rel comparison among attribut weight estim qualiti attribut rational formula updat weight good attribut valu instanc class subtract differ differenti instanc differ class ad differ function diff use also calcul distanc instanc find nearest neighbor total distanc simpli sum differ attribut fact origin relief use squar differ discret attribut equival diff experi signific differ result use diff squar differ enc n number train instanc complex algorithm on theta n theta all attribut interpret relief estim follow deriv show relief estim strongli relat impur function obviou relief estim w a attribut approxim follow differ probabl differ valu aj nearest instanc differ class gammap differ valu aj nearest instanc class elimin requir select instanc nearest formula becom differ valu ajdiffer class gammap differ valu ajsam class rewrit equal valu classjequ valu obtain use bay rule sampl replac strict sens follow equal hold use equal obtain const theta highli correl giniindex gain class c valu v attribut a differ instead factor giniindex gain use equat show strong relat re lief weight giniindex gain probabl two instanc valu attribut eq kind normal factor multivalu at tribut impur function tend overestim multivalu attribut variou normal heurist need avoid tendenc eg gain ratio distanc measur binar attribut equat show relief exhibit implicit normal effect anoth defici giniindex gain valu tend decreas increas number class denomin constant factor equat given attribut serv kind normal therefor relief estim exhibit strang behavior giniindex gain doe deriv elimin nearest instanc condit probabl put back interpret relief estim averag local estim smaller part instanc space enabl relief take account context attribut ie condit depend attribut given class valu detect context local global point view depend hidden due effect averag train instanc exactli make impur function myopic impur function use correl attribut class disregard context attribut use global point view disregard local peculiar exampl data set given tabl illustr differ myopic estim function relief three attribut eight train instanc class valu determin xor function attribut a third attribut randomli gener relief equat correctli estim attribut import contribut attribut poor hand wa equat tabl exampl data set estim qualiti attribut function class inform gain gainratio distanc ginigain equat origin giniindex gain inform gain gain ratio distanc measur estim contribut highest attribut estim complet irrelev hong develop procedur similar relief estim qualiti attribut directli emphas use contextu inform differ relief approach use inform nearest miss ignor nearest hit besid hong use normal penal contribut nearest miss far away given instanc extens relief origin relief deal discret continu attribut howev deal incomplet data limit twoclass problem onli equat crucial import extens relief turn extens relief straightforward unless realiz relief fact approxim probabl extens design way probabl reliabl approxim develop extens relief call relieff improv origin algorithm estim probabl reliabl extend deal incomplet multiclass data set brief descript extens follow reliabl probabl approxima tion paramet n algorithm re lief describ section repres number instanc approxim probabl eq larger n impli reliabl approxim obviou choic adopt relieff rel small number train instanc up one thousand run outer loop relief avail train instanc select nearest neighbor crucial import relief purpos find nearest neighbor respect import attribut redund noisi attribut may strongli affect select nearest neighbor therefor estim probabl noisi data becom unreli increas reliabl probabl approxim relieff search k nearest hitsmiss instead one near hitmiss averag contribut k nearest hitsmiss shown extens significantli improv reliabl estim attribut qualiti overcom problem paramet tune experi k set which empir give satisfactori result problem significantli better result obtain tune as typic major machin learn algorithm incomplet data enabl relief deal incomplet data set function diffattributeinst instanc relieff extend miss valu attribut calcul probabl two given instanc differ valu given attribut ffl one instanc eg i unknown valu ffl instanc unknown valu condit probabl approxim rel frequenc train set nearest neighbor correl coeffici independ att pariti problem figur correl relieff estim intend qualiti attribut data set condit independ strongli depend attribut approach assum condit probabl attributevalu given class applic without context at tribut may case naiv howev includ context atribut far ineffici multiclass problem kira rendel relief use estim attribut qualiti data set two class split problem seri class problem solut seem unsatisfactori in section discuss perform approach compar extens describ below use prac tice relief abl deal multiclass problem without prior chang knowledg represent could affect final outcom instead find one near miss differ class relieff search k near miss differ class c averag contribut updat estim w a averag weight prior probabl class idea algorithm estim abil attribut separ pair class regardless two class closest other normal prior probabl class necessari k near miss differ class would tend exagger influenc class small number case note time complex relieff on theta attribut n number train instanc relieff estim attribut qualit estim contribut paramet k nearest hitsmiss relieff estim attribut qualiti kononenko compar intend inform gain attribut estim gener relieff calcul standard linear correl coeffici correl coeffici show intend qualiti estim qualiti attribut relat typic graph data set condit independ attribut strongli depend attribut pariti problem variou de gree shown figur condit independ attribut qualiti estim monoton increas number nearest neighbor conditionali depend at tribut qualiti increas maximum later decreas number nearest neighbor exce number instanc belong peak distribut space given class note that attribut evalu myopic impur function like giniindex inform gain qualiti estim would high condit independ attribut poor strongli depend attribut correspond estim relieff larg number nearest hitsmiss test effect normal factor eq run relieff also one well known medic data set primari tumor describ author section major differ estim impur function estim relieff primari tumor problem estim two signific attribut inform gain giniindex overestim one attribut valu by opinion physician specialist relieff normal version impur function correctli estim attribut less import assistantr assistantr reimplement assist learn system top induct decis tree basic algorithm goe back cl concept learn system develop hunt et al reimplement sever author see overview follow describ main featur assist binar attribut algorithm gener binari decis tree decis step binar version attribut select maxim inform gain attribut continu attribut decis point select maxim at tribut inform gain discret attribut heurist greedi algorithm use find local best split attribut valu two subset purpos binar reduc replic problem strengthen statist support gener rule decis tree prune preprun postprun techniqu use prune unreli part decis tree preprun ing three userdefin threshold provid minim number train instanc minim attribut inform gain maxim probabl major class current node postprun method develop niblett bratko use use laplac law success estim expect classif error current node commit pruningnot prune subtre incomplet data handl learn train instanc miss valu select attribut weight probabl attribut valu condit class label classif instanc miss valu weight uncondit probabl attribut valu naiv bayesian classifi intern node decis tree eventu third successor appear label attribut valu train instanc avail null leav naiv bayesian formula use calcul probabl distribut leaf use attribut appear path root leaf note calcul done offlin ie learn phase classif null leav alreadi label calcul class probabl distribut use classif manner ordinari leav main differ assist reimplement assistantr reli eff use attribut select addi tion wherev appropri instead rel frequenc assistantr use mestim probabl shown often significantli increas perform machin learn algorithm prior probabl laplac law success use possibl outcom n number trial n x number trial outcom x prior probabl use mestim condit probabl paramet trade contribut rel frequenc prior probabl experi paramet set thi set usual use default and em piric give satisfactori result although tune problem domain better result may expect mestim use naiv bayesian formula postprun instead laplac law success propos cestnik bratko relieff estim probabl eq use probabl root tree estim prior probabl lower intern node nt correspond train instanc ajnearest miss ajnearest miss root ajnearest hit ajnearest hit root experiment environ algorithm comparison perform seri experi assistantr compar perform follow algorithm assistanti variant assistantr instead relieff use inform gain select criterion assist how ever differ assist remain mestim probabl algorithm enabl us evalu contribut re lieff paramet assistanti assistantr fix throughout experi no preprun postprun lfc ragavan et al use limit lookahead lfc lookahead featur con struction algorithm top induct decis tree detect signific condit depend attribut construct induct show interest result data set reimplement algorithm test perform result present paper show drawback experiment comparison describ ragavan rendel confirm advantag limit lookahead construct induct lfc gener binari decis tree node algorithm construct new binari attribut origin attribut use logic oper conjunct disjunct negat construct binari at tribut best attribut select process recurs repeat two subset train instanc correspond two valu select attribut construct induct limit lookahead use space possibl use construct re strict due geometr represent condit entropi estim attribut qualiti reduc search space algorithm also limit breadth depth search lfc use lookahead less myopic greedi algorithm assist comparison result may show perform greedi search combin reli eff versu lookahead strategi make result compar assistantr equip lfc prune probabl estim facil describ section test perform default set paramet depth lookahead beam size although domain better result may obtain paramet tune howev higher valu paramet may combinatori increas search space lfc make algorithm impract naiv bayesian classifi classifi use naiv bayesian formula calcul probabl class given valu attribut assum condit independ attribut new instanc classifi class maxim calcul probabl mestim probabl use paramet set experi perform naiv bayesian classifi serv estim condit independ attribut knn knearest neighbor algorithm given new instanc algorithm search nearest train instanc classifi instanc frequent class k instanc knn algorithm distanc measur use relieff see section present result obtain manhattandist result use euclidian distanc practic same best result respect paramet k pre sent although fair comparison paramet tune allow train test set select naiv bayesian classifi knn algorithm comparison well known simpl perform well mani realworld problem perform two algorithm may show natur classif problem experiment methodolog experi data set perform time randomli select instanc learn test result averag system use subset instanc learn test order provid experiment condit verifi signific differ use onetail ttest confid level null hypothesi state differ zero differ result valu statist threshold consid signific except methodolog experi finit element mesh design problem experiment methodolog dictat previou publish result describ section besid classif accuraci measur also averag inform score measur elimin influenc prior probabl appropri treat probabilist answer classifi averag inform score defin as test instanc test instanc inform score classif ith test instanc defin by class ith test instanc p cl prior probabl class cl probabl return classifi return probabl correct class greater prior probabl inform score posit obtain inform correct interpret prior inform necessari correct classif minu posterior inform necessari correct classi ficat return probabl correct class lower prior probabl inform score neg obtain inform wrong interpret prior inform necessari incorrect classif minu posterior inform necessari incorrect classif main differ classif accuraci inform score illustr follow exampl let prior distribut class p let posterior distribut return classifi p correct class c inform score posit classif accuraci treat given posterior distribut wrong answer correct class c inform score neg classif accuraci treat given posterior distribut correct answer classif accuraci may special case exhibit high varianc inform score much stabl special case data set irrelev attribut exactli instanc one class instanc class leav oneout test probabilist classifi would give approxim accuraci thedefault classifi classifi everi instanc major class accuraci would slight modif distribut train instanc would drastic chang latter accuraci approxim drastic modif distribut say case one class other would increas accuraci default classifi accuraci probabilist classifi would approxim theta theta howev classifi inform score would scenario remain approxim bit would indic classifi unabl extract use inform attribut experiment result section give result sever artifici realworld data set present experi divid four part accord four group data set artifici data set control condit depend attribut benchmark artifici data set medic data set realworld data set group give brief descript data set follow result result tabl includ averag sever run standard error artifici data set gener sever data set order compar perform variou algorithm inf domain three condit independ inform binari attribut three class three random binari attribut learner detect three attribut inform rel easi task five algorithm abl solv problem inf domain obtain inf replac inform attribut two attribut whose valu defin valu origin attribut xor relat prob lem learner detect six import attribut fact attribut pairwis strongli condit depend fairli complex problem cannot solv myopic heurist data set show advantag lfc assistantr tree domain whose instanc gener decis tree intern node contain differ binari attribut random binari attribut ad descript instanc problem easi greedi decis tree learn algorithm approach may difficulti due inappropri knowledg represent target concept par pariti problem two signific binari attribut random binari at tribut randomli select instanc label wrong class problem hard lot attribut equal score evalu myopic evalu function inform gain par par except three signific attribut pariti relat make problem harder par par except four signific attribut pariti relat make problem hardest among pariti problem use experi basic characterist artifici data set list tabl characterist includ percentag major class which interpret default accuraci class entropi give impress complex classif problem result learn algorithm lfc assistanti assistantr well naiv bayesian classifi knn algorithm given tabl classif accuraci tabl inform score result expect show that ffl classifi perform well rel sim ple domain condit independ attribut ffl version assist perform well problem reconstruct decis tree tree classifi significantli wors assistantr lfc abl success solv problem strong condit depend attribut inf par howev two assistantr perform better especi case hardest problem par note lfc solv par depth lookahead increas tabl basic descript artifici data set domain class att valatt instanc majclass entropybit inf tabl classif accuraci learn system artifici data set domain lfc assistanti assistantr naiv bay knn inf sigma sigma sigma sigma sigma inf sigma sigma sigma sigma sigma tree sigma sigma sigma sigma sigma sigma sigma sigma sigma sigma howev time complex lookahead increas exponenti depth hand assistantr solv pariti problem equal quickli ffl inform score naiv bayesian classifi problem strong condit depend attribut poor indic classifi fail find regular data set benchmark artifici data set besid artifici data set previou subsect use also follow benchmark artifici data set use author note result author directli compar result experiment condit trainingtest split same bool boolean function defin attribut class nois optim recognit rate target function is data set use smyth et al and report sigma classif accuraci naiv bay sigma back propag sigma rulebas classifi led leddigit problem nois attribut valu optim recognit rate estim smyth et al report sigma classif accuraci naiv bay sigma backpropa gation sigma rulebas classi fier data set obtain irvin databas krk problem legal kingrook king chess endgam posit attribut describ relev relat piec same rank adjac file origin data includ five set exampl learn test use test induct logic program algorithm report classif accuraci sigma use one set exampl ie instanc train krk krk except avail attribut coordin piec data set use mladen report result accuraci atri system assist basic descript data set provid tabl result given tabl interest led domain naiv bayesian classifi knn algorithm reach estim upper bound classif accuraci suggest attribut consid optim classif domain problem attribut condit independ given class therefor good perform naiv bayesian classifi surpris howev three domain perform naiv bayesian classifi poor due strong tabl averag inform score learn system artifici data set domain lfc assistanti assistantr naiv bay knn tabl basic descript benchmark artifici data set domain class att valatt instanc majclass entropybit tabl classif accuraci learn system artifici data set domain lfc assistanti assistantr naiv bay knn led sigma sigma sigma sigma sigma krk sigma sigma sigma sigma sigma krk sigma sigma sigma sigma sigma tabl averag inform score learn system artifici data set domain lfc assistanti assistantr naiv bay knn led sigma sigma sigma sigma sigma condit depend attribut inform score see tabl show naiv bayesian classifi provid on averag inform bool krk domain perform differ variant assist almost same except krk domain perform assistanti poor note default accuraci krk perform assistantr knn algorithm significantli better confid level howev inform score show both assistantr knn success problem expect without construct induct possibl reveal regular chess posit describ coordin piec lfc abl construct import attribut domain enabl achiev significantli better result algorithm medic data set compar perform algorithm sever medic data set ffl data set obtain univers medic center ljubljana slovenia problem locat primari tumour patient metastas prim problem predict recurr breast cancer five year remov tumour brea problem determin type cancer lymphographi lymp diagnosi rheumatolog rheu ffl hepa prognost surviv patient suffer hepat data provid gail gong carnegiemellon univers ffl data set obtain statlog databas diagnosi diabet diab diagnosi heart diseas heart diab data set ragavan rendel report classif accuraci lfc al gorithm also report poor perform tabl basic descript medic data set domain class att valatt instanc majclass entropybit prim tabl classif accuraci learn system medic data set domain lfc assistanti assistantr naiv bay knn brea sigma sigma sigma sigma sigma lymp sigma sigma sigma sigma sigma hepa sigma sigma sigma sigma sigma heart sigma sigma sigma sigma sigma tabl averag inform score learn system medic data set domain lfc assistanti assistantr naiv bay knn sever algorithm without construct induct up howev result see below result statlog project show poor result algorithm domain due lack construct induct experi diab dataset classifi perform equal well except naiv bayesian classifi significantli better basic characterist medic data set given tabl result experi data set provid tabl medic data set attribut typic condit independ given class there fore surpris naiv bayesian classifi show clear advantag data set interest perform knn algorithm good domain although wors perform naiv bayesian classifi inform score tabl brea data set indic learn algorithm abl solv problem suggest attribut relev version assist similar per formanc except hepa domain where assistantr significantli better perform confid level detail analysi show problem relieff discov signific condit interdepend two attribut given class two attribut score poorli consid indepen dentli assistanti abl discov regular data hand attribut avail contain similar inform two attribut togeth reason naiv bayesian classifi perform better tri provid naiv bayesian classifi addit attribut join two condit depend attribut how ever perform remain same achiev significantli better result two induct algorithm lymp domain construct induct seem use howev lfc perform significantli wors rheu domain domain three induct algorithm perform equal well nonmed realworld data set compar perform algorithm also follow nonmed real world data set soyb iri vote obtain irvin databas sat obtain statlog databas soyb famou soybean data set use iri well known fisher problem determin type iri flower meshmesh problem determin number element edg object finit element mesh design problem five object expert construct appropri mesh five experi one object use test four learn result averag result report dzeroski variou ilp system classif accuraci foil mfoil golem result report pomp et al sfoil descript mesh problem appropri ilp system attribut learner relat ariti ie attribut use describ problem note domain trainingtest split algorithm test methodolog special case leaveoneout therefor result tabl problem standard deviat quinlan report result ilp system achiev domain test posit neg instanc howev result mislead posit instanc ten neg instanc averag therefor copi instanc classif instanc correct least copi give classif accuraci classifi alway classifi wrong class mesh contain three basic attribut origin databas ignor relat descript object therefor domain attribut learner given less inform ilp learner contain besid origin at tribut attribut deriv relat background knowledg prob lem attribut learner advantag alreadi provid addit attribut provid descript object ilp learner actual inform princi ple attribut number addit attribut could deriv extrem cleaver ilp learner relat descript background knowledg how ever fairli complex task therefor attribut learner mesh data set better chanc ilp learner reveal good hypothesi sat databas consist multiclass spectral valu pixel theta neighborhood satellit imag classif central pixel neighborhood result statlog project classif accuraci knn algorithm backpropag c cn naiv bayesian classifi use rel frequenc mestim probabl vote vote record session unit state congress smyth et al report classif accuraci naiv bayesian classifi backpropag rulebas classifi basic characterist nonmed real world data set present tabl tabl give result soyb iri data set classifi perform equal well result naiv bayesian classifi indic attribut condit rel independ data set agreement previous publish result sat data set knn significantli outperform algorithm agreement result statlog project how ever naiv bayesian classifi mestim probabl reach classif accuraci induct learn algorithm result naiv bayesian classifi use author tabl basic descript nonmed realworld data set domain class att valatt instanc majclass entropybit tabl classif accuraci learn system nonmed realworld data set domain lfc assistanti assistantr naiv bay knn iri sigma sigma sigma sigma sigma tabl averag inform score learn system nonmed realworld data set domain lfc assistanti assistantr naiv bay knn statlog project much wors cestnik shown mestim significantli increas perform naiv bayesian classifi also confirm experi version assist perform data set except sat data set assistantr lfc achiev significantli better result confid level result confirm relieff estim qualiti attribut better inform gain vote data set naiv bayesian classifi worst version assist compar rule base classifi smyth et al interest result appear domain although attribut learner mesh less inform ilp system outperform result ilp system report dzeroski pomp et al addit attribut mesh result induct learner significantli improv induct learn system significantli outperform naiv bayesian classifi knn algorithm detail analysi show excel result version assist due use naiv bayesian formula calcul class probabl distribut null leav see section name problem often happen test instanc fall null leaf train instanc valu signific attribut test instanc naiv bayesian classifi effici solv problem lfc gener null leav construct attribut strictli binari valu true fals therefor classif object differ valu origin attribut train instanc alway proce branch label fals effect strategi that given test instanc correspond leaf contain train instanc similar valu attribut appear path root leaf strategi also work well mesh problem discuss note null leav version assist influenc perform arti ficial data set miss valu data also mesh problem perform lfc good although gener null leav therefor use null leav crucial differ assist lfc equat show interest relat relief estim impur func tion relief effici estim continu discret attribut implicit normal eq enabl relief appropri deal multivalu attribut howev assistanti would use eq instead inform gain would still myopic ex ampl par problem eq would estim attribut equal nonimport therefor reason success assistantr nearest instanc heurist influenc estim probabil iti heurist enabl relief detect strong condit depend attribut would overlook estim probabl would done randomli select instanc instead nearest instanc relieff effici heurist estim attribut qualiti abl deal data set condit depend independ at tribut extens relieff enabl deal noisi incomplet multiclass data set increas number k nearest hitsmiss correl relieff estim impur function also increas unless k greater number instanc peak instanc space studi report show relieff accept bia respect measur estim attribut differ number valu myopia current induct learn system partial overcom replac exist heurist function relieff assistantr variant top induct decis tree algorithm use relieff estim qualiti attribut significantli outperform classifi domain strong condit depend at tribut myopia induct learner may caus overlook signific relat easili demonstr artifici data set also shown two real world problem hepa sat data set relieff detect signific condit interdepend attribut result significantli better result assistantr result assistanti one featur relief address paper attribut replic data set replic get estim increas number replic qualiti estim descreas replic attribut affect distanc instanc construct induct lfc use limit lookahead detect signific condit depend attribut lfc show similar advantag algorithm assist r doe one artifici problem krk one real world problem lymp lfc perform significantli better due construct induct howev case construct induct may spoil result case rheu data set lfc perform well prob lem suggest limit lookahead good search strategi realworld prob lem lookahead howev reason limit time complex exponentiali increas lookahead depth although relieff may overcom myopia useless assistantr chang represent requir case construct induct appli exampl krk problem assistantr achiev good result improv without construct induct good idea construct induct may use relieff instead combin lookahead naiv bayesian classifi obviou advantag domain condit rel independ attribut medic diagnost problem domain naiv bayesian classifi abl reliabl estim condit probabl also abl use at tribut ie avail inform would interest appropri combin power relieff naiv bayesian classifi current ilp system abl use attribut appropri demonstr mesh domain attribut learn er outperform exist ilp system enabl ilp system deal attributevalu rep resent combin semi naiv bayesian classifi could use hand current ilp system use greedi search techniqu heurist guid search myopic pomp kononenko implement adapt version relieff foil like ilp system call ilpr prelemi nari experi show similar advantag system ilp system assistantr assistanti conclus relieff effici heurist estim attribut qualiti abl deal data set condit depend independ at tribut noisi incomplet multiclass data set myopia current induct learn system partial overcom replac exist heurist function reli eff accept increas comput complex may certain domain payoff eventu discoveri strong condit depend attribut cannot detect use myopic impur measur guid greedi search experiment result indic major real world problem myopia margin effect one may wonder whether myopia realli worth much attent all howev face new data set unreason tri myopic algorithm unless know advanc data set strong condit depend attribut seriou applic machin learn new data tri discov much regular data po sibl therefor nonmyop approach one describ paper use indispens tool analys data acknowledg use mestim equat propos bojan cestnik thank matjaz zwitter prim brea data set milan soklic lymp gail gong hepa padhraic smyth bool led saso dzeroski krk mesh bob hen eri diab heart sat data set statlog databas strathclyd univers patrick murphi david aha data set irvin databas grate colleagu saso dzeroski matevz kovac matjaz kukar uro pomp tanja urbanc anonym review comment earlier draft significantli improv paper work support slovenian ministri scienc technolog r wadsworth intern group estim probabl crucial task machin learn estim probabl tree prune assist gener statist applic induct logic program finit element mesh de sign handl nois induct logic pro gram use contextu inform featur rank discret experi in duction practic approach featur select featur select prob lem tradit method new algorithm induct bayesian learn medic diagnosi bias estim multivalu attribut inform base evalu criterion classifi perform id revisit distanc base criterion attribut select learn told learn exampl experiment comparison two method knowledg acquisit context develop expert system soybean diseas diagnosi combinatori optim induct concept learn uci repositori machin learn databas learn decis rule noisi domain linear space induct first order logic relieff induct decis tree minimum descript length principl categor theori lookahead featur construct learn hard concept learn complex realworld conceptsthrough featur construct construct induct decis tree rule induct use inform theori tr ctr xin jin rongyan li xian shen rongfang bie automat web page categor relieff hidden naiv bay proceed acm symposium appli comput march seoul korea use contextu inform featur rank discret ieee transact knowledg data engin v n p septemb marko robnikikonja igor kononenko theoret empir analysi relieff rrelieff machin learn v n p octobernovemb david a bell hui wang formal relev applic featur subset select machin learn v n p novemb llu mrquez llu padr horacio rodrguez machin learn approach po tag machin learn v n p april saher esmeir shaul markovitch anytim learn decis tree journal machin learn research p huan liu hiroshi motoda lei yu select sampl approach activ featur select artifici intellig v n p novemb foster provost venkateswarlu kolluri survey method scale induct algorithm data mine knowledg discoveri v n p june