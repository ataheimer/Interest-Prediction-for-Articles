t adapt sampl method scale knowledg discoveri algorithm a scalabl key requir kdd data mine algorithm one biggest research challeng develop method allow use larg amount data one possibl approach deal huge amount data take random sampl data mine it sinc mani data mine applic approxim answer accept howev argu sever research random sampl difficult use due difficulti determin appropri sampl size paper take sequenti sampl approach solv difficulti propos adapt sampl method solv gener problem cover mani actual problem aris applic discoveri scienc algorithm follow method obtain exampl sequenti onlin fashion determin obtain exampl whether alreadi seen larg enough number exampl thu sampl size fix priorisemi instead iadapt depend situat due adapt worst case situat fortun happen mani practic applic solv problem number exampl much smaller requir worst case prove correct method estim effici theoret illustr use consid one concret task requir sampl provid algorithm base method show effici experiment b introduct scalabl key requir knowledg discoveri data mine algorithm previous observ mani well known machin learn algorithm scale well therefor one biggest research challeng develop new method allow use machin learn techniqu larg amount data face problem huge input data set typic two possibl way address it one way could redesign known algorithm that almost maintain perform run ecient much larger input data set second possibl approach random sampl data mine applic approxim answer accept thu could take random sampl instanc space data mine it howev argu research see instanc approach less recommend due diculti determin appropri sampl size need paper advoc second approach reduc dimension data random sampl thi propos gener problem cover mani data mine problem gener sampl algorithm solv it typic task knowledg discoveri data mine nd rule law explain huge set exampl well often case size possibl candid rule still manag task simpli select rule among candid certain util dataset problem discuss paper call gener rule select specic given input data set x exampl set h rule util function u measur use rule x problem nd nearli best rule h precis h satisfi uh uh h best rule given accuraci paramet though simpl problem cover sever crucial topic knowledg discoveri data mine shown section would like solv gener rule select problem random sampl statist point view problem solv take rst random sampl domain x select h h largest uh s choos enough number exampl x randomli guarante select h nearli best within certain condenc level refer simpl method batch sampl approach one import issu random sampl choos proper sampl size ie number exampl sampl method must take account problem paramet accuraci paramet condenc paramet determin appropri sampl size need solv desir problem non theoret sound sampl method like take xed fraction data set wide use empir machin learn research appropri data mine amount data avail huge moreov method take account accuraci condenc consider therefor discuss here wide use theoret sound tool determin appropri sampl size given accuraci condenc paramet call concentr bound larg deviat bound like cherno hoed bound commonli use theoret learn research see exampl well mani branch comput scienc exampl sampl size calcul concentr bound data mine problem see eg bound usual allow us calcul sampl size need mani situat usual case result sampl size immens obtain reason good accuraci condenc moreov situat appli bound need assum knowledg certain problem paramet unknown practic applic import notic that batch sampl approach sampl size calcul priori thu must big enough work well situat might encount word sampl size provid theoret bound batch sampl approach worst case sampl size thu overestim situat one main reason research found that practic bound overestim necessari sampl size mani non worstcas situat see eg discuss toivonen sampl associ rule discoveri overcom problem propos paper sampl onlin sequenti fashion instead batch is algorithm obtain exampl sequenti one one determin obtain exampl whether alreadi receiv enough exampl issu current best rule nearli best high condenc thu x sampl size priori instead sampl size depend adapt situat hand due adapt worst case situat fortun happen practic case may abl use signicantli much less exampl worst case follow approach propos gener algorithm adaselect solv gener rule select problem provid us ecient tool mani knowledg discoveri applic gener algorithm evolv preliminari work onlin adapt sampl specic problem relat model select associ rule done idea adapt sampl quit natur variou method implement idea propos literatur statist particular method studi depth name sequenti test sequenti analysi howev main goal test statist hypothes thu even though method applic instanc gener rule select problem far author know method reliabl ecient adaselect gener rule select problem use simpl exampl explain next section dierenc advantag adaselect relat algorithm includ one follow batch sampl approach paper organ follow next section explain still intuit level advantag algorithm random sampl method section present problem algorithm prove theorem concern reliabl complex section describ sever applic algorithm particular data mine problem improv might use studi particular situat describ section conclud section highlight futur work relat work idea determin number necessari exampl adapt therebi reduc averag number exampl quit natur method implement idea propos literatur statist method call sequenti test sequenti analysi sinc a wald publish pioneer textbook sequenti analysi mani research studi sequenti analysi method depth main goal been howev test statist hypothes thu even though method applic purpos is evalu andor compar valu given function given huge dataset method far author know reliabl ecient gener algorithm adaselect illustr dierenc adaselect method let us consid follow simpl problem need simpl util function problem test whether probabl p given condit c hold accord wald textbook idea sequenti test procedur goe back hf dodg hg romig databas x not c held exactli transact x would check databas notic it thu let us suppos intuit condit hold mani transact for instanc databas sampl small number transact enough gure answer posit neg hand closer transact condit hold dicult test sampl correct answer use adaselect solv problem follow keep two function h h map transact valu given one transact x h x output transact x satis condit c otherwis h x output hand h negat h util function use uh is dierenc posit neg half proport transact purpos algorithm need detect whether uh posit in case neg thu need x number less run algorithm set would abl determin high condenc whether condit c occur transact x notic applic adaselect alway solv problem matter small far hand sampl complex the number necessari exampl depend henc algorithm might requir lot transact small specic number transact need sampl databas o ln ignor factor depend condenc paramet therefor closer valu and thu p larger number exampl need be batch sampl approach also applic problem use appropri larg deviat bound eg cherno bound determin number exampl sucient detect high condenc whether condit hold x notic choos appropri sinc high condenc algorithm guarante hand number exampl need o therefor use smaller underestim sampl complex becom larg word batch sampl approach alway big enough cover possibl valu bigger thu depend sinc worst case might equal hand adaselect depend case hand thu sampl size depend moreov practic applic might unrealist assum assum knowledg lower bound quantiti want estim clearli see advantag algorithm simpl batch sampl sophist way solv problem could follow instead use cherno bound that provid estim within multipl error probabl estim thu adequ purpos cannot use unless lower bound known use hoed bound also usual refer addit version cherno bound sampl size provid bound independ probabl estim thu need assum knowledg lower bound hand estim guarante within addit error valu estim therefor gener imposs use one singl sampl guarante problem solv instead follow suppos run batch sampl calcul appropri size hoed bound obtain estim p p high probabl p satisfi thu p greater determin with high condenc p greater hand p less determin p less howev p rang is p cannot conclud anyth whether p last situat occur choos small enough sampl complex becom larg underestim one way solv problem iter execut algorithm smaller accuraci paramet obtain estim safe rang case exampl run algorithm continu process obtain estim ith iter rang i i suppos algorithm alway give close estim p routin calcul show algorithm termin log iter approach use o exampl obtain close estim ignor factor depend condenc paramet everi step henc altogeth need o give order adaselect fact roughli speak idea adaselect hand adaselect iter phase natur incorpor thu adaselect better sampl complex furthermor easi gener techniqu estim andor compar gener function valu method sampl describ refer classic statist multipl sampl one earlier work sequenti sampl method recent work adapt sampl come databas commun due lipton etal follow problem discuss given databas queri databas for instanc select joint want estim queri size is number transact associ queri databas certain error condenc level design algorithm task refer algorithm adapt estim specic given databas x condit c accuraci paramet condenc paramet adapt estim estim through random sampl probabl p transact multipl error is probabl least algorithm yield estim p p p p achiev task adapt estim collect exampl databas sequenti random check whether collect exampl sucient termin execut current estim number exampl use algorithm depend correct algorithm prove use larg deviat tool particular use central limit theorem thu word adapt estim sequenti version multipl cherno bound howev import notic adapt estim work estim total probabl exampl provid us multipl estim p approach quit similar adapt estim algorithm adaselect propos also collect exampl given databas sequenti random check whether collect exampl sucient furthermor also use one larg deviat tool order guarante correct ie reliabl output algorithm thu one may think superci adaselect dier adapt estim point enabl us estim gener valu ie valu user dene util function fact could estim advantag instead p exampl note dierenc essenti exampl problem adapt estim exactli problem batch sampl method hoed bound thu cannot use gener must use iter describ befor also remark choic util function u import use uh problem execut adaselect becom essenti adapt estim technic due gener stop condit sampl algorithm monoton requir care probabl analysi order keep explan intuit level explain typic algorithm omit detail dierenc algorithm see paper cite detail algorithm adaselect present paper evolv previou work hypothesi select sampl associ rule fact two case treat simpl case gener util function introduc paper algorithm present paper greatli gener adapt algorithm provid use attack sever problem adapt sampl algorithm section formal describ problem would like solv present algorithm investig reliabl complex begin introduc notat let larg set exampl let nite larg set n function thought function evalu exampl x produc real valu result intuit h h correspond rule law explain exampl call rule measur good rule x in follow identifi h correspond rule usual call h rule exampl task predict particular boolean featur exampl x term featur could set featur predict correctli h predict incorrectli also assum xed realvalu nonneg util function uh measur global good rule correspond to h set x specic x uh s dene f function ir ir avg denot take arithmet averag ie ii jij uh simpli dene uh x section describ sever applic framework u instanti specic function mean becom clear readi state problem gener rule select given x h goal find h h uh rule maximum valu uh remark accuraci paramet intuit task nd h h whose util reason high compar maximum uh accuraci uh uh speci paramet certainli closer uh uh better howev depend choic u accuraci essenti case may abl use larg advantag algorithm becom clear case recal exampl discuss section see also discuss end section remark condenc paramet want achiev goal random sampl ie use exampl randomli select x must chanc select bad exampl make algorithm yield unsatisfactori h h thu introduc one paramet specifi condenc requir probabl error bound remark condit h order simplifi discuss assum follow valu hx hx d constant from on denot constant remark condit u goal make sens uh neg thu assum uh posit also order ani sort of random sampl work cannot happen singl exampl chang drastic valu u otherwis would forc look exampl x even approxim valu uh thu requir function f dene u smooth formal f need clipschitz constant c dene below from on c denot lipschitz constant f denit function f ir ir clipschitz x hold jf x f yj c jx yj lipschitz constant f minimum c f clipschitz if ani observ lipschitz function continu dierenti function bound deriv lipschitz fact f dierenti mean valu theorem lipschitz constant f max x jf xj see section natur function use applic describ satisfi condit c also note condit cd uh cd h h remark minim problem situat primari goal might maxim util function data minim penalti function p is want nd h p h solv gener hypothesi select problem algorithm analysi similar one present here end remark one trivial way solv problem evalu function h h exampl x x henc comput uh h nding h maxim valu obvious x larg method might extrem ineci want solv task much ecient random sampl is want look fairli small randomli drawn subset x nd h maxim uh s still sure probabl h output satis uh uh one easili think follow simpl batch sampl approach obtain random sampl x priori xed size output function h highest util s sever statist bound calcul appropri number exampl paper choos hoed bound wide use comput scienc see eg one use reason bound here choos one use determin consid reliabl ecienc reason choos hoed bound basic assumpt necessari use bound estim error probabl calcul sampl size hand bound exampl central limit theorem might appropri practic situat sinc behav better although slighlti less reliabl easi modifi algorithm analyz altern bound roughli sampl size error valu hoed bound provid us upper bound probabl estim calcul randomli drawn sampl apart real valu thu use bound determin sampl size guarante batch sampl yield rule satisfi requir problem probabl least batch sampl solv problem ecienc satisfactori choos sampl size worst case overcom ineci take sequenti sampl approach instead static decid sampl size new algorithm obtain exampl sequenti one one stop accord condit base number exampl seen valu function exampl seen far is algorithm adapt situat hand thu worst case algorithm would abl realiz stop assumpt obtain sampl independ obtain distribut natur assumpt hold problem consid here algorithm repeat x randomli drawn exampl x constant close see proof theorem output h h largest uh figur pseudocod onlin sampl adaselect figur show pseudocod algorithm propos call adaselect solv gener rule select problem provid two theorem discuss reliabl complex algorithm adaselect proof make use follow lemma lemma let x set size obtain independ draw element x random h h proof let g valu avgi hx x x g random variabl avgi s observ use fact f clipschitz prf jg egj c g g averag independ random variabl rang bound d hoed bound probabl less exp claim end proof rst prove reliabl algorithm adaselect theorem probabl adaselectx h output function h h uh uh proof xed dene h g show function output adaselectx h h bad probabl less is want bound follow error probabl p error regard one repeatloop iter basic step algorithm measur algorithm run time term number repeatloop iter use denot number execut repeatloop iter particular let integ follow inequ hold note strictli decreas function t henc uniqu determin see below algorithm termin th step ie th repeatloop iter high probabl deriv bound consid follow two case case h h bad satis stop condit repeatloop th step case satisfi stop condit rst step clearli whenev algorithm make error one case certainli occur thu bound probabl either case case occur bound error probabl p error algorithm first bound probabl case let h bad rule h bad largest util case hold g prf h satis stop condit adaselect tth step g stop condit adaselect tth step g g t p t bound follow use fact uh uh uh bad lemma thu estim case hold g n exp next consid case clearli case impli uh thu probabl case bound follow bound p rst estim let b use assumpt uh fact uh cd henc may consid b therefor b p bound follow nt summari b probabl either case case hold bound end proof next estim run time algorithm regard one repeat loop iter basic step algorithm measur algorithm run time term number repeatloop iter exactli number requir exampl proof alreadi show probabl algorithm termin within step is case occur thu follow theorem immedi proof theorem probabl adaselectx h halt within step in word adaselectx h need exampl largest integ let us express conveni form recal then sinc approxim approxim x ln x x ln y cd let us discuss mean formula sinc n within log func tion uenc complex small word handl rel larg number rule requir high condenc without increas much sampl size need main term formula cduh recal uh cd h h henc cduh least depend choic u case may assum cduh larg or case may need small thu larg adaselect perform well latter case specic adaselect show advantag u chosen rel larg sucient though cduh bound gener larg lucki case happen often bad case see section clever choic u might allow us choos larg overal number exampl might larg exampl applic section describ two domain instanc algorithm use solv particular problem two domain studi model hypothesi select induct decis tree due space limit cannot describ possibl applic problem like associ rule mine which alreadi studi subgroup discoveri batch sampl method base larg deviat method alreadi propos speed comput process see instanc and algorithm also appli order instanti framework particular problem need specifi mean function class h util function u condit condit u satis follow problem model hypothesi select typic applic framework class function h seen xed set hypothes model set could obtain instanc dierent run rival learn algorithm learn algorithm dierent input paramet architectur could contain sever dierent memorybas hypothesi xed certain restrict model space consequ design decis notic later case case algorithm tri select hypothesi simpl small class hypothes for instanc decis stump amplifi precis use vote method like boost thu rest discuss assum class h xed nite tractabl size util function captur criterion good hypothesi typic one predict error order keep discuss simpl level assum hypothes binari good criteria predict error case one might naiv set util function ident function is uh notic howev worst possibl predict error answer ip random coin henc precis speak good hypothesi h measur advantag random guess thu want algorithm output hypothesi whose advantag random guess close best possibl advantag class fact set ts particularli well vote method like adaboost typic one need obtain hypothesi better random guess everi step purpos set uh particular select hypothesi vote method choic may import set constant smaller similar set previous studi maron moor propos algorithm call hoed race acceler model select idea discard hypothes clearli go among best one criteria discard base invert hoed bound refer reader paper detail clearli add featur algorithm without compromis reliabl complex possibl acceler total run time notic combin hoed race algorithm reduc much number exampl need sinc depend logarithm number model n might greatli reduc comput time depend linearli n follow research moor lee develop ecient version hoed race base bayesian approach assumpt model accuraci dataset normal distribut furthermor also introduc modic discard model almost indistinguish other thu allow race output model best class notic also accuraci paramet framework allow one use complic util function could incorpor size smooth consider togeth predict error case realvalu function could also consid instanc mean squar error decis tree induct algorithm decis tree induct typic work choos test root certain node function class and subsequ root subtre explor train data choos one best accord certain split criteria like entropi measur gini index larg dataset could possibl reduc train time choos split base subsampl whole data musick catlett russel describ algorithm implement idea choos sampl base dicult decis node typic algorithm use small sampl root node enlarg progress tree grow here propos altern way select appropri sampl size need everi node use instanti algorithm describ follow follow notat simplic assum want construct decis tree approxim unknown function use train data set x furthermor assum class node function f xed priori nite small instanc input variabl negat fact class commonli use standard softwar packag c cart final denot g split criteria use topdown decis tree induct algorithm typic exampl function binari entropi let decis tree whose intern node label function f node label valu f g let l leaf want make new intern node substitut leaf l function h f goal choos function h valu g origin tree that is sum valu g everi leaf weight probabl reach leaf decreas substitut l h assumpt make sens attribut discret discret priori label new label l l accord major class instanc reach l l respect formal let set instanc reach l x h f denot p probabl fx p probabl hx p probabl hx fx p probabl hx fx notic probabl taken distribut induc initi distribut train set typic assum uniform distribut thu given leaf l given s goal nd function h maximum valu t l h t l denot h function mention larg dataset ecient way attack problem follow given tree leaf l take sampl x output function h highest valu t l h sampl sampl size chosen appropri valu t l h h function output algorithm close t l h appli algorithm use appropri amount data follow use f h t l h uh x remain determin constant c lipschitz condit u notic u addit three g function dierent input thu g lipschitz certain constant c u state obtain lipschitz constant g leav reader calcul appropri constant whole function u gq gini index deriv g thu mean valu theorem lipschitz constant gq binari entropi hq improv split criterion present deriv bound rang therefor cannot xed constant work possibl valu howev suppos ignor input valu close consid instanc interv function lipschitz constant interv notic input function g estim sampl thu assumpt make sens sinc admit certain error valu thu run algorithm input h u discuss desir accuraci condenc level algorithm output probabl larger node function h t l h t again crucial point choic precis speak t l h denit uh x easi see algorithm also work situat u moreov accord result h t l h t suce reduc overal error whole tree ad new intern node thu x inform describ anoth possibl applic algorithm problem decis tree induct problem nding good cut point continu attribut order discret it case everi function h repres possibl cut point even though total number cut point innit notic need consid cut point appear dataset set consid thu k them k size x although x might big notic bound given theorem depend logarithm size h thu particular applic size x give us upper bound size h furthermor notic run algorithm need function h priori everi time new exampl reveal new possibl cut point add new function class calcul util function exampl seen far util function case split criterion use compar split function describ abov thu algorithm problem would choos almost optim respect split criterion cut point particular continu attribut done use attribut discret attribut decid attribut use label node build improv section describ improv incorpor main algorithm adaselect complet rigor justic other seem intuit clear harder captur form theorem use multipl cherno bound instead addit hoed bound develop algorithm adaselect use hoed bound deviat averag valu appear addit case also possibl use cherno bound deviat appear multipl proof slightli involv appli cherno seem requir previou knowledg expect valu util function precis tri estim care also adapt applic let us circumv problem util function particular done case f ident function plu minu constant problem model hypothesi select case use cherno clear advantag case small probabl precis bound number exampl o depend uh linear instead quadrat although seem asymptot better hidden constant bigger precis thu happen better uh consid varianc case may true valu hx alway d moder d larg probabl version hoed call berstein bound that instead assumpt incorpor varianc hx bound estim varianc known plug adaselect may give quit advantag use worstcas constant d adapt local lipschitz constant bound depend constant c global lipschitz constant f howev mani region much smaller constant may enough bound growth rate f consid exampl entropi style function discuss decisiontre induct saw appropri choic c around probabl near howev probabl near quit common case function almost at ie c much closer suce practic one probabl use step worstcas lipschitz constant within uncertainti interv uh ie uh dicult give rigor analysi new version intuit clear may result signic improv essenti aect reliabl conclud remark present new methodolog sampl that keep theoret guarante previou one applic wider set moreov like use practic key point that rather decid priori sampl size obtain batch algorithm perform sampl sequenti maintain stop condit depend problem hand futur work verifi advantag approach experiment although theorem provid paper suggest algorithm might ecient applic sever domain still plenti work test whether assert true not one hand algorithm take prot non worst case situat therefor like outperform usual batch sampl approach hand asymptot alon guarante practic sinc huge constant might spoil advantag sampl use data even ecient sampl algorithm use test second point preliminari work use synthet data could test wide rang valu result promis sampl size use method greatli outperform one use batch approach moreov sampl size wa mani case reason small suggest reduc data size sampl algorithm might allow us improv overal run time experiment result although dierent context also encourag case remain experi use real world data test real practic algorithm furthermor point sever improv one might perform appli algorithm particular situat due gener approach everi applic deserv individu deeper studi see possibl enhanc one particular set acknowledg would like thank heikki mannila point us work sampl databas queri estim encourag us follow previou research adapt sampl would also like thank chri watkin tell us hoed race pedro domingo point us sever relat machin learn paper r multipl sampl constant probabl method sampl inspect ricard gavald ricard gavald decisiontheoret gener onlin learn applic boost boost abil topdown decis tree learn algorithm introduct comput learn theori power sampl knowledg discoveri je random algorithm decis theoret subsampl induct larg databas sampl larg databas associ rule sequenti analysi bala iyer je algorithm multirel discoveri subgroup tr ctr geoff hulten pedro domingo mine complex model arbitrarili larg databas constant time proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli edmonton alberta canada szymon jaroszewicz tobia scheffer fast discoveri unexpect pattern data rel bayesian network proceed eleventh acm sigkdd intern confer knowledg discoveri data mine august chicago illinoi usa osamu watanab sequenti sampl techniqu algorithm learn theori theoret comput scienc v n p decemb huan liu hiroshi motoda issu instanc select data mine knowledg discoveri v n p april jaekyung yang sigurdur olafsson optimizationbas featur select adapt instanc sampl comput oper research v n p novemb pierrealain laur richard nock jeanemil symphor pascal poncelet mine evolv data stream frequent pattern pattern recognit v n p februari