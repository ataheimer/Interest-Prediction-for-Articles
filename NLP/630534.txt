t scalabl featur mine sequenti data a classif algorithm difficult appli sequenti exampl text dna sequenc vast number featur potenti use describ exampl past work featur select focus search space subset avail featur intract larg featur set author adapt data mine techniqu act preprocessor select featur standard classif algorithm naiv bay winnow appli algorithm number data set experiment show featur produc algorithm improv classif accuraci b introduct mani real world dataset contain irrelev redund attribut may data collect without data mine mind attribut depend known priori data collect well known mani data mine method like classif cluster etc degrad predict accuraci train dataset contain redund irrelev attribut featur select right featur set improv accuraci also reduc run time predict algorithm lead simpler understand model good featur select thu one fundament data preprocess step data mine research featur select todat focus nonsequenti domain problem may defin select optim featur subset size full ddimension featur space ideal d select subset maxim optim criterion classif accuraci faith captur origin data distribut subset search space exponenti larg number featur contrast tradit nonsequenti data focu sequenc data exampl repres sequenc event event might describ set predic ie deal categor sequenti domain exampl sequenc data includ text dna sequenc web usag data multiplay game plan execut trace sequenti domain featur order set partial event descript exampl sequenti featur describ chess game black move knight white move bishop squar d featur hold chess game other thu might use classifi chess game into exampl one play expert vs one play novic select right featur sequenti tempor domain even challeng nonsequ data origin featur set undefin potenti infinit number sequenc arbitrari length categor attribut dimens even restrict maximum sequenc length k potenti od k subsequ dimens complex consid maximum subsequ length d oppos nonsequenti case goal featur select sequenti domain select best subset sequenti featur k possibl sequenti featur ie subsequ compos attribut describ individu event motiv use data mine techniqu set possibl featur exponenti larg altern concept problem construct new featur primit describ event new featur augment dimension origin space effect pull apart exampl class make easili distinguish classif algorithm cours process construct featur primit equival process select featur space combin primit input system set label train sequenc output function map new sequenc label word interest select or construct featur sequenc classif order gener function algorithm first use sequenc mine portion train data discov frequent distinct sequenc use sequenc featur feed classif algorithm winnow naiv bay gener classifi remaind data past work rule produc data mine algorithm use construct classifi primarili order rule decis list eg merg gener rule occur train data eg paper convert pattern discov mine algorithm set boolean featur feed standard classif algorithm classif algorithm turn assign weight featur allow evid differ featur combin order classifi new exampl two main contribut paper first combin two power data mine paradigm sequenc mine effici search pattern correl target class classif algorithm learn weigh evid differ featur classifi new exampl second present scalabl featur mine algorithm handl larg dataset thousand item million record addit present criteria select featur present prune rule allow effici mine featur present featuremin scalabl algorithm capabl handl larg diskresid dataset mine good sequenti featur integr prune constraint algorithm itself instead postprocess enabl effici search larg pattern space exampl poker let first preview main idea paper simpl illustr exampl suppos observ three peopl play poker bet sequenc outcom as exampl p bet p call p rais p rais p fold p call p win exampl p pass p bet p fold p rais p rais p call p win object learn function predict like win given bet sequenc task resembl standard classif given label train exampl must produc function classifi new unlabel exampl mani classifi requir howev exampl repres vector featurevalu pair paper address problem select featur repres bet sequenc first consid obviou poor featur set let n length longest bet sequenc repres bet sequenc n featur gener distinct featur everi n person made ith bet type ith bet amount ith bet section show experiment featur set lead poor classif one problem featur individu featur express particular complet bid sequenc took place interest subsequ occur as featur featur dollar first featur would import p tend win whenev rais twice classifi could construct boolean express featur describ captur notion p rais twice express would disjunct sinc need disjunct p rais ith bet jth believ import consid partial specif difficult know advanc whether p rais twice p rais rais use featur altern use much larger featur set player bid differ amount specif bet someon bet chain partial specif togeth and then relat p rais someon bet number featur length k k problem featur set larg set featur consid larg classif algorithm furthermor irrelev redund featur reduc classif accuraci adopt middl ground two extrem use data mine techniqu search second huge featur set select subset show criteria similar use gener knowledg discoveri task work well decid featur use data mine featur formul present algorithm featur mine formul involv specifi languag featur express sequenc partial descript event with gap p rais later bid fold present criteria select subset featur use classif entir set express languag final describ featuremin algorithm effici mine featur select criteria begin adopt follow terminolog close resembl use sequenc mine eg let f set distinct featur finit set possibl valu let contain uniqu element everi possibl featurevalu pair sequenc order list subset exampl fa b cg exampl sequenc would ab bc sequenc denot sequenc element subset length sequenc width maximum size n say subsequ denot exist integ j exampl ab c subsequ ab bc let h set class label exampl pair h ci sequenc c h label exampl uniqu identifi eid timestamp occur exampl h ci said contain sequenc input databas consist set exampl mean data look multipl sequenc compos set item frequenc sequenc d denot fr d fraction exampl contain let sequenc c class label confid rule c denot conf c d condit probabl c label exampl given contain sequenc is conf c c subset exampl class label c sequenc said frequent frequenc userspecifi min freq threshold rule said strong confid userspecifi min conf threshold goal mine frequent strong pattern figur show databas exampl exampl belong class c belong class c gener two class look differ min freq sequenc class exampl c frequent class c frequent class c rule c c confid rule confid sequenc classifi function sequenc class label h classifi evalu use standard ba aa eid c time c ac class c exampl new boolean featur class eid figur exampl b new databas boolean featur metric accuraci coverag final describ frequent sequenc n use featur classif recal input standard classifi exampl repres vector featurevalu pair repres exampl sequenc vector featurevalu pair treat sequenc boolean featur true iff exampl suppos featur f sequenc ab bd bc would repres hf truei hf falsei sequenc abcd would repres truei note featur skip step featur bc hold ab bd bc figur b show new dataset creat frequent sequenc exampl databas in figur a use frequent sequenc featur exampl gener use good subset frequent sequenc featur describ below select criteria mine specifi select criteria select featur use classif object find sequenc repres exampl sequenc yield highli accur sequenc classifi howev want search space subset featur instead want evalu new sequenti featur isol pairwis comparison candid featur certainli criteria select featur might depend domain classifi use believ howev follow domainandclassifi independ heurist use select sequenc serv featur featur frequent featur distinct least one class featur set contain redund featur intuit behind first heurist simpli rare featur can definit rare use classifi exampl problem formul heurist translat requir featur minimum frequenc train set note sinc use differ min freq class pattern rare entir databas still frequent specif class ignor pattern rare class intuit second heurist featur equal like class help determin class exampl belong to cours conjunct multipl nondistinct featur distinct case algorithm prefer use distinct conjunct featur rather non distinct conjunct encod heurist requir select featur significantli correl least one class frequent in motiv third heurist two featur close correl other either use classif are show reduc number featur time need mine featur prune redund rule addit want prune featur provid inform also want prune featur anoth featur avail provid strictli inform let mfd set exampl contain featur f say featur f subsum featur respect predict class c data set iff mf intuit f subsum f class c f superior f predict c f cover everi exampl c train data f cover f cover subset nonc exampl f cover note featur f better predictor class c f even f cover exampl c f if exampl everi exampl f cover c half exampl f cover c case neither featur subsum other third heurist lead two prune rule first prune rule extend ie special featur accuraci let f featur contain exampl one class special f may pass frequenc confid test definit featur mine subsum f follow lemma follow definit subsum justifi prune rule respect class c next prune rule concern correl individu item recal exampl repres sequenc set say exampl b occur everi set everi sequenc occur follow lemma state b featur contain set b subsum one gener lemma let subsum precomput set b relat immedi prune featur search contain set b section discuss b relat aris show crucial success approach problem defin featur mine task input featuremin algorithm set exampl paramet min freq maxw max l output nonredund set frequent distinct featur width maxw length max l formal featur mine given exampl paramet min freq maxw max l return featur set f everi featur f everi class c d significantli greater jd c jjdj f contain f contain featur subsum f respect class c j data set we use chisquar test determin signific effici mine featur present featuremin algorithm leverag exist data mine techniqu effici mine featur set train exampl sequenc mine algorithm design discov highli frequent confid pattern sequenti data set well suit task featuremin base recent propos spade algorithm fast discoveri sequenti pattern spade scalabl diskbas algorithm handl million exampl sequenc thousand item consequ featuremin share properti well construct featuremin adapt spade algorithm search databas label exampl featuremin mine pattern predict class databas simultan oppos previou approach first mine million pattern appli prune postprocess step featuremin integr prune techniqu mine algorithm itself enabl search larg space previou method would fail featuremin use observ subsequ relat defin partial order sequenc say gener specif relat monoton special relat respect frequenc fr d ie frequent sequenc subsequ also frequent algorithm systemat search sequenc lattic span subsequ relat gener specif sequenc depthfirst manner figur show frequent sequenc exampl databas eid suffixjoin idlist time time time time aa ba bb ac intersect ab bb intersect b figur frequent sequenc lattic frequenc comput frequenc comput featuremin use vertic databas layout associ item x sequenc lattic idlist denot lx list exampl id eid event time time pair contain item figur show idlist item b given sequenc idlist determin support ksequenc simpli intersect idlist two k length subsequ check cardin result idlist tell us whether new sequenc frequent not two kind intersect tempor equal exampl figur show idlist b obtain perform tempor intersect idlist b ie lb done look if within eid occur b list occurr hand idlist obtain equal intersect ie lab b check see two subsequ occur within eid time addit detail found also maintain class index tabl indic class exampl use tabl abl determin frequenc sequenc class time exampl occur eid f g howev eid f g label c f g label c thu frequenc c c class frequenc pattern shown frequenc tabl use limit amount mainmemori featuremin break sequenc search space small independ manag chunk process memori accomplish via suffixbas partit ing say two k length sequenc equival class partit share common k length suffix partit fa b cg base length suffix call parent partit parent partit independ sens complet inform gener frequent sequenc share suffix exampl class x element possibl frequent sequenc next step obviou item q lead frequent sequenc suffix x unless qx q x also x parent partit p enumeratefeaturesp element element ruleprun maxw accuracyr return true return fals figur featuremin algorithm featur enumer featuremin process parent partit depthfirst manner shown pseudocod figur input procedur partit along idlist element frequent sequenc gener intersect idlist distinct pair sequenc partit check cardin result idlist min supc sequenc found frequent class c current level form partit next level process repeat frequent sequenc enumer integr constraint featuremin integr prune constraint mine algorithm itself instead appli prune postprocess step shall show allow featuremin search larg space effici would infeas otherwis ruleprun procedur elimin featur base two prune rule also base length width constraint first prune rule test time extend sequenc new item exist effici onetim method appli b rule idea first comput frequenc length sequenc b remov ab suffix partit b guarante point futur ab appear togeth set sequenc empir evalu describ experi test whether featur produc system improv perform winnow naiv bay classif algorithm winnow multipl weightupd algorithm use variant winnow maintain weight w ij featur f class c j given exampl activ level class c j x featur f true exampl otherwis given exampl winnow output class highest activ level train winnow iter train exampl winnow classif train exampl agre label winnow updat weight featur f true exampl multipli weight correct class constant multipl weight incorrect class constant experi learn often sensit valu use chose valu base common literatur small amount experiment winnow actual use prune irrelev featur exampl run winnow larg featur set say throw away featur assign weight near howev practic sequenc classif sinc space potenti featur exponenti naivebay classifi featur f class c j naiv bay comput pf jc j fraction train exampl class c j contain f given new exampl featur f f n true naiv bay return class maxim p though naiv bay algorithm appear make unjustifi assumpt featur independ shown perform surprisingli well often well better c describ domain test approach discuss result experi random pariti problem first describ nonsequenti problem standard classif algorithm perform poorli problem everi featur true exactli half exampl class way solv problem discov combin featur correl differ class intuit construct problem gener n randomlyweight meta featur compos set actual observ featur pariti observ featur determin whether correspond meta featur true fals class label instanc function sum weight meta featur true thu order solv problem featuremin must determin observ featur correspond meta featur import discov meta featur higher weight one lower weight addit increas difficulti problem add irrelev featur bear class instanc formal problem consist n pariti problem size l distract irrelev featur everi boolean featur f ij addit k l irrelev boolean featur k gener instanc randomli assign relev irrelev boolean true fals probabl exampl instanc nml featur nml distinct instanc possibl instanc equal like also choos n weight w wn uniform distribut use assign instanc one two class label on off follow instanc credit weight w iff ith set featur even pariti is score instanc sum weight w number true featur f i f im even instanc score greater half sum weight instanc assign class label on otherwis assign off note featur indic class label off pariti problem hard classifi job featuremin essenti figur featur group togeth exampl featur produc featuremin result shown tabl includ f true f true f true f fals use min freq forest fire plan featuremin algorithm origin motiv task plan monitor stochast domain probabilist planner construct plan high probabl achiev goal task monitor watch plan execut predict advanc whether plan like succeed fail facilit replan order build monitor given plan goal first simul plan repeatedli gener execut trace label execut trace success failur depend whether goal hold final state simul use execut trace input featuremin plan monitor or monitor probabilist process simul attract area machin learn essenti unlimit suppli train data although cannot consid possibl execut path number path exponenti length plan process gener arbitrari number new exampl mont carlo simul problem overfit reduc test hypothes fresh data set exampl domain construct simpl forestfir domain base loos phoenix fire simul execut trace avail email contact leshmerlcom use grid represent terrain grid cell contain veget water base exampl terrain shown figur begin bbbb dd dd dd bbdbbd dbbd dbbd dbd bbbbwwwwww dbbd dbbd dd wwwwwwwwwwww wwwwww wwwwww wwwwww wwwwwwwwwwww wwwwww wwwwww wwwwww wwwwww www www www time figur ascii represent sever time slice exampl simul fire world domaina indic fire b indic base b indic bulldoz d indic place bulldoz dug fire line w indic water unburn terrain simul fire start random locat iter simul fire spread stochast probabl cell ignit time calcul base cell veget wind direct mani cell neighbor burn time addit bulldoz use contain fire exampl terrain handdesign plan bulldoz dig fire line stop fire bulldoz speed vari simul simul exampl simul look like time ignit x y time moveto bd x y time moveto bd x y time digat bd x y time ignit x y time ignit x y time digat bd x y time ignit x y time digat bd x y time ignit x y time ignit x y time ignit x y tag plan success none locat base burn final state failur otherwis train plan monitor predict time k whether base ultim burn includ event occur time k train exampl exampl featur produc featuremin domain are first sequenc hold bulldoz bd move second column time second hold fire ignit anywher second column bulldoz move third row time mani correl use second prune rule describ section aris data set exampl aris one test plan bulldoz never move eighth column fire data boolean featur describ event thu number composit featur search l experi report here use min experi winnow winnowtf winnowfm bay bayestf bayesfm pariti pariti pariti spell vs na na spell vs na na spell vs na na spell vs na na tabl classif result averag classif accuraci use differ featur set repres exampl legend tf use featur obtain time featur approach fm use featur produc featurem ine highest accuraci obtain featur produc featuremin algorithm standard deviat shown parenthes follow averag except spell problem one test train set use contextsensit spell correct also test algorithm task correct spell error result valid word substitut test chose two commonli confus word search sentenc millionword brown corpu contain either word remov target word repres word word itself partofspeech tag brown corpu posit rel target word exampl sentenc and polit translat wordand tagcc po wordthen tagrb po wordi tagbez po wordpolit tagnn po exampl featur produc featuremin includ po wordth indic word occur least word target word indic noun occur within three word target word featur for reason obviou us significantli correl either train set i vs me dataset train exampl test exampl featurevalu pair there vs their dataset train exampl test exampl featurevalu pair than vs then dataset train exampl test exampl featurevalu pair final your vs your dataset train exampl test exampl featurevalu pair n number featurevalu pair search n maxw experi report here use min result test pariti fire domain gener random train exampl mine featur exampl prune featur pass chisquar signific test for correl class featur frequent in exampl train classifi remain exampl test addit exampl result tabl averag test spell correct experi evalu select featur featur fire world time spell vs tabl mine result number featur consid return featuremin experi cpu second cpu second cpu second featur featur examin featur prune examin examin prune prune prune b prune prune random fire world hour spell tabl impact prune rule run time node visit featuremin without b prune result taken one data set exampl use exampl brown corpu roughli exampl per word set split by sentenc train test set mine featur sentenc train classifi entir train set tabl show featur produc featuremin improv classif perform compar use featur set produc featuremin use primit featur themselv ie featur length fire domain also evalu featur set contain featur primit featur time step thi featur set size n describ section winnow naiv bay perform much better featur produc featuremin pariti experi mine featur dramat improv perform classifi experi mine featur improv accuraci classifi signific amount often tabl show number featur evalu number return sever problem largest random pariti problem featuremin evalu million featur select fact million possibl featur there boolean featur give rise featurevalu pair search depth sinc reject implicitli prune rule tabl show impact b prune rule describ section mine time result one data set domain slightli higher valu max l maxw experi prune rule improv mine time case made tremend differ fire world prob lem event descriptor often appear togeth without b prune fire world problem essenti unsolv featuremin find million frequent sequenc relat work great deal work done featuresubset select motiv observ classifi perform wors featur set f f f eg algorithm explor exponenti larg space subset given featur set contrast explor exponenti larg set potenti featur evalu featur independ featuresubset approach seem infeas problem consid contain hundr thousand million potenti featur appli winnowbas algorithm contextsensit spell correct use set featur either use featur prune base classif accuraci individu featur obtain higher accuraci did approach howev involv ensembl winnow combin major weight took care choos good paramet specif task goal here demonstr featur produc featuremin improv classif perform data mine algorithm often appli task classif build decis list pattern found associ mine nonsequenti version sequenc mine addit previou work explor new method combin associ rule build classifi thrust work leverag augment standard classif algorithm prune rule resembl one use also employ data mine techniqu construct decis list previou work use data mine classif focus combin highli accur rule togeth contrast classif algorithm weigh evid mani featur low accuraci order classifi new exampl work close spirit also construct set sequenti boolean featur use classif algorithm employ heurist search algorithm call fgen increment gener featur cover train exampl base classif perform holdout set train data wherea perform exhaust search to depth accept featur meet select crite ria addit use differ featur languag test approach differ classifi have conclus shown data mine techniqu use effici select construct featur sequenti domain dna text web usag data plan execut trace domain challeng exponenti number potenti subsequ featur form primit describ item sequenc data number featur larg practic handl today classif algorithm furthermor featur set contain mani irrelev redund featur reduc classif accuraci approach search set possibl featur mine one frequent predict not redund adapt scalabl diskbas data mine algorithm abl perform search effici howev one three domain studi search practic due prune rule incorpor search algorithm experi sever domain show featur produc appli select criteria significantli improv classif accuraci particular shown construct problem classifi perform better random guess use origin featur perform near perfect accuraci use featur produc featuremin furthermor shown featur produc featuremin improv perform much simul fireplan domain spell correct data gener work show appli classif algorithm domain obviou small set featur describ exampl larg space combin primit featur probabl contain use featur futur work could involv appli idea classif of exampl imag audio signal r learn decis list use homogen rule integr classif associ rule mine mine audit data build intrus detect model greedi attribut select effici enumer frequent sequenc learn quickli irrelev attribut abound new linearthreshold algorithm pattern classif scene analysi beyond independ condit optim simpl bayesian cla sifier predict explain success task durat phoenix planner appli winnow contextsensit spell correct comput analysi presentday american english featur gener sequenc categor tr ctr xiaonan ji jame bailey guozhu dong mine minim distinguish subsequ pattern gap constraint knowledg inform system v n p april florenc duchn catherin garbay vincent riall learn recurr behavior heterogen multivari timeseri arifici intellig medicin v n p januari sanyih hwang chihp wei wanshiou yang discoveri tempor pattern process instanc comput industri v n p april sbastien ferr ross d king dichotom search algorithm mine learn domainspecif logic fundamenta informatica v n p januari moham j zaki charu c aggarw xrule effect algorithm structur classif xml data machin learn v n p februari chihm chen increment person web page mine util selforgan hcmac neural network web intellig agent system v n p januari chihm chen increment person web page mine util selforgan hcmac neural network web intellig agent system v n p august