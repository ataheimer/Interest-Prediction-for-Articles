t block distribut memori model a abstractw introduc comput model develop analyz parallel algorithm distribut memori machin model allow design algorithm use singl address space assum particular interconnect topolog captur perform incorpor cost measur interprocessor commun induc remot memori access cost measur includ paramet reflect memori latenc commun bandwidth spatial local model allow initi placement input data pipelin prefetchingw use model develop parallel algorithm variou data rearrang problem load balanc sort fft matrix multipl show algorithm achiev optim near optim commun complex simultan guarante optim speedup comput complex ongo experiment work test evalu algorithm thu far shown promis result b introduct parallel process promis offer quantum leap comput power like substanti impact variou aspect comput field particular exploit investig wide rang call grand challeng problem scienc engin wide recogn import ingredi success technolog emerg comput model use algorithm develop accur predict perform algorithm real machin take similar view comput model bridg model link two layer hardwar softwar exist comput model tend bias toward one layer except except bulk synchron parallel bsp model advoc valiant one except paper introduc comput model specif attempt bridg model share memori singl address program model distributedmemori messag pass architectur distribut memori system configur singl address space usual refer scalabl share memori multiprocessor machin achiev scalabl distribut memori architectur simpl program style provid singl address space model also use predict perform data parallel algorithm run distribut memori architectur sinc comput model predict perform real machin start discuss basi measur commun cost incur access remot data indic hardwar organ massiv parallel processor mpp seem converg toward collect power processor connect commun network model complet graph commun subject restrict impos latenc bandwidth properti network accord common or ganiz commun differ processor handl point topoint messag whose rout time control paramet relat network latenc processor commun bandwidth overhead prepar me sage network capac model avoid descript exact structur network sinc algorithm exploit specif featur network less like robust enough work well varieti architectur adapt easili possibl futur technolog chang howev program machin messagepass level impos heavi burden programm make algorithm develop evalu quit complic hand dataparallel sharedmemori program model appeal term eas use term close relationship sequenti program model assum singl address space block distribut memori bdm model introduc next section captur perform share memori singl address space algorithm incorpor cost measur interprocessor commun caus remot memori access cost model use latenc commun bandwidth processor sinc remot memori access involv transmiss packet typic contain number consecut word model encourag use spatial local incorpor paramet repres cost associ access consecut word cost incur even singl word need model allow initi placement input data includ memori latenc hide techniqu pipelin prefetch sinc measur amount local comput amount commun separ abl normal commun cost drop one paramet make analysi correspond algorithm simpler use model develop parallel algorithm variou data rearrang problem load balanc sort ing fast fourier transform fft comput matrix multipl show algorithm achiev optim near optim commun complex simultan guarante optim speedup comput complex next section provid detail model section describ collect algorithm handl data rearrang occur frequent share memori algorithm load balanc problem address section commun effici algorithm present section devot present effici algorithm sort fft matrix multipl result algorithm seem share common structur highperform algorithm test real machin block distribut memori bdm model comput model block distribut memori bdm defin term four paramet p oe m see later paramet oe drop without loss gener paramet p refer number pro cessor processor view unit cost random access machin ram addit processor interfac unit interconnect network handl commun among differ processor data commun processor via pointtopoint messag messag consist packet hold word consecut locat local processor memori sinc assum share memori program model request remot locat involv prepar request packet inject packet network recept packet destin processor final send packet contain content consecut locat includ request valu back request processor model cost handl request remot locat read write formula maximum latenc time take request processor receiv appropri packet oe rate processor inject receiv word from network moreov processor send receiv one packet time result note follow two observ first permut p element remot memori request issu processor destin processor p i complet moe time processor simultan second k remot access request issu k distinct processor destin processor requir k moe time complet addit make assumpt rel order request complet current interconnect network multiprocessor use sever hardwar softwar techniqu hide memori latenc model allow pipelin prefetch hide memori latenc particular k prefetch read oper issu processor complet underli commun model bdm consist logp postal model addit paramet incorpor spatial local howev model allow lowlevel handl messag pass primit except implicitli data access particular algorithm written model specifi initi data placement among local memori p processor use processor id refer specif data item use synchron barrier synchron activ variou processor whenev necessari remot data access charg accord commun model specifi abov synchron barrier make assumpt that bdm model provid primit oper two main reason make assumpt first barrier implement hardwar effici rel small cost second make latenc paramet larg enough account synchron cost result commun cost conserv side affect overal structur result algorithm complex parallel algorithm bdm model evalu term two measur comput time comp commun time tcomm measur comp refer maximum local comput perform processor measur standard sequenti ram model commun time tcomm refer total amount commun time spent overal algorithm access remot data main goal design parallel algorithm achiev optim nearoptim comput speedup is sequenti complex problem consider way total commun time tcomm minim sinc tcomm treat separ comp normal measur divid oe underli commun model bdm view postal model ad paramet reflect spatial local henc access oper remot locat take m time k prefetch read oper execut time note paramet view upper bound capac interconnect network ie upper bound maximum number word transit processor estim bound commun time make simplifi and reason assumpt integr multipl m believ local import factor taken consider design parallel algorithm larg scale multiprocessor incorpor paramet model emphas import spatial local notion processor local also seem import current multiprocessor architectur architectur tend hierarch henc latenc much higher access processor hierarchi close by featur incorpor model modifi valu reflect cost associ level hierarchi need use remot memori access done similar fashion memori hierarchi model studi sequenti processor howev paper opt simplic decid includ processor local consider sever model discuss literatur logp postal model refer earlier relat bdm model howev signific differ model model exampl asynchron pram block pram assum presenc share memori intermedi result held particular assum data initi store share memori make data movement oper consider simpler model anoth exampl direct connect machin dcm latenc use messag pass primit particular model allow pipelin prefetch bdm model basic algorithm data movement design commun effici parallel algorithm depend exist effici scheme handl frequent occur transform data layout section consid data layout specifi twodimension array a say size q theta p column contain subarray store local memori processor transform pi layout map element layout pia necessarili size present optim near optim algorithm handl sever transform includ broadcast oper matrix transposit data permut algorithm describ determinist except algorithm perform gener permut start address sever broadcast oper simplest case broadcast singl item number remot locat henc layout describ onedimension array assum element a copi remain entri a view concurr read oper locat a execut processor next lemma provid simpl algorithm solv problem later use algorithm deriv optim broadcast algorithm lemma given pprocessor bdm array a resid processor p j element a copi remain entri time proof simpl algorithm consist round pipelin rth round processor p j read aj a copi aj sinc round realiz prefetch read oper result commun complex readi follow theorem essenti establish fact kari balanc tree broadcast algorithm best possibl recal earlier made assumpt integr multipl m theorem given pprocessor bdm item processor broadcast remain processor d log p log e commun time hand broadcast algorithm use read write synchron barrier instruct requir least log p log m log p commun complex proof start describ algorithm let k integ determin later algorithm view kari tree root locat a dlog k pe round first round a broadcast locat use algorithm describ lemma follow synchron barrier second round element locat broadcast distinct set locat on commun cost incur round given therefor total commun cost tcomm set md log p log log e next establish lower bound state theorem broadcast algorithm use read write synchron barrier instruct view oper phase phase end synchron barrier whenev singl phase suppos phase amount commun execut phase least maximum number copi read processor phase i henc total amount commun requir least m note end phase i desir item reach remot locat follow that end phase s desir item reach processor must commun time m minim k logk commun time least logk complet proof theorem prove follow claim logk log m k proof claim let logk logk logk then case decreas f k increas rang claim follow easili note f log logarithm base unless otherwis state case show fk increas k r show note sinc k least larg posit nonzero integ valu k henc fk f claim follow sum p element pprocessor bdm comput d log p log e commun time use similar strategi base observ easi show follow theorem theorem given n number distribut equal among p processor bdm comput sum o n log time d log p log e commun time comput time reduc o n anoth simpl broadcast oper processor broadcast item remain processor oper execut minf time shown next lemma lemma given pprocessor bdm array a distribut one element per processor problem broadcast element processor done minf commun time proof bound follow simpl algorithm describ lemma p significantli larger m use follow strategi use previou algorithm processor element next block element broadcast circular fashion appropri d p processor one verifi result commun complex next data movement oper matrix transposit defin follow let q p let p divid q evenli without loss gener data layout describ suppos rearrang layout first column contain first qp consecut row laid row major order form second column contain second set qp consecut row a on clearli correspond usual notion matrix transpos effici algorithm perform matrix transposit bdm model similar algorithm report round fulli pipelin use prefetch read oper first round appropri block qp element ith column read processor p imodp appropri locat second round appropri block data column read processor p imodp on result total commun time given pm amount local comput oq clearli algorithm optim whenev pm divid q henc follow lemma lemma q theta p matrix transposit perform pprocessor bdm pm e bound reduc next discuss broadcast oper block n element resid singl processor p processor describ two algorithm first suitabl number n element rel small second suitabl larg valu n algorithm base circular data movement use matrix transposit algorithm detail given proof next theorem theorem problem broadcast n element processor p processor complet d log p log use kari balanc tree algorithm hand problem solv pm e commun time use matrix transposit algorithm proof first algorithm use kari tree singl item broadcast algorithm describ theorem use matrix transposit strategi distribut n element broadcast among k processor processor receiv contigu block size n k view p processor partit k group group includ exactli one processor contain block item broadcast procedur repeat within group on similar revers process gradual read n item processor forward backward phase carri use cyclic data movement matrix transposit algorithm one check commun time bound follow km log p log pm broadcast n element pm commun time use matrix transposit algorithm lemma twice distribut n element among p processor processor receiv block size second time circul block processor problem distribut n element singl processor solv use first half either two broadcast algorithm henc follow corollari corollari problem distribut n element one processor processor processor receiv n p element complet minfd log p log pm eg commun time final address follow gener rout problem let n array n element initi store one column per processor pprocessor bdm machin element consist pair datai index processor data reloc assum ff n element rout singl processor constant ff describ follow random algorithm complet rout o n comput time c constant larger maxf ffg complex bound guarante hold high probabl is probabl posit constant ffl long logarithm base e overal idea algorithm use variou random rout algorithm mesh follow close scheme describ random rout mesh bound queue size describ algorithm introduc terminolog use auxiliari array size cn theta p manipul data intermedi stage hold final output c ffg column held processor array divid p equal size slice slice consist cn consecut row henc slice contain set cn consecut element column set refer slot readi describ algorithm algorithm random rout input input array a n element consist pair datai processor index data rout processor destin ff n p element constant ff output output array hold rout data c constant larger maxf ffg begin processor p j distribut randomli n element p slot jth column jth slice store jth processor processor p j distribut local cn element everi element form i resid slot i perform matrix transposit henc jth slice layout gener end step resid p j next two fact allow us deriv complex bound random rout algorithm analysi assum lemma complet step number element slot cn high probabl c pproof procedur perform processor similar experi throw n bin henc probabl exactli cn ball place particular bin given binomi distribut use follow chernoff bound estim tail binomi distribut obtain probabl particular bin cn ball upper bound therefor probabl bin cn ball bound lemma follow lemma complet step number element processor destin processor cn high probabl ffproof probabl element assign jth slice end step henc probabl cn element destin singl processor fall jth slice bound b cn processor destin ffn element sinc p slice probabl cn element processor destin processor bound pe gamma c henc lemma follow from previou two lemma easi show follow theorem theorem rout n element store initi n array pprocessor bdm ff n p element destin processor complet high probabl comput time c constant larger maxf ffg remark sinc assum effect paramet domin bound c n as n balanc balanc load among processor import sinc poor balanc load gener caus poor processor util load balanc problem also import develop fast solut basic combinatori problem sort select list rank graph problem problem defin follow load processor p given array repres number use element p max n suppos redistribut element p processor n p element store processor assum without loss gener p divid n section develop simpl effici load balanc algorithm bdm model correspond commun time given tcomm m overal strategi describ next then overal strategi load balanc algorithm describ follow first load balanc problem n n store p array consid henc output array array may km pm step next processor element appropri processor step detail given next algorithm assum simplic n power two algorithm load balanc processor p contain input array element redistribut way n p element store output array begin processor p read held remain processor step perform commun time lemma perform follow local comput comput prefix sum i t els remark index chosen way that read n element t p read n element indic l r use next step determin locat n p n element move p notic step take op comput time read appropri number element l r respect remark step need special attent sinc case set consecut processor read element one processor say p h processor p read appropri element p notic h npgammam step divid two substep follow first substep read element substep done commun time appli corollari second substep rest rout perform use sequenc read prefetch oper sinc remain element processor access singl processor henc total commun time requir step m n read remain element appropri processor correspond indic l comput local step remark step complet processor read element processor read prefetch thu one show follow theorem theorem load balanc n element p processor element resid processor realiz commun time sort fft matrix multipl section consid three basic comput problem sort fft matrix multipl present commun effici algorithm solv problem bdm model basic strategi use wellknown implement model requir care attent sever technic detail sort first consid sort problem bdm model three strategi seem perform best model column sort sampl sort see eg relat refer rotat sort turn column sort algorithm best n sampl sort rotat sort better column sort algorithm particularli use n implement time column sort algorithm practic sinc constant term grow exponenti n decreas sampl sort algorithm provabl effici implement p gamma d time o n log n probabl rotat sort algorithm implement comput time whenev n p begin descript column sort algorithm column sort column sort algorithm gener oddeven mergesort describ seri elementari matrix oper let q theta p matrix element initi entri matrix one n element sort complet algorithm sort column major order form column sort algorithm eight step step element within column sort step entri matrix permut permut similar matrix transposit lemma sinc case two step done commun time step consist qshift oper clearli done commun time henc column sort algorithm implement model within thu follow theorem theorem given n element n p element store local memori set p processor n element sort column major order form comput time second sort algorithm consid section sampl sort algorithm random algorithm whose run time depend input distribut key depend output random number gener describ version sampl sort algorithm sort bdm model em comput time whenev complex bound guarante high probabl use random rout algorithm describ section overal idea algorithm use variou sampl sort algorithm algorithm describ follow close scheme describ sort connect machin cm howev first three step differ algorithm sampl sort input n element distribut evenli pprocessor bdm output n element sort column major order begin processor p randomli pick list ln n element local memori processor p read sampl processor henc processor p ln n sampl execut step processor p sort list p ln n sampl pick sampl processor p partit n element set ij belong interv jth pivot j st pivot th pivot gamma pth pivot processor p read element p set i use algorithm random rout processor p sort element local memori follow lemma immedi deduc result lemma ff probabl processor contain element step ne next show follow theorem theorem algorithm sampl sort implement pprocessor bdm o n log n em time high probabl proof step done em commun time use techniqu similar use prove lemma lemma total number element processor read step n element high probabl henc step implement commun time high probabl use theorem comput time step clearli o n log n theorem follow rotat sort rotat sort algorithm sort element mesh altern appli transform row column algorithm run constant number rowtransform columntransform phase phase assum n p naiv implement origin algorithm model requir simpl permut similar matrix transposit local sort within pro cessor slightli modifi algorithm algorithm implement model simpl permut local sort within processor sinc simpl permut perform model commun time algorithm implement commun time o n log n comput time bdm model simplic assum n t result gener valu n p slice subarray size p p theta p consist row l block subarray size p p theta p p consist posit i j l r describ algorithm briefli detail appear begin specifi three procedur serv build block main algo rithm procedur consist sequenc phase accomplish specif transform array procedur balanc input array size v theta w a sort column downward b rotat row i mod w posit right c sort column downward procedur unblock a rotat row i mod p p p p posit right b sort column downward procedur shear a sort evennumb column downward oddnumb column upward b sort row right overal sort algorithm follow algorithm rotatesort balanc input array size n p theta p sort row right unblock array balanc slice p theta p p array lie side unblock array transpos array shear array sort column downward complet correct proof algorithm see easili prove algorithm perform local sort step within processor also prove simpl permut done time similar way lemma step done one simpl permut step also done one simpl permut overlap second permut first permut step respect origin step repeat shear three time design remov six dirti row left step henc step requir simpl permut model sinc assum p length column larger row reduc number applic shear procedur step transpos matrix step thu sinc assumpt n p impli two dirti column execut step one applic procedur shear enough step remov two dirti column follow theorem theorem given n p element n element p processor bdm model n element sort column major order form commun time o n log n notic need repeat shear dlog e time step remov dirti column commun time algorithm rotatesort k e sort algorithm given element integ p o local sort need previou algorithm done o n appli radix sort henc follow corollari corollari pprocessor bdm machin n integ p o sort column major order form o n comput time commun time n e em commun time high probabl two sort algorithm worth consid radix sort see eg relat refer approxim median sort radix sort perform model o b r r tcomm n p commun time b number bit represent key r algorithm examin key sort rbit time tcomm n p commun time rout gener permut n element and henc bound corollari appli approxim median sort similar sampl sort random use processor sort element processor done model o n log n commun time n fast fourier transform next consid fast fourier transform fft comput algorithm comput discret fourier transform dft ndimension complex vector x defin co gamma on log n arithmet oper implement bdm model base follow wellknown fact eg see let ndimension vector x store n p theta p matrix x rowmajor order form p arbitrari integ divid n dft vector x given w n submatrix w n consist first n row first p column twiddlefactor scale elementwis multipl notic result output p theta n matrix hold vector w n x column major order form equat interpret comput dft n p column x follow twiddlefactor scale final comput dftp row result matrix let bdm machin p processor p divid n n p initi data layout correspond row major order form data ie local memori processor p hold x algorithm suggest perform follow three stage first stage involv local comput dft size n p processor follow twiddlefactor scale elementwis multipl w n second stage commun step involv matrix transposit outlin lemma final n local fft size p suffici complet overal fft comput n point therefor follow theorem theorem comput npoint fft done o n log n divid n commun time reduc remark algorithm describ also implement model within complex bound howev algorithm somewhat simpler implement matrix multipl final consid problem multipli two nthetan matric b assum log n partit matric b p submatric say ij b ij size theta n assum without loss gener p integ divid n simplic view processor indic arrang cube size p theta p theta p is given p ijk show product comput o n comput time d log p commun time overal strategi similar one use relat experiment result support effici algorithm appear present algorithm establish follow lemma lemma given p matric size n theta n distribut one matrix per proce sor sum comput on comput time d log p log commun time proof partit p processor p k group group contain processor use matrix transposit algorithm put first set nk row matrix group first processor group second set nk row second processor on processor add k submatric local point processor group hold n k theta n portion sum matrix correspond initi matric store processor continu strategi ad set k submatric within group k processor howev time submatric partit along column result submatric size n theta n repeat procedur log p log e time time processor n portion overal sum matrix collect submatric singl processor complex bound follow proof theorem algorithm matrix multipl input two n theta n matric b p n log n initi submatric ij b ij store processor p ij output processor p ij hold submatrix c ij c ij size n theta n begin block ij b jk initi store processor respect block read concurr p processor step perform d log p commun time use first algorithm describ theorem processor multipli two submatric store local memori step done o n comput time sum product submatric p processor p ijk comput store processor p ij step done o n comput time d log p commun time use algorithm describ lemma therefor follow theorem theorem multipli two n theta n matric complet o n time d log p commun time pprocessor bdm model log n remark could use second algorithm describ theorem execut step matrix multipl algorithm result commun bound would r commun latenc pram comput hierarch memori block transfer april processor architectur multiprocess design broadcast algorithm postal model messagepass system multipl messag broadcast postal model comparison sort algorithm connect machin cm overview ksri comput system logp toward realist model parallel comput asynchron pram algorithm scalabl parallel algorithm matrix mul tiplic cachecoher protocol data diffus machin load balanc rout hypercub relat network optim broadcast summat logp model complex theori effici parallel algorithm tight bound complex parallel sort stanford dash multiprocessor comput framework fast fourier transform sort constant number row column phase mesh probabilist analysi local maintain load balanc algorithm optim rout algorithm meshconnect processor array effici algorithm list rank solv graph problem hypercub parallel sort regular sampl report purdu workshop grand challeng comput architectur support high perform comput bridg model parallel comput tr ctr david r helman david a bader joseph jj parallel algorithm person commun sort experiment studi extend abstract proceed eighth annual acm symposium parallel algorithm architectur p june padua itali assefaw hadish gebremedhin moham essadi isabel gurin lassou jen gustedt jan arn tell pro model design analysi effici scalabl parallel algorithm nordic journal comput v n p decemb