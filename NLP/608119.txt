t combin classifi meta decis tree a paper introduc meta decis tree mdt novel method combin multipl classifi instead give predict mdt leav specifi classifi use obtain predict present algorithm learn mdt base c algorithm learn ordinari decis tree odt extens experiment evalu new algorithm perform twentyon data set combin classifi gener five learn algorithm two algorithm learn decis tree rule learn algorithm nearest neighbor algorithm naiv bay algorithm term perform stack mdt combin classifi better vote stack odt addit mdt much concis odt thu step toward comprehens combin multipl classifi mdt also perform better sever approach stack b introduct task construct ensembl classier broken two subtask rst gener divers set baselevel classier baselevel classier gener issu combin predict aris sever approach gener baselevel classier possibl one approach gener classier appli dierent learn algorithm with heterogen model represent singl data set see eg merz anoth possibl appli singl learn algorithm dierent paramet set singl data set final method like bag boost gener multipl classi appli singl learn algorithm dierent version given data set two dierent method manipul data set use random sampl replac also call bootstrap sampl bag reweight misclassi train exampl boost techniqu combin predict obtain multipl baselevel classier cluster three combin framework vote use bag boost ing stack gener stack cascad vote baselevel classier give vote predict predict receiv vote nal predict stack learn algorithm use learn combin predict baselevel classier induc metalevel classier use obtain nal predict predict baselevel classier cascad iter process combin classier iter train data set extend predict obtain previou iter work present focus combin predict baselevel classier induc appli dierent learn algorithm singl data set adopt stack framework learn combin baselevel classier end introduc notion meta decis tree mdt propos algorithm learn evalu mdt comparison method combin classier meta decis tree mdt novel method combin multipl classier dierenc meta ordinari decis tree odt mdt leav specifi baselevel classier use instead predict class valu directli attribut use mdt deriv class probabl distribut predict baselevel classier given exampl develop mlc modic c induc meta decis tree mdt mlc describ section perform mdt evalu collect twentyon data set mdt use combin classier gener baselevel learn algorithm two tree learn algorithm c ltree rulelearn algorithm cn knearest neighbor knn algorithm modic naiv bay algorithm experi compar perform stack mdt perform stack odt also compar mdt two vote scheme two stack approach final compar mdt boost bag decis tree state art method construct ensembl classier section report experiment methodolog result experiment result analyz discuss section present work put context previou work combin multipl classier section section present conclus base empir evalu along direct work combin multipl classier paper focu combin multipl classier gener use dierent learn algorithm singl data set rst phase depict left hand side figur set n baselevel classier gener appli learn algorithm singl train data set l train set cn x new exampl cn cml figur construct use ensembl classier left hand side gener baselevel classier appli n dierent learn algorithm singl train data set l right hand side classic new exampl x use baselevel classier c combin method cml assum baselevel classier c predict probabl distribut possibl class valu thu predict baselevel classier c appli exampl x probabl distribut vector set possibl class valu p c c jx denot probabl exampl x belong class c estim and predict classier c class c j highest class probabl p c c j jx predict classier c classic new exampl x metalevel depict right hand side figur first n predict fp c x p c baselevel classier c x gener obtain predict combin use combin method cml dierent combin method use dierent combin framework follow subsect combin framework vote stack present vote vote framework combin classier predict baselevel classier combin accord static vote scheme chang train data set l vote scheme remain dierent train set set learn algorithm or baselevel classier simplest vote scheme plural vote accord vote scheme baselevel classier cast vote predict exampl classi class collect vote renement plural vote algorithm case class probabl distribut predict baselevel classier let p c x class probabl distribut predict baselevel classier c exampl x probabl distribut vector return baselevel classier sum obtain class probabl distribut metalevel vote classier predict class x class c j highest class probabl p cml stack contrast vote cml static stack induc combin method cml metalevel train set base l addit baselevel classier cml induc use learn algorithm metalevel metalevel exampl construct predict baselevel classier exampl l correct classic latter combin intend combin predict baselevel classier induc entir train set l unseen exampl special care taken construct metalevel data set end crossvalid procedur present tabl appli tabl algorithm build metalevel data set use induc combin cml stack framework function build combinerl fa stratifi partitionl m n let c ji classier obtain appli j l n l let cv ji class valu predict c ji exampl l let cd ji class distribut predict c ji exampl l endfor endfor appli aml lml order induc combin cml return cml endfunct first train set l partit disjoint set equal size partit strati sens set l roughli preserv class probabl distribut l order obtain baselevel predict unseen exampl learn algorithm j use train baselevel classier c ji train set l n l train classier c ji use obtain predict exampl l predict baselevel classier includ predict class valu cv ji well class probabl distribut cd ji use calcul metalevel attribut exampl l metalevel attribut calcul n learn algorithm join togeth set metalevel exampl set one part metalevel data set lml repeat procedur time onc set l obtain whole metalevel data set final learn algorithm aml appli order induc combin cml framework combin multipl classier use paper base combin methodolog describ stack framework two ap proach class valu predict baselevel classier use metalevel attribut therefor meta level attribut procedur use framework trivial return class valu predict baselevel classier approach use class probabl distribut predict baselevel classier addit predict class valu calcul set metalevel attribut metalevel attribut use studi discuss detail section meta decis tree section rst introduc meta decis tree mdt discuss possibl set metalevel attribut use induc mdt final present algorithm induc mdt name mlc meta decis tree structur meta decis tree ident structur ordinari decis tree decis inner node speci test carri singl attribut valu outcom test branch lead appropri subtre leaf node mdt predict classier use classic exampl instead predict class valu exampl directli as odt would do dierenc ordinari meta decis tree illustr exampl present tabl first predict baselevel classier tabl a obtain given data set includ predict class probabl distribut well class valu themselv metalevel data set tabl b metalevel attribut c c class valu predict two baselevel classier c c given exampl two addit metalevel attribut conf conf measur condenc predict c c given exampl highest class probabl predict baselevel classier use measur predict condenc tabl build metalevel data set a predict baselevel classier b metalevel data set a predict baselevel classier baselevel attribut x p c jx p c jx pred p c jx p c jx pred b metalevel data set meta decis tree induc use metalevel data set given tabl a mdt interpret follow condenc conf baselevel classier c high c use classifi exampl otherwis baselevel classier use ordinari decis tree induc use metalevel data set given tabl b much less comprehens despit fact ect rule choos among baselevel predict note mdt odt need predict baselevel classier order make predict tabl dierenc ordinari meta decis tree a meta decis tree induc metalevel data set by mlc b odt induc metalevel data set by c c mdt written logic program a mdt induc conf c conf c b odt induc conf conf conf conf c mdt written logic program comprehens mdt tabl a entir due extend express mdt leav mdt odt tabl a b induc proposit data set odt induc pure proposit mdt not rst order logic program equival mdt present tabl c predic combineconf c conf c c use combin predict baselevel classier c c class c accord valu attribut variabl conf conf claus program correspond one leaf node mdt includ nonproposit class valu assign rst second claus proposit framework possibl assign one class valu anoth way interpret meta decis tree meta decis tree select appropri classier given exampl domain consid subset exampl fall one leaf mdt identi subset data one baselevel classier perform better other thu mdt identifi subset rel area expertis baselevel classier area expertis baselevel classier rel sens predict perform area better compar perform baselevel classier dierent area expertis individu baselevel classier subset data predict singl baselevel classier correct note process induc meta decis tree two type attribut use ordinari attribut use decis inner node mdt eg attribut conf conf exampl metalevel data set role attribut ident role attribut use induc ordinari decis tree class attribut eg c c hand use leaf node onli baselevel classier class attribut valu attribut predict baselevel classier thu class attribut assign leaf node mdt decid baselevel classier use predict induc odt combin classier class attribut use way ordinari attribut partit data set rel area expertis base valu ordinari metalevel attribut use induc mdt exist studi area expertis individu classier origin baselevel attribut domain hand use use dierent set ordinari attribut induc mdt properti class probabl distribut predict baselevel classier ect certainti condenc predict howev origin baselevel attribut also use induc mdt detail two set metalevel attribut given follow subsect metalevel attribut metalevel attribut calcul properti class probabl cdp distribut predict baselevel classier ect certainti condenc predict first maxprobx c highest class probabl ie probabl predict class predict baselevel classier c exampl x next entropyx c entropi class probabl distribut predict classier c exampl x final weightx c fraction train exampl use classier c estim class distribut exampl x decis tree weight exampl leaf node use classifi exampl rule weight exampl cover rule use classifi exampl properti use nearest neighbor naiv bay classier appli straightforward fashion entropi maximum probabl probabl distribut ect certainti classier predict class valu probabl distribut return highli spread maximum probabl low entropi high indic classier certain predict class valu hand probabl distribut return highli focus maximum probabl high entropi low thu indic classier certain predict class valu weight quanti reliabl predict class probabl distribut intuit weight correspond number train exampl use estim probabl distribut higher weight reliabl estim exampl mdt induc imag domain uci repositori given tabl leaf denot asterisk speci c classier use classifi exampl maximum probabl class probabl distribut predict knn smaller fraction exampl leaf tree use predict larger exampl train set entropi class distribut predict c less sum knn classier condent predict c classier tabl meta decis tree induc imag domain use class distribut properti ordinari attribut knn maxprob c weight knn c weight c entropi c c entropi ltree condent predict leaf recommend use c predict consist commonsens knowledg domain classier combin anoth set ordinari attribut use induc meta decis tree set origin domain baselevel attribut bla case rel area expertis baselevel classier describ term origin domain attribut exampl mdt tabl tabl meta decis tree induc imag domain use baselevel attribut ordinari attribut shortlinedens shortlinedens knn shortlinedens ltree shortlinedens shortlinedens ltree shortlinedens c leaf denot asterisk tabl speci c use classifi exampl shortlinedens valu larger mdt base baselevel ordinari attribut provid new insight applic baselevel classier domain use howev human expert domain use interpret mdt induc use attribut cannot interpret directli point view classier combin note anoth import properti mdt induc use cdp set metalevel attribut domain independ sens languag express meta decis tree use domain x set baselevel classier use mean mdt induc one domain use domain combin set baselevel classier although may perform well part due fact cdp set metalevel attribut domain independ depend set baselevel classier c howev odt built set metalevel attribut still domain depend two reason first use test class valu predict baselevel classier eg test root node odt tabl b second odt predict class valu itself clearli domain depend sum three reason domain independ mdt cdp set metalevel attribut use class attribut decis inner node predict baselevel classier use instead predict class valu itself mlc modic c learn mdt subsect present mlc algorithm learn mdt base quinlan c system induc odt mlc take input metalevel data set gener algorithm tabl note data set consist ordinari class attribut four dierenc mlc c ordinari attribut use intern node assign form class attribut made mlc leaf node oppos assign form class valu goodnessofsplit intern node calcul dierent as describ below mlc postprun induc mdt rest mlc algorithm ident origin c algorithm describ cs mlc measur select attribut intern node patch use transform sourc code c mlc avail httpaiijssibernardmdt c greedi divid conquer algorithm build classic tree step best split accord gain or gain ratio criterion chosen set possibl split attribut accord criterion split chosen maxim decreas impur subset obtain split compar impur current subset exampl impur criterion base entropi class probabl distribut exampl current subset train exampl denot rel frequenc exampl belong class c gain criterion select split maxim decrement info measur mlc interest accuraci baselevel classier c c exampl s ie proport exampl class equal class attribut c newli introduc measur use mlc dene as accuracyc s denot rel frequenc exampl correctli classi baselevel classier c vector accuraci probabl distribut properti it element sum entropi calcul reason replac entropi base measur accuraci base one c split process stop least one follow two criteria satis accuraci one classier current subset lead info ml user dene minim number exampl achiev current subset case leaf node construct classier maxim accuraci predict leaf node mdt order compar mdt odt principl fashion also develop intermedi version c call ac induc odt use accuraci base info measur experiment methodolog result main goal experi perform evalu perform meta decis tree especi comparison method combin classier vote stack ordinari decis tree well method construct ensembl classier boost bag also investig use dierent metalevel attribut mdt perform experi collect twentyon data set uci repositori machin learn databas domain theori data set wide use compar studi remaind section rst describ classic error rate estim compar list baselevel metalevel learn algorithm use studi final describ measur divers baselevel classier use compar perform metalevel learn algorithm estim compar classic error rate experi present here classic error estim use fold strati cross valid cross valid repeat ten time use dierent random reorder exampl data set set reorder use experi pairwis comparison classic algorithm calcul rel improv pair ttest describ below order evalu accuraci improv achiev given domain use classier c compar use cla sier c calcul rel improv errorc errorc analysi present section compar perform meta decis tree induc use cdp ordinari metalevel attribut approach c thu refer combin induc mlc use cdp averag rel improv across domain calcul use geometr mean error reduct individu domain classic error c c averag ten run fold cross valid compar data set errorc errorc refer averag statist signic dierenc perform test use pair ttest exactli fold use c c signic level right gure tabl result mean classier c signicantli betterwors c anoth aspect tree induct perform simplic induc decis tree experi present here use size decis tree measur number intern leaf node measur simplic smaller tree simpler is baselevel algorithm five learn algorithm use baselevel experi two treelearn algorithm c ltree rulelearn algorithm cn knearest neighbor knn algorithm modic naiv bay algorithm algorithm use default paramet set output baselevel classier exampl test set consist least two compon predict class class probabl distribut baselevel algorithm use studi calcul class probabl distribut classi exampl two knn naiv bay calcul weight exampl use classic see section code three c cn adapt output class probabl distribut well weight exampl use classic classic error baselevel classier twentyon data set present tabl appendix a smallest overal classic error achiev use linear discrimin tree induc ltree howev dierent data set dierent baselevel classier achiev smallest classic error metalevel algorithm metalevel evalu perform eleven dierent algorithm construct ensembl classier list below nine make use exactli set baselevel classier induc algorithm previou section brief two perform stack odt use algorithm c ac see previou sec three perform stack mdt use algorithm mlc three dierent set metalevel attribut cdp bla cdpbla two vote scheme selectbest choos best baselevel classier scann perform stack nearest neighbor analyz depend among baselevel classier addit boost bag decis tree consid creat larger ensembl tree use ordinari decis tree induc c combin baselevel classier use odt induc ac combin baselevel classier mdtcdp use meta decis tree induc mlc set class distribut properti cdp metalevel attribut mdtbla use mdt induc mlc set baselevel attribut bla metalevel attribut mdtcdpbla use mdt induc mlc union two altern set metalevel attribut cdp bla pvote simpl plural vote algorithm see section cdvote renement plural vote algorithm case class probabl distribut predict baselevel classier see section selectbest select baselevel classier perform best train set as estim fold strati crossvalid equival build singl leaf mdt scann perform stack correspod analysi nearest neighbour correspond analysi use deal highli correl predict baselevel classier scann transform origin set potenti highli correl metalevel attribut ie predict baselevel classier new smaller set uncorrel metalevel attribut nearest neighbor classier use classic new set metalevel attribut boost decis tree two hundr iter use boost decis tree induc use j c default paramet set pre post prune weka data mine suit implement adaboost boost method reweight train exampl bag decis tree two hundr iter decis tree use bag use j default set detail report perform method found appendix a classic error found tabl size ordinari meta decis tree induc dierent metalevel combin algorithm given tabl final comparison classic error method mdtcdp in term averag rel accuraci improv number signic win loss given tabl summari detail report given tabl divers baselevel classier empir studi perform show classic error metalevel learn method well improv accuraci achiev use highli correl degre divers predict baselevel classier measur divers two classier use studi error correl smaller error correl greater divers baselevel classier experi bag boost perform use weka data mine suit includ j java reimplement c dierenc j result c result neglig averag maximum rel dierenc correl dene probabl classier make error denit error correl normal maximum valu lower two classic error altern denit error correl propos use paper error correl dene condit probabl classier make error given one make error predict classier c c j given exampl x cx true class x error correl set multipl classier c dene averag pairwis error correl rel improv ltree baselevel degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific rel improv knn baselevel degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur rel accuraci improv achiev mdt compar two baselevel classier ltree knn depend error correl among baselevel classier graph figur conrm result meta decis tree rel accuraci improv achiev mdt ltree knn two baselevel classier highest overal accuraci decreas error correl baselevel cla sier increas linear regress line interpol point conrm trend show perform improv achiev mdt correl divers error baselevel classier tabl summari perform metalevel learn algorithm compar mdt induc use class distribut properti mdtcdp metalevel attribut averag rel accuraci improv in number signic winsloss averag tree size where applic detail tabl appendix a metalevel algorithm ave rel acc imp in mdtbla mdtcdpbla selectbest scann na boost na bag na analysi experiment result result experi summar tabl brief follow main conclus drawn result properti class probabl distribut predict baselevel cla sier cdp better metalevel attribut induc mdt baselevel attribut bla use bla addit cdp worsen perform meta decis tree mdt induc use cdp outperform ordinari decis tree vote combin classier mdt perform slightli better scann selectbest method perform improv achiev mdt correl divers error baselevel classier higher divers better rel perform compar method use mdt combin classier induc dierent learn algorithm outperform ensembl learn method base bag boost decis tree look claim experiment result detail mdt dierent set metalevel attribut analyz depend mdt perform set ordinari metalevel attribut use induc them use three set attribut properti class distribut predict baselevel classier cdp origin baselevel domain attribut bla union cdpbla averag rel improv achiev mdt induc use cdp mdt induc use bla cdpbla cdp signicantli better domain see tabl tabl appendix a mdt induc use cdp time smaller averag mdt induc use bla cdpbla see tabl result show cdp set metalevel attribut better bla set furthermor use bla addit cdp decreas perform remaind section consid mdt induc use cdp analysi result ordinari decis tree induc use cdp bla cdpbla onli result cdp actual present paper show claim hold also odt result especi import highlight import use class probabl distribut predict baselevel classier identifi rel area expertis far baselevel attribut origin domain typic use identifi area expertis baselevel classier meta decis tree vs ordinari decis tree compar combin classier mdt odt rst look rel improv use mlc cc see tabl column cc tabl appendix left hand side figur perform signicantli better signicantli wors data set overal decreas accuraci thi geometr mean entir due result tictacto domain combin method perform well exclud tictacto domain overal rel increas obtain thu say mlc perform slightli better term accuraci howev mdt much smaller size reduct factor see tabl despit fact odt induc c postprun mdt not rel improv in tictacto balanc breastw hypothyroid soya heart imag vote hepat glass echocardiogram waveform iri german australian chess diabet car bridgestd wine ionospher avg insignific signific rel improv in iri bridgestd imag heart soya waveform vote breastw hepat german balanc diabet echocardiogram glass ionospher australian hypothyroid chess wine car tictacto avg insignific signific figur rel improv accuraci use mdt induc mlc compar accuraci odt induc ac c get clearer pictur perform dierenc due extend express power mdt leav as compar odt leav compar mlc cac see tabl column cac tabl right hand side figur mlc ac use learn algorithm dierenc type tree induc mlc induc meta decis tree ac induc ordinari one comparison clearli show mdt outperform odt combin classier overal rel accuraci improv mlc signicantli better cac data set signicantli wors one ionospher consid also graph right hand side figur mdt perform better odt two domain perform gain much larger loss furthermor mdt are averag time smaller odt induc ac see tabl reduct tree size improv comprehens meta decis tree exampl abl interpret comment mdt tabl sum meta decis tree perform better ordinari decis tree combin classier mdt accur much concis comparison mlc ac show perform improv due extend express power mdt leav meta decis tree vs vote combin classier mdt signicantli better plural vote domain signicantli wors howev signic improv much higher signic drop accuraci give overal accuraci improv sinc perform slightli better plural vote smaller overal improv achiev mdt mlc signicantli better data set signicantli wors result show mdt outperform vote scheme combin classier see tabl tabl appendix a rel improv degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific rel improv degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur rel improv accuraci mdt two vote scheme depend degre error correl baselevel classier explor depend accuraci improv mdt vote divers baselevel classier graph figur show mdt make better use divers error baselevel classier vote scheme name domain low error correl and therefor higher divers baselevel classier rel improv mdt vote scheme higher howev slope linear regress line smaller one improv baselevel classier still trend clearli show mdt make better use error divers baselevel predict vote meta decis tree vs selectbest combin classier mdt signicantli better selectbest domain signicantli wors give overal accuraci improv almost see tabl tabl appendix a rel improv selectbest degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur rel improv accuraci mdt selectbest method depend degre error correl baselevel classier result depend analysi accuraci improv mdt select best divers baselevel classier given figur mdt make slightli better use divers error baselevel classier selectbest slope linear regress line smaller one improv vote method meta decis tree vs scann combin classier mdt signicantli better scann domain signicantli wors see tabl tabl appendix a howev signic improv much higher signic drop accuraci give overal accuraci improv almost result show mdt outperform scann method combin classier rel improv degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur rel improv accuraci mdt scann method depend degre error correl baselevel classier explor depend accuraci improv mdt scann divers baselevel classier graph figur show mdt make slightli better use divers error baselevel classier scann slope linear regress line smaller one improv vote method meta decis tree vs boost bag final compar perform mdt perform two state art ensembl learn method bag boost decis tree perform signicantli better boost signicantli better bag data set mlc perform signicantli wors boost domain signicantli wors bag domain onli overal rel improv perform boost bag see tabl tabl appendix a clear mdt outperform bag boost decis tree comparison fair sens mdt use baselevel classier induc decis tree four learn method boost bag use decis tree baselevel learn algorithm howev show approach construct ensembl classier competit exist state art approach relat work overview method construct ensembl classier found sever metalevel learn studi close relat work let us rst mention studi use scann combin baselevel classier mention abov scann perform stack use correspond analysi classic baselevel classier author show scann outperform plural vote scheme also case baselevel classier highli correl scann use class probabl distribut properti predict baselevel classier although possibl extend method direct mention therefor comparison cd vote scheme includ studi studi show mdt use cdp attribut slightli better scann term perform also concept induc scann metalevel directli interpret use identifi rel area expertis baselevel classier cascad baselevel classier induc use exampl current node decis tree or step divid conquer algorithm build decis tree new attribut base class probabl distribut predict baselevel classier gener ad set origin attribut domain baselevel classier use studi naiv bay linear discrimin integr two baselevel classier within decis tree much tighter combiningstack framework similar approach class probabl distribut use version stack gener use class probabl distribut predict baselevel classier implement data mine suit weka howev class probabl distribut use directli properti maxim probabl entropi make domain depend sens discuss section indirect use class probabl distribut properti make mdt domain independ ordinari decis tree alreadi use combin multipl classier howev emphasi studi partit techniqu massiv data set combin multipl classier train dierent subset massiv data set studi focus combin multipl classier gener data set therefor obtain result directli compar their combin classier identifi area expertis alreadi explor studi descript area expertis form ordinari decis tree call arbit induc individu baselevel classier singl data set mani arbit need baselevel classier combin multipl classier vote scheme use combin decis arbit howev singl mdt identifi rel area expertis baselevel classier much comprehens anoth improv present studi possibl use certainti condenc baselevel predict identifi classier expertis area origin baselevel attribut data set present studi also relat previou work topic metalevel learn introduc induct logic program ilp framework learn relat data set characterist perform dierent base level classier express nonproposit formul use repres metalevel exampl data set characterist eg properti individu attribut induc metalevel concept also nonproposit mdt leav express odt leav languag mdt still much less express languag logic program use ilp conclus work present new techniqu combin classier base meta decis tree mdt mdt make languag decis tree suitabl combin classier select appropri baselevel classier given exampl leaf mdt repres part data set rel area expertis baselevel classier leaf rel area expertis identi basi valu origin baselevel attribut bla data set also basi properti class probabl distribut cdp predict baselevel classier latter ect certainti condenc class valu predict individu baselevel classier extens empir evalu show mdt induc cdp perform much better much concis mdt induc bla due extend express mdt leav also outperform ordinari decis tree odt term accuraci concis mdt usual small easili interpret regard step toward comprehens model combin cla sier explicitli identifi rel area expertis contrast exist work use nonsymbol learn method eg neural network combin classier mdt use divers baselevel classier better vote outperform vote scheme term accuraci especi domain high divers error made baselevel classier mdt also perform slightli better scann method combin classier selectbest method simpli take best singl classier final mdt induc cdp perform better boost bag decis tree thu competit state art method learn ensembl mdt built use cdp domain independ are principl transfer across domain x set baselevel learn algorithm sens mdt built one data set use data set sinc use set attribut sever potenti benet domain independ mdt first machin learn expert use mdt domain independ analysi rel area expertis dierent baselevel classier without knowledg particular domain use furthermor mdt induc one data set use combin classier induc set baselevel learn algorithm data set final mdt induc use data set contain exampl origin dierent domain explor option alreadi give us topic work combin data dierent domain learn mdt especi interest avenu work would bring togeth present studi metalevel learn work select appropri classier given domain case attribut describ individu data set properti ad class distribut properti metalevel learn data set preliminari investig along line alreadi made sever obviou direct work ordinari decis tree alreadi known postprun give better result preprun preliminari experi show preprun degrad classic accuraci mdt thu one prioriti work develop postprun method meta decis tree implement mlc interest aspect work use classdistribut properti metalevel learn work combin classier use predict class correspond probabl distribut would interest use learn algorithm neural network bayesian classic scann combin classier base probabl distribut return them comparison combin cla sier use class predict vs class predict along class probabl distribut would also worthwhil consist meta decis tree common sens classier combin knowledg brie discuss section open anoth question research process induc metalevel classier bias produc metalevel classier consist exist knowledg achiev use strong languag bia within mlc or probabl easili within framework meta decis rule rule templat could use acknowledg work report support part slovenian ministri educ scienc sport eufund project data mine decis support busi competit european virtual enterpris ist thank joao gama mani insight inspir discuss combin multipl classier mani thank marko bohanec thoma dietterich nada lavrac three anonym review comment earlier version manuscript r explain degre error reduct due combin multipl decis tree reduct learn multipl descript uci repositori machin learn databas analysi result bag predictor accuraci metalearn scalabl data mine rule induct cn recent improv experi new boost algorithm combin classi discrimin tree linearbay classi er integr multipl classi use correspond analysi combin classi exploit multipl exist model learn algorithm learn logic de studi distancebas machin learn algorithm data mine practic machin learn tool techniqu java implement stack gener tr ctr michael gamon sentiment classif custom feedback data noisi data larg featur vector role linguist analysi proceed th intern confer comput linguist pe august geneva switzerland saso deroski bernard enko combin classifi stack better select best one machin learn v n p march efstathio stamatato gerhard widmer automat identif music perform learn ensembl artifici intellig v n p june christoph giraudcarri ricardo vilalta pavel brazdil introduct special issu metalearn machin learn v n p march joo gama function tree machin learn v n p june pavel b brazdil carlo soar joaquim pinto da costa rank learn algorithm use ibl metalearn accuraci time result machin learn v n p march nicol garcapedraja domingo ortizboy cooper construct method neural network pattern recognit pattern recognit v n p januari s b kotsianti i d zaharaki p e pintela machin learn review classif combin techniqu artifici intellig review v n p novemb