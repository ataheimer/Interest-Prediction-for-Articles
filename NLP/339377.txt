t trust region algorithm timestep select a unconstrain optim problem close relat system ordinari differenti equat ode gradient structur work prove result appli area analyz converg properti trust region levenbergmarquardt algorithm optim algorithm may also regard linear implicit euler method adapt timestep gradient ode optim viewpoint algorithm driven directli levenbergmarquardt paramet rather trust region radiu approach discuss exampl r fletcher practic method optim nd ed john wiley new york converg theori develop give rigor error analysi algorithm establish global converg unusu extrem rapid type superlinear converg precis form superlinear converg exhibitedth ratio success displac limit point bound geometr decreas sequenc also show inexpens chang algorithm lead quadrat converg ode viewpoint work contribut theori gradient stabil present algorithm reproduc correct global dynam give rapid local converg stabl steadi state b introduct work involv idea two area numer anal ysi optim numer solut ordinari differenti equat ode begin point connect underli mathemat problem given smooth function f r algorithm unconstrain optim seek find local minim is point x fx x neighborhood x follow standard result give necessari condit suffici condit x local minim proof may found exampl theorem condit rfx posit semidefinit necessari x local minim whilst condit rfx posit definit suffici hand given smooth function f may consid ode system suppos f form fx j gammarf x chain rule solv dt f dt see along solut ode quantiti fxt decreas euclidean norm increas moreov strictli decreas unless henc solv ode larg valu may regard attempt comput local minimum f condit given theorem may interpret necessari condit suffici condit x linearli stabl fix point ode possibl write fx form gammarf x ode said gradient structur see exampl sever author note depart mathemat univers strathclyd glasgow g xh uk support engin physic scienc research council uk grant grk manuscript appear univers strathclyd mathemat research report connect optim gradient ode schropp examin fix timestep rungekutta rk method dynam system viewpoint found condit numer solut gradient ode converg stationari point f schropp also gave numer evid suggest certain problem class ode formul prefer optim analogu book show mani problem express optim term also written ode often gradient structur chu exploit idea order obtain theoret result numer method particular problem see review optim literatur gradient ode connect also mention see exampl discuss unconstrain optim relat work look use ode method solv system nonlinear algebra equat studi numer method appli ode gradient form lead concept gradient stabil gradient structur aris mani applic area provid use framework analysi ode algo rithm in contrast classic linear strictli contract test problem gradient system allow multipl equilibria posit result prove abil rk method preserv gradient structur henc captur correct long term dynam small fix timestep result requir extra assumpt f impos either onesid lipschitz condit form dissip adapt rk method is method vari timestep dynam analyz author consid special class rk formula pair show tradit error control approach forc good behavior suffici small valu error toler independ initi data would regard global converg proof optim litera ture result requir onesid lipschitz condit f similar result prove gener ode method success control local error perunitstep case error toler must chosen way depend initi data work present two main contribut ffl first note close similar trust region levenberg marquadt algorithm optim adapt linear implicit euler method gradient ode analyz optim algorithm establish new result converg properti also add theori gradient stabil ode mild assumpt f show method global converg enjoy rapid form superlinear converg the notion rate converg equilibrium wide studi optim appear consid gradient ode context easili seen fix timestep rk formula approach equilibrium gener linear rate term timestep number ffl second use idea gradient analysi construct timestep method gener ode give rapid superlinear local converg stabl fix point present organ follow next section introduc new ton method simpl numer ode method section concern specif trust region algorithm unconstrain optim algorithm essenti one found defin x nonrigor discuss converg properti given x main converg theorem prove x algorithm may also regard timestep process gradient ode algorithm analog result state x x develop timestep scheme gener ode give superlinear local converg stabl fix point numer method numer method find local minim f begin initi guess x gener sequenc fx k g similarli onestep method ode produc sequenc fx k g x k xt k timelevel ft k g determin dynam mean timestep deltat k steepest descent method optim form ff k scalar may aris exampl line search equival explicit euler method appli correspond gradient ode timestep deltat k j ff k note pass poor perform steepest descent presenc steepsid narrow valley analog poor perform euler method stiff problem inde figur j figur illustr essenti behavior view two differ perspect newton method optim base local quadrat model note q k ffi quadrat approxim fx k ffi aris taylor seri expans x k r fx k posit definit q k ffi uniqu minim thu arriv newton method follow result concern local quadrat converg newton method may found exampl theorem suppos f c r f satisfi lipschitz condit neighborhood local minim x x suffici close x posit definit newton method well defin k converg second order implicit euler method appli fx j gammarf x use timestep deltat k produc equat gener nonlinear equat must solv x k appli one inter newton method that is newton method solv nonlinear equat initi guess x method sometim refer linear implicit euler method see exampl note larg valu deltat k ode method look like newton method hand small deltat k correspond small step direct steepest descent henc extrem larg small deltat k ode method behav like wellknown optim method howev show much more valu deltat k method identifi trust region process optim connect point goldfarb discuss unconstrain optim relev optim theori develop next section trust region algorithm algorithm seen newton method base idea minim local quadrat model q k ffi step sinc model valid local make sens restrict increment is seek increment ffi minim q k ffi subject constraint kffik h k h k paramet reflect much trust prepar place model throughout work use k delta k denot euclidean vector norm correspond induc matrix norm case solut local constrain quadrat model problem character follow lemma one half theorem weaker version prove complet give proof here lemma given g r mthetam g r if gammag g i posit semidefinit b ffi solut min subject kffik k b ffik furthermor g i posit definit b ffi uniqu solut proof case g i posit semidefinit straightforward show b ffi minim henc ffi b solv problem g i posit definit inequ strict ffi b ffi henc solut uniqu note lemma show comput increment b ffi given trust region constraint kffik h k increment may comput approxim use iter techniqu see exampl page page howev mention reason regard paramet drive algorithmhav chosen valu check gi posit definit may solv linear system posteriori obtain trust region radiu h k k b ffik easili shown g i posit definit increas decreas k b ffik remark motiv algorithm below use min m denot smallest eigenvalu symmetr matrix let ffl small constant given x gener step trust region algorithm proce follow algorithm comput solv comput comput comput use els set r r k set x els set x algorithm involv function note r k record ratio reduct f x k x reduct predict local quadrat model r k significantli less model overoptimist inform use updat trust region paramet case local quadrat model perform poorli doubl paramet correspond reduc trust region radiu next step perform reason retain valu case good perform halv valu therebi indirectli increas trust region radiu emphas algorithm trust region algorithm sens step ffi k solv local restrict problem min subject kffik kffi k k also remark algorithm essenti describ page underli idea ad multipl ident matrix ensur posit definit first appli case f sumofsquar form lead levenbergmarquadt algorithm goldfeld et al extend approach gener object function gave theoret justif theorem provid gener converg theori wide class trust region method howev result appli immedi algorithm sinc algorithm directli control radiu h k kffi k k but rather control indirectli via adapt k fact see behavior establish theorem local quadrat converg hold algorithm awar exist converg analysi appli directli algorithm except gener result form encapsul dennismor character theorem superlinear converg strongli consist approxim hessian theori given refer discuss remark follow theorem motiv converg analysi proof x appendix rather technic henc help orient reader give heurist discuss key point theorem establish global converg proof use argument standard optim literatur essenti global converg follow fact local quadrat model inaccur algorithm choos direct close steepest descent perhap interest rate local converg suppos x k posit definit suppos k b k r k henc follow that constant c note also g k g gamma bound larg k given larg k let ffi newt k denot correct would aris newton method appli x k newt expand use newt let k x henc newt use find newt constant c now sinc x newt k newton step x k have theorem newt constant c triangl inequ give newt newt insert arriv key inequ constant c first term righthand side distinguish algorithm newton method domin rate converg proceed conveni consid shift sequenc let b e k e kn fix n determin k choos n n c now neglect obe lead if addit ignor obe also assum equal hold get equal see error sequenc quadrat converg howev correspond rapid form superlinear converg although analysi use sever simplifi assumpt main conclus made rigor show next subsect type superlinear converg establish like good quadrat converg practic matter discuss proof theorem converg analysi trust region algorithm follow theorem show algorithm satisfi global converg result structur proof similar theorem theorem suppos algorithm produc infinit sequenc x k b ae r g k k b bound f c b accumul point x satisfi necessari condit local minim theorem proof sequenc b must converg subsequ henc collect indic converg subsequ conveni distinguish two case i sup case i form v r must infinit subsequ whose indic form set b also use bounded g k g k henc suppos gradient limit exist descent direct s normal ksk sinc ffi k solv local restrict subproblem q k kffi k ks ks also taylor expans fx conclud r contradict r k henc suppos g gx posit semidefinit direct v pick s k b k then sinc solv local restrict subproblem henc follow r contradict henc g posit semidefinit case ii form v r must infinit subsequ whose indic form set henc gmax sup xb give henc remov earlier indic necessari have h k kffi k k min deltaf s r k follow deltaq k let kffik h set x henc feasibl subproblem solv ffi k let follow q k ffi f also minim q ffi kffik h sinc constraint inact necessari condit theorem must satisfi henc g contradict now case ii suppos g posit semidefinit argument give may appli conclud r follow k sinc min must g posit semidefinit give requir contradict note that mention sinc algorithm comput nonincreas sequenc f k bound region b requir theorem exist level set bound theorem assum g k k g b algorithm essenti termin give x howev case cannot conclud r fx k posit semidefinit next theorem quantifi local converg rate algorithm first part proof base theorem theorem accumul point x theorem also satisfi suffici condit local minim theorem main sequenc further displac error e k constant c e k k e constant e c ratio e k e k unbound proof first show case i proof theorem rule out suppos case i aris r k b s posit definit matrix g k also posit definit larg k b case newton correct ffi newt newt gammag k well defin give global minimum local quadrat model q k defin ff ffkffi newt note sinc ffi k solv local restrict subproblem ff newt newt newt newt newt henc use f newt newt min lower bound smallest eigenvalu g k larg k b follow may conclud r k henc case i cannot aris case ii k k further sinc lower bound smallest eigenvalu g k larg k b follow k must establish k know correct use algorithm look like newton correct ffi newt k satisfi g k ffi newt gammag k let x newt newt k also let k x k s and triangl inequ quadrat converg properti newton method given theorem impli x k suffici close x constant expand term find newt k find use give larg k e k constant repeat argument gener inequ show neighborhood n around x x r k henc k x k n main sequnc lie n k k main sequenc x larg k henc may extend bound constant lemma a give obtain lower bound e k use triangl inequ form constant lemma a give requir result list number remark theorem theorem show algorithm achiev quadrat local converg rate caus fact k approach zero quickli enough reflect first term righthand side straightforward adapt proof show increas rate k possibl make second term righthand side signific quadrat converg recov exampl occur alter strategi chang k and otherwis howev explain item below would expect chang improv perform practic quadrat converg also discuss item below power k appear chosen partli basi simplicityit clear proof lemma a theorem replac ak thi will cours caus constant c chang also clear proof result independ precis numer valu appear algorithm valu replac ff fi respect factor replac factor greater uniti factor replac k k statement theorem remain true power replac power k the chang mention will cours alter constant c e c b c theorem show e k e k henc converg rate superlinear howev geometr decreas upper lower bound e k e k give us much inform asymptot whilst newton method give twice mani bit accuraci per step bound correspond k bit accuraci kth step case asymptot regim e k small enough make converg rate observ small round error signific like consist small number step sever author found condit suffici necessari suffici superlinear converg algorithm optim rootfind comprehens result form dennismor character theorem theorem theorem also section analyz class rootfind algorithm employ consist approxim hessian approach may use establish superlinear converg algorithm howev refer cover gener class algorithm deriv sharp upper lower bound rate superlinear converg type given theorem terminolog x algorithm use strongli consist approxim hessian superlinear converg impli k also follow result quadrat converg aris ensur k ckg k k converg rorder least occur k ckx constant c timestep gradient system identifi trust region paramet k invers timestep deltat k linear implicit euler method ident updat formula algorithm henc algorithm regard adapt linear implicit euler method gradient ode converg analysi x appli complet rewrit algorithm timestep algorithm given deltat x x init gener step algorithm gradient system fx j gammarf x proce follow algorithm comput solv comput comput comput use els set r r k set x els set x appropri analogu function deltat r follow result restat theorem context theorem suppos algorithm fx j gammarf x produc infinit sequenc x bound f c b accumul point x satisfi necessari condit local minim theorem accumul point x also satisfi suffici condit local minim theorem main sequenc further displac error e k constant c e k k e constant e c ratio e k e k unbound addit remark end x follow point note algorithm requir check posit definit symmetr unusu requir timestep algorithm howev point inexpens numer stabl test perform cours choleski factor page test min omit algorithm local converg rate unaffect global converg proof break down rule chang timestep differ spirit usual local error control philosophi ode expect sinc aim reach equilibrium quickli possibl odd aim follow particular trajectori accur time timestep control polici algorithm base measur close linear ode idea gener next section also note local error control algorithm typic involv usersuppli toler paramet understand smaller choic toler produc accur solut algorithm hand involv fix paramet shown that certain assumpt use local error control gradient ode forc numer solut close equilibrium typic solut remain within o equilibrium point toler paramet suggest local error control may form altern posit definit test mean ensur global converg driven solut close equilibrium local error control close linear test could use give superlinear converg timestep gener stabl steadi state motiv x develop algorithm give rapid local converg stabl equilibrium gener ode let f denot jacobian f defin f k fx k k symmetr gener ratio l k indic close f behav linearli region contain x k x k given deltat x x init gener step algorithm proce follow algorithm comput solv comput use deltat els arbitrari sinc concern local converg properti action taken affect analysi theorem below bfl z denot open ball radiu fl z flg theorem suppos fx neighborhood x f strictli neg real part given algorithm fl x further displac error e k constant c e k k e constant e c ratio e k e k unbound proof exist b fl f x nonsingular x let upper bound kf now l k follow reduc b fl necessari jl f k have small e k exist deltat deltat continu reduc b fl necessari deltat henc larg deltat contract show x suffici close x deltat k increas beyond deltat x k remain bbfl x let deltatdeltat deltat x k bbfl x let b k b k deltat deltat may choos suffici small then sinc deltat k deltat k b k henc e k k deltat deltat k f deltat k f sinc f k f bound give k e k constant complet result straightforward show fix timestep rk linear multistep method produc linear rate converg equilibrium gener theorem see algorithm provid systemat mean increas timestep order achiev rapid form superlinear converg mani applic particularli area comput fluid dynam ic common solv discret steadi partial differenti equat introduc artifici time deriv drive solut equilibrium see exampl clear proof theorem suffici larg deltat algorithm permit local converg unstabl fix point regard consequ fact implicit euler method overst sens absolut stabil region contain infinit strip fz righthalf complex plane see exampl page anoth explan newton method optim f ident newton method algebra equat appli see exampl page henc unless measur taken reason stabl fix point prefer algorithm gradient ode check min help forc numer solut stabl fix point like tradit ode error control would also direct solut away unstabl fix point henc idea combin optim ode idea form attract area futur work acknowledg work benefit convers number optim timestepp notabl roger fletcher david griffith appendix a converg rate lemma lemma a let k k constant c further e k k if addit r k k e ratio e k e k unbound proof choos first prove result restrict circumst gener full result assum induct hypothesi note that a hold a true use a use a a therefor induct a true k a hold now consid shift sequenc b e k e kn fix n possibl choos n a a result a hold shift sequenc k translat result origin sequenc find that relabel c c n n let b n henc clearli increas c necessari result also hold finit sequenc n henc a prove inequ a follow divid e k a use a a suffici larg k k e k r r c clearli reduc c necessari result must hold k now reduc necessari a let e e e inequ a a give a requir final use a a find e r fast local converg singl multistep method nonlinear equat solut nonlinear system equat astabl integr tech niqu list matrix flow applic practic method optim practic optim maximis quadrat hillclimb solv ordinari differenti equat solv ordinari differenti equat ii optim dynam system analysi dynam local error control via piecewis continu residu accuraci stabil numer algorithm numer method ordinari differenti system iter solut nonlinear equat sever variabl nonlinear optim use dynam system method solv minim problem nonlinear dynam chao model problem numer stabil theori initi valu problem essenti stabil local error control dynam system global asymptot behaviour iter implicit scheme tr