t runtim parallel schedul processor load balanc a abstractparallel schedul new approach load balanc parallel schedul processor cooper schedul work parallel schedul abl accur balanc load use global load inform compiletim runtim provid highqual load balanc paper present overview parallel schedul techniqu schedul algorithm tree hypercub mesh network present algorithm fulli balanc load maxim local runtim commun cost significantli reduc compar exist algorithm b introduct static schedul balanc workload runtim appli problem predict structur call static problem dynam schedul perform schedul activ concurr runtim appli problem unpredict structur call dynam problem static schedul util knowledg problem characterist reach wellbalanc load howev abl balanc load dynam problem addit requir larg memori space store task graph restrict scalabl static schedul dynam schedul gener approach suitabl wide rang applic adjust load distribut base runtim system load inform howev runtim schedul algorithm util neither characterist inform applic problem global load inform load balanc decis system stabil usual sacrific qualiti quick load balanc parallel schedul promis techniqu processor load balanc parallel schedul ing processor cooper schedul work parallel schedul util global load inform abl accur balanc load provid highqual scalabl load balanc parallel schedul algorithm introduc parallel schedul appli static problem exist schedul algorithm static problem run singl processor scalabl massiv parallel comput store task graph requir larg memori space speed schedul relax demand memori space static schedul parallel kwok ahmad develop parallel algorithm wu parallel mcp algorithm parallel schedul also appli dynam problem parallel schedul appli runtim becom increment collect schedul appli whenev load becom unbalanc processor collect schedul workload system describ start system phase schedul initi task follow user comput phase execut schedul task possibl gener new task next system phase old task execut schedul togeth newli gener task system phase parallel schedul algorithm appli balanc load paper discuss parallel schedul methodolog paper devot particularli kind schedul schedul readi job task is object schedul set job task readi execut schedul algorithm tree hypercub mesh network present algorithm primarili design dynam problem randomli arriv dynam gener job task algorithm fulli balanc load maxim local significantli reduc commun overhead compar exist algorithm paper organ follow section discuss optim schedul problem parallel schedul algorithm tree hypercub mesh topolog present section properti algorithm describ section perform present section previou work discuss section section conclud paper optim schedul problem object schedul schedul work processor work load thu need estim task execut time estim applic specif lead less gener approach sometim estim difficult obtain due difficulti task presum requir equal execut time object algorithm becom schedul task processor number task inaccuraci caus grainsiz variat correct next system phase algorithm estim time task could improv load balanc extent howev sinc algorithm complex schedul overhead increas may overwrit benefit schedul problem describ follow parallel system n comput node connect given topolog node w task parallel schedul appli schedul algorithm redistribut task number task node equal assum sum w node evenli divid n averag number task w avg calcul node w avg task execut schedul algorithm w node must determin send task commun step mani commun perform simultan time spent load balanc activ depend number commun step time taken step parallel schedul algorithm util global inform number commun step order log n n number processor averag time commun step depend total number task migrat travel distanc object function minim number taskhop x e k number task transmit edg k gener problem convert minimumcost maximumflow problem follow edg treat bidirect arc given tupl capac cost capac capac edg cost cost edg set edg processor network add sourc node edg s i node w w avg sink node edg j t node j w cost capac cost minimumcost maximumflow algorithm yield solut problem figur show load distribut eightnod hypercub network graph construct figur given figur w minimum cost algorithm gener solut shown figur complex minimum cost algorithm on v n number node v desir flow valu complex correspond parallel algorithm n node least onv high complex realist runtim schedul certain topolog tree complex reduc olog n n node topolog tree need find heurist algorithm parallel schedul algorithm section present parallel schedul algorithm tree hypercub mesh topolog common featur algorithm total number task obtain figur load distribut dimension hypercub edg figur graph optim schedul problem figur figur optim solut figur parallel reduct oper averag number task per node calcul node send task node unless number task exce averag therefor necessari task migrat discuss individu algorithm differ topolog give gener algorithm shown figur first step collect global inform use sum reduct step averag number task per node calcul number task cannot evenli divid number node remain r task evenli distribut first r node one task other valu w avg r avail node step node calcul quota node know overload underload quota subset node also comput particular topolog step task exchang meet quota minimum commun differ algorithm design differ topolog let w number task node i global inform collect perform sum reduct w comput inform total number task averag load calcul w quota calcul node comput quota q w avg otherwis quota subset node also comput task exchang overload node determin send excess task figur gener parallel schedul algorithm follow subsect present three parallel schedul algorithm tree walk algorithm twa cube walk algorithm cwa mesh walk algorithm mwa tree algorithm optim algorithm term number taskhop hypercub mesh algorithm heurist algorithm tree walk algorithm network topolog tree complex optim schedul reduc tree walk algorithm twa shown figur essenti one present step total number task count parallel reduct oper node record number task subtre children subtre if ani step root calcul averag number task per node broadcast number everi node step subtre root node calcul quota q indic mani task schedul subtre q calcul directli follow node keep record q q j node j node is child if ani step workload exchang end system phase node number task quota tree walk algorithm twa assign node order accord preorder travers n number node subtre total number node system node parent node p also child vector c i c i c im gamma give children node number global inform collect perform sum reduct w averag load calcul quota calcul quota node q comput also quota subtre comput task exchang node comput node j l receiv task node p node receiv task node c ij node j l task node p node ij task node c ij figur tree walk algorithm lemma execut twa number task node equal quota proof assum node j child node c j node j equal gammaj r il node i thu j l receiv jj l task node i similarli j r il node equal gammaj l j node j thu j r receiv jj r task node j therefor execut twa number task node j child j child j child j child j child step spend commun step depth tree commun step step distanc leaf node anoth leaf node m therefor total number commun step algorithm m balanc tree number commun step parallel algorithm n node ologn exampl exampl shown figur node tree number preorder travers begin schedul node w task readi schedul valu w calcul step root calcul valu w avg r then node calcul valu q step valu w shown follow figur exampl tree walk algorithm number task exchang node shown figur end schedul node five task each node four task each cube walk algorithm subsect studi two algorithm design hypercub topolog dem algorithm propos cube walk algorithm cwa dem small domain balanc first combin form larger domain ultim entir system balanc integ version dem describ figur node pair first dimens whose address differ least signific bit balanc load themselv next node pair second dimens balanc load themselv forth node balanc load neighbor number commun step dem algorithm d number dimens dem node exchang node j current valu w w j w task node j w task node j updat valu w figur dem algorithm exampl dem algorithm illustr figur load distribut execut a b c d figur exampl dem algorithm dem algorithm shown figur a first step node exchang load inform balanc load dimens shown figur b then load balanc dimens shown figur c load balanc dimens figur d final result shown figur e load fulli balanc integ number task transmit node total taskhop wherea optim schedul shown figur taskhop execut dem algorithm load differ d dimens hypercub figur show exampl dimension hypercub figur exampl show number task differ result dem dem algorithm simpl low complex load balanc step node pair exchang load inform global inform collect without global load inform imposs node make correct decis mani task sent node pair attempt averag number task anyway node may send excess task neighbor dem unabl fulli balanc load minim commun cost good heurist algorithm design util global load inform present new parallel schedul algorithm hypercub topolog algorithm call cube walk algorithm cwa shown figur let w number task node algorithm appli first step collect system load inform exchang valu w k obtain valu w k node record w vector w k total number task kdimension subcub here kdimension subcub node defin node whose number d gamma kbit prefix node i valu node equal total number task entir cube step node calcul averag number task per node quota vector q calcul step node know kdimension subcub overload underload vector q comput directli follow bitwis bitwis or ffi vector differ w q stand number task sent receiv subcub cube walk algorithm cwa assum cube dimens d number node let phi denot bitwis exclus bitwis and global inform collect perform sum reduct node comput w vector averag load calcul quota calcul node comput vector q k task exchang node comput number task sent task well vector node phi k updat w ffi vector node receiv task well vector node phi k updat w ffi vector dimens figur cube walk algorithm step task exchang conduct among dimens start cube dimens gamma recurs partit cube dimens k two subcub dimens gamma node ni pair correspond node ni subcub particular step exchang task ni ni and send task one direct overload subcub other way overload node necessarili commit send task sinc may postpon action decis made global within subcub calcul vector everi node overload subcub calcul local oper without commun valu ffi n calcul fl vector record number task reserv subcub lower dimens follow lemma show end algorithm node number task quota lemma execut cwa number task node equal quota proof show iter number task node equal quota q need show iter k kdimension subcub q k task then subcub need send ffi k task subcub task sent one direct number task sent overload subcub underload subcub must equal ffi k is proven show three case assign valu case henc case j sinc sinc henc case sinc sinc henc algorithm step spend commun step exchang load inform dimens cube step spend commun step load balanc therefor total number commun step algorithm d exampl run exampl cwa shown figur begin schedul node w task readi schedul valu w k calcul step valu w avg r follow then node calcul valu q k step everi node quota vector step subcub fg overload one valu w k follow node thu node send six task node node send three task node now load subcub f g f g balanc subcub task subcub fg fg overload valu w k follow node thu node send five task node node send two task node load subcub f g f g f g f g balanc subcub task overload valu w k follow a b c figur run exampl cwa node final node send one task node node send two task node node send two task node result balanc load node eight task total number taskhop mesh walk algorithm parallel schedul algorithm mesh topolog name mesh walk algorithm mwa shown figur first scan partial vector w along everi row node record w vector w node i mod calcul sum ij scan oper perform along node keep anoth vector c valu w avg r calcul node n gamma spread node i mod consequ node spread valu w avg igamman along row then vector q ffi calcul node well q igamman valu q calcul directli by i mod r mod r otherwis step first iter load among row node calcul valu j il j ir receiv jj il j task row r gamma receiv jj ir j task row j ir submesh row row overload j ir task need sent row r similarli submesh row underload j il task need sent row r gamma vector calcul determin mani task node need sent calcul j local oper without commun variabl fl ijl indic mani task reserv previou j node row variabl j ijl tell mani task remain sent out valu w ffi updat iter mesh walk algorithm mwa assum n theta n mesh number node global inform collect perform scan oper comput w vector averag load calcul quota calcul comput vector q k task exchang let initi receiv task well vector node n l updat w vector calcul number task sent out ij j l task well vector node n l updat w ffi vector figur mesh walk algorithm balanc load row follow lemma show end algorithm node number task quota lemma execut mwa number task node equal quota proof iter ij larger equal v assum equal assum exist ffi therefor fl j iv r j receiv jj il j task node receiv jj ir j task node therefor iter weight w updat iter therefor iter number task row algorithm step spend n commun step collect load inform along row n commun step collect load inform across row broadcast spread oper spend commun step step spend n commun step load balanc therefor total commun step algorithm n exampl run exampl mwa shown figur total number task comput parallel reduct valu w avg r calcul everi node q respect valu also calcul valu w list follow node row valu w list follow a b c d figur run exampl mwa iter everi j il therefor task sent one direct exampl valu ffi list follow row node send three task node node send six task node node row receiv task vector updat ffi then calcul vector node send nine task node node send three task node final node row updat ffi calcul vector node send three task node node send two task node task exchang shown figur b number task row equal quota q iter w calcul updat valu w valu q are valu j vector follow node exchang task shown figur c accord valu equal j result balanc load node eight task total number taskhop properti schedul algorithm section discuss schedul qualiti local commun cost twa cwa mwa algorithm next theorem show algorithm abl fulli balanc load number task equal divid number node node equal number task otherwis number task node differ one theorem differ number task node one execut twa cwa mwa proof lemma number task node equal quota execut twa cwa mwa sinc quota either w avg w avg differ number task node one algorithm also maxim local local task task migrat node nonloc task migrat node maximum local impli maximum number local task minimum number nonloc task lemma theorem assum number task evenli divid n number node evenli divid n algorithm nearlyoptim follow lemma give minimum number nonloc task lemma reach balanc load minimum number nonloc task proof node w must receiv w task node balanc load therefor total task must migrat nodesth next theorem prove three algorithm maxim local theorem number nonloc task twa cwa mwa algorithm proof time execut twa cwa mwa algorithm number task node less minw w avg twa node receiv task send task cwa mwa node send task weight larger w avg w task sent out thu node least task local therefor number nonloc task n theta w avg gamma w state lemma algorithm minim number nonloc task maxim local twa optim schedul algorithm next theorem prove twa minim number taskhop commun theorem twa algorithm minim total number taskhop total number commun proof edg k connect subtre parent minimum number task transmit parent subtre similarli minimum number task transmit subtre parent therefor total number taskhop minim subtre i q w least one commun subtre parent minimum number commun q commun subtre parent therefor total number commun minim cwa mwa heurist algorithm gener abl minim commun cost howev system less equal four node algorithm minim commun cost lemma cwa mwa algorithm minim commun cost system two four node proof commun cost system minim neg cycl system two node cycl system four node path consist least three edg form neg cycl either cwa mwa longest path two edg therefor neg cycl dem algorithm minim commun cost four node may path consist three edg perform studi twa optim algorithm minim commun maxim local balanc load optim heurist algorithm cwa mwa need studi simul purpos consid test set load distribut test set load processor randomli select mean equal specifi averag number task number processor vari averag number task averag weight per processor vari averag weight made integ load fulli balanc first studi cwa compar perform dem cwa fulli balanc load dem cannot case tabl show percentag fullybalanc case dem algorithm run dem algorithm differ number processor differ weight result test case number processor increas less fullybalanc case processor case processor fullybalanc case test set import measur schedul algorithm local cwa algorithm send necessari task processor maxim local dem algorithm result unnecessari task migrat here studi local dem algorithm dem abl fulli balanc load case fullybalanc case select result averag fullybalanc case test case normal local tabl i percentag fullybalanc case dem number averag weight processor measur tdem total number nonloc task dem algorithm topt minimum number nonloc task figur show normal local processor fullybalanc case exist processor report here normal local weight processor processor processor figur normal local dem next compar load balanc overhead dem simpl runtim overhead load balanc decis small howev unnecessari task migrat lead larg commun overhead compar time spent load balanc decis commun time domin factor cwa hand although need time make accur load balanc decis involv less commun overhead normal commun cost measur copt normal cost weight dem a processor normal cost weight dem b processor normal cost weight dem c processor figur normal commun cost dem cwa normal cost weight a processor normal cost weight b processor figur normal commun cost cwa copt cdem ccwa copt number taskhop dem cwa optim algorithm respect figur compar normal commun cost processor result averag dem fullybalanc case test case number taskhop cwa four processor minimum seen commun cost dem much larger cwa figur show normal commun cost cwa processor data present averag differ test case method assumpt use perform studi mwa algorithm cwa algorithm mwa abl fulli balanc load maxim local howev commun minim case normal commun cost mwa respect optim algorithm measur cmwa copt number taskhop mwa optim algorithm re spectiv mention lemma number taskhop mwa two four processor minimum figur show normal commun cost processor mesh organ either theta theta m data present averag differ test case small mesh mwa provid nearli optim result cost increas number processor normal cost weight processor processor processor a processor normal cost weight processor processor processor b processor figur normal commun cost mwa previou work parallel schedul static schedul share common idea util global inform achiev high qualiti load balanc but parallel schedul differ static schedul three aspect first schedul activ perform runtim therefor deal dynam problem second possibl load imbal caus inaccur grain size estim correct next turn schedul third elimin requir larg memori space store task graph schedul conduct increment fashion lead better scalabl massiv parallel machin larg size applic larg research effort direct toward process alloc distribut system recent comparison studi dynam load balanc strategi highli parallel comput given willebeeklemair reev eager et al compar senderiniti algorithm receiveriniti algorithm work similar assumpt includ gradient model develop lin keller random alloc algorithm develop differ author quit simpl effect adapt contract within neighborhood acwn receiveriniti diffus rid effect algorithm runtim parallel schedul similar dynam schedul certain degre method schedul task runtim instead compiletim schedul decis principl depend adapt runtim system inform howev substanti differ make appear two separ categori first system function user comput mix togeth dynam schedul clear cutoff system user phase runtim parallel schedul potenti offer easi manag low overhead second placement task dynam schedul basic individu action processor base partial system inform wherea parallel schedul schedul activ alway aggreg oper base global system inform categori schedul sometim refer preschedul close relat idea present paper preschedul schedul workload accord problem input there fore problem whose load distribut depend input cannot balanc static schedul balanc preschedul appli preschedul period load balanc runtim fox et al first adapt preschedul applic problem geometr structur work also deal type problem project parti autom preschedul nonuniform problem dimens exchang method dem appli applic problem without geometr structur conceptu design hypercub system may appli topolog kari ncube balanc load independ task equal grain size method extend willebeeklemair reev algorithm run increment correct unbalanc load caus vari grain size nicol propos direct map algorithm comput total number task use sumreduct howev minim commun cost elimin commun conflict increment schedul nbodi simul present task graph reschedul period correct load imbal howev runtim schedul yet parallel conclus recent research demonstr runtim parallel schedul provid lowoverhead load balanc global load inform parallel schedul synchron approach remov stabil problem abl balanc load quickli accur parallel schedul combin advantag static schedul dynam schedul processor cooper collect load inform exchang workload parallel parallel schedul ing possibl obtain high qualiti load balanc fullybalanc load maxim local commun cost reduc significantli three algorithm tree hypercub mesh network present paper difficult develop algorithm kari ncube combin cwa mwa algorithm acknowledg author would like thank xin help discuss r schedul parallel program task onto arbitrari target machin hypertool program aid messagepass system pyrro static task schedul code gener messagepass multiprocessor applic perform analysi compiletim optim approach list schedul algorithm distribut memori multiprocessor adapt load share homogen distribut system a comparison receiveriniti senderiniti adapt load share load distribut local distribut sy tem program hypercub multicomput dynam load balanc distribut memori multiprocessor commun effici global load balanc runtim increment parallel schedul rip distribut memori comput a parallel approach multiprocessor schedul an effici parallel schedul algorithm vector model dataparallel comput network matroid strategi dynam load balanc highli parallel comput analysi graph color base distribut load balanc algorithm dynam criticalpath schedul effect techniqu alloc task graph multiprocessor simul three adapt decentr control job schedul algorithm analysi three dynam distribut loadbalanc strategi vari global inform requir load share distribut system adapt dynam process schedul distribut memori parallel comput schedul multithread comput work steal the gradient model load balanc method fine grain concurr comput a random parallel branchandbound procedur random load balanc tree structur comput solv problem concurr processor parallel hierarch nbodi method a lowcost hypercub load balanc algorithm a partit strategi nonuniform problem multipro cessor dynam load balanc vortex calcul run multiprocessor the parti parallel runtim system the gener dimens exchang method load balanc kari ncube variant experi graph schedul map irregular scientif comput tr ctr chen xime lu xianliang runtim increment concentr schedul nownric acm sigop oper system review v n p april hwakyung rim juwook jang sungchun kim simpl reduct nonuniform dynam load balanc quantiz load hypercub multiprocessor hide balanc overhead journal comput system scienc v n p august janez brest viljem umer milan ojsterek dynam schedul pc cluster proceed acm symposium appli comput p februari march san antonio texa unit state wan yeon lee sung je hong jong kim sunggu lee dynam load balanc switchbas network journal parallel distribut comput v n p march heejun park byung kook kim optim task schedul algorithm cyclic synchron task gener multiprocessor network journal parallel distribut comput v n p march k antoni j garofalaki i mourto p spiraki hierarch adapt distribut algorithm load balanc journal parallel distribut comput v n p januari arnaud legrand hlne renard yve robert frdric vivien map loadbalanc iter comput ieee transact parallel distribut system v n p june chingjung liao yehch chung treebas parallel loadbalanc method solutionadapt finit element graph distribut memori multicomput ieee transact parallel distribut system v n p april yehch chung chingjung liao donlin yang prefix code match parallel loadbalanc method solutionadapt unstructur finit element graph distribut memori multicomput journal supercomput v n p jan