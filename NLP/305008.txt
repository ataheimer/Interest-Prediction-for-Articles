t integr rang comparison dataparallel compil system a abstracta major difficulti restructur compil parallel program gener compar parallel perform rang system problem size execut time vari system problem size initi fast implement may becom slow system problem size scale up paper introduc concept rang comparison unlik convent execut time comparison perform compar particular system problem size rang comparison compar perform program rang ensembl problem size via scalabl perform cross point analysi novel algorithm develop predict cross point automat correct algorithm proven methodolog develop integr rang comparison restructur compil dataparallel program preliminari prototyp methodolog implement test vienna fortran compil system experiment result demonstr rang comparison feasibl effect import asset program evalu restructur compil parallel program b introduct signific question parallel machin today mani decad softwar applic take advantag hardwar parallel tradit distribut memori architectur program use messag pass user respons explicitli insert commun statement sequenti program develop parallel languag vienna fortran fortran high perform fortran hpf improv situat provid highlevel featur specif data distribut among other vienna fortran compil system vfc fortran compil system develop support languag automat gener messag pass program howev current technolog code restructur system inher lack power fulli exploit perform offer distribut memori archi tectur primari motiv parallel process high perform effect effici restructur compil current barrier success simpl highlevel program model approach restructur program seen iter process parallel program transform iter perform current parallel program analyz predict iter then base perform result next restructur transform select improv perform current parallel program iter process termin certain predefin perform criteria met result explicit user intervent integr perform analysi restructur system critic support automat perform tune iter restructur process develop fulli compil integr perform system scalabl parallel machin especi challeng ing scalabl environ perform program vari data distribut system size number processor problem size superior program implement superior rang system problem size predict perform parallel program integr perform indic automat restructur compil two major challeng face research field moreov current perform analysi visual tool target messagepass program model parallel interprocessor commun explicit fall short support highlevel languag readili integr restructur compil two major function dataparallel restructur compil distribut data array processor choic appropri restructur transform key question realiz two function predict scale perform small number data distribut transform automat appropri optim decis made order compar rel perform rang problem system size scalabl predict propos solut studi scalabl abil maintain parallel process gain system problem size increas character scale properti code given machin slow code good scalabl may becom superior system problem size scale up system size perform rank differ code chang call cross point paper introduc concept rang comparison concern determin cross point base analyt result given section automat cross point predict automat rang comparison studi research iter algorithm first deriv predict scalabl cross point given parallel platform then connect iter algorithm exist static perform estim p discuss preliminari prototyp automat rang comparison implement vienna fortran compil system vfc final two applic test two differ data distribut verifi correct feasibl rang comparison approach current experiment result preliminari clearli demonstr feasibl effect rang comparison approach program restructur paper organ follow vfc perform estim tool introduc section concept scalabl perform cross point rang comparison present section iter algorithm automat perform predict describ detail experiment result given section illustr newli propos algorithm integr within vfc order predict cross point automat final section conclud summari compil system vfc parallel compil vienna fortran high perform fortran vfc integr sever tool program analysi transform among other provid parallel techniqu base upon domain decomposit conjunct singleprogrammultipledata spmd program model model impli processor execut program base differ data domain work distribut parallel program determin base underli data distribut accord ownercomput rule mean processor own datum perform comput make assign datum nonloc data referenc processor impli commun optim sever strategi extract singl element messag loop combin vector commun vector remov redund commun commun fusion aggreg differ commun statement commun aggreg analysi describ paper target toward regular comput stencil comput reli heavili compiletim analysi optim provid vfc perform estim integr tool vfc assist user perform tune regular program compil time p base singl profil run obtain characterist data branch probabl statement loop execut count well known overhead access nonloc data remot processor distribut memori architectur commonli order magnitud higher cost access local data commun overhead is therefor one import metric choos appropri data distribut commun overhead two separ perform paramet number data transfer amount data transfer sake breviti issu static estim commun overhead discuss section interest reader may refer inform regard perform paramet p note section defin commun time combin p paramet mention variou machin specif metric number data transfer number data transfer critic paramet reflect high messag startup cost distribut memori architectur commonli overhead commun decreas hoist outsid nest loop moreov commun insid specif loop bodi mani case impli loop sequenti due synchron processor involv commun p care model loop nest level commun place array access pattern data depend distribut control flow compil commun optim eg commun vector fusion order determin number data transfer high accuraci commun hoist outsid loop nest assum loos synchron commun model impli involv processor commun simultan commun statement number data transfer determin maximum number data transfer across involv processor commun cannot hoist outsid loop nest due data depend assum sequenti loop commun place well data transfer impli commun number data transfer commun given sum data transfer across processor involv commun amount data transfer current gener distribut memori architectur reduc impact messag length commun overhead applic transmit small data volum startup cost predomin commun cost factor howev increas data volum transmit messag transfer time per byte turn amount data transfer becom first order perform effect order provid highli accur estim amount data transfer given byte induc parallel program p estim number nonloc data element access incorpor machin specif data type size purpos p examin loop nest level commun place array access pattern data depend distribut control flow compil commun optim compil specifi commun pattern sourc code level target architectur part except data type size ignor consequ paramet port easili larg class distribut memori architectur perform rang comparison execut time import perform metric optim parallel program comparison bond specif pair system problem size execut time alon suffici perform comparison rang system problem size scalabl recogn import properti parallel algorithm machin recent year sever scalabl metric propos howev scalabl tradit studi separ independ properti recent relat scalabl execut time studi concept rang comparison introduc unlik convent execut time comparison perform compar particular system problem size rang comparison compar perform program rang system problem size via scalabl perform cross point analysi fulli understand concept rang comparison background scalabl cross point analysi need introduc isospe scalabl major drive forc behind parallel comput solv larg problem fast tradit execut time measur choic fixeds problem execut time itself howev adequ scalabl comput problem size scale system size speed defin work divid time propos altern primari metric scalabl comput averag speed achiev speed divid number processor use averag speed quantiti ideal would unchang scale system size follow definit first given isospe scalabl algorithmmachin combin algorithmmachin combin scalabl achiev averag speed algorithm given machin remain constant increas number processor provid problem size increas system size larg class algorithmmachin combin amc averag speed maintain increas problem size necessari problem size increas vari algorithm machin combin variat provid quantit measur scalabl let w amount work algorithm p processor employ machin let w amount work algorithm processor employ maintain averag speed scalabl system size p system size p algorithmmachin combin is work w determin isospe constraint final let p w time comput w work p processor system equat show scale execut time comput scalabl three approach propos determin scalabl are comput relat problem size speed directli measur scalabl predict scalabl certain predetermin paramet three approach practic import scalabl predict seem less expens benefit compil support parallel execut time p w divid two part ideal parallel process time parallel process overhead defin work gener debat scientif applic commonli agre float point flop oper count good estim work sequenti execut time delta comput capac defin time per unit work singl processor parallel process overhead contain load imbal overhead commun overhead possibl parallel degrad definit scalabl see scalabl predict scale work size w predict predict formula given comput achiev averag speed parallel process overhead p proce sor parallel degrad exist ie traceabl necessari suffici condit equat achiev process overhead gener function problem size unknown side equat use formula scalabl predict straightforward task perform cross point rang comparison theorem give relat scalabl execut time two differ algorithm machin combin analyt proven experiment confirm theorem algorithmmachin combin execut time ff delta respec tive initi state the initi system problem size combin higher scalabl combin scale system size execut time combin smaller ff multipl execut time combin solv w scale system size w scale problem size combin theorem show amc faster initi state better scalabl other remain faster scalabl rang rang comparison becom difficult initi faster amc smaller scalabl system size scale up origin faster code lower scalabl becom slower anoth code better scalabl find fastslow cross point critic optim perform choos effici data distribut program transform dataparallel environ find superiorityinferior cross point howev difficult definit cross point problem size system size depend definit give formal definit cross point base isospe scalabl scale cross point ff algorithmmachin combin execut time ff respect initi state say scale system size cross point combin ratio isospe scalabl combin combin greater ff p let amc execut time t scalabl phip p scale problem size w let amc execut time scalabl psip p scale problem size w definit p cross point amc fact equat phip notic sinc combin smaller execut time initi state p w superiorityinferior chang execut time give mean perform cross point correct theorem prove theorem algorithmmachin combin larger execut time algorithm machin combin initi state then scale system size p p scale cross point combin smaller scale execut time combin sinc two differ algorithmmachin combin may differ scalabl perform may cross cross point p differ scale problem size w w scale cross point differ equals cross point perform cross problem size theorem give relat scale cross point equals cross point theorem algorithmmachin combin larger execut time algorithm machin combin initi state p scale cross point combin larger execut time combin solv w system size scale problem size combin theorem give necessari condit equals perform cross initi system size p p equals cross point p must scale cross point p hand p scale cross point p equals cross point p perform cross occur scale cross point even term equals perform theorem provid mean rang comparison base theoret find figur give procedur rang comparison term scalabl automat crossingpoint predict procedur rang comparison list figur term scalabl scalabl differ code implement differ algorithmmachin combin gener still need determin rang comparison scalabl differ algorithm implement prestor perform comparison mani situat howev premeasur result scale system avail predict necessari propos iter method list figur comput w predict scalabl automat assum underli applic scalabl work w monoton increas function scale paramet input data size also assum parallel overhead either independ paramet n ideal scalabl monoton increas n parallel degrad exist iter algorithm consist three part main program two subroutin comput function oew invers oew function oew impli equat mathemat iter algorithm find fix point oew proof correct algorithm provid appendix correct proof give converg rate iter algorithm like iter method converg rate algorithm applic depend depend properti function fn scientif comput fn low degre polynomi function algorithm converg fast experiment result show algorithm requir three five iter converg solut error bound assumpt algorithm assum algorithmmachin combin execut time fft respect initi state ff object algorithm predict combin superior rang system size p p rang comparison begin determin scalabl combin determin scalabl combin combin superior rang els scale cross point endfifg endfrang comparison g figur rang comparison via perform cross point automat perform comparison vfc implement prototyp version iter algorithm within vfc predict scalabl execut time parallel code function p vfc fulli implement describ section figur show structur scalabl predict within vfc input program parallel instrument vfc messag pass code gener code compil execut target parallel machin perform analysi tool analyz tracefil obtain comput initi perform indic use scalabl predict final scalabl predict implement iter algorithm describ section iter algorithm problem size specifi sourc code automat parallel perform indic number transfer z amount data transfer d estim p scalabl predict perform process iter algorithm converg experiment result show approach provid effect solut captur scale properti parallel code support optim dataparallel program two case present detail section illustr iter algorithm use within vfc environ predict carri automat experi carri ipsc hypercub processor parallel process overhead use scalabl iter algorithm describ section contain commun overhead load imbal choos two code jacobi redblack contain sever dimension array impli good load balanc contain commun time obtain formula assumpt algorithm assum work w overhead increas function scale paramet n constant assum parallel code studi execut target machin w work p processor object algorithm comput scalabl system size p p error ffl iter method begin initi valu w comput begin iter k k els begin iter k k endfifg endfit methodg begin solv comput comput endfsubroutin oew g begin comput solv figur iter method predict scalabl ttracefil comput to comput computew k ye comput vfc parallel z d mp code instrum execut wt t zdt k comput perform indic scalabl predict sourc code figur scalabl predict within vfc z predict compil time problem size w use p machin specif paramet ae fi startup time transfer time per messag byte respect repres addit overhead network hop h number hop jacobi redblack parallel vfc perform measur processor ipsc hypercub perform indic obtain need comput initi state scalabl predict given work w total execut time p processor p comput time c commun overhead execut model jacobi redblack base equat follow assum comput jacobi redblack uniformli distribut across processor comput rate w averag speed determin measur comput time total execut time initi valu predict algorithm p comput base work w start iter new input data size n obtain k commun overhead scale predict use respect scalabl processor p processor determin termin condit satisfi fix ffl use experi otherwis method iter new paramet tabl show measur predict scalabl jacobi algorithm two differ data distribut strategi twodimension block distribut columnwis distribut program array twodimension onedimension processor array respect differ percentag predict measur valu given third column tabl mea pred mea diff pred mea diff p tabl jacobi twodimension distribut predict measur scalabl mea pred mea diff pred mea diff p tabl jacobi column distribut predict measur scalabl experiment result confirm predict scalabl accur variat scale perform variou data distribut also captur tabl show predict measur scalabl valu redblack algorithm twodimension distribut tabl present predict execut time versu mea pred mea diff pred mea diff tabl redblack twodimension distribut predict measur scalabl measur one jacobi twodimension block distribut one dimension distribut redblack twodimension block distribut respect initi problem size use tabl determin asymptot speed best perform chosen measur averag execut time requir singl iter cover parallel p scalabl predict fig redblack parallel time account sec p sec scalabl predict sec overal everi iter took approxim sec remain constant chang problem mea diff tabl jacobi d predict measur execut time in s mea diff tabl jacobi c predict measur execut time in s size execut time redblack written fft accord tabl scalabl jacobi higher redblack therefor theorem smaller initi execut time larger scalabl show jacobi scale better redblack confirm measur result given tabl interest result given two differ jacobi version tabl see distribut implement larger initi execut time better scalabl columnwis distribut accord theorem cross point scale system size p howev case cross point greater cannot confirm prototyp implement figur show cross point rang processor point scale perform sensit small applic increas system size caus notic chang communicationcomput ratio jacobi communicationcomput ratio increas decreas problem size initi state execut time jacobi columnwis distribut strategi given s jacobi distribut fft redblack mea diff tabl redblack d predict measur execut time in s execut time distribut column distribut figur equals cross point jacobi start point consid scalabl result tabl see distribut scale better columnwis distribut ratio two predict scalabl greater ff therefor definit cross point execut time distribut becom less columnwis distribut cross point due commun behavior involv ipsc confirm measur execut time shown figur a p tabl predict scalabl jacobi distribut p p tabl predict scalabl jacobi columnwis distribut order verifi whether cross point equals cross point measur code accord theorem correspond equals cross point result shown figur b execut time distribut column distribut processor execut time distribut column distribut a b figur scale cross point a equals cross point b jacobi n conclus mani way parallel program rel perform gain differ parallel strategi vari problem size system size compar perform differ implement algorithm rang system problem size crucial develop effect parallel compil ultim reduc burden parallel program studi practic methodolog develop automat rang comparison test dataparallel compil system propos methodolog built rigor analyt model correct effici experiment result confirm effect part parallel compil paper offer sever contribut first identifi import feasibl rang comparison dataparallel compil system next iter algorithm develop experiment predict scalabl algorithmmachin combin enabl automat rang comparison exist static estim modifi integr automat rang comparison dataparallel compil system final rang comparison approach test part vienna fortran compil system experiment result demonstr feasibl high potenti rang comparison parallel compil concept analyt result given section gener applic algorithmmachin combin scalabl predict algorithm given section assum workload determinist function scale factor n assumpt quit reason algorithm requir estim parallel process overhead algorithm test p static perform estim vienna fortran compil system due avail vfc p experiment result present paper limit node ipsc avail univers vienna integr rang comparison methodolog introduc research howev gener adopt larg parallel system well advanc compil system appendix proof correct appendix give formal proof correct iter algorithm list figur proof independ n scalabl instruct main program done otherwis assumpt comput work w parallel process overhead monoton increas function scale paramet n therefor oe accord equat problem size w scale problem size maintain isospe sinc f g increas function n f gamma g gamma also sinc a p constant scalabl predict process relat impli w increas increas therefor conclud oe oe gamma also increas function w definit scalabl initi valu w satisfi equat ideal scalabl scalabl equal one reach sinc parallel process overhead decreas n inequ w w w done instruct main program otherwis iter method need use find w w case main program use iter method increas function induct w also sinc w less w oew increas induct therefor shown inequ preserv nonneg integ k hold initi valu w pass limit side yield impli iter converg true solut w case els instruct main program shown figur time iter formula use follow similar argument given case conclud iter converg solut stabail iter algorithm analyz below b denot purturb valu b delta b p sinc g f function polynomi purturb function b oe close oe long small enough iter w purturb magnitud deriv oe small deriv f away ie k dfx therefor conclud iter w small enough definit f k dfx easili satisfi similar argument iter w small enough requir k dgx c alway satisfi satisfi definit function g parallel overhead increas much origin overhead close w case invers iter w use algorithm acknowledg author grate mr yu zhuang help strengthen proof correct iter algorithm anonym refere construct comment revis paper r the next year program vienna fortran fortran languag specif high perform fortran languag specif version vienna fortran compil system version user guid an integr compil perform analysi environ data parallel program automat perform predict parallel program estim optim perform parallel program buffersaf commun optim base data flow analysi perform predict a unifi framework optim commun dataparallel program a commun placement framework unifi depend dataflow analysi tau a static paramet base perform predict tool parallel program solv problem concurr processor develop parallel method processor hypercub scalabl parallel algorithmmachin combin introduct parallel comput perform metric keep focu runtim the relat scalabl execut time perform rang comparison via cross point analysi perform predict case studi use scalabl sharedvirtu memori machin perform consider share virtual memori machin commun overhead predict influenc scalabl tr ctr xianh sun scalabl versu execut time scalabl system journal parallel distribut comput v n p februari thoma fahring bernhard scholz xianh sun executiondriven perform analysi distribut parallel system proceed nd intern workshop softwar perform p septemb ottawa ontario canada