t algorithm constrain weight nonlinear least squar a hybrid algorithm consist gaussnewton method secondord method solv constrain weight nonlinear least squar problem develop analyz test one advantag algorithm arbitrarili larg weight handl weight merit function get unnecessarili larg iter diverg saddl point local converg properti gaussnewton method thoroughli analyz simpl way estim calcul local converg rate gaussnewton method given assumpt constrain weight linear least squar subproblem attain gaussnewton method ill condit global converg toward firstord kkt point prove b introduct assum f r n continu differenti function diagon matrix weight discuss gaussnewton method second order method solv problem min xr denot norm simplic without loss gener assum weight normal sort normal easili done first sort zero weight reduc problem divid remain nonzero weight smallest posit weight knowledg exist algorithm solv base unweight problem min assum ordinari gaussnewton method use solv search direct p got solv min p rg note solv unweight problem thu condit problem determin kkk kk k k pseudo invers k hand linear without explicitli multipli weight solv weight linear least squar problem obtain search direct p condit problem mainli determin kbk kjk detail discuss condit number see problem may ill condit regard unweight linear least squar problem despit fact well condit regard weight linear least squar problem obvious import look class weight nonlinear least squar problem anoth import advantag use instead former defin gener problem class latter evid allow weight infinit larg precis defin vector equat weight correspond zero element note lagrang multipli correspond ith constraint consequ defin return proper way calcul lagrang multipli problem rewritten use henc allow infinit weight origin problem formul defin class weight nonlinear least squar problem nonlinear equal constraint even specif assum p infinit weight problem state theta f equival formul problem use min cours could start defin problem one instead without need notat would get unnecessarili complic next section describ gaussnewton method solv local converg properti gaussnewton method analyz section section show that certain assumpt nondegeneraci global converg achiev gaussnewton method slow converg second deriv avail reason cost newton method may use solv howev larg possibl infinit weight pure newton method base form hessian gx may work or infinit weight even defin natur approach use perturb method call gener newtonraphson method the gnr method section construct analyz algorithm solv base gnr method comput experi present section final discuss result give hint possibl futur work gaussnewton method use system equat gaussnewton method nonlinear least squar problem linear around current iter point x k search direct p k comput solut next iter x steplength presenc larg weight possibl infinit adequ reformul gammaf simplic drop iter index k sever name linear system equat equilibrium equat system equat augment system equat call system equat matrix call system matrix less obviou reason use element correspond infinit weight approxim lagrang multipli use second order method describ section follow lemma give relev condit system matrix nonsingular lemma system matrix nonsingular row j correspond infinit weight linearli independ j full column rank exist sever stabl algorithm solv see eg refer chosen use modifi qr decomposit see reason follow modifi qr decomposit simpl easi comput ident ordinari qr decomposit weight equal modifi qr decomposit also easili reus second order gnr method see section modifi qr decomposit j r mthetan defin r nthetan upper triangular matrix pi permut matrix decomposit q r nonsingular exist system matrix nonsingular see lemma system equat solv modifi qr decomposit follow way use decomposit get r make partit mmgamman solut mgamman local rate converg gaussnewton method section describ local converg properti gaussnewton method describ previou section analysi depend much upon perturb analysi constrain weight linear least squar problem done defin invers system matrix use notat state prove two import theorem local converg rate project residu fact local converg properti two quantiti are shall see similar final show j k p k local converg rate x x j k p k independ parametr r n assum b x solut defin b correspond notat quantiti evalu b x necessari condit algorithm converg without regular system matrix full rank conveni make follow definit definit system matrix nonsingular x say x nondegener point nondegener point invers system matrix given gener invers j see immedi get follow theorem describ local behaviour x theorem assum fp k g gener solv point x nondegener b x solut b vector b x r f proof x f use taylor expans first term express express second term gammab k f use perturb ident p say use ident z f equat becom equat insert give theorem gaussnewton method written b theorem conclud get follow theorem theorem defin eigenvalu h x lim sup xk xk easi get estim local converg rate use matrix defin b r r gammat pi use quantiti estim close x k solut b x project residu obliqu project f k onto rj k follow theorem show j k p k local converg behaviour theorem assum fp k g gener solv point x nondegener x k vector x k r f proof denot project j k b k p k use taylor expans multipli p k obtain equal b k hold identifi last term equat get henc perturb ident p get use fact k ffij k b k equat becom last equal follow ident gammap k togeth taylor expans ffij k give theorem follow insert matrix correspond h x project residu k b easi show h x h nonzero eigenvalu henc theorem follow corollari corollari defin b k invers system matrix lim sup ks eigenvalu matrix h x defin relat also use determin ks k kk k k reflect linear converg rate second order method use converg gaussnewton method slow use higher order method see also algorithm sever quantiti invari chang parametr exampl follow theorem theorem matrix b independ parametr r n proof assum fx want show b gener invers ry b now consid taylor expans delta x delta x compar taylor expans taylor expans use j final get prove theorem consequ theorem local converg x main argument choos jp measur close solut follow theorem direct consequ theorem project f rj independ parametr r n global converg section assum x k k iter index nondegener p k solut x k noth els state assum limit denot k sum explicitli state upper lower limit one infin merit function merit function chosen goal find matrix k merit weight step length ff k iter global converg toward first order kuhntuck point prove comput k use approxim d fix matrix d defin obvious suffici condit p k descent direct phix d x k oe realiz determin good matrix upsilonx k merit weight solv min kupsilonk st ffi small posit constant lower limit weight determin previous comput weight see below alway solut lim argf min ff note keep weight larg import practic global converg constraint must satsifi describ algorithm comput merit weight k use upsilonx k becom unnecessarili larg first describ method solv algorithm comput actual merit weight k solv chosen use maxnorm sinc give simpl algorithm problem rewritten min kuk u diagon upsilonx k diagon w jp given problem consist vector matric first step algorithm reduc u get new problem correspond part u left reduct ae readi solut otherwis choos y e vector one thu attain equal constraint respect reduc problem copi vector shorter ae smaller procedur repeat whole u found easili realiz infinit weight chang algorithm algorithm termin solut determin actual merit weight k solut upsilonx k weight may get larg close saddl point iter diverg saddl point that alway case gaussnewton method would like weight decreas accomplish save say t older version merit weight matric initi iter kth iter updat algorithm algorithm solv vector ux k k new sequenc algorithm gaussnewton algorithm describ line search quadrat merit function algorithm initi start vector x k converg comput comput use modifi qr decomposit j k determin k algorithm determin step length ff k prove global converg need follow two technic lemma prove algorithm global converg lemma use k arbitrari diagon element k lemma assum k fd k g bound let subsequ fd k g k j k j posit seri converg converg proof take converg too assum b n converg b n henc k g bound sequenc increas limit b gamma converg b lemma assum arbitrari compon k diagon k stay bound k let v k correspond diagon element v lim seri converg proof let us first exclud trivial case v k becom equal upper bound finit k sequenc fv k g increas infinit sequenc henc lim v k exist denot v take ffl arbitrari small fix posit number k kvalu henc v sinc ffl arbitrari impli v d k v k follow thu v v consequ k v let fd k g subsequ fd k g k k lemma know seri converg converg let us prove latter seri converg v k k follow henc sinc subseri increas v seri converg sinc posit seri suffici prove bound henc remain prove seri converg sinc save older weight updat step reach t updat v t equal one earlier t way elimin v t correspond j way seen v t equal one j pair also elimin seri go elimin element way get t thu posit seri bound converg complet proof main global converg theorem cover bound unbound sequenc merit weight theorem let fx k g fd k g gener algorithm assum bound system matrix nonsingular closur g sequenc fx k g either finit termin kkt point accumul point kkt point proof trivial finit termin kkt point let us assum infinit sequenc algorithm impli suffici consid follow two case case treat separ exist subsequ fx k g fx k g kd bound possibl choos subsequ fx j k g fx k g x x e x algorithm follow kd k k continu point closur fx k g except kkt point e x accumul point fx k g kkt point ii inequ one prove point e x cannot accumul point fx k g exist the proof trivial extens similar proof pp lemma know converg goldstein armijo condit algorithm then given k follow everi point e x closur fx k g kkt point exist constant ffl satisfi henc kkt point remain possibl accumul point prove theorem case ii line search chosen keep thing simpl therefor use standard cubic interpol approxim minimum merit function oeff anoth effici line search algorithm found regular use simpl form subspac minim describ unweight constrain case abl prove gener global converg result one theorem shall see comput experi regular seem work appropri gener newtonraphson method constrain newton method solv base quadrat subproblem gp first order approxim lagrang multipli solut p given linear system equat g gammaf main disadvantag use larg weight w quadrat subproblem matrix may ill condit avoid ill condit due larg weight w solv gammaf method gener newtonraphson method gnr method gnr method interest theoret motiv assum reach point x k first order approxim known x k solv perturb problem min project onto rj k henc know solut x k want comput solut perturb problem min use quadrat approxim zx x k comput solut problem whose error okp k f k k chang back origin notat fx perturb solut found solv problem seen exist matrix n k x solut take x quadrat approxim get also seen j k n k depend surfac parameter x consequ j k p k independ parameter r n gener newtonraphson method fact quadrat converg method j k p k independ parametr see assum exist anoth method comput e e seri expans uniqu j k e impli e defin z matrix whose column span null space j call p descent direct p z drawback constrain newton method base gnr method nonsingular matrix suffici p descent direct howev use gnr method close solut see algorithm therefor use gnr method undamp get need g gaussnewton search direct matrix singular use alreadi avail gaussnewton direct use modifi qr decomposit solv possibl reduc size system ignor permut matrix possibl rewrit r impli q reduc r gammag gamma first n element q q respect matrix may indefinit must either use stabl method indefinit system see eg add condit submatric one possibl latter kind assum r well condit use r reduc r gammag gamma solut matrix rmnr gammat g nonsingular take gaussnewton step comput experi algorithm use test shown below algorithm initi determin jacobian j vector f comput gn direct p solv regular need second fals close second rate comput gnr direct p gnr solv matrix nonsingular gn comput merit weight algorithm determin step length ff use line search describ section merit function oeff x use pure gn method variabl second fix valu fals test algorithm three differ problem describ ap pendix schittkowski bogg bogg intent test show algorithm faster exist algorithm show algorithm handl larg weight inadequ model ill condit linear problem anoth import aim test verifi theoret result local converg rate therefor natur use small simpl test problem defin two differ measur converg rate gaussnewton method emphas k excel way estim converg rate regular need b x known first problem schittkowski first solv gaussnewton method result tab largest weight weight multipli explicitli f form algorithm break numer instabl note slow growth merit weight first problem schittkowski gaussnewton method e e e e e e e e e e e e e e e e e e e e e e tabl schittkowski gnr method e e e e e e solv gnr method show tab asterisk indic gnr method use step second problem bogg constrain problem solv gaussnewton method tab gnr method tab merit weight gaussnewton method equal one shown tab remain two test problem illustr regular rank problem shown headlin rank tab second test problem bogg solv gaussnewton method jacobian rank defici start point third problem bogg jacobian solut rank defici result shown tab discuss claim develop effici fairli robust algorithm solv with possibl infinit weight discuss intro duction howev difficult us measur effect algorithm bogg gaussnewton method e e e e e e e e e e e e tabl bogg gnr method e e e e e e e e e e e are knowledg algorithm solv gener problem local converg properti well understood gaussnewton algo rithm especi interest local converg result valid whole problem class defin independ parametr r n merit function especi suit weight constrain problem techniqu choos merit weight effect lead unnecessari larg weight bogg gaussnewton rank defici start point robust shown algorithm global converg iter point nondegener remain find way regular row j correspond larg weight becom almost linearli depend believ difficult challeng problem solv appendix test problem appendix defin three test problem weight sequenc also give start point x start solut b residu fbx exampl includ unconstrain well constrain problem schittkowski unconstrain problem modifi incorpor weight constrain problem jacobian rank defici second bogg gaussnewton rank defici solut e e e e start point x start bogg constrain problem jacobian rank defici solut r strategi global converg sequenti quadrat program algorithm numer method unconstrain optim nonlinear equat matrix comput modifi qr decomposit weight constrain linear least squar iter solut nonlinear equat sever variabl comparis algorithm nonlinear least squar problem test exampl nonlinear program code perturb theori condit number gener constrain linear least squar problem tr ctr hiroshi hosob hierarch nonlinear constraint satisfact proceed acm symposium appli comput march nicosia cypru