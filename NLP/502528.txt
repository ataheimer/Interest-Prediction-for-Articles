t data mine spars grid use simplici basi function a recent present new approach classif problem aris data mine base regular network approach but contrast method employ ansatz function associ data point use grid usual highdimension featur space minim process cope curs dimension employ spars grid thu ohnnd instead ohnd grid point unknown involv denot dimens featur space give mesh size use spars grid combin techniqu classif problem discret solv sequenc convent grid uniform mesh size dimens spars grid solut obtain linear combin contrast former work dlinear function use appli linear basi function base simplici discret allow handl dimens algorithm need less oper per data pointw describ spars grid combin techniqu classif problem give implement detail discuss complex algorithm turn method scale linearli number given data point final report qualiti classifi built new method data set dimens turn new method achiev correct rate competit best exist method b introduct data mine process nding pattern relat trend larg data set exampl rang scien tic applic like postprocess data medicin evalu satellit pictur nancial commerci applic eg assess credit risk select custom advertis campaign letter overview data mine variou task approach see paper consid classic problem aris data mine given set data point ddimension featur space togeth class label data classier must construct allow predict class newli given data point futur decis make wide use approach are besid other decis tree induct rule learn adapt multivari regress spline neural network support vector machin interestingli techniqu interpret framework regular network approach allow direct descript import neural network also allow equival descript support vector machin nterm approxim scheme here classic data interpret scatter data approxim problem certain addit regular term highdimension space present new approach classic problem also base regular network approach but contrast method employ mostli global ansatz function associ data point use independ grid associ local ansatz function minim process similar numer treatment partial dierenti equat here uniform grid would result oh denot dimens featur space give mesh size therefor complex problem would grow exponenti encount curs dimension probabl reason convent gridbas techniqu use data mine now howev socal spars grid approach allow cope complex problem extent method origin develop solut partial dierenti equat use success also integr equat interpol approxim eigenvalu problem integr problem inform base complex commun also known hyper bolic cross point idea even trace back ddimension problem spars grid approach employ oh point di cretiz accuraci approxim howev nearli good convent full grid method provid certain addit smooth requir fulll thu spars grid discret method employ also higherdimension problem curs dimension convent full grid method affect spars grid much less paper appli spars grid combin techniqu classic problem regular network problem discret solv certain sequenc convent grid uniform mesh size coordin direct contrast dlinear function stem tensorproduct approach use appli linear basi function base simplici discret comparison approach allow process dimens need less oper per data point spars grid solut obtain solut dierent grid linear combin thu classier build spars grid point data point discuss complex method give method scale linearli number instanc ie amount data classi therefor method well suit realist data mine applic dimens featur space moder high eg preprocess step amount data larg furthermor qualiti classier build new method seem good consid standard test problem uci repositori problem huge synthet data set dimens turn new method achiev correct rate competit best exist method note combin method simpl use parallel natur straightforward way remaind paper organ follow section describ classic problem framework regular network minim qua dratic function discret featur space deriv associ linear problem focu gridbas discret techniqu then introduc spars grid combin techniqu classic problem discuss properti furthermor present new variant base discret simplic discuss complex aspect section present result numer experi conduct spars grid combin method demonstr qualiti classier build new method compar result one one obtain dierent form svm nal remark conclud paper problem classic data interpret tradit scatter data approxim problem certain addit regular term contrast convent scatter data approxim applic encount quit highdimension space end approach regular network give good framework approach allow direct descript import neural network also allow equival descript support vector machin nterm approxim scheme consid given set alreadi classi data the train rg assum data obtain sampl unknown function f belong function space v dene r sampl process disturb nois aim recov function f given data good possibl clearli illpos problem sinc innit mani solut possibl get wellpos uniqu solvabl problem assum knowledg f end regular theori impos addit smooth constraint solut approxim problem regular network approach consid variat problem min fv here c denot error cost function measur interpol error f smooth function must well dene rst term enforc close f data second term enforc smooth f regular paramet balanc two term typic exampl r denot gradient laplac oper valu chosen accord crossvalid techniqu principl structur risk minim note nd exactli type formul case scatter data approxim method see regular term usual physic motiv discret restrict problem nite dimension subspac function f replac ansatz function f j g n span vn prefer form basi vn coecient f j g n j denot degre freedom note restrict suitabl chosen nitedimension subspac involv addit regular regular discret depend choic vn remaind paper restrict choic given linear oper p way obtain minim problem feasibl linear system thu minim fn nite dimension space vn plug obtain dierenti respect k k k equival matrix notat end linear system c squar n n matrix entri c rectangular n matrix entri b vector contain data label length unknown vector contain degre freedom j length n depend regular oper obtain differ minim problem vn exampl use gradient fn regular express obtain poisson problem addit term resembl interpol problem natur boundari condit partial dierenti equat neumann condit discret give us linear system c correspond discret laplacian obtain classier fn solv system grid base discret approxim yet specic nite dimension subspac vn type basi function want use contrast convent data mine approach work ansatz function associ data point use certain grid attribut space determin classier help grid point similar numer treatment partial dierenti equat reason simplic remaind paper restrict ourself case x i situat alway reach proper rescal data space convent nite element discret would employ equidist grid n mesh size coordin direct n renement level follow alway use gradient regular express let j denot nite element method piecewis dlinear ie linear dimens test trialfunct nj x grid would give nj nj x variat procedur would result discret linear system size matrix entri correspond note fn live space vn spanf nj discret problem might principl treat appropri solver like conjug gradient method multigrid method suitabl ecient iter method howev direct applic nite element discret solut result linear system appropri solver clearli possibl ddimension problem larger four number grid point order oh best case number oper order encount socal curs dimension complex problem grow exponenti d least reason valu n aris system store solv even largest parallel comput today spars grid combin techniqu therefor proceed follow discret solv problem certain sequenc grid l l l uniform mesh size h tth coordin direct grid may possess dierent mesh size dierent coordin direct end consid grid l twodimension case grid need combin formula level shown figur nite element approach piecewis dlinear test trial function lj x grid l would give f l l lj lj x variat procedur would result discret system l matric m unknown vector d solv c figur combin techniqu level two dimens problem feasibl method end use diagon precondit conjug gradient algorithm also appropri multigrid method partial semi coarsen appli discret solut f l contain space piecewis dlinear function grid l note problem substanti reduc size comparison instead one problem size nd deal problem size dimv l moreov problem solv independ allow straightforward parallel coars grain level see also simpl eectiv static load balanc strategi avail final linearli combin result f l lj lj x dierent grid l follow f c result function f c n live spars grid space space dimv span piecewis dlinear hierarch tensor product basi see note summat discret function dierent space v l involv dlinear interpol resembl transform represent hierarch basi detail see howev never explicitli assembl function f c keep instead solut f l dierent grid l aris combin formula now linear oper f f c easili express mean combin figur twodimension spars grid left threedimension spars grid act directli function f l ie ff c l l nd q ff l therefor want evalu newli given set data point f the test evalu set form combin associ valu f l accord evalu dierent f l test point done complet parallel summat need basic allreducegath oper second order ellipt pde model problem proven combin solut f c n almost accur full grid solut fn ie discret error jje c provid slightli stronger smooth requir f full grid approach hold need seminorm bound furthermor seri expans error necessari combin techniqu exist shown pde model problem combin techniqu one variou method solv problem spars grid note exist also nite dierenc galerkin nite element approach work directli hierarch product basi spars grid combin techniqu conceptu much simpler easier implement moreov allow reus standard solver dierent subproblem straightforwardli paralleliz simplici basi function far mention dlinear basi function base tensorproduct approach case present detail grid combin techniqu linear basi function base simplici discret also possibl use socal kuhn triangul rectangular block see figur now summat discret function dierent space l involv linear interpol tabl complex storag assembl matrixvector multipl dierent matric aris combin method one grid l discret approach c l g l store togeth one matrix structur dlinear basi function linear basi function l b l storag o n o n o m o assembl o n od m od m o mvmultipl o n o n o m o figur kuhn triangul threedimension unit cube theroet properti variant spars grid techniqu still investig detail howev result present section warrant use see all slightli wors result linear basi function dlinear basi function believ new approach result approxim order sinc new variant combin techniqu overlap support ie region two basi function nonzero greatli reduc due use simplici discret complex scale signicantli better concern cost assembl storag nonzero entri spars popul matric see tabl note gener oper p complex c l scale o n choic zeroentri aris need consid reduc complex iti see tabl right column c l actual iter solut process by diagon precondit conjug gradient method scale independ number data point approach note howev storag run time complex still depend exponenti dimens d present due limit memori modern workstat mbyte gbyte therefor deal case dlinear basi function linear basi function decomposit matrix entri sever comput parallel environ would permit dimens numer result appli approach dierent test data set use synthet data real data practic data mine applic data set rescal evalu method give correct rate test data set avail tenfold crossvalid result otherwis detail criti figur spiral data set spars grid level top left bottom right cal discuss evalu qualiti classica tion algorithm see twodimension problem rst consid synthet twodimension problem small set data correspond certain structur spiral rst exampl spiral data set propos alexi wieland mitr corp here data point describ two intertwin spiral see figur sure artici problem appear practic ap plicat howev serv hard test case new data mine algorithm known neural network sever problem data set neural network separ two spiral tabl give correct rate achiev leaveoneout crossvalid method ie fold cross valid best test correct achiev level comparison figur show correspond result obtain spars grid combin method level level two spiral clearli detect resolv note grid point contain spars grid level spars grid point shape two reconstruct spiral get smoother tabl result ripley data set linear basi dlinear basi best possibl level tenfold test test data test data linear dlinear level train correct test correct tabl leaveoneout crossvalid result spiral data set reconstruct get precis ripley data set taken consist train data test point data set gener synthet known exhibit error thu better test correct expect sinc train test data proceed follow first use train set determin best regular paramet per tenfold crossvalid best test correct rate correspond given dierent level n rst two column tabl comput spars grid classier train data column three tabl give result classier previous unknown test data set see method work well alreadi level sucient obtain result reason sure rel simplic data see figur hyperplan enough separ class quit properli also see much need use higher level contrari even overt eect visibl figur column show result achiev almost result dlinear function see kind result could possibl sophist strategi determ give last two column tabl test correct achiev best possibl end comput discret valu spars grid classier data point evalu test set pick best result clearli see much dierenc indic approach determin valu train set crossvalid work well almost result linear dlinear basi function note test correct figur ripley data set combin techniqu linear basi function left level right level achiev respect data set dimension problem bupa liver bupa liver disord data set irvin machin learn databas repositori consist data point featur selector eld use split data set instanc instanc respect test data therefor report tenfold crossvalid result compar dlinear result two best result therein introduc smooth support vector machin ssvm classic support vector machin svm jjjj result given tabl expect spars grid combin approach linear basi function perform slightli wors d linear approach best test result level new variant spars grid combin techniqu perform slightli wors ssvm wherea dlinear variant perform slighli better support vector machin note result svm approach like support vector machin use norm approach svm jjjj report somewhat wors tabl result bupa liver disord data set linear dlinear comparison method level fold train correct svm fold test correct ssvm svm jjjj level fold train correct fold test correct level fold train correct fold test correct level fold train correct fold test correct synthet massiv data set measur perform massiv data set produc datgen dimension test case million train point point test use call datgen r xrororo o p e result given tabl note alreadi level test correct achiev main observ test case concern execut time measur pentium iii mhz machin besid total run time also give cpu time need comput matric l see linear basi function realli huge data set million point process reason time note comput time spent data matrix assembl and importantli execut time scale linearli number data point latter also case dlinear func tion but mention approach need oper per data point result much longer execut time compar also tabl especi assembl data matrix need total run time variant present exampl linear basi approach time faster dlinear approach renement level eg level need minut linear case hour dlinear case higher dimens factor even larger dimension problem forest cover type forest cover type dataset come uci kdd archiv also use approach similar follow consist cartograph variabl meter cell forest cover type pre dict origin measur attribut result attribut data set besid quantit variabl binari wilder area binari soil type variabl use quantit variabl class label valu sprucefir lodgepol pine ponderosa pine cottonwoodwillow aspen douglasr krummholz like report result classi cation ponderosa pine instanc total sinc far less instanc belong ponderosa pine weigh class factor ie ponderosa pine class valu other treshold valu separ class data set randomli separ train set test set evalu set similar size result dimens could report tabl present result dimens chosen there ie dimens dimens well give overview behavior sever s present level n overal correct result correct result ponderosa pine correct result class three valu give result evalu set chosen see tabl alreadi level test correct ponderosa pine dimension version higher renement level give better result result evalu set almost correspond test correct note correct rate achiev evalu set usag dimens improv result slightli get evalu result level higher renement level improv result data set note forest cover exampl sound enough exampl classic might strike forest scientist amusingli superci known year dynam forest growth domin eect speci present given locat yet dynam variabl classier one see warn never assum avail data contain relev inform synthet massiv data set measur perform still higher dimension massiv data set produc datgen dimen sional test case million train point point test use call datgen r xro like synthet dimension exampl main observ concern run time measur pentium iii mhz machin besid total run time also give cpu time need comput matric g l note highest amount memori need for level case million data point mbyte mbyte matrix mbyte keep data point memori run time spent assembl tabl result synthet massiv data set train test total data matrix point correct correct time sec time sec iter linear basi function level million level million level million dlinear basi function level million level million data matrix time need data matrix scale linearli number data point see tabl total run time seem scale even better linear conclus present spars grid combin techniqu linear basi function base simplic classic data moderatedimension space new method gave good result wide rang problem capabl handl huge data set million point more run time scale linearli number data import properti mani practic applic often dimens problem substanti reduc certain preprocess step number data extrem huge believ spars grid combin method possess great potenti practic applic problem demonstr ripley data set best valu regular paramet determin also practic relev parallel version spars grid combin techniqu reduc run time signicantli see note method easili paralleliz alreadi coars grain level second level parallel possibl grid combin techniqu standard techniqu known numer treatment partial differenti equat sinc necessarili dimens need maximum renement level modic combin techniqu regard dierent renement level dimens along line seem promis note furthermor approach deliv continu classier function approxim data therefor use without modic regress problem well contrast mani method like eg decis tree also two class handl use isolin dierent valu final reason simplic use oper r dierenti eg oper employ associ regular nite element ansatz function acknowledg part work support german bundesministerium fur bildung und forschung bmbf within project grmbn work carri cooper prudenti system softwar gmbh chemnitz author thank one refere remark forest cover data set r adapt verfahren f uci kdd archiv uci repositori machin learn databas ecolog consequ comput model forest growth tensor product approxim space e learn data concept data mine method knowledg discoveri approxim statist test compar supervis classi inform complex multivari fredholm integr equat sobolev class simplizialzerlegungen von beschr comput eigenproblem hydrogen helium strong magnet electr parallel spars grid approach data mine data mine spars grid numer integr use spars grid equival spars approxim support vector machin regular theori neural network architectur gener cross valid method choos good ridg paramet combin techniqu spars grid solut pde multiprocessor machin adapt spars grid multilevel method ellipt pde base optim tensorproduct approxim space spars grid boundari integr equat combin techniqu solut spars grid problem high dimension smooth base multilevel analysi grundlagen der goemetrischen datenverarbeitung combinatori lemma topolog ssvm smooth support vector machin classi program creat structur data bayesian neural network classi neural network relat method classi compar classi die method der finiten di interpol spars grid nikolskijbesov space domin mix smooth spiral pattern recognit possibilist measur quadratur interpol formula tensor product certain class function approxim function bound mix deriv solutio illpos problem estim depend base empir data natur statist learn theori spline model observ data spiral data set spars grid tr regular theori neural network architectur approxim scatter data use smooth grid function natur statist learn theori inform complex multivari fredholm integr equat sobolev class spiral pattern recognit possibilist measur equival spars approxim support vector machin data mine method knowledg discoveri adapt spars grid multilevel method ellipt pde base finit differ approxim statist test compar supervis classif learn algorithm bayesian neural network classif comput eigenproblem hydrogen helium strong magnet electr field spars grid combin techniqu learn data compar classifi parallel solut pde network workstat vector comput ctr jochen garck regress optimis combin techniqu proceed rd intern confer machin learn p june pittsburgh pennsylvania deepak k agarw shrinkag estim gener proxim support vector machin proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli edmonton alberta canada j garck m griebel m thess data mine spars grid comput v n p novemb