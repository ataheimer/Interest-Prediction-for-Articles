t data mine criteria treebas regress classif a paper concern construct regress classif tree adapt data mine applic convent tree end propos new split criteria grow tree convent split criteria attempt perform well side split attempt compromis qualiti fit left right side contrast adopt data mine point view propos criteria search interest subset data oppos model data equal well new criteria split base compromis left right bucket effect pick interest bucket ignor othera expect result often simpler character interest subset data less expect new criteria often yield whole tree provid interpret data descript surprisingli flaw work advantag new criteria increas tendenc accept split near boundari predictor rang socal endcut problem lead repeat peel small layer data result unbalanc highli express interpret tree b introduct tree method appli two kind predict problem regress tree use predict continu respons classif tree use predict class label goal tree method partit data small bucket respons valu regress tree class label classif tree well predict subset figur show partit regress tree left panel classif tree right panel left panel data partit two subset order explain respons vertic axi best possibl mean subset right panel data partit two subset order explain class label best possibl andrea buja technolog consult att lab research park ave po box florham park nj andreasresearchattcom httpwwwresearchattcomandrea yungseop lee graduat student depart statist rutger univers hill center mathemat scienc busch campu piscataway nj regress tree x classif tree x class figur partit regress classif tree structur tree data repeatedli partit even smaller subset mean binari split thu tree describ diagram figur a node repres subset data pair daughter node repres binari split subset correspond parent node a b figur two predictor exampl standard tree partit data binari split along predictor variabl is two daughter subset parent subset obtain split fix valu fix threshold exampl x goe left daughter x goe right daughter figur a illustr tree repeat split x respect x respect x respect geometri result partit illustr figur b tree construct greedi optim split one repeatedli search best possibl split subset search possibl threshold valu variabl optim accord impur measur discuss detail section regress tree impur measur variant rss classif tree impur measur exampl misclassif rate entropi gini index one stop split subset signific gain impur obtain subset form termin node leaf tree sinc cart breiman et al size tree somewhat complex one tend grow first overli larg tree prune back second stage reason greedi tree construct look ahead one step may henc miss success split line overgrow prune tree may therefor find optim tree grow alon split criteria data mine tree grow strategi specifi defin measur impur split done defin measur impur left right bucket split combin two measur overal impur measur split convent split criteria left right combin weight sum two side effect one compromis left right bucket take size account new data mine criteria howev interest model data equal well rather content long find subset data interest therefor propos combin impur left right bucket split way split occur one bucket alon low impur regardless bucket is low impur one bucket alon caus low valu impur measur split data mine criteria split need develop regress classif tree separ section deal regress section classif data tree grow tree recent tree method appli mani area data mine sometim even data suitabl tree method gener grow tree use depend predictor heterogen complex interact present depend heterogen complex multipl local structur handl tree method model handl singl promin structur strength tree detect interact effect advert name first tree method interact detect morgan sonquist chisquarebas aid hartigan predict accuraci tree suffer follow situat ffl regress tree may fail dose respons present term dose re spons borrow biostatist refer gradual monoton depend opposit depend threshold effect ffl classif tree may fail optim decis boundari align way variabl axe henc split variabl abl make full use inform contain predictor interpret tree hand may suffer presenc highli correl predictor correl predictor substitut appear less random altern fact one predictor would suffic effect ad complex interpret data analyst and even wors possibl mislead conclus separ distinct effect attribut predictor even though share effect due correl exampl grow tree waveform data breiman et al p exampl unsuit data tree grow data gener artifici dimension predictor three class whose distribut predictor space analyt describ follow number u ffl independ distribut accord uniform distribut gaussian zero mean unit varianc respec tive three dimension vector h irrelev except fact form obliqu place triangl side length roughli shape result pointcloud three sausag end link togeth reflect project onto first two princip compon shown figur reason tree method success data optim classif boundari align coordin axe author mention p geometri data immedi linear discrimin analysi outperform tree thu appli tree method blindli one perform preliminari exploratori analysi determin type classif procedur make best use avail inform data figur distribut class waveform data use tree two principl must balanc use tree grow algorithm accuraci predict interpret predict problem one want grow tree produc accur classifi base train sampl gener well test sampl often one also want grow interpret tree is tree whose node repres potenti use meaning subset interpret top tree usual valuabl part top node describ use condit gener step tree add new inequ descript node for except see below also help although essenti interpret top node tree tend statist less variabl lower level node simplic interpret tree present work concern construct method favor interpret tree is attempt find method search meaning node close top tree possibl emphas interpret node near top deemphas precis calibr tree depth predict stop criteria grow prune tree low prioriti purpos interpret data analyst alway ignor lower node tree grown deepli harmless long analyst interpret statist fluke lower node deemphas lower part tree may sacrific global accuraci predict remark simplic interpret tree order although literatur bia favor balanc tree balanc interpret differ concept exist type extrem unbalanc tree highli interpret name use variabl repeatedli cascad split see figur exampl simplic tree stem fact node describ one two condit regardless tree depth tree fragment similar exampl appear often tree fit data exhibit dose respons exampl figur appar mean valu node respons show monoton increas depend predictor x kind tree structur found data analyst may want consid linear addit model describ monoton depend direct way hand dose respons may present local case tree may still success descript data linear addit model illustr boston hous data new data mine criteria uncov local dose respons new criteria split sometim gener tree less balanc yet interpret convent balanc tree contradict preced consider show x x figur artifici exampl simpl interpret yet unbalanc tree regress tree convent criteria regress tree mention section tree grown recurs split data base minim split criterion convent split criteria compromis impur left right bucket impur measur choic bucket simpli varianc compromis split criterion weight averag varianc function thereof left right bucket need notat mean varianc left right bucket denot r nr r nr compromis split deriv maximum likelihood estim combin gaussian model two bucket iid nl oe l left bucket iid nr oe r right bucket cart equal varianc assum necess assumpt give criteria equal nonequ varianc minim neg log likelihood model follow split criteria result equal varianc model cart crit lr nl nr n l oe n l log l n r log oe make precis sens convent criteria compromis left right bucket minim neg log likelihood straightforward anyway equal varianc case min l r oe gammalog likelihoodl oe l pool varianc estim thu minim yield split minim neg log likelihood nonequ varianc case get min l oe l r oe r gammalog likelihoodl r log constant drop affect minim split data mine criteria regress tree circumst convent criteria tree grow unabl immedi identifi singl interest bucket interest could mean bucket high mean valu respons high puriti term small varianc respons kind situat mind depict figur left hand plot show respons subset small varianc right right hand plot subset extrem mean right plain cart criterion deal properli left hand situat assum equal varianc right hand situat cart find split middl around x wherea may interest find small bucket extrem high mean right approach identifi pure bucket oe small extrem bucket ex treme quickli possibl exampl ignor left bucket right side interest r small r high or low thu compromis anymor left right bucket order gener type tree use two new criteria split x x figur exampl pure extrem bucket left around x find pure bucket small oe right around x find extrem bucket larg mean criterion search one pure bucket earli possibl end rather use weight averag two varianc criterion is crit minim criterion possibl split find split whose left right side singl bucket smallest varianc puriti note subsequ split highpur bucket ignor bucket candid split thu ignor bucket get chanc highpur bucket split later on typic highpur bucket unlik split again result tree grown criterion tend purpos unbalanc ffl new criterion onesid extrem high low valu respons criterion search high mean respons variabl earli possibl dual criterion would search low mean criterion radic departur convent approach notion puriti never question far mean never thought split criteria although often greater interest varianc point view minim variancebas criterion circuit rout search interest mean mean criterion propos maxim larger mean left right bucket crit implicitli bucket smaller mean ignor maxim criterion possibl split find split whose left right side singl bucket highest mean point natur critic criteria may aris potenti excess greedi is tree built criteria may miss import split variabl may instead captur spuriou group peripheri variabl rang thu exacerb socal end cut problem critic grain truth paint situat bleaker is true import split variabl gener miss depend data hand whether convent newli propos criteria success criterion search onesid extrem exampl success extrem respons valu often found peripheri variabl rang reason monoton mani respons surfac end cut problem prefer cut near extrem variabl rang share treebuild strategi see breiman et al p noth peculiar new criteria second critic lack balanc tree construct criteria superfici one might expect balanc tree interpret unbalanc one defeat rational criteria concern unfound though show real data exampl below case criteria succeed produc interpret tree due simpl rational underli them final recal present goal devis method produc superior fit method enhanc interpret therefor concern usual problem tune treedepth fit stop prune strategi cours interpret tree user simpli ignor lower level node longer interpret classif tree convent criteria classif tree consid twoclass situat class label denot given split left right bucket let p probabl left right respect convent loss impur notion bucket ffl misclassif rate left bucket minp breiman et al p implicitli one assign class bucket major vote estim misclassif rate proport class ffl entropi inform gammap l probabl estim rel frequenc denot abus notat entropi also interpret mingammalog likelihoodn l multinomi model left bucket nl size left bucket breiman et al p ffl gini index p l term estim essenti mean squar fit mean n f g n l short calcul show l number s n l number s left bucket misclassif gini index figur impur function bucket left right misclassif rate entropi gini index as function p l exampl impur criteria bucket convent blend impur criteria split form weight sum left right bucket thu compromis left right denot pl margin probabl left right bucket compromis take follow form misclassif rate entropi r log r log gini index impur function bucket depict figur sever desir properti given node take maximum valu class equal proport minimum valu bucket member class also function symmetr henc two class treat equal assum equal prior among three impur function misclassif rate problemat may lead mani indistinguish split may intuit prefer other problem illustr exampl breiman et al p gener reason linear misclassif rate either half unit intervalse left plot figur linear impli data shift within limit left right bucket without chang combin misclassif rate split follow consider give idea larg number potenti split equival misclassif rate consid misclassif count nlminp rate train data estim probabl rel frequenc denot n l l n l r count minor class loser left right correspondingli n w l n w r count major class winner left right l r n w r l w f g note r misclassif count l r n w r count left right bucket respect r n w r count parent bucket fix valu misclassif count exist mani combin n l r satisfi condit exampl fix exist larg number combin gener exist combin fix n amount possibl fix n maximum number combin n attain misclassif count figur show number combin function missclassif count number combin parent bucket size figur number combin misclassif count fix n consider suggest misclassif rate use split criterion suffer consider nonuniqu minim split consid two exampl equival split howev one observ quickli one two split usual prefer reason misclassif rate exampl among two equival split result combin n l respect latter clearli prefer provid one larg bucket r complet pure root problem piecewis linear misclassif rate minp r right bucket therefor need impur function acceler toward zero is decreas faster linearli proport domin class bucket move closer rational use concav impur function entropi gini index cart breiman et al salford system use gini index c quinlan splu venabl ripley use entropi twoclass case seem exist clear differ perform entropi gini index multiclass case howev recent work breiman brought light differ gini entropi criterion gini index tend assign major class one pure bucket if exist rest class bucket is tend form unbalanc well distinguish bucket entropi hand tri balanc size two bucket accord breiman result defici entropi share gini index data mine criteria classif tree mention section approach tri identifi pure extrem bucket quickli possibl criteria regress tree base varianc mean one classif tree base probabl class goal therefor restat search bucket one class probabl p either left right bucket necessarili both anoth approach select one two class say look bucket pure class exampl medic context one might want quickli find bucket show high rate mortal high rate treatment effect section use two criteria split correspond two approach describ criterion search pure bucket regardless class earli possibl crit equival crit a minp for exampl monoton transform other criteria also equival crit b one p l maximum minimum latter criterion express idea pure bucket directli ffl new criterion onesid extrem chosen class class interest criterion search pure class bucket among l r crit ident crit p l exampl note criteria direct analog new data mine criteria re gression shown follow tabl regress tree classif tree onesid puriti mino onesid extrem max endcut problem high variabl small bucket lead chanc capit breiman et al p ff is optim split take advantag randomli occur puriti small bucket implic split method lead extrem unbalanc split problem even greater data mine criteria look bucket individu without combin sizeweight averag cart usual cart criterion small bucket higher variabl downweight accord size illustr endcut problem simul simpl case unstructur regress data case theoret examin breiman et al theoret cut equal merit empir endcut prefer finit sampl emerg known figur merit simul necessari theoret consider cart criterion carri new data mine criteria thu gener set observ gaussian distribut zero mean unit varianc comput split bucket size cart criterion rssl r new onesid puriti criterion mino l oe r comput optim split locat criteria scheme repeat time optim split locat talli histogram first histogram figur show frequenc split locat minimum cart criterion second histogram show onesid puriti criterion two figur show extent criteria prefer cut locat closer either extrem clearli effect pronounc onesid puriti criterion criteria requir measur counteract effect onesid puriti criterion so split locat minimum total rss data mine criterion split locat minimum puriti criterion figur illustr endcut problem approach solv endcut problem penal bucket small size criterion penalti term make small bucket less viabl penal best understood criterion interpret neg log likelihood suitabl model case literatur offer larg number addit penalti term c p mallow c p statist aic akaik inform criterion bic schwarz bayesian inform criterion mdl the minimum descript length criterion among other present paper work aic bic criteria reason popular aic penalti add effect number estim paramet neg log likelihood wherea bic add number estim paramet multipli logn appli penalti individu bucket obtain constant gaussian multinomi model underli regress classif tree model log likelihood aic bic regress gaussian nlog classif multinomi n entropi stage rais import point intend use aic bic penalti convent penalti use model select context one appli multipl model fix dataset unconvent situat howev appli one fix model multipl dataset name variables nr nl bucket data part larger dataset ensu problem log likelihood compar across differ bucket size log likelihood unbias estim bucket size time diverg model respect actual distribut therefor compar across bucket size gain one use averag log likelihood unbias estim diverg across bucket size log p z log p xdqx in rest section n denot gener sampl size bucket size order avoid subscript nl nr consequ penal averag log likelihood penalti term also divid bucket size model ave log likelihood regress gaussian log classif multinomi entropi penalti term n log n n log n n monoton decreas n converg zero n behavior obviou requir addit penalti penal valu associ bic bigger associ aic except small bucket illustr figur unfortun even though approach produc intuit pleas penalti perform experi somewhat disappoint expect howev approach perform better recent result jianm ye taken account light ye insight plausibl penalti number paramet model replac ye gener degre freedom gdf take consider fact extens search implicitli consum degre freedom gdf tend consider higher convent df exampl follow section counteract endcut problem impos minimum bucket size roughli overal sampl size exampl regress tree boston hous data follow breiman et al demonstr applic new data mine criteria boston hous data wellknown data origin bucket size penal valu aic penalti bic penalti figur plot log n except small size n creat harrison rubinfeld also exploit belsley kuh welsch quinlan harrison rubinfeld main interest data investig air pollut concentr nox affect valu singl famili home suburb boston although nox turn minor factor ani data frequent use demonstr new regress method boston hous data avail uc irvin machin learn repositori httpwwwicsuciedumlearnmlrepositoryhtml data contain median hous valu respons predictor variabl censu tract boston area predictor display tabl comparison criteria regress tree construct sever tree base cart new data mine cri teria facilit comparison tree gener equal size name termin node minimum bucket size chosen overal sampl size prune appli interest interpret oppos predict result display figur variabl descript crim crime rate zn proport residenti land zone lot sq ft indu proport nonretail busi acr cha charl river dummi variabl tract bound river otherwis nox nitric oxid concentr pphm rm averag number room per dwell age proport owneroccupi unit built prior di weight distanc five boston employ center rad index access radial highway tax fullvalu properti tax rate per ptratio pupil teacher ratio proport black lstat percent lower statu popul respons median valu owner occupi home s tabl predictor variabl boston hous data summar tabl figur mean respons m size sz given node perus six tree summari sequenc worthwhil return cart tree figur begin appli lesson extrem mean tree last two figur recogn cart tree rm domin variabl particular rm indic monoton depend rm larg valu rm rm lstat take over learnt high mean tree rm exist monoton decreas depend lstat cart tree tri tell stori prejudic favor balanc split incap success layer data accord ascend valu lstat split lstat second level divid bucket size left bucket divid lstat comparison high mean criterion creat level split lstat bucket size clearli indic left bucket first half dozen tree ring ascend order lstat descend order hous price summari appear us least interpret tree first two correspond cart criterion separatevari criterion although highest among six tree greater interpret gain onesid puriti criterion partli due fact success peel mani small bucket result less balanc yet tell tree greatest lstat b crim m m m m m m m m sz m m m m m m m m boston hous pool varianc model cart figur boston hous data tree cart criterion di rm age m m m m m m m m m m m sz m m boston hous separ varianc model figur boston hous data tree separ varianc criterion age m m m m m m sz m m m m m m m m m m boston hous raw onesid puriti figur boston hous data tree onesid puriti criterion m m m m m m m m m sz m m m m m m m m m m boston hous data penal onesid puriti figur boston hous data tree penal onesid puriti criterion lstat m m m m m m m m m m m m m m sz m m m m m m m m m m boston hous onesid extrem high figur boston hous data tree high mean criterion lstat ptratio m m m m m m m m m m sz m m m m m m m m m m boston hous onesid extrem low figur boston hous data tree low mean criterion r cart pool varianc model somewhat balanc tree depth major variabl rm x lstat x minor variabl appear nox crim b ptratio di indu split mostli expect direct mean termin node vari tree nl log r separ varianc model balanc tree cart tree depth major variabl rm x lstat x minor variabl appear split expect direct mean termin node vari tree mino r data mine criterion raw onesid puriti unbalanc tree depth ptratio x appear top cannot judg top import split small bucket size appar cluster school district significantli wors pupiltoteach ratio ma joriti crimeinfest neighborhood peel next small bucket size crim x nox make surprisingli appear anc would made harrison rubinfeld happi third split top nox break highli pollut area low bucket mean compar rest power variabl lstat x creat next power split bucket size mean respect notic ambigu role di x correl neg hous valu low valu lstat highstatu posit high valu lstat lowstatu high valu nox pollut rm x play role highstatu neighborhood crime neighborhood peel earli singular area extrem low hous valu crim x split age x zn x irrelev due low meandiffer log oe data mine criterion penal onesid puriti aic qualit tree surprisingli similar previou one differ lower level tree penal seem affect split till tree mine criterion onesid ex treme high mean search high respons valu creat unbalanc tree singl power split peel split small bucket one side repeat appear two variabl rm x level lstat x howev tell power stori highest hous price bucket mean averag size home measur rm variabl mat ter rm persist monoton decreas depend lstat take over median hous valu simpl interplay rm lstat lend strike interpret tree tell simpl convinc stori bottom crime crim x pollut nox x show remain smaller effect expect direct smaller effect di tax also seen halfway tree r data mine criterion onesid ex treme low mean tree tell similar stori previou one greater precis achiev low hous valu criterion look first tree unbalanc first peel split crim x set asid bucket crime infest neighborhood lowest hous valu around second lowest mean bucket consist censu tract low b correspond sigma africanamerican popula tion due quadrat transform thereaft monoton decreas depend lstat take form six peel split follow monoton increas depend rm form five peel split two success dose respons effect essenti previou tree found revers order due peel high low hous valu tabl result regress tree boston hous data interpret achiev onesid extrem mean criteria partli due extrem imbal interpret found exampl two side it ffl bucket extrem high low mean near top tree bucket desir interpret describ extrem respons behavior term simpl claus find bucket exactli purpos extrem mean criteria boston hous data highmean criterion exampl immedi find bucket welloff area larg home rm lowmean criterion comparison immedi find highcrim bucket crim cart also find area larg home second level find high crime bucket all ffl dose respons effect monoton depend iter peel behavior data mine criteria allow detect gradual increas decreas respons function individu predictor iter peel predictor becom appar essenti peel layer form seri small dangl termin bucket henc form highli unbalanc tree cart comparison handicap regard favor balanc split data mine criteria last point iron impli greater endcut problem data mine criteria compar cart work favor convers cart endcut problem suffici strong allow clearli detect monoton depend highli unbalanc tree monoton depend detect plausibl switch tree model addit even linear model includ suitabl interact term interact term may necessari local monoton depend exampl tree gener low mean criterion might suggest linear model follow form graphic diagnost regress tree although treebas method sens flexibl mani convent parametr method still necessari guard artifact best techniqu diagnos artifact missfit graphic contrast linear regress basic diagnost regress tree straightforward requir addit comput first cut may suffici graphic render effect split turn may achiev plot respons variabl predictor split point parent bucket one graphic differenti point two child bucket plot differ glyph color creat seri diagnost plot tree gener low mean criterion figur show bucket ascend hous valu split off ffl high crime area strongli africanamerican neighborhood ffl segment decreas fraction lower statu peopl ffl commun unfavor pupilteach ratio school ffl anoth segment decreas fraction lower statu peopl final ffl segment increas size home matter plot confirm split plausibl high crime factor depress hous valu most exist cluster neighborhood whose pupilteach ratio clearli wors well separ major final monoton depend clearli visibl decreas percentag lower statu peopl increas number room also visibl outlier name desir area beacon hill back bay near boston downtown top hous valu yet limit size home figur graphic view major split appli boston hous data use low mean criterion exampl classif tree pima indian diabet demonstr applic new data mine criteria classif tree pima indian diabet data pima data short data origin own nation institut diabet digest kidney diseas avail uc irvin machin learn repositori httpwwwicsuciedumlearnmlrepositoryhtml class label pima data diabet otherwis predictor variabl patient femal least year age pima indian heritag near phoenix az among patient test posit diabet class detail data see document uc irvin repositori predictor variabl definit shown tabl variabl descript prgn number time pregnant plasma plasma glucos concentr two hour oral glucos toler test bp diastol blood pressur mm hg thick tricep skin fold thick mm insulin two hour serum insulin uml bodi bodi mass index weight kgheight m diabet pedigre function age age year respons class variabl diabet otherwis tabl predictor variabl pima indian diabet data use pima data construct four tree base cart new data mine criteria minimum bucket size impos overal sampl size regress tree boston hous data sinc concern interpret use prune result tree shown figur node proport p class size sz given tabl summar tree tree summari becom clear plasma power predictor follow bodi particular third tree almost complet domin two variabl interleav appear tree suggest combin monoton depend studi care diabet plasma class diabet figur distribut two class pima diabet data bodi plasma fulli figur show distribut two class plasmabodi plane switch anoth fit method natur describ monoton depend name nearestneighbor fit everi point estim condit class probabl p plasma bodi fraction class sampl among nearest neighbor term euclidean distanc plasmabodi coordin standard variabl unit varianc figur show sequenc plot data plasma bodi plane rendit p plasma bodi term highlight slice increas sequenc six valu c plot make clear respons behavior quit complex first plot show slice best describ cut low valu bodi follow four slice veer clockwis last slice best describ cut high valu plasma one featur worth note though third plot notic hole center highlight slice hole fill blob data fourth plot featur infer exist mild hump p surfac center data summari function p plasma bodi shape clockwis ascend spiral rule surfac hump middl obvious tree quit suboptim fit respons charac terist figur show third tree figur tri approxim surfac step function axesalign rectangular tile plasma plasma figur pima indian diabet data bodi plasma highlight repres slice nearconst p ffl valu p slice increas left right top bottom open squar diabet class figur pima diabet data bodi plasma plain tile accord bucket tree figur open squar diabet class age plasma pedigre insulinp p p p p p p p p p p p p p p p sz p p p p p p p p p p p pima misclass error figur pima indian diabet data tree cart criterion plasma bodi plasma pedigre age p p p p p p p p p p p p p p p p p sz p p p p p p p p p p pima onesid puriti misclass error figur pima indian diabet data tree onesid puriti plasma bodi thick plasma thick thick typic balanc tree depth strongest variabl plasma x creat success split top bodi x next import variabl much less so follow pedigre x age x class ratio termin bucket rang left right split right direct overal tree plausibl simpl interpret r data mine criterion onesid pu riti extrem unbalanc tree depth spite depth tree overal structur simpl tree move right layer high class no diabet shave off and con vers tree step left layer high class diabet shave off top tree domin bodi age pedigre play role lower part tree larg rest bucket get harder harder classifi tree maxp r data mine criterion onesid ex treme high class extrem unbalanc tree simpl structur criterion search layer high class no diabet tree keep step right order describ condit class preval appear bodi plasma mat ter tree show sequenc interleav split two variabl indic combin monoton depend them see investig behavior interpret tree success one tabl result classif tree pima indian diabet data tree maxp r data mine criterion onesid ex treme high class anoth extrem unbalanc tree simpl structur criterion search layer high class diabet caus tree step left order describ condit class preval plasma x matter far most follow prgn x tabl result classif tree pima indian diabet data summari follow messag investig experi ffl tree grown interpret global measur good fit alway desir ffl hypergreedi data mine criteria give differ insight ffl highli unbalanc tree reveal monoton depend doserespons effect endcut problem turn virtu ffl realli understand data algorithm extens visual necessari follow topic would merit research assess endcut problem hurt help ffl extend new class criteria multiclass problem ffl develop sophist rule stop prune ffl increas accuraci limit step lookahead procedur new cri teria adopt suggest breiman r a new look statist model regress diagnost technic note properti split criteria classif regress tree treebas model a statist perspect knowledg discoveri databas from data mine knowledg discoveri overview model select principl minimum descript length hedon price demand clean air cluster algorithm some comment c p uci repositori machin learn data base httpwww problem analysi survey data propos estim dimens model cart supplementari modul sy tat xgobi interact data visual x window system modern appli statist splu on measur correct effect data mine model select tr c program machin learn technic note simpl fast effect rule learner ctr xiaom huo seoung bum kim kwokleung tsui shuchun wang fbp frontierbas treeprun algorithm inform journal comput v n p januari soon tee teoh kwanliu ma paintingclass interact construct visual explor decis tree proceed ninth acm sigkdd intern confer knowledg discoveri data mine august washington dc owen carmichael martial hebert shapebas recognit wiri object ieee transact pattern analysi machin intellig v n p decemb vasili agg panagioti anagnost ebank predict use data mine method proceed th wsea intern confer artifici intellig knowledg engin data base p februari salzburg austria