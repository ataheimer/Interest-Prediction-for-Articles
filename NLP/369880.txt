t enlarg margin perceptron decis tree a capac control perceptron decis tree typic perform control size prove quantiti relev reduc flexibl combat overfit particular provid upper bound gener error depend size tree margin decis node enlarg margin perceptron decis tree reduc upper bound gener error base analysi introduc three new algorithm induc larg margin perceptron decis tree assess effect larg margin bia oc journal artifici intellig research murthi kasif salzberg wellknown system induc perceptron decis tree use baselin algorithm extens experiment studi real world data show three new algorithm perform better least significantli wors oc almost everi dataset one except oc perform wors best marginbas method everi dataset b introduct perceptron decis tree pdt introduc number author differ name decis tree intern node associ hyperplan gener posit input space use mani real world pattern classif task good result given high flexibl featur share standard decis tree one produc c tend overfit data complex somehow kept control standard approach control complex limit size earli stop prune procedur paper introduc novel approach complex control pdt base concept margin name distanc decis boundari train point control quantiti basi eectiv system vapnik support vector machin adaboost bayesian classifi prove quantiti import treesiz capac control paramet theoret motiv behind approach lie datadepend structur risk minim scale cover use vc theori provid bound gener error depend margin henc hierarchi class chosen respons data cours two complex control criteria use togeth combin prune phase bia toward larg margin obtain better perform result motiv new class pdt learn algorithm aim produc larg margin tree propos three algorithm fat moc moc compar perform oc one best known pdt learn system three largemargin system outperform oc real world dataset use indic overfit pdt ecient combat enlarg margin decis boundari train data perceptron decis tree common decis tree node check valu singl attribut could defin axi parallel test associ node equival axisparallel hyperplan input space mani variat simpl model propos sinc introduct system earli s involv complex test decis node usual test one attribut decis tree whose node test linear combin attribut propos dierent research dierent name linear combin tree multivari dt obliqu dt perceptron decis tree etc first system propos breiman incorpor packag cart test associ node equival hyperplan gener posit partit input space polyhedra illustr figur obvious includ special case common decis tree output system like c x x x x x x x x x x x x x x figur perceptron decis tree way split input space extrem flexibl system make particularli expos risk overfit ecient method control express power typic prune techniqu alway use combin standard topdown growth algorithm class function comput pdt formal defin follow definit gener decis tree gdt given space x set boolean function class gdtf gener decis tree f function implement use binari tree intern node label element f leaf label either evalu particular tree input x x boolean function associ node assign argument x x argument x valu assum determin uniqu path root leaf intern node left respect right edg child taken output function associ intern node respect path known evalu path valu function x valu associ leaf reach say input x reach node tree node evalu path x follow node intern node binari tree leav extern one exampl given tree bdt gdt given tree cdt gdt kind decis tree defin continu space output common algorithm like c cart refer cdt given tree pdt gdt assum input augment coordin constant valu henc implement threshold perceptron pdt gener induc mean topdown growth procedur start root node greedili choos perceptron maxim cost function usual measur impur subsampl implicitli defin split maxim usual hard perform sometim replac random suboptim subsampl map two children node procedur recurs appli node tree grown stop criterion met tree use start point bottomup search perform prune tree impli elimin node redund unabl pay themselv term cost function gener prune overfit tree produc better classifi obtain earli stop sinc make possibl check promis direct fact worth explor local good solut contrari deadend so standard topdown algorithm extrem greedi procedur introduct prune possibl lookahead allow discoveri hidden structur capac control pdt henc complet achiev control size tree complex overal classifi propos altern method contrari focus reduc complex node classifi independ tree size possibl thank theoret analysi gener perform function class defin pdt framework vc theori theoret analysi gener gener perform learn machin studi mean uniform converg bound techniqu introduc vapnik chervonenki central concept analysi eectiv capac class hypothes access machin richer class higher risk overfit featur learn machin often refer flexibl capac issu prevent overfit allow right amount flexibl therefor known capac control notion eectiv cardin function class captur growth function boolean class cover number real valu function size cover number depend accuraci cover well function class itself larger margin less accuraci requir cover follow concern estim capac class pdt see margin aect flexibl hypothesi class treesiz motiv altern techniqu control overfit albeit conceptu similar prune act complex node classifi rather complex overal tree begin definit fatshatt dimens first introduc use sever problem learn sinc definit let f set real valu function say set point x shatter f rel real number r x index x x binari vector b index x function f b f satisfi fat shatter dimens fat f set f function posit real number integ map valu size largest shatter set finit infin otherwis exampl relev subsequ analysi consid class quot follow result see also theorem let f lin restrict point ball n dimens radiu r origin follow theorem bound gener classifi term fat shatter dimens rather usual vapnikchervonenki pseudo dimens let denot threshold function class function f theorem consid real valu function class f fat shatter function bound function afat r n continu right fix r learner correctli classifi independ gener exampl z train error zero confid expect error h bound m k m em import theorem use explain classifi give better gener would predict classic analysi vc dimens essenti expand margin perform automat capac control function class small fat shatter dimens theorem show larg margin achiev work lower vc class stress gener bound obtain better case larg margin observ priori guarante margin occur therefor priori classic vc bound use view correspond lower bound gener error term vc dimens posteriori bound depend favor probabl distribut make actual learn task easier henc result use distribut favor least adversari sens result distribut depend result despit distribut depend tradit sens assumpt distribut made deriv benign behavior distribut automat estim learn process order perform similar analysi perceptron decis tree consid set margin obtain node bound gener function valu turn bound fat shatter dimens pdt view real function classifi dicult therefor direct gener analysi mimick proof theorem take account margin decis node tree definit let x d pseudo metric space let subset x set cover if everi a exist b b da b cover number a n a minim cardin cover if finit cover defin cover number f respect pseudometr measur maximum discrep sampl x respect distanc f number bound follow lemma present histor reason though fact requir slightli gener corollari lemma alon et al let f class function x p distribut x choos let expect e taken wrt sampl x drawn accord p corollari let f class function x a b p distribut x choos expect e sampl x drawn accord p posit tackl main lemma bound probabl doubl sampl first half zero error second error greater appropri here error interpret dierent classifi output tree order simplifi notat follow lemma assum decis tree k node denot fat f lin fat lemma let perceptron decis tree k decis node margin k decis node satisfi k correctli classifi label exampl x gener independ accord unknown but fix distribut p support ball radiu r second sampl bound follow probabl less xy tree correctli classifi x fraction misclassifi m k m k d logm use standard permut argument as may fix sequenc xy bound probabl uniform distribut swap permut sequenc satisfi condit state consid gener minim k cover xy valu k suppos node tree margin hyperplan w satisfi therefor find xy whose output valu within w consid tree obtain replac node perceptron w correspond f tree perform classif function first half sampl margin node remain larger point second half sampl incorrectli classifi either still incorrectli classifi adapt tree one decis node closer decis boundari k point thu distinguish left hand side point correctli classifi margin greater k node i henc point must kept right hand side order condit satisfi henc fraction permut allow one choic function cover m must take union bound choic function cover use techniqu number choic bound corollari follow valu lemma statement therefor ensur union bound less lemma appli particular tree specifi number node architectur fat shatter dimens node practic observ quantiti run learn algorithm gener tree henc obtain bound appli practic must bound probabl uniformli possibl architectur dimens aris give theorem give bound requir two result first due vapnik page key bound error probabl term probabl discrep doubl sampl lemma let x set system set x p probabl measur x x as as second result give bound number dierent tree architectur given number comput node theorem number k k node decis tree skeleton combin two result lemma obtain follow theorem theorem suppos abl classifi sampl label exampl use perceptron decis tree suppos tree obtain contain k decis node margin node i bound gener error probabl greater less r radiu sphere contain support distribut must bound probabl dierent architectur tree dierent margin first use lemma bound probabl error term probabl discrep perform two halv doubl sampl order appli lemma must consid possibl architectur occur architectur dierent pattern k s decis node fix valu k theorem give number decis tree skeleton largest allow valu k fix k bound number possibl count possibl label k leaf node henc number applic lemma fix k sinc largest valu k take m let sum choos applic lemma ensur probabl statement fail hold less note replac constant order ensur continu right requir applic theorem upperbound logemk logem henc appli lemma case probabl statement theorem fail hold less experiment result theori present previou section follow largemargin pdt like gener well bia toward largemargin tree implement number dierent way either postprocess phase exist tree brand new impur measur determin splittingstop criteria topdown growth algorithm facilit comparison implement three algorithm modif one bestknown pdt learn system oc murthi kasif salzberg freeli avail internet eect largemargin bia henc directli assess run marginarbitrari version algorithm data first algorithm fat accept input pdt construct use oc output larg margin version tree two moc moc dierent impur measur take consider margin three algorithm work multiclass data three system compar oc benchmark data set result confirm predict theoret model clearli indic gener improv enlarg margin data set use studi data set use origin oc paper data set publicli avail uci data repositori data set studi dim bright wisconsin breast cancer pima indian diabet boston hous iri four addit data set bupa sonar heart wisconsin breast cancer prognosi data set dier greatli subject size number attribut subject data set rang medic astronom size number attribut detail data set see data set singl run fold crossvalid carri out relev quantiti experi dierenc test accuraci pdt arbitrari margin construct oc pdt larg margin data compar learn algorithm drawn extens attent recent singl run fold crossvalid reason number data set still prefer number attribut point data set follow bright bupa can cer dim heart hous iri pima prognosi practic approach prone detect dierenc two algorithm basic follow approach recommend rest section first briefli review oc system present three larg margin algorithm compar perform oc review oc oc random algorithm perform random hillclimb search learn perceptron build tree topdown start root node system choos hyperplan minim predefin impur measur eg inform gain gini index two rule etc system greedi stage choos best split avail random best split obtain mean exhaust search random hillclimb process throughout studi use two rule impur measur oc fat moc moc use modifi two rule impur measur impur measur also appli fat moc without chang moc would need minor chang two rule total number instanc current node number class two class problem number instanc left split ie w number instanc right split ie w number instanc categori left split number instanc categori right split good measur rather impur one oc attempt maxim split tree growth via minim twoingv alu detail random prune split criteria found result fat descript algorithm fat algorithm fat use tree produc oc start point maxim margin involv find node hyperplan perform split perform oc tree maxim margin done consid subsampl reach node perfectli divid two part feed data accordingli relabel algorithm find optim separ separ hyperplan maxim margin linearli separ data optim separ hyperplan place correspond decis node new tree test test data note that pdt produc fat tree structur train accuraci origin pdt construct oc dier test accuraci use support vector machin svm algorithm find optim separ hyperplan conform definit pdt kernel use svm optim separ hyperplan construct input space algorithm fat construct decis tree use oc call ocpdt start root ocpdt travers nonleaf node node relabel point node x class right point node class left find perceptron optim separ hyperplan separ class right class left perfectli maxim margin replac origin perceptron new one output fatpdt optim separ hyperplan svm algorithm linearli separ case follow problem solv node find optim separ hyperplan linearli separ data min subject w x correspond class right correspond class left number point reach decis node comput reason usual solv dual problem min subject fatpdt gener error bound theorem observ fat complet reli restrict perceptron decis tree induc oc mani case margin split found oc small fat littl scope optim gener big margin top split root node fat gener much better impli greedi algorithm oc good tree induc fat sens margin need find better nongreedi tree induc fat hand fat provid new approach appli support vector machin multiclass classif task comparison fat oc dataset fold crossvalid use measur learn abil algorithm fat oc pair ttest use test dierenc mean fat oc fold crossvalid result fat vs oc oc fold cv averag accuraci fat fold averag accuraci signific signific xy figur comparison fold cv result fat versu oc point line indic fold cv mean fat higher oc vice versa figur show fat outperform oc data set outperform data set figur see that fat outperform oc data set outperform oc data set studi fold crossvalid mean dierenc fat oc data set signific pair ttest appli one data set prognosi oc outperform fat dierenc signific also observ that except one case prognosi fat perform good better oc everi fold fold crossvalid fat higher mean oc signific small level pair ttest even though dierenc small strong indic perceptron decis tree larg margin gener better fold crossvalid mean p valu summar tabl result moc descript moc moc margin oc variat oc modifi object function oc consid size margin underli philosophi find separ plane tradeo train accuraci size margin node idea motiv support vector machin linearli nonsepar case minim classif error maxim margin time svm soft margin minim sum misclassif error constant c multipli reciproc soft margin svm tri find split high classif accuraci larg soft margin analag svm minim sum impur measur constant time reciproc hard margin moc algorithm minim follow object function object impur measur oc studi default two rule use impur measur current margin sum perpendicular distanc hyperplan two nearest point dierent side current separ hyperplan scalar weight point current node determin much larg margin weight select split tune could improv perform determin weight margin also take number point current node consider idea constant weight margin node good weight abl adapt posit current node size train exampl current node sinc particularli interest find tree highest possibl accuraci rather demonstr larg margin improv gener tune data set achiev highest possibl accuraci set data set word result moc present best result possibl comparison moc oc previou section use fold crossvalid measur learn abil algorithm moc oc test dierenc mean moc oc pair ttest use figur see moc higher fold crossvalid mean oc data set significantli higher oc higher mean two data set cancer prognosi dierenc tini signific overal moc outperform oc data set good oc four six data set studi moc outperform oc five perform well oc final one cancer see tabl respect mean p valu oc cv averag accuraci moc averag accuraci signific signific xy figur comparison fold cv result moc versu oc point line indic fold cv averag moc higher oc vice versa figur show moc outperform oc data set perform good oc four data set result moc descript moc moc use modifi two rule directli incorpor idea larg margin impur measur unlik moc moc use soft margin treat point fall within margin outsid margin dierent impur measur alter rest standard oc algorithm modifi two rule mtr total number instanc current node number class two class problem number instanc left split ie w number instanc right split ie w number instanc categori left split number instanc categori right split number instanc left split w mtr number instanc right split w number instanc categori w number instanc categori w modifi two rule goal is node find split fewer point fall within margin in accuraci outsid margin good overal accuraci again tri achiev balanc classif accuraci size margin thi want push apart two class separ hyperplan far possibl maintain reason good classif accuraci henc improv gener induc decis tree advantag moc free paramet tune comparison moc oc previou section fold crossvalid use measur learn abil algorithm moc oc pair ttest use test dierenc mean moc oc figur see moc higher mean data set slightli lower mean one data set hous higher mean significantli higher one lower mean signific overal moc outperform oc oc cv averag accuraci moc averag accuraci fold cross valid result moc vs oc signific signific xy figur comparison fold cv result moc versu oc point line indic fold cv mean moc higher oc data set vice versa figur show moc outperform oc data set perform well oc data set data set perform well oc six data set studi moc outperform oc three them perform well oc three respect mean p valu summar tabl modifi two rule open new way measur good split directli incorpor gener factor measur experi proven use measur tree size fat tree size exactli oc sinc fat pdt tree structur oc pdt fat replac split node oc pdt larg margin perceptron perform exactli split ten data set moc induc five smaller tree one size tree four larger tree compar leav depth leav depth leav depth bright bupa cancer heart hous iri prognosi sonar tabl fold cv averag tree size oc fat moc moc x p valu x p valu x p valu classifi bright moc cancer fat heart moc hous fat iri fat pima moc prognosi moc tabl fold cv mean oc fat moc moc oc moc induc five smaller tree five bigger tree compar oc find consist pattern tree size tabl list tree size oc fat moc moc summari experiment result theori state maxim margin data point side separ hyperplan perceptron decis tree improv error bound perceptron decis tree like gener better theori guarante specif classifi low error rate fold crossvalid result data set fat higher mean oc significantli higher moc higher mean significantli higher moc higher mean significantli higher equal lower mean happen data set cancer moc slightli smaller mean oc it moc mean oc it hous moc slightli smaller mean oc it prognosi fat significantli smaller mean it moc also slightli smaller mean dierenc signific classifi highest mean fat produc four moc moc produc three oc produc none experi believ pdt larg margin like smaller varianc perform too experi case fat moc moc produc classifi smaller varianc mani significantli smaller though occasion produc classifi significantli larger varianc howev cannot draw confid conclus varianc therefor present studi varianc here short experiment result show find separ hyperplan larg margin node perceptron decis tree improv error bound henc pdt like higher averag accuraci ie gener better furthermor believ improv error bound margin maxim learn algorithm perform consist like smaller varianc well conclus experiment result present paper clearli show enlarg margin improv gener bia insert growth algorithm itself provid tree specif built minim theoret bound gener error tree lose desir featur readabl eas mainten updat flexibl speed furthermor theoret analysi algorithm show dimens input space aect gener perform henc possibl conceiv perceptron decis tree highdimension featur space take advantag kernel marginmaxim support vector machin would provid side eect natur approach multiclass classif support vector machin theoret result exist indic tree size necessarili good measur capac analysi also show take advantag theoret observ design learn algorithm control hypothesi complex act complex nodeclassifi henc whole tree three propos approach postprocess method fat two margin base split criteria moc moc led signific improv baselin oc method open question method best maxim margin consider everi pdt algorithm r function learn interpol gener perform support vector machin pattern classifi robust linear program discrimin two linearli insepar set multicategori discrimin via linear program ming serial parallel multicategori discrimin support vector decis tree databas market olshen r bayesian classifi larg margin hyperplan hilbert space approxim statist test compar supervis classif learn algorithm studi crossvalid bootstrap accuraci estim model select pattern recognit via linear pro gram theori applic medic diagnosi kasif s assess relev determin method use delv gener neural network machin learn learn decis tree use minimum descript lenght principl grow prune neural tree network compar classifi pitfal avoid recommend approach boost margin new explan e structur risk minim datadepend hierarchi neural tree new tool classif estim depend base empir data natur statist learn theori uniform converg rel frequenc event probabl univers california tr infer decis tree use minimum descript length principl c program machin learn multivari decis tree natur statist learn theori network fatshatt learnabl realvalu function scalesensit dimens uniform converg learnabl gener perform support vector machin pattern classifi approxim statist test compar supervis classif learn algorithm compar classifi grow prune neural tree network boost margin bayesian classifi larg margin hyperplan hilbert space function learn interpol ctr volkan vural jennif g dy hierarch method multiclass support vector machin proceed twentyfirst intern confer machin learn p juli banff alberta canada nello cristianini colin campbel chri burg editori kernel method current research futur direct machin learn v n p laurenc hirsch robin hirsch masoud saeedi evolv lucen search queri text classif proceed th annual confer genet evolutionari comput juli london england martin anthoni gener error fix combin classifi journal comput system scienc v n p august martin anthoni gener error bound threshold decis list journal machin learn research p