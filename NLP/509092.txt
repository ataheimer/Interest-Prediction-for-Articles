t make spars gaussian elimin scalabl static pivot a propos sever techniqu altern partial pivot stabil spars gaussian elimin numer experi demonstr wide rang problem new method stabl partial pivot main advantag new method partial pivot permit priori determin data structur commun pattern gaussian elimin make scalabl distribut memori machin base priori knowledg design highli parallel algorithm spars gaussian elimin triangular solv show suitabl largescal distribut memori machin b introduct earlier work develop new algorithm solv unsymmetr spars linear system use gaussian elimin partial pivot gepp new algorithm highli effici workstat deep memori hierarchi share memori parallel machin modest number processor portabl implement algorithm appear softwar packag superlu serial superlu mt multithread public avail netlib among fastest avail code problem share memori gepp algorithm reli finegrain memori access synchron share memori provid manag data structur need fillin creat dynam discov column depend column symbol use central task queue schedul load balanc reason perform dynam comput graph unfold runtim thi contrast choleski pivot order numer stabl howev techniqu expens research use resourc nation energi research scientif comput center support offic energi research us depart energi contract no deacsf research support part nsf grant asc doe grant defger ut subcontract no ora arpa contract no daalc doe grant defger nsf infrastructur grant cda cda doe grant defcer rowcolumn equilibr row permut p r delta r delta delta c r c diagon matric p r row permut chosen make diagon larg compar offdiagon find column permut p c preserv sparsiti c control diagon magnitud set ii p endif use l u factor follow iter refin iter multipli solv delta goto iter endif figur outlin new gesp algorithm distribut memori machin instead distribut memori machin propos pivot dynam enabl static data structur optim graph manipul load balanc as choleski yet remain numer stabl retain numer stabil varieti techniqu prepivot larg element diagon iter refin ment use extra precis need allow low rank modif correct end section show promis propos method numer experi call algorithm gesp gaussian elimin static pivot section present mpi implement distribut algorithm lu factor triangular solv algorithm use elabor d nonuniform blockcycl data distribut initi result demonstr good scalabl factor rate exceed gflop node cray te stabil tradit partial pivot use control element growth gaussian elimin make algorithm numer stabl practic howev partial pivot way control element growth varieti altern techniqu section present altern show experi appropri combin effect stabil gaussian elimin furthermor techniqu usual inexpens compar overal solut cost especi larg problem gesp algorithm figur sketch gesp algorithm incorpor techniqu consid motiv step recal diagon domin matrix one diagon entri ii larger magnitud sum magnitud offdiagon entri row p exist even gepp unstabl rare column p j known choos diagon pivot ensur stabil matric expect diagon entri somehow made larger rel offdiagon row column diagon pivot stabl purpos step choos diagon matric r c permut p r make ii larger sens experi number altern heurist algorithm step depend follow graph represent n theta n spars matrix a repres undirect weight bipartit graph one vertex row one vertex column edg appropri weight connect row vertex column vertex j nonzero entri ij find permut p r put larg entri diagon thu transform weight bipartit match problem graph diagon scale matric r r chosen independ make row column r ad c largest entri equal magnitud use algorithm lapack subroutin dgeequ algorithm choos p r maxim differ properti diagon p r r ad c smallest magnitud diagon entri sum product magnitud best algorithm practic seem one pick p r r c simultan diagon entri p r r ad c sigma offdiagon entri bound magnitud product diagon entri maxim report result algorithm onli worst case serial complex algorithm on delta nnza delta log n nnza number nonzero a practic much faster actual time appear later step new need superlu superlu mt column permut p c obtain fillreduc heurist now use minimum degre order algorithm structur a futur use approxim minimum degre column order algorithm davi et al faster requir less memori sinc explicitli form a also use nest dissect note also appli p c row ensur larg diagon entri obtain step remain diagon step simpli set tini pivot encount elimin p machin precis equival small half precis perturb origin problem trade numer stabil abil keep pivot get small step perform step iter refin solut accur enough also correct perturb step termin criterion base componentwis backward error berr condit berr mean comput solut exact solut slightli differ spars linear system nonzero entri ij chang one unit last place zero entri left unchang thu one say answer accur data deserv termin iter backward error berr smaller machin epsilon decreas least factor two compar previou iter second test avoid possibl stagnat figur show berr alway small numer result subsect illustr numer stabil runtim gesp algorithm unsymmetr matric wide varieti applic applic domain matric given tabl them except two ecl wu obtain harwellbo collect collect davi matrix ecl provid jagesh sanghavi eec depart uc berkeley matrix wu provid yushu disciplin matric fluid flow cfd af bbmat bramley bramley ex fidapm garon graham lnsp ln raefski rma venkat wu fluid mechan goodwin rim circuit simul add gre jpwh memplu oneton oneton twoton devic simul wang wang ecl chemic engin extr hydr lhr radfr rdist rdist rdista west petroleum engin orsirr orsreg sherman sherman sherman finit element pde av av stiff ode fs olmstead flow model olm aeroelast tol reservoir model pore crystal growth simul cri power flow model gemat dielectr waveguid dw eigenproblem astrophys mcfe plasma physic utm econom mahinda orani tabl test matric disciplin wu earth scienc divis lawrenc berkeley nation laboratori figur plot dimens nnza nnzl ie number nonzero l u factor the fillin matric sort increas order factor time matric interest parallel one take time ie one right graph figur clear matric larg dimens number nonzero also requir time factor time result report subsect obtain sgi onyx machin run irix system mhz mip r processor mbyte main memori use singl processor sinc mainli interest numer accuraci parallel runtim report section detail perform result section tabular format avail httpwwwnerscgovxiaoyesc among matric would get wrong answer fail complet via divis zero pivot without pivot precaut matric contain zero diagon begin remain zero elimin creat zero diagon elimin therefor pivot would fail complet matric matric would get unaccept larg error due pivot growth experi righthand side vector gener true solut x true vector one ieee doubl precis use work precis machin epsilon gamma figur show number iter taken iter refin step matric termin iter step matric requir step matric requir step matric requir step matric requir step matrix present two error metric figur figur assess accuraci stabil gesp figur plot error gesp versu error gepp as implement superlu matrix red dot green diagon mean two error same red dot diagon mean lu factor time second dimens nonzero nonzero lu figur characterist matric condit number number iter refin step gesp red geppblu figur iter refin step gesp gesp accur red dot mean gepp accur figur show error gesp littl larger smaller error gepp figur show componentwis backward error also small usual near machin epsilon never larger gamma although combin techniqu step figur work well matric found matric combin better exampl fidapm jpwh orsirr error larg unless omit p r step ex radrf cannot replac tini pivot p therefor softwar provid flexibl interfac user abl turn option evalu cost step gesp figur done respect serial implement sinc parallel numer phase algorithm step timeconsum particular larg enough matric lu factor step domin step measur time step respect step simpl equilibr step comput r c use algorithm dgeequ lapack usual neglig easi parallel row column permut algorithm step comput p r p c easi parallel their parallel futur work fortun memori requir onnza wherea memori requir l u factor grow superlinearli nnza meantim run singl processor figur show fraction time spent find p r step use algorithm fraction factor time time signific small problem drop larg matric requir long time factor problem interest parallel machin time find sparsitypreserv order p c step much matrix depend usual cheaper factor although exist matric order expens nevertheless applic repeatedli solv system equat nonzero pattern differ valu order algorithm need run onc cost amort factor plan replac part algorithm error partial pivot refin gesp figur error jjx true gammaxjj condit number backward error gesp figur backward error lu factor genp time second fraction genp time permut larg diagon triangular solv figur time factor solv permut larg diagon comput residu estim error bound mhz mip r order bbmat tabl characterist test matric numsym fraction nonzero match equal valu symmetr locat strsym fraction nonzero match nonzero symmetr locat someth faster outlin section seen figur comput residu spars matrixvector multipl cheaper triangular solv take small fraction factor time larg matric solv time often less factor time algorithm parallel see section parallel perform data final code abil estim forward error bound true error jjx true gammaxjj far expens step factor for small matric expens factor sinc requir multipl triangular solv therefor user ask it implement mpi section describ design implement perform distribut algorithm two main step gesp method spars lu factor step spars triangular solv use step implement use mpi commun data highli portabl test code number platform cray te ibm sp berkeley now here report result node cray te nersc illustr scalabl algorithm restrict attent eight rel larg matric select testb tabl repres differ applic domain characterist matric given tabl matrix distribut distribut data structur distribut matrix twodimension blockcycl fashion distribut p process not restrict power arrang d process grid shape p r theta p c matrix decompos block submatric then block cyclic map onto process grid row column dimens although d decomposit natur spars matric much easier implement d layout strike good balanc among local by block load balanc by cyclic map lower commun volum by d map d layout use scalabl implement spars choleski factor describ partit global matrix block partit base notion unsymmetr supernod first introduc let l lower triangular matrix lu factor supernod rang column l triangular block diagon full row structur block ident row structur supernod store dens format memori supernod partit use block partit row column dimens n supernod nbyn matrix matrix partit n block nonuniform size size block matrix depend clear diagon block squar full we store zero u upper triangl diagon block wherea offdiagon block may rectangular may full matrix figur illustr partit blockcycl map mean block map onto process coordin i mod p r j mod p c process grid use map block li j factor need row process block row similarli block ui j need column process block column j d map block column l resid one process name column process exampl figur kth block column l resid column process f g process own two nonzero block contigu global matrix schema right figur depict data structur store nonzero block process besid numer valu store fortranstyl array nzval column major order need inform interpret locat row subscript nonzero store integ array index includ inform whole block column individu block it note mani offdiagon block zero henc store neither store zero nonzero block lower upper triangl diagon block store l data structur process own dnp c e block column l need dnp c e pair indexnzv array matrix u use row orient storag block row own process although numer valu within block still use column major order similarli l also use pair indexnzv array store block row u due asymmetri nonzero block u skylin structur shown figur see detail skylin structur therefor organ index array differ l omit show figur sinc dynam pivot nonzero pattern l u determin symbol factor numer factor begin therefor block partit setup data structur perform symbol algorithm much cheaper execut oppos partial pivot size data structur cannot forecast must determin fli factor proce spars lu factor figur outlin parallel spars lu factor algorithm use matlab notat integ rang submatric three step kth iter loop step column process particip factor block column lk n k step row process particip triangular solv obtain block row ukk rankb updat lk step repres work also exhibit parallel two step b block size kth block columnrow eas understand algorithm present simplifi actual implement use pipelin organ process procc k step iter k soon rankb updat step iter k block column index storag block column l block nzval block row subscript full row lda nzval block row subscript full row global matrix process mesh u figur d blockcycl layout data structur store local block column l let mycol myrow process column row number process grid let procc k procr k column row process block column row k block n obtain block column factor process row need els receiv need endif perform parallel triangular solv process column need els receiv need endif n n endif end figur distribut spars lu factor algorithm complet updat trail matrix ak own procc k pipelin allevi lack parallel step processor cray te instanc observ speedup nonpipelin implement iter major commun step sendrec lk n k across process row sendrec ukk process column data structur see figur ensur block lk n k ukk process contigu memori therebi elimin need pack unpack sendrec oper send mani smaller messag sendrec pair two messag exchang one index anoth nzval reduc amount commun employ notion elimin dag edag is send kth column l rowwis process own jth column l exist path supernod k j elimin dag done similarli columnwis commun row u therefor block l may sent fewer p c process block u may sent fewer p r process word commun take account sparsiti factor oppos sendtoal approach dens factor exampl af theta process total number messag reduc fewer messag reduct even process sparser problem spars triangular solv spars lower upper triangular solv also design around distribut data structur forward substitut proce bottom elimin tree root wherea back substitut proce root bottom figur outlin algorithm spars lower triangular solv algorithm base sequenti variant call inner product formul formul kth subvector xk solv updat inner product must accumul subtract bk diagon process coordin k mod p r k mod process grid respons solv xk two counter frecv fmod use facilit asynchron execut differ oper frecvk count number process updat xk receiv diagon process own xk need distribut among row process procr k due sparsiti process procr k contribut updat frecvk becom zero necessari updat xk complet xk solv fmodk count number block modif sum local inner product updat store lsumk xk fmodk becom zero partial sum lsumk sent diagon process own xk execut program messagedriven process may receiv two type messag one partial sum lsumk anoth solut subvector xk appropri action taken accord messag type asynchron commun enabl larg overlap commun comput import commun comput ratio much higher triangular solv factor algorithm upper triangular solv similar illustr figur howev row orient storag scheme use matrix u slight complic actual implement name build two vertic link list enabl rapid access matrix entri block column u let mycol myrow process column row number process grid let procc k column process block column k block k send xk column process procc k endif end work receiv messag messag lsumk send xk column process procc k endif els messag xk k li k send lsumi diagon process own li i endif end endif figur distribut lower triangular solv l symbol numer tabl lu factor time second megaflop rate node te parallel perform recal partit block base supernod largest block size equal number column largest supernod larg matric thousand especi toward end matrix l larg granular would lead poor parallel load balanc therefor occur break larg supernod smaller chunk chunk exceed preset threshold maximum block size experi found maximum block size good cray te use perform result report section tabl show perform factor cray te symbol analysi step figur yet parallel start copi entir matrix processor run step independ processor thu time independ number processor first column tabl report time spent symbol analysi memori requir symbol analysi small store manipul supernod graph l skeleton graph u much smaller graph l u subsequ column tabl show factor time vari number processor four larg matric bbmat ecl fidapm wang factor time continu decreas processor demonstr good scalabl last column report numer factor rate mflop gflop achiev matrix ecl fastest publish result seen implement parallel spars gaussian elimin tabl start processor exampl could run fewer processor refer compar distribut memori code share memori superlu mt code use small number processor exampl use processor dec alphaserv factor time superlu mt matric af ex second respect compar processor te time indic distribut data structur messag pass algorithm incur much overhead tabl show perform lower upper triangular solv altogeth number processor continu increas beyond solv time remain roughli same although triangular solv achiev high megaflop rate time usual much less factor effici parallel algorithm depend mainli workload distribut much time spent commun one way measur load balanc follow let processor one te processor except mb tertiari cach bbmat ecl tabl triangular solv time second megaflop rate te comm fact sol tabl load balanc commun processor cray te f denot number floatingpoint oper perform process i comput load balanc word b averag workload divid maximum workload clear better load balanc parallel runtim least runtim slowest process whose workload highest tabl present load balanc factor b factor solv phase seen tabl distribut workload good matric except twoton tabl also show fraction runtim spent commun number collect perform analysi tool call apprentic te amount commun quit excess even matric scale well bbmat ecl fidapm wang factor time spent commun solv much smaller amount comput commun take total time expect percentag commun even higher processor total amount comput less constant although twoton rel larg matrix factor scale well larg matric one reason present submatrix process map result poor load distribut anoth reason due long time commun look commun time use apprentic found process idl time wait receiv column block l sent process column left step figur idl time wait receiv row block u sent process row step figur clearli critic path algorithm step must preserv certain preced relat iter pipelin method shorten critic path extent expect length critic path reduc sophist dag task graph schedul solv found process idl time wait messag arriv at line figur process much work larg amount commun commun bottleneck also occur matric problem pronounc twoton anoth problem twoton supernod size or block size small column averag result poor uniprocessor perform low megaflop rate conclud remark futur work propos number techniqu place partial pivot stabil spars gaussian elim inat effect demonstr numer experi techniqu enabl static analysi nonzero structur factor commun pattern result scalabl implement becom feasibl largescal distribut memori machin hundr processor preliminari softwar use quantum chemistri applic lawrenc berkeley nation laboratori complex unsymmetr system order solv within minut techniqu numer stabil although current gesp algorithm success larg number matric fail solv one finit element matrix av pivot growth still larg combin current techniqu plan investig complementari techniqu stabil algorithm exampl use judici amount extra precis store matrix entri accur perform intern comput accur facil avail free intel architectur perform arithmet effici bit regist modest cost machin extra precis use factor residu comput also mix static partial pivot pivot within diagon block own singl processor or smp within cluster smp enhanc stabil use aggress pivot size control strategi step algorithm is instead set tini pivot delta jjajj may set largest magnitud current column incur nontrivi amount rank perturb origin matrix end use shermanmorrisonwoodburi formula recov invers origin matrix cost step invers iter remain seen circumst idea employ practic also theoret question answer high perform issu order make solver entir scalabl need parallel symbol algorithm case start matrix initi distribut manner symbol algorithm determin best layout numer algorithm redistribut matrix necessari also requir us provid good interfac user know input matrix distribut manner lu factor investig gener function matrixtoprocess map schedul comput commun exploit knowledg edag expect relax much synchroni current factor algorithm reduc commun also consid switch dens factor one implement scalapack submatrix lower right corner becom suffici dens uniprocessor perform also improv amalgam small supernod larg one speed spars triangular solv may appli graph color heurist reduc number parallel step also altern algorithm substitut base partit invers select invers howev algorithm usual requir preprocess differ matrix distribut one use factor unclear whether preprocess redistribut offset benefit offer algorithm probabl depend number righthand side relat work duff koster appli techniqu permut larg entri diagon direct iter method direct method use multifront approach numer factor first proce diagon pivot previous chosen analysi structur aa diagon entri numer stabl elimin delay larger frontal matrix pass later stage show use initi permuta tion number delay pivot greatli reduc factor experi iter method gmre bicgstab qmr use ilu precondition converg rate substanti improv mani case initi permut employ amestoy duff lexcel implement multifront approach distribut memori machin host perform fillreduc order estim frontal matrix structur static map assembl tree base symmetr pattern send inform processor numer factor frontal matrix factor master processor one slave processor due possibl delay pivot frontal matrix size may differ predict analysi phase master processor dynam determin mani slave processor actual use frontal matrix show good perform processor ibm sp mcspars parallel unsymmetr linear system solver key compon solver reorder step transform matrix border block upper triangular form reorder first use unsymmetr order put rel larg entri diagon algorithm modifi version duff unsymmetr order use sever symmetr permut preserv diagon order matrix desir form larg diagon entri better chanc obtain stabl factor pivot within diagon block number pivot border thu reduc larg medium grain parallel exploit factor diagon block elimin border block implement parallel factor algorithm cedar experiment share memori machin fu jiao yang design parallel lu factor algorithm base follow static inform sparsiti pattern household qr factor contain union sparsiti pattern lu factor possibl pivot select use memori alloc comput conserv on possibl zero entri arbitrarili conserv particularli matric aris circuit devic simul sever matric incur much overestim show good factor speed processor cray te interest compar perform differ approach acknowledg grate iain duff give us access earli version harwel subroutin mc permut larg entri diagon r highli parallel spars triangular solut multifront parallel distribut symmetr unsymmetr solver scalapack user guid univers florida spars matrix collect approxim minimum degre order unsymmetr matric appli numer linear algebra supernod approach spars partial pivot asynchron parallel supernod algorithm spars gaussian elimin algorithm algorithm obtain maximum transvers design use algorithm permut larg entri diagon spars matric user guid harwellbo spars matrix collect releas effici spars lu factor partial pivot distribut memori architectur solv larg nonsymmetr spars linear system use mcspars nest dissect regular finit element mesh elimin structur unsymmetr spars lu factor matrix comput optim scalabl parallel spars choleski factor scalabl iter solut spars linear system spars gaussian elimin high perform comput modif minimum degre algorithm multipl elimin effici parallel spars triangular solut select invers effici blockori approach parallel spars choleski factor tr elimin structur unsymmetr spars italicluital factor effici blockori approach parallel spars choleski factor scalabl iter solut spars linear system modif minimumdegre algorithm multipl elimin solv larg nonsymmetr spars linear system use mcspars appli numer linear algebra user guid effici spars lu factor partial pivot distribut memori architectur algorithm obtain maximum transvers algorithm permut zerofre diagon f spars gaussian elimin high perform comput asynchron parallel supernod algorithm spars gaussian supernod approach spars partial pivot ctr bergen f hulsemann u rude x unknown largest finit element system solv today proceed acmiee confer supercomput p novemb laura grigori xiaoy s li new schedul algorithm parallel spars lu factor static pivot proceed acmiee confer supercomput p novemb baltimor maryland mark baertschi xiaoy li solut threebodi problem quantum mechan use spars linear algebra parallel comput proceed acmiee confer supercomput cdrom p novemb denver colorado olaf schenk klau grtner twolevel dynam schedul pardiso improv scalabl share memori multiprocess system parallel comput v n p februari patrick r amestoy iain s duff jeanyv lexcel xiaoy s li analysi comparison two gener spars solver distribut memori comput acm transact mathemat softwar tom v n p decemb xiaoy s li overview superlu algorithm implement user interfac acm transact mathemat softwar tom v n p septemb xiaoy s li jame w demmel david h bailey greg henri yozo hida jimmi iskandar william kahan suh y kang anil kapur michael c martin brandon j thompson teresa tung daniel j yoo design implement test extend mix precis bla acm transact mathemat softwar tom v n p june anshul gupta recent advanc direct method solv unsymmetr spars system linear equat acm transact mathemat softwar tom v n p septemb xiaoy s li jame w demmel superlu_dist scalabl distributedmemori spars direct solver unsymmetr linear system acm transact mathemat softwar tom v n p june