t effici nonparametr densiti estim sphere applic fluid mechan a applic nonparametr probabl densiti function estim purpos data analysi well establish recent method appli fluid flow calcul sinc densiti fluid play crucial role determin flow furthermor calcul involv direct axial data domain interest fall surfac sphere accur fast estim probabl densiti function crucial calcul sinc densiti estim perform iter comput particular valu fn x fn x fn xn densiti estim sampl point xi need evolv system usual nonparametr estim make use kernel function construct fn propos special sequenc weight function nonparametr densiti estim especi suitabl applic result method comput advantag kernel method certain situat also parallel easili condit converg turn similar requir kernelbas method also discuss experi differ distribut compar comput effici method kernel base estim b introduct esti mati oni problem esti mati valu li ty ven sampl associ ate di stri buti on made type di stri buti whi ch sampl drawn thi si si n contrast esti mati whi ch assum come ven fami ly paramet esti mate ou stati sti cal method earli contri butor theori nonparametri c esti mati oni nclude smi rnov rosenblatt parzen chentsov descri pti on ou approach nonparametri c along wi th bi bli ographi book lverman nadaraya recent develop presentedi n book scott wand jone result experi mental compari son deli use method addi ti data analysi s ani mportant appli cati nonparametri c onal flui mechani cs flow calculati on per lagrangi framework set space evolv usi ng ng on poi nt werei ni ti alli close move apart leadi ng mesh di storti cal di culti es problem th mesh di storti eli mi nate extent use smooth cle hydrodynami cs que sph treat nt bei ng track sampl comi ng unknown li ty di stri buti on calculati on often requi computati valu unknown densi ty buti ts gradi ent well receiv editor august accept public in revis form august publish electron june httpwwwsiamorgjournalssischtml depart comput scienc univers california santa barbara ca omerc ucsbedu depart mathemat indian institut technolog bombay india ashokmath iitbernetin contrast appli cati on concern wi th di splay densi ty ci ent esti mate densi ty gri di n flui flow calculati on requi red sampl nt anoth di erencei n two type appli cati onsi deali ng th data analysi s usual concern th opti mal accuraci one get ven sampl si ze flui flow calculati on addi ti onal data ned wi thi ncreas di screti zati on usual concern wi th opti mal vari ati onal eort error appli cati on examplei n ng di recti onal data sampl li e ci rcle along surfac al case di recti onal al whi ch c center ci rcle sphere ou method propos nonparametri c cal stati sti cs kernel orthogon seri es method kernel method extensi veli studi ed probabl popular appli cati on sph thi method valu densi ty nt xi esti mate ni esti mate ven sampl posi ti on sampl drawn li ty di stri buti wi th unknown ki kernel hi ndow wi dth hi normali zati factor make f ni nto li ty ty one drawback kernel method onal costi nvolv even possi ble reduc onedi mensi onal case usi ng expansi polynomi al kernel ng strategi thi strategi cannot ly extend hi gher di mensi on ng method usedi n di mensi on howev si nce evalu gri d methodi sui tabl flui flow calculati on whi ch arei nterest requi red sampl nt propos cosi nebas wei ght nonparametri c esti mati on whi chi al case class esti mator form sequenc thi mi lar kernel esti mator eas evaluati seri es expansi on role ndow wi dth paramet h kernel methodi replac smoothi ng paramet method f ni form choi ce c cularli sui tabl appli cati onsi n flui flow calculati on valu f n x sampl di recti on requi red stepi n flow show th esti mator red n valu comput eci entli usi ng om d n operati on di recti onal data om n operati on al di mensi on need larg long wi thout bound th n thi si si n contrast on on red kernel method computati oni n worst case expect complexi ty oh th ng bound support howeveri n al case kernel method reduc li near ng step gl u ashok srinivasan deri on whi ch sequenc esti mate on f n fashi converg unknown experi mental veri fy accuraci eci enci methodi n practi cal test case experi ment cal analys alsoi ndi cate vari th n opti mal accuraci paperi organi zed follow secti defin wei ght on converg ntegrat squar error mise sampl spacei theorem on guarante ef n also present correspondi ng result secti scheme eci ent computati esti mate present secti on descri experi mental result th esti mator wi th kernel method di stri buti on practi ce experi mentsi mpli net savi ng number on perform kernel methodsi n on also veri fy formula found opti mal choi ce m result show kernel method esti mator perform di erent setti ng thu complement other conclusi on presentedi n secti ns addi ti onal test result cosin estim converg mise secti on first menti relat work done spheri cal data defin esti mator deri on ts converg di recti onal data ci rcle correspondi ng result di recti onal al data sphere al data ci rcle kernel method nonparametri c esti mati di recti onal al di scussedi n whi le deali ng th di recti onal data fi sher lewi s embleton recommend usi ng ng kernel exp al data recommend kernel normali ze w li ty on c ni reci procal h usedi n defini ti kernel esti mator x x cartesi represen tati nt p p respecti veli x x ii thei nner product two vector w n role kx x hall watson cabrera analyz esti mator di recti onal data wi th x x replac observ term x x ii cosi ne angl nt ii measur di stanc along surfac sphere nt p p inner product play cruci al rolei n esti mator consi der esti mator term power nner product power playi ng role smoothi ng paramet thi enabl us expand esti matori n seri es li tate fast computati on c x c x ooc x a b x fig ns c x c case first defin esti mator assum x sequenc ndepend andi denti calli di stri bute i i d random abl observati on di recti onal data th li ty wei mpose addi ti onal condi ti si nce random abl x j defin ci rcle esti mator densi ty di recti onal data fx x der nonparametri c esti mator form ven th co normali zati factor ven make c xi ntegrat co dx maki ng use tabl ofi ntegral gradshteyn ryzhi k usi ng shown exampl on c x c shown fi gure a thei nterval fi gure b wi sh find suci ent on whi ch sequenc esti mator f n converg fi n mise sens order thi s first show converg bi deri on whi ch anc converg shall use result prove converg mise fi rst show expect valu esti mate f n x approach actual uni formli ven n lemma suppos f c andl et f n x given uniforml y independentl n proof sfsd gl u ashok srinivasan showni n lverman whi ttle chang abl x x usi ng peri odi ci ty c f along th mean valu theorem dy x nt x y therefor ntegral evalu nce yc yi odd on secondi ntegral evalu let ng esti mate as am co yy dy yam co yy dy yam co yy dy yam co ydi co nce co decreas yi ncreas thei nterval consi derati on furthermor bound therefor order get bound wi choos functi m take thi term decay exponenti alli second i product thi term m thu product approach si nce exponenti al decay domi nate order get good bound first term wi sh choos ng condi ti small possi ble choos arbi trari ly small thu mi asymptoti c bound as furthermor ndepend x henc uni form lemma suppos f c andl et f n x given uniforml n provid n proof showni n whi ttle consequ lemma secondi ntegral approach asymptoti calli henc second term approach nce bound thu suce show converg firsti ntegral x fx maki ng chang abl usi ng n expressi ri ghthand consequ pressi nce mn abovei ntegral converg nce mi si ndepend x uni form therefor vari anc uni formli on lemma note bound bi cosi ne method ven lemma form bound anc ven lemma therefor role play cosi ne methodi h kernel base method hi ndow wi dth kernel esti mator word bound bi vari anc cosi ne esti mator arei n accord wi th behavi kernel method lverman si mi lari ty rate convergencei expect si nce cosi ne essenti alli li ke kernel esti mator though form on di er wi shown later advantag cosi ne esti mator li esi ni ts onal eci enci theorem suppos f c f n x given n ef n proof ef showni n whi ttle lemma thei ntegral approach henc mise converg gl u ashok srinivasan fact misei form c bound constant shall explai n later exact asymptoti c constant mportant practi cal on condi ti on converg esti mate ts deri vati ve real li nei nstead consi der case di recti onal data li e along surfac case let x n sequenc abl th valu surfac center suppos li ty fx x j bound second deri vati ve consi der nonparametri c esti mator form determi ned functi n c thi case follow xx denot angl nt x x co normali zi ng factor ven below deri vati along li ne case ci rcle ng theorem prove converg esti mator theorem suppos f c andl et f n x given n ef analog form misei found expressi mise see asi n case hi ndow wi dth kernel esti mator deali ng th al data consi der ng al esti mator spheri cal data co xx also defin correspondi ng esti mator ci rcle take cosi ne arc length two poi ntsi nstead cosi ne half arc length case di recti onal data case ci rcle sphere veli ecient evalu densiti estim secti on shall descri eci ent algori thm computati esti mate f n x evalu set n observ nt x ci rcle case also show f valu f n arbi trari xi desi red ly accompli shed comput eci enci methodi base fact f n term on c x suppos repres posi ti on observ nt x thei r cartesi coordi nate show x f n x express polynomi al total degre mi n coordi nate x coeci ent polynomi al determi nedi n turn coordi nate x moreov coeci ent sum contri buti on due x ii ndepend fi rst consi der case di recti onal data halfangl formula cosi ne get denot poi nt correspondi ng angl x x n cartesi coordi nate let repres standardi nner product r cosx ng thi si nto get expressi i polynomi al degre fix m comput coeci ent addi ng contri buti x follow usi ng al theorem rsm x r thei nner th changi ng order summati rsm mr s n i ami ven use expressi onal eas fie rsm gl u ashok srinivasan tabl co mputatio nal co mplexityo f co sine estimato r circl axial direct larg m consi der number on requi red evaluati f n x ven on x power x r x r fix comput th om multi pli cati on ng thi re omn multi pli cati on conclusi thi step om averag mr s ven r comput wi th addi ti onal on on si nce total om correspondi ng rs th thi mean coeci ent polynomi ali n comput wi th total om n on coeci ent f n x comput evalu f n x th calcul power x r x r mi n om on si nce coeci ent alreadi avai labl remai ni ng re multi pli cati on addi ti on result di erent case summari zedi n tabl remark mise converg condi ti theorem musti ncreas wi thout bound th n theoreti calli take ng li ke resulti mpli es computati densi ty sampl poi nt accompli shed usi ng on magni tude ve accept accuraci f n x problem th ng slowli magni tude control error converg proof eci ent algori thm evaluati f n x di recti onal data construct larli observati on drawn unknown shown rstm th mr s t n thi ti coeci ent polynomi ali n comput wi th total om n on preprocessi ng evaluati f n x re on ng result deri ved al data summari zedi n tabl also note need cartesi representati data data cal coordi nate wi addi ti onal overhead ng cartesi representati on howev thi overhead take li near ti wi negli gi ble suci entli larg data furthermorei shown ani mportant class appli cati on cartesi coordi nate prefer cal coordi nate latter systemi calli stabl solvi ng di erenti al equati on se subsequ part secti shall compar onal e ci enci scheme wi th kernel method parallel one advantag onal strategi de bed abovei eas paral zati on paral zati oni redi n mani flui flow calculati on due larg si ze system kernel methodi some di cult paral ze use eci ent kern mplementati perform kernel evaluati on nt whi ch di stanc h ven sampl eci enti mplementati paral zati re load ng decomposi ti poi nt close remai n processor processor roughli loadi n term onal eort also communi cati pattern kernel method regular contrast paral zati cosi ne esti mator ly accompli shed global reducti operati on whi ch eci on usual avai labl thi method requi re onal eort poi nt loadi ly balanc havi ng number processor decomposi ti play ani mportant si nce poi nt processor theoret comparison kernel cosin estim analyz onal eci enci kernel cosi ne esti mati method ani mportant measur eci enci algori thmsi converg rate error th sampl ze n onal eort c red functi error e kernel esti mator te hi smoothi ng paramet di mensi on ni sampl ze onal eort requi red nonparametri c esti mati express dependi ng detai ls algori thm use ven sampl ve mal h h n d howev si nce equati onal also depend h need der possi bi li ty valu h smaller opti mal valu may actual result lower onal eort let us consi der vari ati h th n form mi ni mum error expon term ri ght same otherwi se error due hi gher term wi domi nate thi lead whi chi valu mal ven n let h optn repres opti mal h mi ni mi zi ng mise ven n h optc repres opti mal gl u ashok srinivasan mi ni mi zi ng onal eort functi error expressi deri ved necessari lyi mpli h si nce relati would sti sfi expressi constant k k choos subopti mal valu hi n order toi mprove speed algori thm opti mal vari ati error th onal usi ng thi valu ven let us consi der cosi ne esti mator te asymptoti c mise follow ei mise mi smoothi ng paramet di di mensi ci rcle sphere ni sampl ze onal eort requi red esti mator express n determi ned tabl expressi c abovei th recal ng behav h mi lar previ ou case show opti mal vari ati error th onal ven exampl cosi ne esti mator ci rcle th al data di recti onal data onal complexi ty error relat veli complexi ty kernel esti matori al di recti onal data howev sever di erent possi bi li ti es st dependi ng eci ent thei mplemen tati esti matori s der esti mator form ven howeveri f consi der kernel th bound support use eci mentati algori thm comput kernel poi nt nonzero contri buti on expect valu data ci rcle note worst case remai ns case consi der eci ent algori thm usi ng polynomi al kernel ng whi ch use li near ani ni ti al on log n ng step thi case whi ch mean kernel method better cosi ne kernel howev appear natur generali zati thi updat strategi hi gher di mensi on result di erent case determi nedi n manner demonstr presentedi n tabl wi sh menti exact constantsi n theorem qui te mportant compar wi th expon e nce asymptoti calli slowdowni ncur cach domi nate overal runni ng me expect mpler memori access pattern esti mator wi makei advantag kernel methodi n asymptoti c case tabl theo ptimal co mputatio nal eo rt versu mise number tabl repres relatio nship co mputatio nal es take acco unt initi rting step estim circl cosin axial data cosin direct data kernel worst case kernel expect case si nce worst case es kernel method cosi ne esti mator di recti onal data sphere order eci enci es method test experi ment larli si nce worst case complexi ty cosi ne esti mator al data spherei expect case eci enti mplementati kernel esti mator need perform experi ment test meri ts two esti mator experiment result perform cal experi ment al di recti onal data ci rcle spherei n order test eecti veness esti mator first plot esti mate known di stri buti on demonstr mise follow expect trend di stri buti on final compar onal eci enci esti mator wi th kernel method ri cal result presentedi n appendi x consi der normali ze functi densi ty surfac sphere si known functi u angl azi muth cal coordi nate thi soluti cular flui mechani cs fi gure a present cal esti mate versi taken thi figur take data di recti onal howev nce th respect center ci rcle consi der data al use al esti mator see fi gure b re much smaller valu m fi gure a misei compar versu n onedi mensi onal di stri buti usi ng al cosi ne esti mator also compar th one case di recti onal esti matori n order show benefit usi ng al esti mator fi gure b misei compar versu n twodi mensi onal versi di stri buti surfac sphere usi ng di recti onal esti mator next present result experi ment compari ng speed cosi ne kernel esti mator consi der opti mal vari ati onal eort th mise order get opti mal onal eort ven mise allow possi bi li ty may di erent sampl si ze kernel cosi ne esti mator thi si fie calculati on one ly chang sampl ze changi ng di screti zati system perform son spheri cal data case data ci rcle dere asymptoti c analys previ ou secti whi ch clearli cate li near kernel algori thmi n onedi mensi onal case wi outperform cosi ne esti mator howeveri n paral mplementati on ng step li near kernel algori thm may slow one may wi sh consi der cosi ne esti mator gl u ashok srinivasan a b co sine estim theo nedimensio nal caseo f defin abo ve lid line repres true densiti a dash line repres directio nal estim b dash line repres axial estim ng kernel chosen son otherwi se a b n n fig mise versusm n fo r densiti a onedimensio nal o n circl exp us co xa lid line sho ws result fo r axial co sine estimato r dash line fo r directio nal estimato r with two dimensio nal o n exp us co a defin abo ve mise fo r directio nal co sine estimato r ai normali zati constant rati di stanc two nt along surfac sphere hi ven argument kernel on use thi kernel compari son fie ts popular use gl u ashok srinivasan time fig co mpariso f time in seco nd versu mise fo r co sine kernel data sampl defin abo ve po int mark repres kernel estim po int mark x repres co sine estim flui mechani cs calculati on furthermor cannot expect kernel ficantli better perform ng reason i iti well known kernel equal good tabl th respect eci enci gi ven eci encyi same consi derati oni onal eorti nvolv kernel take ng nt operati on nonzero evaluati i ncludi ng cost computi ng squar di stanc reason kernel would requi least ng nt on apart thi s memori access ti me zeroevaluati on would add constant kernel fi gure compar onal eort requi red cosi ne wei ght esti mator kernel esti mator es obtai ned data usi ng ng procedur perform esti mate ou valu n m h obtai ned mise ti calculati on cosi ne kernel esti mate separ plot data requi red calculati on versu error chose lower envelop data curv cular esti mator si nce valu m n data lower envelop best nabl speed ven mise thei mplementati kernel esti mator di vi ded spherei nto cell si de cell length least h nce kernel defin ndow dth h rather h place samplei n ate cell computi ng densi ty cular cell need search cell expect complexi ty first der data esti mate usi ng al cosi ne esti mator al vari ant kernel esti mator fi gure show result twodi mensi onal di stri buti on thi si exampl hi ghli nonuni form di stri buti on see kernel cosi ne esti mator equal fast next consi der di stri buti ven i azi muth i on result presentedi n fi gure a show cosi ne esti mator outperform kernel esti mator order magni tude al form esti mator use thi consi dere two es menti one treat data di recti onal esti mate usi ng di recti onal vari ant kernel cosi ne esti mator di stri buti on cosi ne esti mator perform poorli onal eci enci present result thi case fi gure b present result di stri buti ven co see cosi ne esti mator sti outperform kernel esti mator though sli ghtli discuss compari son esti mate wi th true densi tyi ndi cate cosi ne esti mator produc accur result di stri buti on test plot mise versu n follow expect trend sampl zei ncreas error decreas besi de opti mal valu mi ncreas sampl zei ncreas also seen number poi ntsi ncreas rang whi ch esti mate perform well alsoi ncreas use thi advantag choosi ng subopti mal valu whi ch decreas onal eort ficantli buti ncreas error sli ghtli experi ment compari ng onal eci enci es show cosi ne esti mator outperform kernel esti mator al data di stri buti oni moder uni form di stri buti oni hi ghli nonuni form two esti ma tor compar perform al data cosi ne esti mator outperform kernel esti mator sli ghtli di recti onal data di stri buti oni moder uni form howev ng result cosi ne esti mator poor hi ghli nonuni form di recti onal data gener datai nonuni form smoother wei ght on use thi ve low valu whi chi mpli es fast evaluati usi ng cosi ne esti mator howev thi lead hi gher h kernel esti mator whi chi mpli es sampl contri bute kernel evaluati sampl nt and henc thi lead onal eort convers di stri buti oni hi ghli nonuni form especi alli di recti onal data ker nel methodi prefer ri cal test result presentedi n demonstr nt also analyz experi mental data esti mate opti mum vari ati th n usi ng result experi ment perform least squar mate kn onedi mensi onal esti mati whi chi expect base expressi mise ng appear reason esti mate densi ty surfac sphere thi resulti also stent wi th cal predi cti on here magni tude k depend complexi ty functi on es di stri buti on dere here also note valu m n h whi ch gave opti mal onal eort ven mise compar result kernel cosi ne esti mator observ valu h close valu whi ch gave mi ni mum mise ven sampl si ze howev valu cantli lower valu whi ch gave mi ni mum mise ven sampl ze though errori nvolvedi tself much hi gher mi ni mum mise appear choos subopti mal smoothi ng parameteri n order ncreas speedi n case cosi ne esti mator gl u ashok srinivasan b a time time fig plo f time in seco nd versu mise fo r co sine kernel estimatio f data sampl po int mark repres kernel estim po int mark x repres co sine estim a data treat axial b data treat directio nal elev densiti fig plo f densiti ns g dierent elevatio n lid line dash line dashdo tted line tted line conclu ion thi paper descri bed wei ght esti mator nonparametri c esti mati li ty on base cosi ne provi ded on whi ch esti mate ts deri vati ve converg actual on develop scheme eci ent computati densi ty present experi mental result check perform esti mator practi cal problem result cularli relev flui mechan calculati on andi n gener on sampl si ze control exampl though refin di screti zati on also ven empi r cal formula choosi ng wei ght expon paramet esti mator experi mental result suggest cosi ne esti mator outperform kernel esti mator di recti onal al data moder uni form ve perform compar kernel esti mator hi ghli nonuni form al data whi le kernel methodi prefer hi ghli nonuni form di recti onal data potenti al theoreti cal studi esti mator appendix test result present test resultsi n secti studi eci enci es cosi ne kernel techni que ed systemati calli bei ng veli uni form bei ng sharpli peak test chose on g si constant govern sharp i elevati on normali ze thi li ty on fi gure show densi ty functi elevati alon di erent valu paramet s thi c center sphere thu use al esti mator alsoi gnore knowledg use gener di recti onal esti mator gl u ashok srinivasan gl u ashok srinivasan gl u ashok srinivasan time a b present result experi ment plot versu mise kernel esti mator versu cosi ne esti mator al di recti onal data kernel esti matori one usedi n ri cal test perform intel celeron mhz processor th mb memori c code led wi th gcc compi ler opti mi zati level o see fi gure sharp cosi ne esti mator outperform kernel esti mator al di recti onal data densi ty becom sharper kernel method start outperformi ng cosi ne esti mator di recti onal data though latteri sti better al data densi ty becom extrem sharp kernel method becom better type data though al data two method sti compar extenti n term speed result follow calli predi cted trend demonstr two method complement di erent type data appendix thank refere thei r detai led comment advi ce esp ci alli di recti ng attenti current li teratur r glo bal measureso f deviatio nso f densiti functio n estim estimatio f unkno wn pro babil densiti basedo bservatio ns fast implementatio nso f nparametr curv estimato rs statist analysiso f spheric data kernel densiti estimatio n spheric data treesph unificatio f sph hierarch tree metho estimatio f pro babil densiti cumul fo urier seri metho ds thed particl hydro dynam estimatio f pro babil densiti functio n mo de remarkso n nparametr estimateso f densiti functio n estimatio f pro babil densiti ano rtho go nal seri multivari densiti estimatio n fast algo rithm fo r nparametr curv estimatio n kernel densiti estimatio n use fast fo urier transfo rm appro ximatio f pro babil densitieso f rando variabl numer lutio f partial di densiti estimatio n fo r statist data analysi new co mputatio nal metho fo r lutio f flo w pro blemso f micro structur fluid pro babil densiti estimatio n astro pro babil densiti estimatio n use delta sequenc kernel smo thing estimatio f pro babil densiti smo ns tr ctr jeff racin parallel distribut kernel estim comput statist data analysi v n p august