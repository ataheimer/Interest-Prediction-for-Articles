t adapt schedul parallel loop distribut sharedmemori system a abstractus runtim inform load distribut processor affin propos adapt schedul algorithm variat differ control mechan propos algorithm appli differ degre aggress adjust loop schedul granular aim improv execut perform parallel loop make schedul decis match real workload distribut runtim experiment compar perform algorithm variat sever exist schedul algorithm two parallel machin ksr convex exemplar kernel applic program use perform evalu care select differ class parallel loop result show use runtim inform adapt adjust schedul granular effect way handl loop wide rang load distribut prior knowledg execut use overhead caus collect runtim inform insignific comparison perform improv experi show adapt algorithm five variat outperform exist schedul algorithm b introduct oop richest sourc parallel wide use scientif applic program mani scientif applic set independ task typic exist parallel loop call doall loop process element iter independ other perform loop schedul algorithm mainli affect three overhead sourc synchron loop alloc load imbal data commun although desir effici algorithm minim three sourc overhead usual imposs conflict aris among them exploit processor affin processor affin refer certain data access depend task specif processor precis definit given section favor alloc loop iter close data tend caus load imbal load balanc favor fine grain alloc loop iter where small number iter alloc order minim effect uneven assign howev fine grain alloc tend increas synchron overhead loop alloc overhead differ applic overhead sourc affect perform differ henc effici loop schedul algorithm optim perform adapt trade synchron overhead loop alloc overhead load imbal overhead data commun overhead moreov dynam schedul algorithm assum prior knowledg execut time loop iter execut loop usual unpredict practic far mani novel dynam schedul algorithm propos eg algorithm fall two distinct class central queue base distribut queue base central queue base algorithm iter parallel loop store share central queue processor exclus grab iter central queue exe cute major advantag use central queue possibl evenli balanc workload keep good load balanc central queue base algorithm differ way reduc synchron loop alloc overhead howev three limit associ use central queue iter central queue like dynam alloc execut processor facilit exploit processor alloc processor one remot access central work queue therebi gener heavi network traffic processor contend central queue central queue tend perform bottleneck result longer synchron delay order exploit processor affin inher parallel execut mani loop elimin central bottleneck affin schedul algorithm propos distribut central queue local proc ieee y yan x zhang high perform comput softwar laboratori univers texa san antonio san antonio c jin intervoic inc dalla texa email cjinintervoicecom manuscript receiv feb inform obtain reprint articl pleas send email to transpdscomputerorg refer ieeec log number d yan et al adapt schedul parallel loop sharedmemori system essor algorithm partit iter parallel loop static local queue processor involv remot access load imbal occur markato leblanc show affin schedul almost achiev best perform test case compar central queue base algorithm enhanc affin schedul algorithm presenc larg correl imbal loop execut time subramaniam eager propos two loop partit method dynam partit wrap partit two partit method howev improv affin schedul specif applic execut specif assumpt distribut loop execut time design distribut queue base algorithm reason prefer kind loop partit method uniform partit due uneven unpredict execut time loop iter henc crucial distribut queue base algorithm abl dynam effici schedul task runtim even load imbal caus static partit exist affin schedul algorithm processor schedul loop iter local queue use alloc scheme where time p remain iter local queue alloc p number processor iter alloc scheme may effici exampl initi loop partit balanc processor complet execut iter local queue time processor grab iter local queue alloc instead p remain iter hand initi loop partit balanc lightli load processor finish execut iter local queue soon possibl immedi turn help heavili load processor henc processor abl dynam increas decreas alloc granular base runtim inform reduc synchron loop alloc overhead balanc load evenli motiv us design adapt schedul algorithm improv exist affin schedul algorithm major object paper exploit potenti dynam inform reduc loop execut time propos adapt schedul algorithm five variat algorithm dynam adjust alloc granular accord program execut histori classifi parallel loop execut pattern fairli select set applic experiment verifi effect algorithm comparison propos affin schedul algorithm experiment result show use runtim inform adapt adjust schedul granular effect way handl wide rang load distribut prior knowledg use overhead caus collect runtim inform insignific comparison benefit gain method proper algorithm design experi show aggress algorithm use dynam in format improv execut perform parallel loop adapt algorithm outperform exist schedul algorithm experiment organ paper follow section describ detail main idea design adapt schedul algorithm present five variat differ degre aggress adjust loop schedul granular order assess precis effect propos algorithm practic analyz classifi program characterist applic section select five repres kernel applic benchmark perform evalu section report experiment result compari son summar paper section similar affin schedul algorithm adapt affin schedul algorithm also construct follow three phase initi partit phase determinist assign polici use partit iter parallel loop local queue processor ensur iter alway assign processor start assign scheme parallel loop execut repeatedli parallel iter access data set differ execut first execut parallel loop bring data local processor subsequ execut parallel loop involv local data access local schedul phase base local schedul polici processor alloc part remain iter local queue execut local queue empti local schedul caus remot access overhead local queue share processor critic section use protect alloc loop iter local queue local schedul overhead mainli come synchron overhead loop alloc overhead execut critic section reduc number alloc crucial improv perform local schedul phase remot schedul phase processor finish execut iter local queue remot alloc portion iter load processor system execut remot schedul phase aim dynam balanc workload iter reassign onc avoid processor thrash remot schedul caus remot data access overhead well synchron overhead loop alloc overhead instead reli preknowledg loop exe cution adapt affin schedul algorithm exploit potenti use dynam execut histori adapt adjust iter chunk size reduc synchron loop alloc overhead algorithm also maintain better load balanc main idea design minim local schedul overhead phase dynam balanc workload ieee transact parallel distribut system vol no januari speed up result reduct loop execut time initi phase loop n iter partit chunk uniform size np p processor reason prefer partit method absenc precis predict execut distribut loop iter initi partit ident one local schedul phase process speed variabl term ps variabl set processor keep track number iter processor execut far initi set zero increas one time processor finish execut iter compar local ps variabl ps variabl processor observ load distribut time processor smaller ps variabl valu execut iter heavier workload execut processor larger ps variabl valu becaus appli cation load distribut state certain steadi dura tion feasibl specul load distribut near futur current observ although applic realli surg varianc load distri bution predict differ minim dynam readjust order processor respons spontan dynam chang iter work load necessari differenti workload state processor fair select averag number iter execut processor ie p pivot partit workload state processor follow three type heavili load hlthe processor ps valu smaller p normal load nlthe processor ps valu within rang p p lightli load llthe processor ps valu equal larger p nonneg rang control variabl adjust distribut hl processor nl processor processor variat paramet would affect algorithm perform dynam featur execut real applic loop make impract imposs analyt determin optim valu a here discuss effect differ valu perform experi give empir method determin performanceeffici a order control chunk size alloc loop it erat chunksiz control variabl k set processor processor alway remov k remain iter local work queue execut begin local schedul phase chunksiz control variabl initi valu p total number processor then adapt independ adjust chunksiz control function p function p use load state current valu k processor two input paramet adjust chunksiz control variabl processor heavili load p increas k aim reduc chunk size iter remain heavili load processor execut lightli load processor therefor balanc workload effici processor normal load lightli load p decreas k aim increas chunk size normal load lightli load processor finish iter local work queue soon possibl immedi start help heavili load processor processor complet execut iter local queue turn remot schedul phase affin schedul algorithm processor exhaust local work queue start help heavili load processor remov p remain iter heavili load processor alloc method may effici processor turn help processor here determin chunk size accord current number lightli load normal load processor abl help heavili load processor near futur processor i determin chunk control variabl k follow n total number lightli load processor normal load processor n mean includ heavili load processor processor alloc remain iter p total number processor then processor alloc k remain iter heavili load processor execut procedur repeat local work queue empti initi k smaller valu p big chunk size use reduc number remot alloc experi next section show select big chunk size increas risk imbalanc load subsequ processor becom lightli load normal load k increas reach maxim valu p follow pseudocod descript adapt affin schedul algorithm given impl mentat code automat insert compil applic program processor dynam schedul execut loop without interfer oper system exist work gener dynam schedul program hand experi order focu algorithm studi initi partit phase initial_partitionn p n iter uniformli partit p processor for iter processor i yan et al adapt schedul parallel loop sharedmemori system local schedul phase processor i loop processor get k local iter execut adjust k k iter rang load state processor i adjust chunk granular remot schedul phase processor i loop locklocal_queue_j iter processor j all iter finish adapt chang loop schedul granular major characterist distinguish adapt affin schedul affin schedul algorithm remot read ps variabl processor overhead caus adapt schedul algorithm collect execut histori processor increas overhead nullifi benefit adapt vari loop schedul granular adapt affin schedul algorithm may exhibit perform improv exist affin schedul algorithm differ variat adapt affin schedul algorithm construct design differ chunk size control protocol function p here propos four mechan adapt algorithm let k chunk size control variabl processor local schedul phase exponenti adapt ea mechan ea mechan processor increas decreas valu chunksiz control variabl k factor time accord current load state chunksiz control function p formal defin state base base c h base integ constant here choos two base initi k set p adapt algorithm linearli adapt la mechan la mechan processor increas decreas chunk size control variabl k constant time interv accord current load state chunksiz control function p formal defin state con con con constant specifi user choos experi la mechan chang chunk size slower pace ea algorithm less risk imbalanc work load larger synchron loop alloc overhead conserv adapt ca mechan care select chunk size loop schedul algorithm crucial find compromis synchron overhead load imbal anc alloc bigger chunk iter loop tend reduc synchron loop alloc overhead increas risk imbalanc load previou work show order reason load imbal synchron over head safe chunk size control variabl k choos valu p p ca mechan construct restrict vari rang chunk size control variabl la mechan within p p chunk size control function defin follow state min con constant p use one experi greedili adapt ga mechan ga mechan employ twophas consensu method greedili enlarg chunk size non heavili load processor ga mechan record previou load state processor processor find nonheavili load state two consecut alloc greedili reduc chunksiz control variabl ie grab remain iter local work queue exe cute otherwis processor increas decreas chunk size use conserv method ca mechan pre record previou load state processor i let c record current load state processor i chunk size control function r pre c pre min c h hl hl hl hl keep maintain ps variabl processor allow four adapt mechan know exactli current workload processor therebi ps variabl use adjust speed proc ieee transact parallel distribut system vol no januari essor consequ adjust workload among processor also introduc loop alloc over head here design heurist variat denot still adopt framework adapt schedul algorithm instead use ps variabl determin workload distribut among processor use number iter actual execut processor guid adjust schedul granular initi parallel loop uniformli distribut proce sor processor repeat grab k remain iter local queue execut without adjust k processor finish iter local work queue turn get iter heavili load processor j processor said lightli load processor j heavili load processor increas schedul granular processor decreas schedul granular henc lightli load processor turn earli possibl help heavili load processor heavili load processor remain much workload possibl even lightli load processor end execut parallel loop processor check whether execut approxim number iter ie balanc workload so processor increas schedul granular speed subsequ execut parallel loop compar four variat adapt algo rithm ea la ca ga ha variat differ sever aspect instead determin load state time local schedul use adapt algo rithm ha variat updat load state processor remot schedul phase end one execut parallel loop caus less schedul overhead adapt algorithm ha variat work requir parallel loop nest sequenti loop execut repeatedli parallel loop execut onc ha variat becom affin algorithm pseudocod heurist variat adapt affin schedul algorithm ha variat shown follow initi partit phase initial_partitionn p n iter uniformli partit p processor for iter processor i local schedul phase processor i loop locklocal_queue_i remain iter remot schedul phase processor i loop locklocal_queue_j iter processor j increas chunk size processor i decreas chunk size processor j program section end parallel loop barrierbarri p tid execut code find_maximum_and_minimum_of_chunk_ kmax kmin p workload bal anc increas chunk size each processor barrierbarri p markato leblanc show affin schedul algorithm hereaft simplifi ml algorithm outperform algorithm exploit processor affin henc focu compar variat adapt schedul algorithm affin schedul algorithm two variat schedul algorithm evalu compar are ml affin schedul algorithm se dynam initi partit affin schedul algorithm adapt affin algorithm exponenti adapt mechan ea adapt affin algorithm linearli adapt affin mechan la adapt affin algorithm conserv adapt mechan ca adapt affin algorithm greedili adapt mechan ga heurist adapt variat ha experi conduct two machin ksr hierarchicalringbas cach coher sharedmemori system convex examplar crossbar ringbas cach coher sharedmemori system here address method select applic kernel evalu algorithm principl select applic kernel consid effect program featur schedul algorithm character parallel loop three factor affin loop iter processor distribut loop execut time granular loop iter iter parallel loop may exhibit affin processor loop nest sequenti loop execut repeatedli one fact parallel process domin overhead sourc mani applic commun synchron henc first classifi parallel loop two class potenti affin parallel loop nest sequenti loop nonaffin parallel loop execut onc strong iter potenti affin parallel loop exhibit affin processor significantli affect size data set access iter data local iter better data local iter mean data set access iter chang less significantli differ execut iter data local determin affin iter processor hand size data set access iter determin benefit exploit processor affin parallel loop better data local iter small data set eg one integ exploit processor affin improv execut time parallel loop balanc load reduc synchron overhead let di data set iter ith execut parallel loop let di size byte data set di then n fi averag size data set iter n execut parallel loop n f f averag size differ two data set two consecut loop execut iter indic approxim much data reload execut iter parallel loop so data local iter quantit evalu follow defin local rate local rate valu local rate one mean iter alway access set data larger local rate repres better data local then strong iter affin processor quantit evalu locality_r averag number data set access repeatedli these data set may alway store local cach select potenti affin parallel loop use data local data size differenti affin iter processor unpredict varianc execut time parallel loop major obstacl loop schedul algorithm work effici order show much parallel loop schedul algorithm toler differ distribut workload among iter select parallel loop load distribut cover three distinguish type loop balanc loop iter amount comput time predict imbalanc loop comput time iter parallel loop vari predict function loop control variabl load distribut parallel loop fix execut repeatedli unpredict imbalanc loop comput time iter chang randomli depend initi input runtim variabl eg execut time branch statement depend actual execut path ml algorithm handl load imbal remot schedul se algorithm improv ml algorithm perform predict imbalanc parallel loop load distribut parallel loop chang multipl execut parallel loop execut time iter loop increas decreas monoton loop control variabl adapt algorithm variat dynam adjust loop schedul granular speed load balanc procedur base execut histori processor follow experi show adapt algorithm handl load imbal effici wider rang ml se algorithm besid affin load distribut iter granular loop anoth import factor affect perform loop schedul algorithm parallel loop coars granular execut time loop iter significantli larger overhead remot access delay balanc workload crucial reduc synchron loop alloc over head parallel loop fine granular execut time loop iter much smaller overhead remot access delay import minim schedul overhead determin iter granular parallel loop depend interact parallel loop underli system difficult tell whether parallel loop coars grain fine grain execut instead classifi parallel loop granular consid effect iter granular experi base analys classifi parallel loop six type affin load distribut i loop potenti affin balanc workload ii loop potenti affin predict workload iii loop potenti affin unpredict workload iv loop nonaffin balanc workload v loop nonaffin predict workload vi loop nonaffin unpredict workload order complet understand well schedul algorithm work area realworld applic select one applic type loop nonaffin unpredict workload rare case practic therefor evalu schedul algorithm applic first five type loop applic select applic kernel includ potenti affin loop success overrelax sor type i jacobi iter ji type ii transit closur tc type iii matrix multipl mm type iv adjoint convolut type v applic kernel includ non affin loop type i balanc affin loop sor ieee transact parallel distribut system vol no januari iter sor parallel loop take time execut iter alway access set data exploit processor affin may improv perform better balanc workload applic parallel iter local rate one data set n array element comput granular parallel iter on type ii predict affin loop jacobi iter ji iter precis ajk ne andj ne ji program top row element nonsingular matrix nonzero element gener random number gener iter parallel loop differ workload determin distribut nonzero element a exploit load imbal would improv perform howev workload parallel iter chang execut repeatedli jth iter parallel loop alway access jth row matric a bj xj jth iter fix execut repeatedli processor need reload xj cach xj updat execut parallel loop henc applic kernel exhibit good processor affin iter data set size n data local close one averag comput granular iter smaller sor kernel type iii unpredict imbalanc affin loop transit closur tc kernel aji eq true aik eq true may exhibit seriou load imbal ji iter parallel loop execut parallel iter may comput granular o on depend input matrix a iter exhibit weaker affin processor sor ji due random comput fea ture difficult quantifi data local affin parallel iter type iv balanc nonaffin loop matrix multipl mm cijcijaik mm program affin exploit parallel iter comput granular on so reduc synchron loop alloc overhead way improv perform applic use investig whether adapt algorithm lower schedul overhead ml algorithm type v predict imbalanc nonaffin loop adjoint convolut ac similar matrix multipl applic parallel loop ac kernel execut onc henc exhibit processor affin howev comput granular ith parallel iter on i chang specif function control variabl produc signific imbalanc load distribut a triangular pat tern kernel use examin effici adapt algorithm handl load imbal caus uniform partit perform metric use evalu algorithm execut time execut time measur differ schedul algorithm work differ type applic given problem size comparison loop schedul algorithm first use np valu four adapt schedul variat ca la ea ga shall discuss effect valu perform later section discuss np costeffect next section fig present execut time in second sor run two eight processor ksr convex exemplar sinc sor perfectli balanc applic kernel dynam partit se algorithm improv perform ml affin algorithm hand introduc overhead ml algorithm result ml se perform worst among all due overhead caus loop alloc synchron step adapt increas chunk size yan et al adapt schedul parallel loop sharedmemori system time processor access local work queue adapt algorithm reduc time processor need access local work queue therefor schedul synchron overhead reduc five adapt algorithm outperform ml se algo rithm ea ga perform best among all sinc take three step adjust chunk size finish remain iter la variat need alloc step ea ga need ha ca variat chang chunk size limit rang therefor could get best benefit reduc synchron loop alloc overhead perfectli balanc applic fig plot execut time jacobi iter ji differ schedul algorithm ksr convex exemplar ji applic fit se algorithm best sinc workload distribut illustr rectangular shapeth leftmost heavi load remain almost zero workload se algorithm readjust initi partit balanc workload processor improv execut time lower execut time curv se algorithm confirm thi instead readjust initi partit adapt algorithm reduc execut time adjust chunk size processor lightli load processor took larger number iter execut turn help heavili load processor heavili load processor took small number iter execut might leav iter processor finish solv linear system size ji kernel la ga ea ha variat perform well se ca variat perform slightli wors adapt algorithm becaus use ca variat processor zero workload still cannot take p iter execut therefor need time finish lightli load job turn help heavili load processor meantim heavili load processor may alreadi taken larg number job execut leav enough job idl processor a b fig perform sor ksr a exemplar b a b fig perform ji ksr a exemplar b ieee transact parallel distribut system vol no januari fig present execut time transit closur kernel random input graph node edg uniformli present execut parallel loop workload uniformli distribut among iter howev total workload increas next execut parallel loop fig fig b show compar perform seven test algorithm respect ksr machin exemplar se algorithm ml algorithm perform similarli becaus case se algorithm littl chanc improv ml algorithm readjust load distribut algorithm la ea ga perform best among adjust schedul granular aggress combin result experiment result sor conclud load balanc applic aggress adjust schedul granular effici method reduc schedul synchron over head thu improv perform well result also show overhead collect state inform signific compar benefit gain adapt adjust schedul granular again test schedul algorithm variat transit closur kernel skew input graph node contain cliqu node edg case load imbal signific comput across iter total load parallel loop increas one execut next execut time schedul algorithm present fig fig b although author claim se algorithm assum execut time particular iter vari wide one execut loop anoth result show se algorithm still improv ml algorithm case studi adapt algorithm captur varianc load precis se algorithm la ea ga ha perform better se algorithm variat perform similarli se algorithm a b fig perform tc skew input ksr a exemplar b a b fig perform tc random input ksr a yan et al adapt schedul parallel loop sharedmemori system experiment result show adapt adjust schedul granular effici way handl load imbal unpredict loop applic parallel loop embed sequenti loop we call nonaffin loop se algorithm heurist variat ha chanc improv ml affin algorithm adjust initi partit adjust chunk size near end one execut parallel loop hope new partit new chunk size play role next execut parallel loop want see adapt variat perform better ml algorithm nonaffin loop fig fig b present perform schedul algorithm matrix multipl mm algorithm ml se ha perform similarli algorithm ea la ga dynam detect workload distribut condit rapidli increas chunk size processor take remain iter execut access local work queue variat also increas chunk size limit p remain iter therefor involv less synchron loop alloc overhead ml present overhead ga la ea compar experiment result kernel sor adapt variat improv ml algorithm mm significantli parallel loop execut one time fig fig b present perform schedul algorithm kernel adjoint convolut se ha could improv ml algorithm sinc parallel loop embed within sequenti loop load imbal across iter signific sinc first iter took time proport on last iter took time proport o expect ml se ha perform similarli ea la ga perform best among all ca variat perform between determin costeffici valu previou section use np valu adapt schedul algorithm variat a b fig perform ac ksr a exemplar b a b fig perform mm ksr a exemplar b n number iter parallel loop p number processor use execut parallel loop here test sever valu tri give optim valu evalu adapt schedul algorithm variat differ valu five benchmark applic ksr exemplar valu select evalu np np respect due space limit present part result two adapt schedul variat ea ca respect one kernel applica tion remain result specifi follow also support conclus go present fig present perform sor kernel ksr use ea adapt variat differ valu also present perform ml algorithm run sor kernel comparison ea show best perform ea present worst perform sinc sor wellbalanc applic processor normal workload larg valu like np guarante workload state processor alway normal processor increas chunk size reduc execut time although sor wellbalanc sometim event cach miss page fault interprocessor commun delay bring execut time varianc among iter use small valu a presenc interfer kind event processor take workload state heavi and therefor decreas chunk size factor two sinc give limit chunk size ea variat decreas chunk size exponenti rate may caus processor take small chunk processor may take one iter access local work queue similar selfschedul ea with spent much time ml number processor two four number processor increas six eight becom close np reason hold processor cannot determin workload state correctli due system interfer small valu a number processor increas get close valu np therefor good perform algorithm number processor four six eight fig b present perform sor applic ksr use ca adapt variat differ valu also show curv ml algorithm curv ea variat order compar them fig b show ca np perform best among all ca show small valu in comparison valu np may caus neg effect perform adapt algorithm due system interf enc ca perform worst among curv also notic curv much lower ea reason limit rang chunk size ca variat within p p guarante processor take least remain iter execut access local work queue conclus adapt adjust loop alloc granular accord workload execut speed proc essor loop schedul algorithm demonstr better perform affin schedul algorithm propos markato leblanc dynam partit affin schedul algorithm propos subramaniam eager author shown two algorithm present best perform among loop schedul algorithm adapt schedul algorithm suitabl wider rang applic program reduc execut time well loadbalanc parallel loop also load unbalanc parallel loop experi show overhead caus collect state inform sig a b fig perform sor ksr use ea differ valu a use ca differ valu b yan et al adapt schedul parallel loop sharedmemori system nific compar benefit gain one import conclus research effici use runtim inform significantli improv effici loop schedul algorithm among variat adapt schedul algo rithm ea la ga variat alway demonstr better perform ca ha variat although ea la ga higher risk ca term caus loadimbal term much sensit system interfer observ worst perform phenomena case studi ping pong effect state processor often switch lightli load heavili load caus overwhelm schedul over head addit neg effect ea la ga variat significantli reduc select appropri workload control constant np current develop analyt model determin optim valu a machin architectur may anoth import factor affect perform loop schedul algorithm far abl test adapt algorithm variat ksr exemplar experiment result indic algorithm perform quit independ sharedmemori architectur how ever effect adapt algorithm significantli affect system size system size scale larg cost collect runtim inform increas advantag adapt algorithm nullifi increas overhead so adapt algorithm suitabl schedul parallel loop small number processor acknowledg appreci neal wagner samir da care read manuscript construct comment wish thank anonym refere help comment suggest work support part us nation scienc foundat grant ccr ccr us air forc research agreement fd air forc offic scientif research grant afosr r convex comput corp factor practic robust method schedul parallel loop a dynam schedul method irregular parallel program safe selfschedul parallel loop schedul scheme sharedmemori multiproc sor use processor affin loop schedul sharedmemori multiprocessor design tradeoff process schedul share memori multiprocessor system guid selfschedul practic selfschedul scheme parallel supercomput affin schedul unbalanc workload processor selfschedul multipl nest parallel loop trapezoid selfschedul practic schedul scheme parallel compil tr ctr tatiana tabirca len freeman sabin tabirca laurenc tianruo yang feedback guid dynam loop schedul converg continu case journal supercomput v n p novemb jose l aguilar ernst l leiss data depend loop schedul base genet algorithm distribut share memori system journal parallel distribut comput v n p may clemen grelck svenbodo scholz sac offtheshelf support dataparallel multicor proceed workshop declar aspect multicor program p januari nice franc yong yan xiaodong zhang zhao zhang cachemin runtim approach exploit cach local smp ieee transact parallel distribut system v n p april sotiri ioannidi umit rencuzogullari robert stet sandhya dwarkada craulcolon compil runtim integr adapt loadthi work support part nsf grant cda ccr ccrsemi extern research grant compaq scientif program v n p august clemen grelck share memori multiprocessor support function array process sac journal function program v n p may