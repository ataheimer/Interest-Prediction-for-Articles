t parallel formul decisiontre classif algorithm a classif decis tree algorithm use extens data mine mani domain retail target market fraud detect etc highli parallel algorithm construct classif decis tree desir deal larg data set reason amount time algorithm build classif decis tree natur concurr difficult parallel due inher dynam natur comput paper present parallel formul classif decis tree learn algorithm base induct describ two basic parallel formul one base synchron tree construct approach base partit tree construct approach discuss advantag disadvantag use method propos hybrid method employ good featur method also provid analysi cost comput commun propos hybrid method moreov experiment result ibm sp demonstr excel speedup scalabl b introduct classif import data mine problem classif problem input dataset call train set consist number exampl number attribut attribut either continu attribut valu order categor attribut valu un order one categor attribut call class label classifi attribut object use train dataset build model class label base attribut model use classifi new data train dataset applic domain includ retail target market fraud detect design telecommun servic plan sever classif model like neural network genet algorithm decis tree propos decis tree probabl popular sinc obtain reason accuraci rel inexpens comput current classif algorithm c sliq base id classif decis tree algorithm data mine domain data process tend larg henc highli desir design comput effici well scalabl algorithm one way reduc comput complex build decis tree classifi use larg train dataset use small sampl train data method yield classif accuraci decis tree classifi use entir data set order get reason accuraci reason amount time parallel algorithm may requir classif decis tree construct algorithm natur concurr node gener children classif tree gener concurr furthermor comput gener successor classif tree node also decompos perform data decomposit train data nevertheless parallel algorithm construct classif tree challeng follow reason first shape tree highli irregular determin runtim furthermor amount work associ node also vari data depend henc static alloc scheme like suffer major load imbal second even though successor node process concurr use train data associ parent node data dynam partit alloc differ processor perform comput differ node high cost data movement data partit appropri perform bad due loss local paper present parallel formul classif decis tree learn algorithm base induct describ two basic parallel formul one base synchron tree construct approach base partit tree construct approach discuss advantag disadvantag use method propos hybrid method employ good featur method also provid analysi cost comput commun propos hybrid method moreov experiment result ibm sp demonstr excel speedup scalabl relat work sequenti decisiontre classif algorithm exist inductionbas algorithm like c cdp sliq sprint use hunt method basic algorithm recurs descript hunt method construct decis tree set train case class denot fc g case contain case belong singl class c j decis tree leaf identifi class c j case contain case belong mixtur class test chosen base singl attribut one mutual exclus outcom g note mani implement n chosen lead binari decis tree partit subset contain case outcom chosen test decis tree consist decis node identifi test one outlook tempf humid windi class sunni sunni sunni fals play sunni fals play sunni fals play overcast true play overcast fals play overcast overcast fals play rain true play rain rain rain fals play rain fals play tabl small train data set qui play dont play play play play dont play dont play play sunni overcast rain outlook sunni overcast rain play outlook humid nonleaf node expand leaf node nonexpand leaf node a initi classif tree b intermedi classif tree c final classif tree figur demonstr hunt method branch possibl outcom tree build machineri appli recurs subset train case case contain case decis tree leaf class associ leaf must determin inform exampl c choos frequent class parent node attribut valu class play play overcast tabl class distribut inform attribut outlook attribut valu binari test class play play tabl class distribut inform attribut humid tabl show train data set four data attribut two class figur show hunt method work train data set case hunt method test base singl attribut chosen expand current node choic attribut normal base entropi gain attribut entropi attribut calcul class distribut inform discret attribut class distribut inform valu attribut requir tabl show class distribut inform data attribut outlook root decis tree shown figur continu attribut binari test involv distinct valu attribut consid tabl show class distribut inform data attribut humid class distribut inform attribut gath ere attribut evalu term either entropi gini index best attribut select test node expans c algorithm gener classificationdecis tree given train data set recurs partit data decis tree grown use depthfirst strategi algorithm consid possibl test split data set select test give best inform gain discret attribut one test outcom mani number distinct valu attribut consid continu attribut binari test involv everi distinct valu attribut consid order gather entropi gain binari test effici train data set belong node consider sort valu continu attribut entropi gain binari cut base distinct valu calcul one scan sort data process repeat continu attribut recent propos classif algorithm sliq sprint avoid costli sort node presort continu attribut begin ning sprint continu attribut maintain sort attribut list list entri contain valu attribut correspond record id best attribut split node classif tree determin attribut list split accord split decis hash tabl order number train case map record id record belong accord split decis entri attribut list move classif tree node accord inform retriev probe hash tabl sort order maintain entri move presort order decis tree usual built two step first initi tree built till leaf node belong singl class onli second prune done remov overfit train data typic time spent prune larg dataset small fraction less initi tree gener therefor paper focu initi tree gener prune part comput parallel decisiontre classif algorithm sever parallel formul classif rule learn propos re centli pearson present approach combin nodebas decomposit attributebas decomposit shown nodebas decomposit task parallel alon sever probelm one problem processor util begin due small number expand tree node anoth problem mani processor becom idl later stage due load imbal attributebas decomposit use remedi first problem number expand node smaller avail number processor multipl processor assign node attribut distribut among processor approach relat natur partit tree construct approach discuss paper partit tree construct approach actual data sampl partit horizont parti tion wherea approach attribut partit vertic partit gener approach parallel c discuss dynam task distribut dtd scheme master processor alloc subtre decis tree idl slave processor scheme requir commun among processor suffer load imbal dtd becom similar partit tree construct approach discuss paper number avail node decis tree exce number processor dprec scheme distribut data set evenli build decis tree one node time scheme ident synchron tree construct approach discuss paper suffer high commun overhead dpatt scheme distribut attribut scheme advantag loadbalanc requir minim commun howev scheme scale well increas number processor result show effect differ parallel scheme vari significantli data set use kufrin propos approach call parallel decis tree pdt approach similar dprec scheme synchron tree construct approach discuss paper data set partit among proce sor pdt approach design one processor host processor remain processor worker processor host processor data set receiv frequenc statist gain calcul worker processor host processor determin split base collect statist notifi split decis worker processor worker processor collect statist local data follow instruct host processor pdt approach suffer high commun overhead like dprec scheme synchron tree construct approach pdt approach addit commun bottleneck everi worker processor send collect statist host processor roughli time host processor send split decis work processor time parallel implement sprint scalparc use method partit work ident one use synchron tree construct approach discuss paper serial sprint sort continu attribut begin keep separ attribut list record identifi split phase decis tree node maintain sort order without requir sort record again order split attribut list accord split decis sprint creat hash tabl record map record identifi node goe base split decis parallel implement sprint attribut list split evenli among processor split point node decis tree found parallel howev order split attribut list full size hash tabl requir processor order construct hash tabl alltoal broadcast perform make algorithm unscal respect runtim memori requir reason processor requir on memori store hash tabl on commun overhead alltoal broadcast n number record data set recent propos scalparc improv upon sprint employ distribut hash tabl effici implement split phase sprint scalparc hash tabl split among processor effici person commun use updat hash tabl make scalabl respect memori runtim requir goil aluru ranka propos concaten parallel strategi effici parallel solut divid conquer problem strategi mix data parallel task parallel use solut parallel divid conquer algorithm data parallel use enough subtask geneart task parallel use ie processor work independ subtask strategi similar principl partit tree construct approach discuss paper concaten parallel strategi use problem workload determin base size subtask task parallel employ howev problem classificatoin decis tree workload cannot determin base size data particular node tree henc one time load balanc use strategi well suit particular divid conquer problem parallel formul section give two basic parallel formul classif decis tree construct hybrid scheme combin good featur approach focu present discret attribut onli handl continu attribut discuss section parallel formul assum n train case randomli distribut p processor initi processor np case synchron tree construct approach approach processor construct decis tree synchron send receiv class distribut inform local data major step approach shown below select node expand accord decis tree expans strategi eg depthfirst breadthfirst call node current node begin root node select current node data attribut collect class distribut inform local data current node exchang local class distribut inform use global reduct among processor simultan comput entropi gain attribut processor select best attribut child node expans depend branch factor tree desir creat child node number partit attribut valu split train case accordingli class distribut inform class distribut inform figur synchron tree construct approach depthfirst expans strategi repeat step node avail expans figur show overal pictur root node alreadi expand current node leftmost child root as shown top part figur four processor cooper expand node two child node next leftmost node child node select current node in bottom figur four processor cooper expand node advantag approach requir movement train data item howev algorithm suffer high commun cost load imbal node decis tree collect class distribut inform processor need synchron exchang distribut inform node shallow depth commun overhead rel small number train data item process rel larg decis tree grow deepen number train set item node decreas consequ comput class distribut inform node decreas averag branch factor decis tree k number data item child node averag th number data item parent howev size commun decreas much number attribut consid goe one henc tree deepen commun overhead domin overal process time problem due load imbal even though processor start number train data item number item belong node decis tree vari substanti among processor exampl processor might data item leaf node none leaf node b processor might data item node b none node a node select current node processor work similarli node b select current node processor work do load imbal reduc node frontier expand simultan ie one pass data processor use comput class distribut inform node frontier note improv also reduc number time commun done reduc messag startup overhead reduc overal volum commun rest paper assum synchron tree construct algorithm classif tree expand breadthfirst manner node level process time partit tree construct approach approach whenev feasibl differ processor work differ part classif tree particular one processor cooper expand node processor partit expand successor node consid case group processor pn cooper expand node n algorithm consist follow step processor pn cooper expand node n use method describ section node n expand successor node processor group pn also partit successor node assign processor follow case number successor node greater jp n j partit successor node jp n j group total number train case correspond node group roughli equal assign processor one node group shuffl train data processor data item belong node respons for expans subtre root node group proce complet independ processor serial algorithm case otherwis if number successor node less jp n j assign subset processor node number processor assign node proport number train case correspond node data item data item figur partit tree construct approach shuffl train case subset processor train case belong node respons for processor subset assign differ node develop subtre ind pendent processor subset contain one processor use sequenti algorithm expand part classif tree root node assign them processor subset contain one processor proceed follow step recurs begin processor work togeth expand root node classif tree end whole classif tree construct combin subtre processor figur show exampl first at top figur four processor cooper expand root node like synchron tree construct approach next in middl figur set four processor partit three part leftmost child assign processor node assign processor respect set processor proceed independ expand assign node par ticular processor processor proceed expand part tree use serial algorithm group contain processor split leftmost child node three node three new node partit two part shown bottom figur leftmost node assign processor two assign processor on processor also independ work respect subtre advantag approach processor becom sole respons node develop subtre classif tree independ without commun overhead howev number disadvantag approach first disadvantag requir data movement node expans one processor becom respons entir subtre commun cost particularli expens expans upper part classif tree note number node frontier exce number processor commun cost becom zero second disadvantag poor load balanc inher algorithm assign node processor done base number train case successor node howev number train case associ node necessarili correspond amount work need process subtre root node exampl train case associ node happen class label expans need hybrid parallel formul hybrid parallel formul element scheme synchron tree construct approach section incur high commun overhead frontier get larger partit tree construct approach section incur cost load balanc step hybrid scheme keep continu first approach long commun cost incur first formul high cost becom high processor well current frontier classif tree partit two part descript assum number processor power processor connect hypercub configur algorithm appropri modifi p power also algorithm map parallel architectur simpli embed virtual hypercub architectur precis hybrid formul work follow ffl databas train case split equal among p processor thu n total number train case processor np train case local begin processor assign one partit root node classif tree alloc partit ffl node frontier tree belong one partit process togeth use synchron tree construct approach section ffl depth tree within partit increas volum statist gather level also increas discuss section point level reach commun cost becom prohibit point processor partit divid two partit current set frontier node split alloc partit way number train case partit roughli equal load balanc done describ follow hypercub two partit natur correspond sub cube first correspond processor within two subcub exchang relev train case transfer subcub exchang processor within subcub collect train case partit number train case processor vari lambdan now load balanc step done within subcub processor equal number data item ffl now process within partit proce asynchron step repeat one partit particular subtre process repeat complet classif tree grown ffl group processor partit becom idl partit join partit work number processor done simpli give half train case locat processor donor partit processor receiv partit comput frontier depth figur comput frontier comput phase key element algorithm criterion trigger partit current set processor and correspond frontier classif tree partit done frequent hybrid scheme approxim partit tree construct approach thu incur much data movement cost partit done late suffer high cost commun statist gener node frontier like synchron tree construct approach one possibl split accumul cost commun becom equal cost move record around split phase precis split done partit partit figur binari partit tree reduc commun cost commun movingcost loadbalanc exampl hybrid algorithm figur show classif tree frontier depth far partit done processor work cooper node frontier next frontier depth partit trigger node processor partit two partit shown figur detail analysi hybrid algorithm present section handl continu attribut note handl continu attribut requir sort processor contain np train case one approach handl continu attribut perform parallel sort step attribut node decis tree construct parallel sort complet processor comput best local valu split simpl global commun among processor determin global best split valu howev step parallel sort would requir substanti data exchang among processor exchang inform similar natur exchang class distribut inform except much higher volum henc even case use use scheme similar hybrid approach discuss section effici way handl continu attribut without incur high cost repeat sort use presort techniqu use algorithm sliq sprint scalparc algorithm requir one presort step need construct hash tabl level classif tree parallel formul algorithm content hash tabl need avail global requir commun among processor definit total number train sampl total number processor number processor cooper work tree expans number categor attribut c number class averag number distinct valu discret attribut present level decis tree start time commun latenc kggk w perword transfer time commun latenc kggk tabl symbol use analysi exist parallel formul scheme perform commun similar natur synchron tree construct approach discuss section again commun formul reduc use hybrid scheme section anoth complet differ way handl continu attribut discret preprocess step case parallel formul present previou subsect directli applic without modif anoth approach toward discret discret everi node tree two exampl approach first exampl found quantil use discret continu attribut second exampl approach discret node spec cluster techniqu use spec shown effici term runtim also shown perform essenti ident sever wide use tree classifi term classif accuraci parallel discret everi node tree similar natur parallel comput entropi gain discret attribut method discret requir global commun among processor respons node particular parallel formul cluster step spec essenti ident parallel formul discret case discuss previou subsect analysi hybrid algorithm section provid analysi hybrid algorithm propos section give detail analysi case discret attribut present analysi case continu attribut found detail studi commun pattern use analysi found tabl describ symbol use section assumpt ffl processor connect hypercub topolog complex measur topolog easili deriv use commun complex express topolog given ffl express commun comput written full binari tree l leav depth l express suitabl modifi tree full binari tree without affect scalabl algorithm ffl size classif tree asymptot independ n particular data set assum tree repres knowledg extract particular train data set increas train set size beyond point lead larger decis tree comput commun cost leaf level class histogram tabl need com munic size tabl product number class mean number attribut valu thu size class histogram tabl processor leaf is class histogram size number leav level l l thu total size tabl is combin class histogram tabl processor c l level l local comput cost involv io scan train set initi updat class histogram tabl attribut local comput cost n c unit comput cost end local comput processor synchron involv global reduct class histogram valu commun cost per level commun cost processor partit split two leaf assign one partit way number train data item two partit approxim same order two partit work independ other train set move around train case leaf assign processor partit load balanc system processor partit must n train data item movement done two step first processor first partit send relev train data item correspond processor second partit refer move phase processor send receiv maximum n data correspond processor partit cost move phase thi intern load balanc phase insid partit take place everi processor equal number train data item move phase load balanc phase start processor train data item count vari lambdan processor send receiv maximum n train data item assum congest interconnect network cost load balanc is cost load balanc phase detail deriv equat given also cost load balanc assum network congest reason assumpt network bandwidthrich case commerci system without assum anyth network congest load balanc phase done use transport primit time n split done accumul cost commun becom equal cost move record around split phase split done commun cost move cost balanc criterion split ensur commun cost scheme within twice commun cost optim scheme split recurs appli mani time requir split done comput appli partit partit processor start idl send request busi partit idl state request sent partit processor roughli size idl partit next round split idl partit includ part busi partit comput proce describ abov scalabl analysi isoeffici metric found use metric scalabl larg number problem larg class commerci parallel comput defin follow let p number processor w problem size in total time taken best sequenti algorithm w need grow maintain effici e fe p defin isoeffici function effici e plot fe p respect p defin isoeffici curv effici e assum data classifi tree depth l depth remain constant irrespect size data sinc data fit particular classif tree total cost creat new processor subpartit product total number partit split cost partit split n use equat number partit split processor particip less equal l depth tree cost creat new processor partit l commun cost level given equat log p combin commun cost product number level commun cost level combin commun cost process attribut l log p total commun cost sum cost creat new processor partit commun cost process class histogram tabl sum equat total commun cost comput cost given equat is total comput total parallel run time sum equat commun time comput time parallel run serial case whole dataset scan level serial time get isoeffici function equat p time total parallel run time use equat serial comput time therefor isoeffici function isoeffici p log p assum network congest load balanc phase transport primit use load balanc isoeffici op experiment result implement three parallel formul use mpi program librari use binari split decis tree node grow tree breadth first manner gener larg dataset use wide use synthet dataset propos sliq paper experi ten classif function also propos dataset use function dataset algorithm dataset two class label record consist attribut categor continu attribut dataset also use sprint algorithm evalu perform experi done ibm sp result compar speedup three parallel formul report parallel run processor experi hybrid approach report processor processor clock speed mhz mb real memori oper system aix version processor commun high perform switch hp implement keep attribut list disk use memori store program specif data structur class histogram cluster structur first present result scheme context discret attribut onli compar perform three parallel formul processor ibm sp result discret continu attribut uniformli specif discret continu attribut salari commiss age hvalu hyear loan equal interv measur speedup work differ size dataset million train case million train case increas processor result figur show speedup comparison three parallel algorithm propos paper graph left show speedup million exampl train set graph show speedup million exampl result show synchron tree construct approach good speedup processor poor speedup processor two reason thi first synchron tree construct approach incur high commun cost process lower level tree second synchron done among differ processor soon commun buffer fill up commun buffer histogram discret variabl node thu contribut node independ tupl count tupl count node proport comput process node process lower level tree synchron done mani time level after everi node experi distribut tupl decis tree node becom quit differ lower tree therefor processor wait synchron thu contribut poor speedup partit tree construct approach better speedup synchron tree construct approach howev effici decreas number processor increas partit tree construct approach processor speedup million exampl partit hybrid o synchron x processor speedup million exampl partit hybrid o synchron x figur speedup comparison three parallel algorithm suffer load imbal even though node partit processor get equal number tupl simpl way predict size subtre particular node load imbal lead runtim determin heavili load processor partit tree construct approach also suffer high data movement partit phase partit phase take place higher level tree processor involv take longer reach point processor work local data onli observ experi load imbal higher commun order major caus poor perform partit tree construct approach number processor increas hybrid approach superior speedup compar partit tree approach speedup keep increas increas number processor discuss section analyz section hybrid control commun cost data movement cost adopt advantag two basic parallel formul hybrid strategi also wait long enough split larg number decis tree node split among processor due alloc decis tree node processor random larg extent good load balanc possibl result confirm propos hybrid approach base two basic parallel formul effect also perform experi verifi split criterion hybrid algorithm correct figur show runtim hybrid algorithm differ ratio commun cost sum move cost load balanc cost ie commun cost move cost logsplit criteria ratio x ratio runtim runtim split differ valu ratio processor million exampl logsplit criteria ratio x ratio runtim runtim split differ valu ratio processor million exampl figur split criterion verif hybrid algorithm graph left show result million exampl processor graph show result million exampl processor propos split ratio would optim time result verifi hypothesi runtim lowest ratio around graph right million exampl show clearli split choic critic obtain good perform split decis made farther away optim point propos runtim increas significantli experi processor clearli demonstr hybrid approach give much better perform split criterion use hybrid approach close optim perform experi run hybrid approach number processor differ size dataset studi speedup scalabl experi use origin data set continu attribut use cluster techniqu discret continu attribut decis tree node note parallel formul give almost ident perform serial algorithm term accuraci classif tree size result figur show speedup hybrid approach result confirm hybrid approach inde effect studi scaleup behavior kept dataset size processor constant exampl increas number processor figur show runtim increas number processor curv close ideal case horizont line deviat ideal case due fact isoeffici function op log p op current experiment data consist deriv isoeffici function intend conduct addit valid experi number processor speedup curv differ size dataset million exampl million exampl million exampl million exampl million exampl million exampl figur speedup hybrid approach differ size dataset number processor total run time runtim algorithm k exampl processor figur scaleup algorithm conclud remark paper propos three parallel formul inductiveclassif learn algorithm synchron tree construct approach perform well classif tree remain skinni node level throughout tree rel larg number train case node level thu commun overhead rel small load imbal avoid process node level synchron among processor howev tree becom bushi larg number node level number train data item node decreas frequent synchron done due limit commun buffer size forc commun process fix number node node lower depth tree tupl assign them may highli variabl distribut tupl processor lead load imbal henc approach suffer high commun overhead load imbal bushi tree partit tree construct approach work better synchron tree construct approach tree bushi approach pay big commun overhead higher level tree shuffl lot train data item differ processor everi node sole assign singl processor processor construct partial classif tree independ without commun processor howev load imbal problem still present shuffl train data item sinc partit data done static hybrid approach combin good featur two approach reduc commun overhead load imbal approach use synchron tree construct approach upper part classif tree sinc node rel larg number train case associ node upper part tree commun overhead small soon accumul commun overhead greater cost partit data load balanc approach shift partit tree construct approach increment partit take place reason number node present level partit gradual perform random alloc classif tree node result better load balanc load imbal lower level tree processor group finish process assign subtre handl allow idl processor group join busi processor group size shape classif tree vari lot depend applic domain train data set classif tree might shallow other might deep classif tree could skinni other could bushi classif tree might uniform depth tree might skew one part tree hybrid approach adapt well type classif tree decis tree skinni hybrid approach stay synchron tree construct approach hand shift partit tree construct approach soon tree becom bushi tree big varianc depth hybrid approach perform dynam load balanc processor group reduc processor idl acknowledg signific part work done anurag srivastava vineet singh ibm tj watson research center work support nsf grant asc armi research offic contract dadaah cray research inc fellowship ibm partnership award content necessarili reflect polici govern offici endors infer access comput facil provid ahpcrc minnesota supercomput institut cray research inc nsf grant cda note messag size larg rout messag part commun step done constant k refer section detail r databas mine perform perspect cloud classif larg outofcor dataset megainduct machin learn larg databas experi multistrategi learn met alearn metalearn multistrategi learn parallel learn concaten parallel techniqu effici parallel divid conquer genet algorithm search use contextu inform featur rank discret new scalabl effici parallel classif algorithm mine larg dataset unstructur tree search simd parallel comput decis tree parallel processor introduct parallel comput algorithm design analysi introduct comput neural net sliq fast scalabl classifi data mine coars grain parallel induct heurist sprint scalabl parallel classifi data mine experi cost benefit window id tr ctr amir baror daniel keren assaf schuster ran wolff hierarch decis tree induct distribut genom databas ieee transact knowledg data engin v n p august robert grossman yike guo data mine task method parallel method scale data mine algorithm larg data set handbook data mine knowledg discoveri oxford univers press inc new york ny doina caragea adrian silvescu vasant g honavar analysi synthesi agent learn distribut dynam data sourc emerg neural comput architectur base neurosci toward neuroscienceinspir comput springerverlag new york inc new york ny olcay taner yldz onur dikmen parallel univari decis tree pattern recognit letter v n p may vipin kumar moham zaki high perform data mine tutori pm tutori note sixth acm sigkdd intern confer knowledg discoveri data mine p august boston massachusett unit state raymond t ng alan wagner yu yin icebergcub comput pc cluster acm sigmod record v n p june s ruggieri effici c ieee transact knowledg data engin v n p march massimo coppola marco vanneschi parallel distribut data mine parallel skeleton distribut object data mine opportun challeng idea group publish hershey pa aleksandar lazarev zoran obradov boost algorithm parallel distribut learn distribut parallel databas v n p march vipin kumar moham zaki high perform data mine tutori pm tutori note sixth acm sigkdd intern confer knowledg discoveri data mine p august boston massachusett unit state massimo coppola marco vanneschi highperform data mine skeletonbas structur parallel program parallel comput v n p may jack dongarra ian foster geoffrey fox william gropp ken kennedi linda torczon andi white refer sourcebook parallel comput morgan kaufmann publish inc san francisco ca