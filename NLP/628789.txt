t combin belief network neural network scene segment a concern problem imag segment pixel assign one predefin finit number label bayesian imag analysi requir fuse togeth local predict class label prior model label imag follow work of consid use treestructur belief network tsbn prior model paramet tsbn train use maximumlikelihood object function em algorithm result model evalu calcul effici code label imag number author use gaussian mixtur model connect label field imag data paper compar approach scaledlikelihood method local predict pixel classif neural network fuse tsbn prior result show higher perform obtain neural network evalu classif result obtain emphas maximum posteriori segment also uncertainti evidenc eg pixelwis posterior margin entropi also investig use condit maximumlikelihood train tsbn find give rise improv classif perform mltrain tsbn b introduct concern problem imag segment pixel assign one nite number class work appli imag outdoor scene class label sky road veget etc scene typic complex involv mani dierent object object highli variabl eg tree mean modelbas approach readili applic much work scene segment base approach rst segment whole imag region classifi region carri task success import classifi region use attribut also take account context region take account context handl two way either search consist interpret whole scene take account local context region nd exampl wholescen method localcontext method use major problem approach process region creation unreli lead under oversegment altern approach allow segment emerg along classic process formul bayesian framework use prior model repres knowledg like pattern label imag likelihood function describ relationship observ class label two main type prior model investig call noncaus markov random eld mrf causal mrf statist imag model literatur graphic model commun two type model known undirect direct graphic model respect earli work bayesian imag model concentr noncaus mrf see eg one disadvantag model suer high comput complex exampl problem nding maximum posteriori map interpret given imag in gener nphard altern causal mrf formul use direct graph commonli use form model treestructur belief network tsbn structur illustr figur imag model standard depend structur quadtre one attract featur tsbn model hierarch multiscal natur longrang correl readili induc contrast noncaus mrf typic at nonhierarch structur also shall see infer tsbn carri time linear number pixel use sweep tree leav root back again graphic model literatur infer procedur known pearl messagepass scheme algorithm also known upwarddownward algorithm generalis tree standard baumwelch forwardbackward algorithm hmm see eg one disadvantag tsbn random eld nonstationari exampl figur common parent fourth fth pixel left x l root node whilst third fourth pixel share parent layer abov give rise blocki segment tsbn model use number author imag analysi task bouman shapiro introduc model use discret label node imag segment task perez et al discuss map mpm maximum posterior margin infer tsbn imag process earli work direct carri feldman yakimovski task lafert et al extend model use multiscal featur pyramid imag decomposit use em algorithm paramet estim cheng bouman investig trainabl multiscal model use decis tree compactli repres condit probabl tabl cpt model tsbn model also use continuouslyvalu gaussian process one two dimens generalis kalman lter model chain tree studi number group notabl prof willski group mit develop theori deriv fast algorithm problem optic ow estim surfac reconstruct textur segment see also also crous et al use multiscal tsbn model wavelet coecient debonet viola use interest treestructur network imag synthesi use nongaussian densiti howev requir prior classlabel imag work tsbn discretevalu node german purpos mention abov exact infer procedur noncaus mrf are gener nphard howev note import recent work approxim infer procedur graph use local probabl propag scheme local scheme which guarante give correct answer graph without loop see give approxim answer gridstructur graph typic use imag analysi work messagepass scheme loopi graph includ decod errorcorrect code work criticis basi at ie nonhierarch noncaus mrf model use although possibl appli similar messag pass scheme loopi hierarch graph see section discuss work carri databas imag outdoor scene see section detail colour imag correspond label imag avail paper make number contribut investig eect adapt or train paramet tree respons data two method consid rst tree train maximis probabl label imag call maximum likelihood ml train similar work lafert et al allow nonstationari parameteris tree ect regular imag databas second method tree train maximis probabl correct label imag given raw input imag call condit maximum likelihood cml train qualiti mltrain tsbn model evalu compar well code test set label imag perform compar number code scheme includ jpegl lossless codec also provid analysi tsbn code allow us quantifi benet use higher level tree which correspond longerrang correl tsbn compris prior aspect bayesian model also requir likelihood term wherebi imag data uenc segment direct approach produc gener model probabl densiti pixel featur given imag class exampl class condit densiti model use gaussian mixtur model compar approach altern one neural network use make local predict given pixel featur predict combin prior principl manner use scale likelihood method see section detail eect combin method ml cml train tree also investig evalu perform segment algorithm use pixelwis classic rate also analysi posterior pixelwis entropi condit probabl label imag given colour imag remaind paper organis follow section describ tsbn model scaledlikelihood method detail explain infer carri out section deriv equat train tsbn use maximum likelihood ml condit maximum likelihood cml method imag code use tsbn section give detail data train variou model section result present concern imag code estim cpt section analys classic result network neural network model imag segmenta tion gener model model data illustr figur observ data assum gener underli process x x tsbn network arrang layer highest level level one node x children level lower level denot on x l level l fundament properti belief network encod condit independ layer structur mean distribut x n n l given coarser scale node depend x n inde treestructur network mean node x n depend singl node x n typic experi parent node four children give rise quadtreetyp architectur node multinomi variabl take one c class label label use segment eg road sky vehicl etc link node dene condit probabl tabl cpt parent root node uncondit prior distribut instead cpt node x l onetoon correspond observ data the observ data case featur deriv block pixel rather individu pixel raw imag model observ illustr figur observ depend correspond variabl x l note necessari hidden node cclass multinomi variabl use conveni give rise simpl initialis tsbntrain describ section figur d graphic model illustr small treestructur belief network layer x denot on x l case denot raw imag inform likelihood model describ fulli gener model dene cpt root downward sinc pixel compos number compon featur space p y densiti function one method use gaussian mixtur densiti use describ section howev databas use provid raw data label segment x l given inform natur train classier eg neural network predict x l well known neural network train variou error function includ crossentropi meansquar error approxim posterior probabl p x l fusion predict belief network x cannot achiev immedi requir p y jx l term howev use bay theorem obtain infer x data xed factor p y need consid further dene scale likelihood lx l locat obtain replac lx l principl method fusion local predict global prior model p x the notat p denot estim desir probabl method combin neural network belief network suggest for hmm smyth morgan bourlard interest connect scale likelihood mutual inform ix random variabl x ix mutual inform expect valu log scale likelihood describ abov would need train separ neural network predict p x pixel clearli undesir term comput eort amount data requir solut adopt train one neural network make posit coecient pixel part input neural network use scale likelihood requir imag turn p x depend posit pixel i know ensembl imag regular sky appear top number way approach estim p x one train network predict class label given posit pixel altern would use relationship p x approxim integr averag appropri featur vector experi see section compar spatial one deriv pixelwis margin mltrain tsbn result obtain similar potenti advantag scaledlikelihood method gener model p y jx may quit complex although predict distribut p x jy actual quit simpl mean gener approach may spend lot resourc model detail p y jx particularli relev task infer x infer given new imag wish carri infer x l given probabilist model comput posterior p x would highli expens would requir enumer possibl c k state x l two altern comput feasibl i comput posterior margin p x l give rise segment base maximum posterior margin mpm ii map interpret data x achiev pearl messag pass scheme describ scheme nonit involv one upward one downward pass tree detail given mpm comput appendix a along method scale calcul avoid ow comput margin likelihood p x l train tsbn assum paramet use dene p x known fact estim train data let denot paramet prior probabl root node cpt tree let x il denot possibl valu x let pa ik set possibl valu taken pa parent x paramet ikl denot cpt entri l simplic symbol x pa drop probabl written p x il jpa ik train prior model assum number observ imag associ label imag x lm avail index imag train set let denot paramet likelihood model p yjx discuss turn maximum likelihood train x condit maximum likelihood train x note nding congur x like equival nding congur maximis p x x maximum likelihood maximum likelihood train paramet vector estim ml see likelihood model paramet tsbn model paramet estim separ choos likelihood model paramet maximis prior model paramet maximis assum likelihood model xed obtain ml j optimis carri use em algorithm use bottomup topdown messag pass infer posterior probabl hidden node estep use expect count transit reestim cpt reestim formula deriv directli maximis baum auxiliari function q new estim paramet vector x denot hidden variabl x nx lm pattern m updat entri cpt given joint probabl obtain local use messag pass scheme see appendix detail updat give separ updat link tree given limit train data un desir set variabl share cpt denot x em paramet updat given inform avail one still carri maximum likelihood train model paramet set would adapt case known unsupervis learn describ tsbn disadvantag scaledlikelihood method cannot use unsupervis learn p y avail section iii c appear paramet reestim test imag unusu standard pattern recognit methodolog model paramet estim train data xed appli test imag follow standard methodolog condit maximum likelihood cml procedur object predict correctli label x l associ evid y paramet estim maximis probabl correct label given evid y cml analog boltzmann machin observ comput condit probabl requir comput probabl p clamp phase ie x lm xed probabl py j freerun phase with xed assum likelihood model p yjx object function view function onli carri optimis equat take logarithm dene log log p use subscript c f mean clamp free use decomposit simpli log log log then nd cml equat need maximis log p use terminolog clamp freerun follow unfortun em algorithm applic cml estim cml criterion express ration function howev maximis equat carri variou way base gradient l speech analysi method base gradient ascent use scale conjug gradient optimis algorithm use work use search method need calcul gradient l wrt let ik jx lm shown see appendix b detail ikl ikl ikl n ikl obtain propag x lm respect see equat maximis l must ensur probabl paramet remain posit properli normalis softmax function use meet constraint dene l e z ikl z ikl s new unconstrain auxiliari variabl ikl alway sum one l index construct gradient wrt z ikl express entir term ikl n ikl n n ikl z ikl ikl ikl l imag code tsbn provid gener probabilist model label imag evalu qualiti model label process evalu likelihood test set label imag model calcul log p x l label pixel imag obtain code cost bitspixel minimum attain code cost entropi in bitspixel gener process comput p intract mrf model compar tsbn result lossless jpegl codec avail httpwwwhplhpcomloco code cost tsbn model use tsbn model distribut imag margin likelihood label imag x l calcul ecient root node x tree see appendix a also consid eect truncat tree level root tree case instead one larg tree imag model consist number smaller tree and correl dierent tree ignor allow us quantifi benet use higher level tree correspond longerrang correl prior smaller tree calcul propag prior downward cpt obtain prior root likelihood imag truncat model simpli product likelihood subimag comput smaller tree experiment detail data colour imag outdoor scene sowerbi imag databas british aerospac use experi databas contain urban rural scene featur varieti everyday object road car hous lane eld variou place near bristol uk scene photograph use smallgrain mm transpar lm care control condit imag databas digitis calibr scanner gener high qualiti bit colour represent colour imag correspond label imag provid databas label imag creat overseg imag hand label region produc possibl label organis hierarch system combin label produc seven class name sky veget road mark road surfac build street furnitur mobil object instanc class street furnitur combin mani type road sign telegraph pole databas made avail research pleas contact dr andi wright dr gareth ree advanc inform process depart advanc technolog centr sowerbi bae system ltd po box filton bristol bs qw uk email garethsreesbaesystemscom detail undefin veget road mark road surfac build furnitur mobil object figur rural urban scene handlabel classic a origin imag b handlabel classic right key describ label use bound object figur show two scene test imag set databas one rural one urban figur b show handlabel classic dierent greylevel label imag correspond seven dierent possibl class origin imag divid randomli independ train test set size respect fullresolut colour imag size pixel downsampl region size pixel label reduc region chosen major vote within region tie resolv order label categori refer reduc label imag label imag origin label imag longer use featur extract import step classic featur select initi forti featur extract region among them six featur base r g b colour compon ie mean varianc overal intens region colour hue angl sine cosin rb grb as use r g b indic mean red green blue compon respect textur featur greylevel dierenc vector gldv textur featur contrast entropi local homogen angular second moment mean standard deviat cluster shade cluster promin gldv featur extract base absolut dierenc pair gray level distanc apart four angl x y locat region also includ featur space describ section featur normalis use linear transform zero mean unit varianc train set use limit number featur use increas number featur increas free paramet need optimis neural network train phase generalis linear model glm use normalis featur input softmax output use featur select input sum absolut valu weight come input train glm calcul twentyon featur sum larger uniti retain select procedur base idea import featur tend give rise larger weight cf automat relev determin idea mackay neal mlp train multilay perceptron mlp use task predict p x l explain section probabl estim mlp take input nonposit featur vector posit pixel i retain featur produc featur vector region fed mlp input node output node one hidden layer train classifi region one seven class activ function output node hidden node softmax function tanh sigmoid function respect error function use train process crossentropi multipl class see scale conjug gradient algorithm use minimis error function train perform use region extract train imag dataset valid independ valid dataset region valid dataset use order choos optim number hidden node mlp eventu best perform valid set obtain mlp node train dataset mlp train form choos randomli region class singl imag tri use equal number region class train set mlp aim rebalanc train set give net better chanc learn infrequ class see p probabl class train set mlp denot estim simpli evalu fraction train set data point class correspond probabl pixel whole train set imag denot turn order class sky veget road mark road surfac build street furnitur mobil object two set prior probabl dierent almost uniformli distribut class bias toward class two four correspond veget road surfac respect sinc train set mlp reweight class accord necessari consid eect scale likelihood fact follow p nd z input network pixel i network output class k p c k jy compens network output z normalis factor use make one henc see scale likelihood p equal unimport constant call predict p c k jy as given equat compens mlp predict segment obtain choos probabl class pixel independ call raw mlp compens mlp segment use uncompens compens predict respect gaussian mixtur model train section describ mlp train relat imag featur label altern approach build classcondit densiti estim class use along bay rule make predict follow use gaussian mixtur model gmm task specic cluster program avail httpwwwecepurdueedubouman use train set use mlp consid three dierent featur set i averag r g valu region ii featur use train mlp iii featur addit two dierent set cluster program use allow either diagon full covari matric gaussian program select number mixtur compon automat use mdl criterion recommend initialis start three time mani compon featur use gmm class combin prior probabl class the p c k s given section produc pixelwis classic overal classic accuraci full diag full diag full diag model respect test set gmm model highest pixelwis perform name full use experi see section detail number mixtur compon full model seven class respect found train gmm sometim make condent misclass caus ow problem evalu condit probabl p tsbn x l jy condit probabl ground truth label x l given imag see section reason replac likelihood term p y jx l minimum valu need avoid ow mltsbn tsbn train tsbn use basic quadtre except six children root node take account aspect ratio imag downsampl imag total pixel took pixel downsampl imag leaf node belief network built eightlevel tsbn total link node adjac level link separ cpt larg train set would need ensur cpt well determin turn impli huge comput resourc could need order nd suitabl minimum cml object function practic approach clearli impract one techniqu dimension reduct case tie cpt experi cpt level constrain equal except transit level level tabl separ exibl allow knowledg broad natur scene eg sky occur near top imag learn network inde ect learn cpt see section train mltsbn network paramet initialis number dierent way found highest margin likelihood train data obtain initi valu comput use probabl deriv downsampl version imag sparsedata problem appear initi valu cpt pair occur train data dealt problem ad small quantiti condit probabl pc k jc normalis modi probabl use case least one c plot likelihood iter number level iter databas pixel unlabel assum valu miss random treat uninstanti node easili handl belief network framework cml train initialis mltsbn solut plot condit likelihood iter number level iter cml train scale conjug gradient optimis gmm mlp predictor upward propag tree take around s downward propag around sgi r processor tree node made avail c code tsbn train infer along matlab demonstr call function httpwwwdaiedacukdaidbpeoplehomesckiwcodecbnhtml combin pixelwis predict tree gmm mlp local predictor ml cml train tsbn give rise larg number possibl combin pixelwis predictor tree one investig reason import consid cpt entri set zero em algorithm move away zero train raw gmm pixelwis predict compens gmm pixelwis predict spatiallyuniform compens compens gmm pixelwis predict use margin mltsbn gmm likelihood gmm likelihood raw mlp pixelwis predict compens mlp pixelwis predict spatiallyuniform compens compens mlp pixelwis predict use margin mltsbn tsbn method calcul scale likelihood describ section map infer use pixelwis predict entri compens use margin mltsbn note dierent compens probabl use six region imag dene six cpt root level perform method investig section result tsbn train section describ result train tsbn use ml cml train rst discuss labelimag code result use mltrain tree inspect learn cpt mltrain tsbn cmltrain tsbn imag code result section present result compar mltrain tsbn lossless jpeg code relev theori describ section detail tsbn train given section truncat level bitspixel figur bit rate bitspixel function truncat level tsbn averag bit rate tsbn model bitspixel bpp comparison purpos jpegl codec gave averag bit rate bpp also tri compress label imag use code use unix util gzip gave bpp fact similar level compress perform obtain jpegl tsbn suggest tsbn reason good model label imag use truncat tree scheme discuss section analys tsbn result further figur show bit rate in bitspixel evalu function truncat tree level time level reach correspond block size almost benet attain learn cpt cpt deriv use ml train shown figur note six separ cpt use transit root node level explain section also calcul prior margin node tree simpli take prior root node pass relev cpt path root node consider fact six cpt root level transit mean are eect six dierent prior margin level dene aspect ratio imag prior margin shown figur may easi interpret cptsmargin permut state label also achiev use pearl propag scheme outlin appendix a everi leaf node uninstanti node correspond permut incom outgo cpt would leav overal model unchang howev appear downsampl initialis mean larg problem analys figur see prior margin level ect overal statist imag sky veget road surfac class frequent occur sky class like found top half imag road surfac bottom half similar pattern detect level figur although veget label less preval upper half level train cpt level exhibit strong diagon structur impli children like inherit parent class level level cpt need read conjunct root prior distribut provid good explan level prior margin although lafert et al carri em train tsbn note estim cpt tie layerbylay basi data figur show relax constraint use cpt prior margin obtain cml train similar shown figur respect probabl due fact cml train initialis mltsbn solut gmm mlp predictor segment result perform evalu turn classic test imag often classic perform evalu pixelwis accuraci howev complex realworld classic task our tell whole stori number factor concern us notabl fact predict label pixel imag spatial coher import also note fraction pixel dierent class tremend dierent groundtruth label use assess perform percent correct downsampl process also inaccuraci handlabel process therefor dicult task assess qualiti classic deriv variou method may also depend use classic put to earli refer assess qualiti segment recent a prior root node b root node level c level level d level level level level f level level g level level level level figur estim prior root cpt ml train eightlevel belief network train train imag area black squar proport valu relev probabl a prior probabl root node b six independ cpt link root node six children rst level ch cpt link adjac level level level respect seven label ski veget road mark road surfac build street furnitur mobil object cpt entri top lefthand corner read from level l index row to level l index column level level level level level level level level key veget road mark road surfac build street furnitur mobil object veget road mark road surfac build street furnitur mobil object veget road mark road surfac build street furnitur mobil object veget road mark road surfac build street furnitur mobil object figur prior margin train ml algorithm area black squar proport valu relev probabl see text detail realis aim segment may return singl segment multipl solut probabl distribut segment p x l jy posterior distribut explor mani way describ two name i posterior margin entropi ii evalu condit probabl p jy x l ground truth imag given input data y section compar perform classic base smooth segment imag section pixelwis predict accuraci section margin entropi section condit probabl section smooth rural scene figur figur show classic use combin outlin section classic obtain singlepixel method typic lot highfrequ nois due local ambigu region ml cmltrain tree tend smooth nois similar smooth obtain use major lter one simpli choos common class within window center pixel interest howev one drawback majoritylt smooth reasonablys window tend remov ne detail road mark contrast seem tsbn method yield someth like adapt smooth depend strength local evid also note majoritylt return probabl distribut segment pixelwis classic accuraci tabl show pixelwis classic accuraci class overal accuraci ten method list section tsbn method map segment result report mpm result similar although gener wors tenth one percent notic featur perform obtain mlp method superior gmm method look result detail notic raw result gmm mlp column improv compens column resp compens method simpli give figur classic rural scene i raw gmm pixelwis predict ii raw mlp pixelwis predict iii compens gmm pixelwis predict iv compens mlp pixelwis predict v map segment segment mlp segment gmm tsbn viii map segment mlp weight frequent occur class seen compar column small dierenc spatial uniform compens column mltsbn margin compens scheme column column combin pixelwis evid mltsbn gmm mlp local model perhap surpris perform decreas compar column respect thi fair comparison method column use margin mltsbn correl structur column show perform gmm mlp local model combin tree train use cml method relev data case perform better fusion mltsbn mlp method obtain best overal perform comparison note mccauley engel compar perform bouman shapiro smap algorithm pixelwis gaussian classier remot sens task found overal classic accuraci smap higher vs reason superior perform mlp experi entir clear howev note test imag rel divers set imag although drawn distribut train imag may featur import mlp classier similar train test imag featur whose distribut model gmm vari train test set contrast evalu literatur eg use singl test imag train data drawn subset pixel case issu interimag variabl aris also note comparison gmm mlp classier carri use train set particular size composit dierent result might obtain factor vari pixelwis entropi interest understand uncertainti describ p x l jy appear comput joint entropi condit distribut intract howev posterior margin entropi readili comput posterior margin p x l tabl perform method show percentag correct class overal second column tabl give overal percentag class test imag class percentag veget road mark road surfac build street furnitur mobil object overal kji imag display posterior margin entropi shown figur pertain origin imag shown right figur expect pixelwis entropi reduc use tsbn particularli eectiv cml tree notic pixel signic posterior margin entropi good indic pixel misclassi especi true cml combin figur properti could well use inform later stage process condit probabl model develop good one p x l jy ascrib high probabl ground truth label x l dierent imag model compar term rel valu p jy particular compar tsbn imag model independ pixel model ignor spatial correl obtain pmlp mlp local predict similarli gmm local predict tsbn p x l jy calcul follow revis paper becam awar calcul posterior margin entropi propos independ perez et al determin condenc map a c d figur posterior margin entropi mlp predictor a compens pixelwis predict b mltsbn c cmltsbn greyscal black denot zero entropi white denot bit number underneath plot averag pixelwis posterior entropi d binari imag show misclassi label bright correctlyclassi label dark equat follow equat p y jx l denomin evalu method outlin appendix a complex aris calcul pixel label pmlp x jy pixel simpli ignor p tsbn x l jy unlabel pixel ignor numer denomin equat achiev set vector appropri node vector one see appendix detail figur plot log p x l jy variou model panel b show test imag posterior probabl mlpcmltsbn method larger compens mlp use independentpixel model panel a show similar comparison use gmm predictor cmltsbn method better case notic also rel scale plot especi gmm model make condent mistak pixel therebi drag averag posterior probabl logp gmm logp gmm cmltsbn logp mlp logp mlp cmltsbn a b figur comparison log p x l jyn a compens gmm vs gmm compens mlp larg number similar plot made comparison posterior probabl mltrain tsbn independ model come roughli equal number better code two model gmm mlp predictor cmltrain tsbn mlp predict better method test imag remain four mltsbn mlp win paper made number contribut use em algorithm train mltsbn observ learn paramet ect underli statist train imag qualiti probabilist model evalu code term found compar stateoftheart method truncat tree analysi show scale correl import compar perform gmm mlp pixelwis classier sizabl realworld imag segment task perform discriminativelytrain mlp found superior classcondit gmm model also shown scaledlikelihood method use fuse pixelwis mlp predict tsbn prior compar condit maximum likelihood cml train tree maximum likelihood ml train number dimens includ classic accuraci pixelwis entropi condit probabl measur p x l jy problem evalu segment old one full answer may well depend decisiontheoret analysi take account endus segment eg autom drive system howev one attract featur tsbn framework aspect posterior uncertainti comput ecient eg posterior margin entropi discuss section architectur ultim imag model know run gener give rise blocki label imag number interest research direct tri overcom problem bouman shapiro suggest make complex crosslink model problem infer becom much complex one need use junction tree algorithm see eg one interest idea suggest retain pearlstyl messag pass even though exact idea analys anoth approach infer use altern approxim scheme recognit network use helmholtz machin meaneld theori altern creat crosslink architectur retain tsbn move away rigid quadtre architectur allow treestructur adapt present imag formul bayesian fashion set prior probabl distribut treestructur initi result approach report believ gener area creat gener model imag data nding eectiv infer scheme fruit area research appendix a pearl probabl propag procedur describ pearl scheme probabl propag tree comput margin likelihood p x l j scale procedur algorithm avoid ow a pearl scheme rst consid calcul probabl distribut p xje node x tsbn given instanti node evid e consid tree fragment depict figur base figur p xje depend two distinct set evid evid subtre root x denot e x evid rest tree denot e x shall assum node nite number state c each node dierent number state add extra notat necessari applic bay rule togeth independ properti tsbn yield product rule x partit e x e dene recurs assum node x n children ik kth valu node x known messag sent node x child node x given recurs z z sx z sx z k kth state node z sx denot sibl x ie children z exclud x itself normalis factor valu x z sum fact z e sx denot evid sibl x x z known messag sent node x e e x x z figur fragment causal network show incom messag name messag shown solid arrow outgo messag messag broken arrow node x parent z propag procedur complet dene boundari condit root leav tree vector root tree equal prior probabl class leav tree vector vector one node uninstanti equal vector singl entri and entri correspond instanti state comput p xje node tree perform use upward phase messag pass downward phase messag pass nd maximum posteriori congur hidden variabl x given evid e use similar messag pass scheme describ section posterior margin requir em updat cml deriv given set node sibl node x denot messag sent node pa node y show thi partit e pa e sx rst calcul p use condit independ describ tree obtain pa ik comput divid side equat p e calcul a margin likelihood consid procedur comput p ej assum x root node have use root node e x empti a scale pearl probabl propag order understand scale requir implement messag propag consid two distinct messag pass scheme separ firstli consid denit x equat x probabl given evid x give long normalis factor appli time calcul messag case scale need x consid denit x equat x equat valu node x product messag sent children child node form weight sum valu form messag sent parent elementwis multipl messag equat weight sum calcul equat caus numer valu vector decreas exponenti distanc leav tree scale x three goal keep scale x within dynam rang comput node tree maintain local propag mechan pearl probabl propag recov true valu end comput achiev recurs formula children x equat initialis leav x valu give reason scale x use work unscal valu x comput use x x x product scale coecient subtre root x and includ x fact interest calcul p xje necessari worri unduli scale factor vector simpli rescal node requir p xje calcul scale vector vector requir p xje sum howev scale import wish calcul margin likelihood p ej refer back equat nd dx product scale factor use propag procedur sinc dx could machin dynam rang comput log p log dx appendix b calcul deriv cml optimis appendix calcul gradient wrt section suppress depend p yjx notat conveni first note p y j written sum possibl valu x tsbn use condit independ relat p xj easili decompos product transit probabl link follow idea krogh hmm deriv l f wrt ikl ikl ikl ikl scale issu discuss perez et al appear address issu scale comput posterior margin paper explicitli scale comput p ej ikl ikl ikl ikl ikl step equat equat deriv fact ikl appear product state l pa state k deriv term l c calcul similar manner except summat variabl tree taken hidden variabl x acknowledg work fund epsrc grant grl combin spatial distribut predict neural network epsrc grant grl probabilist model sequenc author grate acknowledg assist british aerospac project make sowerbi imag databas avail us also thank dr andi wright bae help discuss dr ian nabney help netlab routin neural network dr gareth ree bae discuss segment metric dr john elgi introduc us work prof kevin bowyer point work also thank three anonym refere associ editor prof charl bouman help comment advic consider improv manuscript r comput vision model estim multiresolut stochast process statist analysi dirti pirtur neural network pattern recognit multiscal random field model bayesian imag segment trainabl context model multiscal segment helmholtz machin decis theori arti revolut belief propag graph cycl stochast relax inequ ration function applic statist estim problem introduct bayesian network statist pattern recognit imag analysi multiresolut gaussmarkov random eld model textur segment hidden markov model label sequenc graphic model dynam measur comput gener imag segment remot sens imag interpret bayesian belief network tool stochast pars likelihood calcul class multiscal stochast model statist method automat interpret digit scan comparison scene segment smap neural network statist recognit continu speech bayesian learn neural network textur imag segment return multipl solut probabilist reason intellig system network plausibl infer tutori hidden markov model select applic speech recognit neural network classi hidden neural network framework hmmnn hybrid paramet estim depend tree model use em algorithm hidden markov model fault detect dynam system dynam posit tree structur imag analysi locoi lossless imag compress algorithm principl standard jpegl correct belief propag gaussian graphic model arbitrari topolog compar studi textur measur terrain classi dynam tree imag label neural network use neural network region label scene un derstand tr ctr neil d lawrenc andrew j moor hierarch gaussian process latent variabl model proceed th intern confer machin learn p june corvali oregon todorov michael c nechyba dynam tree unsupervis segment match imag region ieee transact pattern analysi machin intellig v n p novemb amo j storkey christoph k i william imag model positionencod dynam tree ieee transact pattern analysi machin intellig v n p juli sanjiv kumar martial hebert discrimin random field intern journal comput vision v n p june todorov michael c nechyba interpret complex scene use dynam treestructur bayesian network comput vision imag understand v n p april richard j howarth spatial model widearea visual surveil comput approach spatial buildingblock artifici intellig review v n p april simon marinai marco gori giovanni soda artifici neural network document analysi recognit ieee transact pattern analysi machin intellig v n p januari