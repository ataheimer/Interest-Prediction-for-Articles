t experiment comparison nearestneighbor nearesthyperrectangl algorithm a algorithm base nest gener exemplar nge theori salzberg classifi new data point comput distanc nearest gener exemplar ie either point axisparallel rectangl combin distancebas charact nearest neighbor nn classifi axisparallel rectangl represent employ mani rulelearn system implement nge compar knearest neighbor knn algorithm domain found significantli inferior knn them sever modif nge studi understand caus poor perform show perform substanti improv prevent nge creat overlap rectangl still allow complet nest rectangl perform improv modifi distanc metric allow weight featur salzberg best result obtain studi weight comput use mutual inform featur output class best version nge develop batch algorithm bnge fwmi usertun paramet bnge fwmi perform compar firstnearest neighbor algorithm also incorpor featur weight howev knearest neighbor algorithm still significantli superior bnge fwmi domain inferior conclud that even improv nge approach sensit shape decis boundari classif problem domain decis boundari axisparallel nge approach produc excel gener interpret hypothes domain test nge algorithm requir much less memori store gener exemplar requir nn algorithm b introduct salzberg describ famili learn algorithm base nest gener exemplar nge nge exemplar singl train exampl gener exemplar axisparallel hyperrectangl may cover sever train exampl hyperrectangl may overlap nest nge algorithm grow hyperrectangl increment train exampl process gener exemplar learn test exampl classifi comput euclidean distanc exampl gener exemplar exampl contain insid gener exemplar distanc d wettschereck tg dietterich gener exemplar zero class nearest gener exemplar output predict class test exampl nge approach view hybrid nearest neighbor method proposit horn claus rule like nearest neighbor method euclidean distanc appli match test exampl train exampl like horn claus rule train exampl gener axisparallel hyperrectangl salzberg report promis classif result three domain howev report below nge test addit domain give less accur predict mani domain compar knearest neighbor knn algorithm goal paper demonstr perform understand caus test algorithm modif might improv nge perform first part paper devot studi compar nge knn compar algorithm fairli necessari find optim set variou paramet option nge knn henc first describ seri experi studi perform nge and lesser extent knn determin sever key paramet option includ number start seed treatment ungener exemplar treatment nomin featur valu present result show nge under best paramet set substanti inferior knn domain test superior knn domain second part paper attempt diagnos repair caus perform deficit present sever hypothes includ a inappropri nest hyperrectangl bia b inappropri overlap hyperrectangl bia c poor perform search algorithm heurist construct hyperrectangl experi present test hypothes version nge call nong disallow overlap rectangl retain nest rectangl search procedur uniformli superior nge domain significantli better them batch algorithm obng incorpor improv search algorithm disallow nest rectangl but still permit overlap rectangl superior nge one domain and wors two experi lead us conclud major sourc problem nge creation overlap rectangl also present batch version nong call bnge effici requir user tune paramet recommend bnge employ domain batch learn appropri third part paper take issu learn featur weight weight euclidean distanc salzberg propos onlin weight adjust algorithm data present show algorithm often perform poorli errat altern featur weight algorithm base mutual inform shown work well nn nge bnge final part paper compar best version nge bnge fwmi best version knn knn cv fwmi comparison show despit improv nge still significantli inferior knn domain significantli superior domain compar singl nearest neighbor nn best version nge fare better significantli superior domain significantli inferior ideal behavior hybrid algorithm like nge domain axisparallel rectangl appropri nge take advantag find concis interpret represent learn knowledg howev domain axisparallel rectangl appropri nge behav like nearest neighbor algorithm version nge develop take advantag hyperrectangl perform poorli domain hyperrectangl inappropri research need develop ngelik algorithm robust situat axisparallel hyperrectangl inappropri algorithm experiment method nge algorithm figur summar nge algorithm follow close salzberg definit nge nge construct hyperrectangl process train exampl one time initi randomli select userdefin number seed train exampl construct trivial point hyperrectangl seed new train exampl first classifi accord exist set hyperrectangl comput distanc exampl hyperrectangl class nearest hyperrectangl train exampl coincid nearest hyperrectangl extend includ train exampl otherwis second nearest hyperrectangl tri thi call second match heurist first second nearest hyperrectangl differ class train exampl train exampl store new trivial hyperrectangl queri classifi accord class nearest hyperrectangl distanc comput follow exampl lie outsid exist hyperrectangl weight euclidean distanc comput exampl fall insid hyperrect angl distanc hyperrectangl zero exampl equidist sever hyperrectangl smallest chosen implement nge first make pass train exampl normal valu featur interv linear normal aha featur valu test set normal scale factor but note may fall outsid rang asid scale pass basic algorithm entir increment hyperrectangl h j label output class hyperrectangl repres lower left corner h j lower upper right corner h j upper distanc h j exampl e featur f f nfeatur d wettschereck tg dietterich build nge classifi input number seed initi assum train exampl given random order first train exampl e call createhyperrectangle train remain train exampl e find two h j deh j minim case tie choos two h j minim area call hyperrectangl h closest h second closest compareh closest e generalizeh closest e els compareh second closest e generalizeh second closest e els createhyperrectangle compar class hyperrectangl exampl compareh class classh return true els return fals gener hyperrectangl featur e do h lowerf replmissfeaturesh e creat hyperrectangl createhyperrectangle h lower replmissfeaturesh e replac miss featur hyperrectangl replmissfeaturesh featur e do featur e miss classif test exampl classify output classh j case tie choos h j tie minim area figur pseudocod describ construct nge classifi classif test exampl h gener denot hyperrectangl e exampl defin follow w where lowerf lowerf weight featur see section weight hyperrectangl j comput as number time compareh j call number time compareh j return true origin nge algorithm design continu featur onli discret symbol featur requir modif distanc area comput nge adopt nge polici symbol discret featur set cover featur valu store hyperrectangl analog store rang featur valu continu featur hyperrectangl cover certain featur valu valu member cover set hyperrectangl gener includ miss discret symbol featur flag set correspond featur hyperrectangl cover featur valu futur area nontrivi hyperrectangl comput follow nfeatur comput follow h f gener includ miss featur els f continu h upperf h lowerf els els f discret symbol featur number valu f cover h number possibl valu f note maximum possibl size hyperrectangl therefor fur thermor probabl line execut low sinc unlik two continu featur valu match exactli therefor deem unnecessari adjust area hyperrectangl case origin nge paper also specifi polici handl exampl contain miss featur context nearest neighbor algorithm aha section evalu three method distanc comput miss fea ture adopt ignor method one simplest method deal miss featur featur exampl miss distanc featur furthermor total distanc featur divid number known featur distinguish perfect match miss featur both distanc incorpor methodolog gener procedur nge follow whenev hyperrectangl nge extend includ exampl miss featur rang hyperrectangl extend miss featur cover entir input space featur see line figur d wettschereck tg dietterich nearest neighbor algorithm one vener algorithm machin learn nearest neighbor algorithm nn see dasarathi survey literatur entir train set store memori classifi new exampl euclidean distanc possibl weight comput exampl store train exampl new exampl assign class nearest neighbor exampl gener k nearest neighbor comput new exampl assign class frequent among k neighbor we denot knn aha describ sever spaceeffici variat nearestneighbor algorithm nge adopt aha ignor method handl train exampl miss featur reader note perform nge nn may chang substanti differ missingvalu polici use data set studi employ eleven data set three synthet remain eight drawn ucirvin repositori murphi aha aha machin learn databas synthet data set construct test sensit nge shape decis boundari number class figur task c axisparallel decis boundari task b diagon decis boundari task b class problem task c class figur artifici data set b gamma indic locat posit neg exampl c digit indic locat exampl class number exampl decis region shown lower left corner region eight irvin data set summar tabl import point note a waveform domain ident waveform domain addit irrelev featur have random valu b cleveland databas detrano et al contain miss featur c mani input featur hungarian databas detrano et al vote record databas miss experiment method measur perform nge nearest neighbor algorithm employ train settest set methodolog data set randomli partit train set contain approxim pattern test set contain remain pattern see also tabl train train set percentag correct classif test set measur procedur repeat total time reduc statist variat experi algorithm compar train and test ident data set ensur differ perform due entir algo rithm gener learn curv follow procedur except subset train set use test set along learn curv constant larger train set contain smaller one report averag percentag correct classif standard error twotail pair ttest conduct determin level signific one algorithm outperform other conclud one algorithm significantli outperform anoth algorithm pvalu obtain ttest smaller tabl domain characterist modifi aha domain train test number kind number set size set size featur class iri display hungarian vote letter recognit experi paramet sensit explor sensit nge knn userspecifi paramet nge paramet interest a number start seed b treatment ungener exemplar c order present exampl knn paramet interest number nearest neighbor k number start seed figur show perform nge task a b c sever differ number start seed perform shown rel perform simpl nearest neighbor task b number class small nge perform particularli poor small number seed d wettschereck tg dietterich contradict salzberg find page first paragraph state perform nge found sensit size seed set number seed ngegammann task c ngegammann task ngegammann task btheta perform rel nn figur perform nge rel nn nge initi vari number seed cv leaveoneout crossvalid base perform nn correct task a task b task c datapoint repres mean replic train exampl test exampl see tabl appendix detail number figur also show surprisingli nge perform better task c a decisionboundari axisparallel task b boundari diagon task b simpl nn outperform nge right end figur over label cv show perform obtain leaveoneout crossvalid weiss kulikowski employ determin optim number seed strategi work well adopt subsequ experi unless otherwis note follow number seed test leaveoneout crossvalid run crossvalid inher nonincrement cost use crossvalid destroy increment natur nge note nge given suffici larg number seed algorithm becom simpl nearestneighbor algorithm limit one seed everi data point limit reach three task howev nge need approxim task a task b task c storag requir nn store entir train set detail number provid tabl appendix treatment ungener exemplar nge hyperrectangl initi point input space therefor size gener nontrivi hyperrectangl see pseudocod figur line found led domain howev initi size hyperrectangl led signific perform improv from sigma correct sigma artifact led domain specif result fact led larg number train exampl ident featur vector belong differ class initi size hyperrectangl effect nge perform domain experi report remaind paper chose initi size hyperrectangl except led domain initi size tabl perform nge one specif trainingtest set partit number shown indic perform nge run random permut train set domain mean median min max iri sigma hungarian sigma vote sigma order present train data nge sensit order train exampl present tabl show result experi train settest set partit fix order present train set randomli vari see perform vari wide across domain seriou drawback nge algorithm unfortun difficult choos good order train set could find effect way appli crossvalid method exampl select good order result report below random order select run nge as algorithm mean run report valu k knearest neighbor algorithm wellestablish noisi domain knearest neighbor algorithm perform better simpl nearest neighbor henc chose k optim leaveoneout crossvalid perform algorithm train set tri possibl valu k thi done rel effici tie broken favor smaller valu k comparison nge knn figur compar perform knearest neighbor algorithm knn nge cv number seed chosen via leaveoneout crossvalid nge seed nge seed nge number seed increas d wettschereck tg dietterich train data nge limit rational behind nge limit amount storag requir hyperrectangl twice amount storag requir store singl data point henc number seed equal train data total space requir nge equal space requir knn assum similar method deal tie miss featur use beyond point nge data compress advantag knn vote hungarian letter iri task c task recognit perform rel figur perform ngecv nge seed nge limit rel knn shown percentag point differ ngecv knn nge seed knn nge limit knn signific differ knn differ nge version indic see tabl appendix detail number knearest neighbor outperform nge cv statist signific amount eight nonconstruct domain display figur domain nge cv achiev signific ie compress data significantli increas number seed nge limit figur possibl significantli improv perform nge cv task b led cleveland hungarian letter recognit domain howev nge limit still significantli inferior knn perform one nonconstruct domain drop perform vote domain task due fact domain leaveoneout crossvalid small number differ seed set size benefici increas size seed set howev improv perform nge limit come high cost case nge perform improv also use memori knn figur show learn curv domain gener curv shape expect induct learn algorithm perform increas number train exampl increas level nearesthyperrectangl comparison task theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta c c c c theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta c c c task c theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta c c c c iri c c c theta theta theta theta theta theta theta theta theta c c c theta theta theta theta theta theta theta theta theta theta theta c c c c c theta theta theta theta theta theta theta theta theta theta theta theta theta c c c c theta theta theta theta theta theta theta theta theta theta theta theta c c c c c theta theta theta theta theta theta theta theta theta theta theta theta hungarian c c c c c c theta theta theta theta theta theta theta theta theta theta theta theta vote c c c theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta letter recognit c c c c c c theta theta theta theta theta theta theta theta theta theta theta theta theta theta number train exampl number train exampl perform perform perform figur perform nge knn differ number train exampl data point denot mean experi note differ scale axe graph train set reach certain size waveform led letter recognit domain perform nge cv level much earlier knn furthermor graph cleveland hungarian vote domain show errat behavior nge cv hungarian vote domain nge cv d wettschereck tg dietterich reach near peak perform train exampl seen train exampl perform nge cv vari within two standard error domain cleveland domain perform nge cv peak also exampl sigma correct drop sigma inspect number size hyperrectangl construct nge cv domain abl determin caus unusu behavior number hyperrectangl store nge cv grow linearli number train exampl although desir properti machin learn algorithm may caus problem nge cv sinc exist hyperrectangl may gener extend often mean everi time hyperrectangl enlarg may actual becom less relev conclud behavior constitut seriou defici nge search gener procedur possibl explan inferior perform nge given close relationship nge knn surpris nge perform much wors knn learn algorithm two fundament sourc problem first bia algorithm may inappropri applic domain second implement bia may poor eg poor search algorithm employ salzberg never formal defin bia nge let us defin find minimum number axisparallel hyperrectangl possibl nest overlap correctli classifi train data evid bia inappropri know task nonaxisparallel decis boundari axisparallel bia inappropri see figur artificiallyconstruct domain howev aha report perform c quinlan six domain also use paper c also rectangular bia perform similar condit significantli better nge six domain aha section suggest axisparallel bia caus nge poor perform examin learn hyperrectangl sever domain suggest permit rectangl nest overlap problem common form nest larg gener hyperrectangl creat mani singlepoint rectangl nest insid except seen figur plot number hyperrectangl creat number actual gener nonpoint rectangl see overwhelm major hyperrectangl never gener singlepoint hyperrectangl virtual never use classifi new test exampl test exampl fall insid larg hyperrectangl distanc hyperrectangl zero singlepoint hyperrectangl use unless nearesthyperrectangl comparison letter recognit theta theta theta theta theta theta theta theta theta theta theta theta c c cccc c c c c c c c number train exampl number exemplar figur number exemplar store nge train seed differ size train set letter recognit task shown total number hyperrectangl store train theta number hyperrectangl gener least ffi data point denot mean experi either a test exampl exactli coincid singlepoint rectangl b singlepoint rectangl nest insid anoth rectangl nge also permit gener rectangl overlap even nest may problem well one situat overlap rectangl creat distribut exampl two class b overlap optim decis rule under uniform loss function cf duda hart place decis boundari point probabl densiti exampl class equal probabl densiti exampl class b howev nge instead arbitrarili assign exampl overlap region one classesth one smaller rectangl addit hypothes bia nge consider evid bia implement well nge increment heurist procedur sensit experi know nge sensit order train exampl present order well task c determin optim set hyperrectangl inspect respect nge find optim solut instead construct averag sigma sigma task b hand optim solut involv larg number rather small overlap rectangl one everi train exampl lie near decis boundari howev nge find solut either construct rectangl larg nest smaller one it figur display rectangl construct nge cv repres experi task a b c summari three hypothes explain nge perform poorli rel knn h nest rectangl h overlap rectangl h poor search algorithm test hypothes conduct seri experi modifi nge elimin one suspect problem measur result chang perform d wettschereck tg dietterich figur rectanglesconstructedbi ngecv task a b c one repres experi b dash solid line indic locat rectangl repres posit neg exampl c digit indic class rectangl repres trivial point rectangl display note task singl rectangl class cover entir input space first experi test h modifi nge produc rel nest rectangl still permit overlap rectangl otherwis chang search procedur second experi test h modifi nge produc overlap rectangl differ class with except rectangl entir nest insid one anoth otherwis chang search procedur third experi test h make simpl modif increment nge improv upon secondmatch heurist goal find fewer hyperrectangl final fourth experi test hypothes simultan implement entir differ search procedur complet elimin nest rectangl overlap rectangl also reduc total number rectangl construct describ experi result greedi nge avoid nest test h want construct variant nge avoid nest rectangl major caus nest rectangl second match heurist line figur nearest rectangl wrong class second nearest rectangl right class secondnearest rectangl expand cover new exampl mani case also cover nearest rectangl which could singl point thu creat nest salzberg section introduc test version nge call greedi nge second match heurist greedi version store exampl new hyperrectangl whenev closest previous store hyperrectangl differ class exampl accord salzberg second match heurist nge necessari construct nest overlap hyperrectangl true nge may still con nearesthyperrectangl comparison struct overlap nest hyperrectangl even second match heurist disabl grow hyperrectangl overlap cover anoth hyperrectangl fact greedi nge construct overlap hyperrectangl quit frequent nest hyperrectangl in case experi conduct figur show predict accuraci greedi nge significantli better nge three domain cleveland hungarian vote significantli wors other task a task c waveform waveform result task c waveform particularli poor base these much evid nest rectangl major problem nge vote letter hungarian iri task c task b task recognit greedi perform rel figur perform greedi nge nge addit match heurist fnoc first two match nearest exemplar exampl class consid nong rel nge indic perform differ nge modif statist signific p see tabl appendix detail number nge without overlap hyperrectangl nong test h want construct variant nge avoid overlap rectan gle accomplish follow let us defin p potenti new hyperrectangl construct call gener line figur rectangl p rectangl form extend either first match second match rectangl cover train exampl d wettschereck tg dietterich nooverlap nge nong construct p check whether would intersect hyperrectangl class p would intersect anoth rectangl reject p creat new singlepoint rectangl instead howev p would complet contain within anoth hyperrectangl accept p way nest rectangl permit overlap nonnest rectangl forbidden figur see nong significantli better nge domain never significantli wors nge strongli support hypothesi hthat overlap rectangl caus problem nge better merg heurist nge nge store train exampl new hyperrectangl whenev two nearest hyperrectangl differ output class exampl case howev creat unnecessari new rectangl consid figur here rectangl c away point p either rectangl rectangl b howev rectangl c class point p could extend cover point p without overlap either rectangl b extend rectangl c way avoid creat new gener exemplar point p develop modifi version nge call fnoc detect situ ation first two match to nearest secondnearest hyperrectangl fail fnoc find nearest hyperrectangl class ex ampl extend nearest hyperrectangl includ new exampl expand hyperrectangl would cover hyperrectangl class otherwis store exampl new hyperrectangl give nge anoth chanc gener gener reduc amount memori requir nge class c class class class figur exampl show rectangl c extend cover point p fnoc consid weak test hypothesi h that search algorithm nge need improv tabl indic addit match heurist inde achiev reduct storag domain henc better implement nge bia howev shown figur fnoc perform significantli better nge task c reduct storag directli relat loss predict accuraci five domain henc improv nge search algorithm explain poor perform nge rel knn nearesthyperrectangl comparison vote letter hungarian iri task c recognit perform rel figur perform obng bnge rel nge shown percentag point differ obng nge bnge nge indic perform differ nge modif statist signific p tabl appendix detail number batch nge obtain better test h construct two batch algorithm obng bnge nge bia algorithm begin train exampl memori point hyperrectangl progress merg form gener hyperrectangl step two hyperrectangl nearest one anoth merg subject one follow constraint obng merg merg would caus misclassif train exampl algorithm requir test entir train set potenti merg permit overlap nest rectangl call obng overlap batch nge bnge merg new hyperrectangl cover or overlap with hyperrectangl class algorithm requir intersect potenti merg hyperrectangl class permit overlap nest call bnge batch nge merg process algorithm repeat merg found note algorithm somewhat depend order potenti merg consid greedi merg accept soon mention condit satisfi d wettschereck tg dietterich algorithm conserv gener beyond train data origin nge algorithm sinc gener hyperrectangl part input space clearli belong certain class furthermor due fact bnge obng repeatedli pass train data may also significantli reduc number hyperrectangl remain end bnge also faster easier use nge sinc crossvalid free paramet requir obng howev feasibl larg train set number display figur tabl show bnge significantli outperform nge domain test case perform bnge better nge hand obng significantli better nge task c significantli wors nge three domain task a task b hungarian provid addit strong evid overlap rectangl inappropri bia domain h test h examin first whether bnge implement better search algo rithm task c bnge attain optim solut hyperrectangl task c furthermor bnge also use one hyperrectangl cover iri setosa class iri domain good evid qualiti bnge search procedur increment version nge similar bnge nong nge without overlap rectangl compar figur tabl a seen bnge outperform nong four domain nong outperform bnge two domain give weak evid improv search algorithm bnge respons improv perform note bnge also train increment cost store train exampl increment bnge would split rebuild hyperrectangl whenev cover new exampl differ class discuss experi see weak support h strong support h explan poor perform nge rel nearest neighbor algorithm support h version nge permit overlap rectangl perform consist better nge domain test batch algorithm bnge permit nest overlap rectangl differ class perform quit well avoid need choos number seed nge crossvalid featur weight experi conduct thu far treat featur equal import comput euclidean distanc nearest hyperrectangl and nearest neighbor howev mani domain involv noisi nearesthyperrectangl comparison tabl percentag nonse exampl cover least one hyperrectangl nge initi seed domain train test seed seed seed seed iri hungarian vote letter recognit complet random featur way improv perform nge knn introduc mechan learn featur import ignor unimport or noisi featur distanc comput salzberg section last paragraph describ method onlin learn featur weight nge assum new exampl e misclassifi exemplar h input featur f weight f w f increas multipli match h f weight w f decreas multipli global featureadjust rate usual set e classifi correctli h featur weight adjust opposit direct two problem heurist first consid task one class much frequent anoth task new exampl tend classifi correctli chanc featur weight chang exponenti featur alway match weight zero featur random receiv infinit weight salzberg person commun pseudo suggest adjust featur weight match ie nearest secondnearest hyperrectangl fail found empir polici featur weight adjust quit infrequ exampl iri task featur weight adjust train exampl waveform featur weight adjust train exampl second seriou problem use featur weight nge high percentag test case fall insid least one hyperrectangl mean distanc nearest hyperrectangl zero featur weight effect distanc calcul tabl show percentag test train case occur suggest limit perform improv obtain use featur weight nest hyperrectangl experi salzberg method comput featur weight found perform almost alway decreas see below therefor consid anoth procedur comput featur weight given promis result exemplarbas learn method bakiri d wettschereck tg dietterich determin weight mutual inform purpos featur weight mechan give low weight featur provid inform classif eg noisi irrelev featur give high weight featur provid reliabl inform henc natur quantiti consid mutual inform valu featur class exampl featur provid inform class mutual inform featur complet determin class mutual inform proport log number class let c probabl class train exampl equal c probabl valu featur j exampl fall interv ninterv joint probabl two event mutual inform featur f j classif c log discret featur ninterv equal number possibl distinct in put continu featur ninterv chosen probabl estim train data miss valu ignor mutual inform measur also known machin learn literatur inform gain use split criterion id c quinlan experi featur weight figur and tabl a show effect includ featur weight compar two differ procedur comput weight salzberg method give statist signific increas perform hungarian domain statist signific decreas task c signific effect domain mutual inform featur weight gener give slight though statist insignific improv domain without irrelev featur improv substanti domain irrelev featur give statist signific improv cleveland hungarian vote domain well task c small p decreas perform observ mutual inform featur weight letter recognit domain mutual inform featur weight similar posit effect perform simpl nearest neighbor and lesser extent knn see tabl a mutual inform weight small irrelev input domain furthermor featur weight differ substanti one random partit data set anoth contrast weight comput nearesthyperrectangl comparison recognit letter hungarian vote iri task c task perform rel figur perform nge fwmi nge fw salzberg rel nge without featur weight shown percentag point differ nge fwmi nge nge fw salzberg nge indic signific differ nge modi ficat see tabl appendix detail number salzberg method differ substanti one partit anoth vari much factor within given train settest set partit featur less equal weight experi section conclud salzberg weight procedur signific impact nge behavior domain mutual inform weight procedur perform well domain larg number irrelev featur furthermor sinc mutual inform weight procedur independ algorithm use for procedur could use effect mani induct learn algorithm filter irrelev featur comparison best variant nge knn develop sever modif nge uniformli improv perform algorithm best combin batch nge mutual inform featur weight bnge fwmi best correspond version nearest neighbor algorithm k nearest neighbor with crossvalid determin mutual inform featur weight knn fwmi section compar two algorithm determin whether modif nge make competit knn figur show result comparison main conclus draw bnge fwmi significantli inferior knn fwmi domain significantli superior two domain domain know d wettschereck tg dietterich hungarian vote letter iri task c task recognit knn fwmi perform rel fwmi figur perform nge fwmi bnge fwmi rel knn fwmi shown percentag point differ nge fwmi bnge fwmi knn fwmi differ statist signific see tabl appendix detail number axisparallel rectangl bia appropri show hyperrectangl appropri bnge fwmi abl exploit them howev domain rectangl evid appropri bnge fwmi s perform suffer knn fwmi robust situat show research still need develop nge algorithm robust situat relat work simpson simpson introduc increment algorithm extrem similar nge call fuzzi minmax neural network main differ nge fuzzi minmax classifi are a hyperrectangl fmmc bound size b fmmc alway extend nearest hyperrectangl class given exampl includ exampl long size new hyperrectangl larger userdefin valu c ffmc shrink hyperrectangl elimin overlap hyperrectangl differ class carpent et al introduc neural network architectur base fuzzi logic adapt reson theori art neural network categori box use fuzzi artmap complement code compar hyperrectan gle hyperrectangl fuzzi artmap complement code grow monoton nearesthyperrectangl comparison ical learn maximum size bound vigil paramet see carpent et al short comparison nge ffmc fuzzi artmap neither fmmc fuzzi artmap use featur weight sens discuss paper summari discuss extens studi nge algorithm conduct basic algorithm number modif evalu eleven domain nge found quit sensit number start seed order present exampl perform nge compar perform knearest neighbor algorithm found substanti wors sever domain even crossvalid appli optim number start seed nge three hypothes introduc explain differ perform a nest rectangl provid poor bia b overlap rectangl provid poor bia c increment search algorithm nge need improv experiment modif nge made order test hypothes two version nge avoid nest rectangl but permit overlap rectan gle perform substanti better nge itself howev algorithm call nong permit nest rectangl avoid overlap rectangl perform uniformli better nge eleven domain the improv statist signific domain batch algorithm bnge implement better search algorithm allow nest overlap rectangl also perform uniformli better nge perform better nong domain wors experi conclud overlap rectangl primari sourc difficulti nge bnge best variant nge studi experi report wettschereck show bnge commit error outsid hyperrectangl use knn classifi test exampl fall outsid hyperrectangl hybrid method bnge knn attain classif accuraci compar knn alon larg improv classif speed version nge effect compress data compar knn also studi whether nge algorithm could improv incorpor featur weight distanc metric comput algorithm featur weight mechan introduc salzberg shown never provid signific improv perform nge without featur weight in deed significantli wors simpl nge three domain hand featur weight mechan base comput mutual inform featur output class shown significantli better nge five domain significantli wors one mechan d wettschereck tg dietterich independ nge therefor use preprocess step induct learn algorithm conclus data present strongli support conclus nge algorithm describ salzberg modifi number way first construct overlap hyperrectangl avoid second entir train set avail store memori classifi train batch mode elimin comput expens crossvalid number initi seed third mutual inform use comput featur weight prior run nge modif nge give superior perform domain axisparallel hyperrectangl bia appropri howev domain nge perform well knn henc gener perform robust critic knn algorithm choic if hand understand memori compress import nge as modifi recommend fast easytous induct learn algorithm acknowledg thank steven salzberg provid assist implement nge thank one anonym review point heurist comput size symbol featur us also thank steven salzberg anonym review bill langford help comment earlier draft note research support part nsf grant iri nasa ame grant nag gift sun microsystem hewlettpackard r studi instancebas algorithm supervis learn task convert english text speech machin learn approach fuzzi artmap neural network architectur increment supervis learn analog multidimension map nearest neighbornn norm nn pattern classif techniqu pattern classif scene analysi simpl classif rule perform well commonli use dataset nearest hyperrectangl learn method fuzzi minmax neural network comput system learn hybrid nearestneighbor nearesthyperrectangl algorithm tr ctr j mitran s bouillant e bourennan svm approxim realtim imag segment use improv hyperrectanglesbas method realtim imag v n p june igor jurisica janic glasgow john mylopoulo increment iter retriev browsingfor effici convers cbr system appli intellig v n p mayjun i jurisica p roger j i glasgow s fortier j r luft j r wolfley m a bianca d r week g t detitta intellig decis support protein crystal growth ibm system journal v n p februari steven l salzberg compar classifi pitfal toavoid recommend approach data mine knowledg discoveri v n p j mitran j mata e bourennan m paindavoin j duboi automat hardwar implement tool discret adaboostbas decis algorithm eurasip journal appli signal process v n p januari charl x ling hangdong wang comput optim attribut weight set nearest neighboralgorithm artifici intellig review v n p feb tam horvth stefan wrobel uta bohnebeck relat instancebas learn list term machin learn v n p aprilmay niloofar arshadi igor jurisica data mine casebas reason highdimension biolog domain ieee transact knowledg data engin v n p august melodi y kiang compar assess classif method decis support system v n p juli jo ranilla oscar luac antonio bahamond heurist learn decis tree prune classif rule ai commun v n p katharina morik peter brockhausen multistrategi approach relat knowledg discoveri indatabas machin learn v n p june jo ranilla oscar luac antonio bahamond heurist learn decis tree prune classif rule ai commun v n p april jinyan li guozhu dong kotagiri ramamohanarao limsoon wong deep new instancebas lazi discoveri classif system machin learn v n p februari d randal wilson toni r martinez reduct techniqu instancebasedlearn algorithm machin learn v n p march francisco azuaj werner dubitzki norman black kenni adamson retriev strategi casebas reason categoris bibliographi knowledg engin review v n p decemb foster provost venkateswarlu kolluri data mine task method scalabl handbook data mine knowledg discoveri oxford univers press inc new york ny dietrich wettschereck david w aha takao mohri review empir evalu featur weight method aclass lazi learn algorithm artifici intellig review v n p feb vassili g kaburlaso ioanni n athanasiadi pericl a mitka fuzzi lattic reason flr classifi applic ambient ozon estim intern journal approxim reason v n p may foster provost venkateswarlu kolluri survey method scale induct algorithm data mine knowledg discoveri v n p june