t distribut represent simpl recurr network grammat structur a paper three problem connectionist account languag consid natur linguist represent complex structur relationship constitu structur repres appar openend natur languag accommod fixedresourc systemus predict task simpl recurr network srn train multiclaus sentenc contain multiplyembed rel claus princip compon analysi hidden unit activ pattern reveal network solv task develop complex distribut represent encod relev grammat relat hierarch constitu structur differ srn state represent tradit pushdown store discuss final section b introduct recent year consider progress develop connectionist model languag work demonstr abil network model account varieti phenomena phonolog eg gasser lee hare touretzki touretzki wheeler morpholog eg hare corina cottrel macwhinney et al plunkett marchman rumelhart mcclelland b ryder spoken word recognit mcclelland elman written word recognit rumelhart mcclelland seidenberg mcclelland speech product dell stemberg role assign kawamoto mcclelland miikkulainen dyer a st john mcclelland clear connectionist network mani properti make attract languag process time remain signific shortcom current work hardli surpris natur languag difficult domain pose difficult challeng paradigm challeng seen posit light test power framework also motiv develop new connectionist approach paper would like focu see three princip challeng success connectionist account languag are hat natur linguist represent ow complex structur relationship constitu ow appar openend natur languag accommod fixedresourc system interestingli problem close intertwin represent in press machin learn one approach address first two problem use localist represen tation localist network node assign discret interpret model eg kawamoto mcclelland st john mcclelland node may repres grammat role eg agent theme modifi relat eg subject daughterof may bound node repres wordtoken instanti either spatial assign kawamoto mcclelland miikkulainen dyer b concurr activ st john mcclelland variou techniqu eg smolenski press although localist approach mani attract number import drawback well first localist dictum one nodeon concept taken togeth fact network typic fix resourc seem varianc openend natur languag node prealloc defin role subject agent order process sentenc multipl subject agent as case complex sentenc must appropri number type node one know type need mani provid situat becom even troublesom one interest discours phenomena gener theori languag chomski made much unbound gener natur languag point rumelhart mcclelland a realiti languag product practic fact finit length number still even one accept practic limit noteworthi soft or contextsensit rather hard or absolut way localist approach would predictfor instanc consid difficulti understand the cat dog mous saw chase ran away compar with the planet astronom univers hire saw explod clearli semant pragmat consider facilit pars structur otherwis hard process see also labov reich dell schlesing stolz experiment demonstr point thu although one might anticip commonli occur structur relat one would like limit process soft rather hard way localist approach would be second shortcom use localist represent often underestim actual rich linguist structur even basic notion word one might assum straightforward linguist primit turn difficult defin one might thought dramat differ term count word across languag even within english morpholog syntact process yield entiti wordlik respect eg appl pie maninthestreet man season fact much linguist theori today concern natur role represent less focu natur oper thu localist approach certain posit aspect definit shortcom well provid good solut problem account openend natur languag commit discret welldefin represent may make difficult captur rich high dimension requir languag represent anoth major approach involv use distribut represent hinton hinton mcclelland rumelhart van gelder press togeth learn algorithm order infer linguist represent model use localist approach typic made priori commit linguist represent such agent patient etc network explicitli train identifi represent input activ node correspond them presuppos target represent theoret valid also beg question in real world correspond teach inform might come from altern approach task must devis abstract linguist represent play explicit role model input output target limit variabl directli observ environ naturalist approach sens model learn use surfac linguist form commun purpos rather linguist analysi whatev linguist analysi done and whatev represent develop intern network servic task valu approach need depend preexist preconcept abstract linguist represent are instead connectionist model seen mechan gain new theoret insight thu approach offer potenti satisfi answer first question natur linguist represent second advantag approach abstract represent form hidden layer also tend distribut across highdimension and continu space describ analog hidden unit activ vec tor mean larger much finergrain represent space work usual possibl localist represent space infinit practic purpos may veri larg approach may also provid better respons third question appar openend natur languag accommod fixedresourc system rosi still left second question repres complex structur relationship constitu distribut represent far complex difficult understand localist represent tendenc feel murki intract distribut entail unanalyz although fact exist variou techniqu analyz distribut represent includ cluster analysi elman hinton sejnowski rosenberg servanschreib cleereman mcclelland press direct inspec tion pollack princip compon phase state analysi elman contribut analysissang result studi limit analys demonstr distribut represent may poss intern structur encod relationship kinship hinton lexic categori structur elman relationship static thu instanc elman network train predict order word sentenc network learn repres word categor noun verb subcategor noun animateinanim humannonhuman etc represent develop network explicitli taught lexic categori sure import languag process easi think sort categor seem differ natur consid follow sentenc a boy broke window b rock broke window c window broke underlin word sentenc noun represent reflect thi nounhood categori properti belong inalien word true regardless appear as noun deriv process may result noun use verb viceversa differ level de scription underlin word also similar categoriz subject sentenc properti howev contextdepend word win dow subject sentenc c two sentenc object still anoth level descript three underlin word differ a subject also agent event b subject instrument c subject patient or theme sentenc contextdepend properti exampl simpl demonstr effect grammat structur is structur manifest level utter addit contextfre categor word inherit properti virtu linguist environ although distribut represent seem potenti abl respond first last problem pose outset clear address question h ow complex structur relationship constitu repres fodor pylyshyn phrase it need two degre freedom specifi thought intent system entertain time one paramet activ vs inact pick node express concept system mind in construct vs not determin concept system mind distribut propost entertain pp point worth remind way complex structur relationship dealt symbol system contextfre properti typic repres abstract symbol s np v etc contextsensit properti dealt variou way theori eg gener phrase structur grammar design context explicit manner socal slashcatego rie approach use addit categori label eg cognit grammar relat grammar govern bind design element subject theme argu ment trajectori path etc addit theori may make use tree bracket coin dex spatial organ tier arc circl diacrit order convey complex relationship map process implement version exist theori nearli requir work buffer stack order account appar recurs natur utter all rather formid armamentarium requir return three question pose outset although distribut represent characterist plausibl may address need represent rich flexibl may provid soft rather hard limit process must ask whether approach captur structur relationship sort requir languag question motiv work report here preliminari evid encourag regard hinton describ scheme involv reduc descript complex structur repres partwhol hierarchi pollack press develop train regimen call recurs autoassoci memori raam appear composit properti support structuresensit oper see also chalmer discuss earlier elman use simpl recurr network srn servanschreib cleereman mcclelland press provid yet anoth approach encod structur relationship distribut form work describ extend latter approach srn taught task involv stimuli underli hierarch and recurs relat ship structur abstract sens implicit stimuli goal see network could a infer abstract structur b repres composit relationship manner support structuresensit oper remaind paper organ follow first network architectur briefli introduc second stimulu set task present properti task make particularli relev question hand describ next result simul present final discuss differ similar approach tradit symbol approach languag process discuss network architectur time import element languag question repres serial order input crucial variou propos advanc for review see elman mozer approach taken involv treat network simpl dynam system previou state made avail addit input jordan jordan work network state anyh point time function input current time step plu state output unit previou time step work here network state depend current input plu intern state repres hidden unit previou cycl hidden unit taught assum specif valu mean develop represen tation cours learn task encod tempor structur task word hidden unit learn becom kind memori taskspecif insert figur type network use current work shown figur network typic connect input unit hidden unit hidden unit output unit addit hidden layer input main hidden main hidden output may use serv transduc compress input output vector addit set unit call context unit provid limit recurr and may call simpl recurr network context unit activ oneforon basi hidden unit fix weight linear activ function result time cycl hidden unit activ copi context unit next time cycl context combin new input activ hidden unit hidden unit therefor take job map new input prior state output constitut prior state must develop represent facilit inputoutput map simpl recurr network studi number task elman gasser hare press task stimuli predict task elman network similar figur train predict order word simpl word sentenc point time word present network network target output simpli next word sequenc lexic item input output repres localist form use basi vector ie word randomli assign vector singl bit turn on lexic item thu orthogon one anoth form item encod inform item categori membership predict made basi current input word togeth prior hidden unit state save context unit task chosen sever reason first task meet desideratum input target output limit observ environ net work input output immedi avail requir minim priori theoret analysi lexic item orthogon arbitrarili assign role extern teacher minim sinc target output suppli environ next moment time task involv might call selfsupervis learn ing second although languag process obvious involv great deal predict predict seem play role process listen inde predict grosjean sequenc word violat expectationsi un predictableresult distinct electr activ brain kuta kuta hill yard tanenhau et al press third accept predict anticip play role languag learn provid partial solut call baker paradox baker pinker paradox children appar receiv or ignor do neg evid process languag learn given frequent tendenc initi overgener posit data clear children abl retract faulti overgener gold howev suppos children make covert predict speech hear other fail predict constitut indirect sourc neg evid could use refin retract scope gener fourth task requir network discov regular underli tempor order word sentenc simul report elman regular result network construct intern represent input mark word form class nounverb well lexicosemant characterist animateinanim humananim largesmal etc result simul howev bore represent lexic categori structur relev grammat structur unclear mono clausal sentenc use share basic structur thu question remain open whether intern represent learn architectur abl encod hierarch relationship necessari mark constitu structur stimuli stimuli simul sequenc word form sentenc addit monoclaus sentenc larg number complex multiclaus sentenc sentenc form lexicon item includ noun verb rel pronoun who endofsent indic a period item repres randomli assign bit vector singl bit set bit reserv anoth purpos phrase structur grammar shown tabl use gener sentenc result sentenc possess certain import properti includ follow insert tabl a agreement subject noun agre verb thu exampl a grammat b the train corpu consist posit exampl onli star exampl actual occur a john feed dog b boy see mari word mark number singularplur form class verbnoun etc grammat role subjectobject etc network must learn first item function would call noun verb etc must learn item exampl singular plural must learn noun subject object sinc agreement hold subject noun verb b verb argument structur verb fall three class requir direct object permit option direct object preclud direct object result sentenc ad grammat wherea sentenc e f ungrammat a girl feed dog do requir b girl see boy do option c girl see do option d girl live do preclud e girl feed f girl live dog word repres orthogon vector type verb overtli mark input class membership need infer time cooccurr fact learn c interact rel claus agreement verb argument fact becom complic rel claus although direct object normal follow verb simpl sentenc rel claus subordin claus direct object head claus case network must recogn gap follow subordin claus verb becaus direct object role alreadi fill thu normal pattern simpl sentenc ad appear also a contrast b a dog chase cat see girl b dog cat chase see girl hand sentenc c seem conform pattern establish a ungrammat c dog cat chase dog see girl similar complic aris agreement fact simpl declar sentenc agreement involv n v complex sentenc a regular vio late straightforward attempt gener sentenc multipl claus would lead ungrammat b a dog boy feed see girl b dog boy feed see girl d recurs grammar permit recurs presenc rel claus which expand noun phrase may introduc yet rel claus etc lead sentenc grammat phenomena note ac may extend consider distanc dog chase see hear viabl sentenc one liter insert grammar occur end sen tenc endofsent marker potenti occur anywher string grammat sentenc might termin thu sentenc caret indic posit might legal occur data exampl sort phenomena linguist argu cannot account without abstract represent precis claim abstract represent offer perspicaci account grammtic phenomena one which exampl simpli list surfac string chomski train data gener grammar summar tabl given point train train set consist sentenc present network time as befor sentenc concaten input stream proceed smoothli without break sentenc howev composit sentenc vari time follow train regimen use order provid increment train network train pass follow corpora phase first train set consist exclus simpl sentenc accomplish elimin rel claus result corpu word form sentenc each sentenc includ termin phase network expos second corpu sentenc consist complex sentenc simpl sentenc complex sentenc obtain permit rel claus mean sentenc length minimum word maximum word phase third corpu increas percentag complex sentenc mean sentenc length minimum word maximum word phase fourth consist sentenc complex simpl mean sentenc length minimum word maximum stage learn strategi develop respons result earlier pilot work work found network unabl learn task given full rang complex data begin train howev network permit focu simpler data first abl learn task quickli move success complex pattern import aspect earlier train constrain later learn use way earli train forc network focu canon version problem appar creat good basi solv difficult form problem result conclus fourth phase train weight frozen final valu network perform test novel set data gener way last train corpu task nondeterminist network unless memor sequenc alway produc error optim strategi case activ output unit ie predict potenti next word extent proport statist likelihood occurr therefor rather assess network global perform look root mean squar error ask close network approxim probabl techniqu describ elman in press use accomplish thi contextdepend likelihood vector gener word everi sentenc vector repres empir deriv probabl occurr possibl predict given sentenc context point network actual output compar likelihood vector error use measur perform error quit low initi error minim error equal activ unit would error also normal comput mean cosin angl vector sd measur indic network achiev high level perform predict gross measur perform howev tell us well network done specif problem area pose task let us look area turn a agreement simpl sentenc agreement simpl sentenc shown figur b insert figur network predict follow word boy either singular verb follow word three singular verb categori activ sinc basi predict type verb els next word may rel pronoun who convers input word boy expect verb plural follow els rel pronoun similar expect hold noun lexicon result follow perform sentenc shown repres sentenc similar structur b verb argument structur simpl sentenc figur show network predict follow initi noun verb three differ verb type insert figur verb live network expect follow item which fact successor permit grammar context verb see hand may either follow option direct object which may singular plural noun proper noun final verb chase requir direct object network learn expect noun follow verb class c interact rel claus exampl far involv simpl sentenc agreement verb argument fact complic complex sentenc figur show network predict word sentenc boy mari chase feed cat network gener pattern agreement found simpl sentenc might expect network predict singular verb follow mari chase insofar predict verb posit all convers might confus pattern n n v fact predict d correctli next verb singular order agre first noun do found mechan repres longdist depend main claus noun main claus verb despit presenc interven noun verb with agreement relat rel claus insert figur note sentenc also illustr sensit interact verb argument structur rel claus structur verb chase take obligatori direct object simpl sentenc direct object follow verb immedi also true mani complex sentenc eg boy chase mari feed cat sentenc display howev direct object boy head rel claus appear verb requir network learn a item function noun verb etc b item fall class c subclass verb differ cooccurr relat noun correspond verbdirect object restrict d verb fall class e expect direct object follow verb know alreadi appear network appear learn thi panel d see expect chase follow verb the main claus verb case rather noun even subtler point demonstr c appear boy follow rel claus contain differ subject who mari prime network expect verb follow must class requir direct object precis direct object filler alreadi appear word network correctli respond presenc filler boy know expect gap follow chase also learn filler correspond object posit rel claus verb requir appropri argument structur network analysi natur question ask point network learn accomplish task success task seem constitut prima faci evid exist intern represent possess abstract structur is seem reason believ order handl agreement argument structur fact presenc rel claus network would requir develop represent reflect constitu structur argument structur grammat categori grammat relat number at least sort infer made case human languag user base behavior data one advantag work artifici system take addit step directli inspect intern mechan gener behavior cours mechan find necessarili use human li tener may nonetheless surpris find solut problem might guess own hierarch cluster use analyt tool help understand internatl represent learn network contribut solv problem cluster diagram hidden unit activ pattern good repres similar structur represent space howev certain lim itat one weak provid indirect pictur represent space anoth shortcom tend deemphas dynam involv process state may signific simpli term similar state regard way constrain movement subsequ state space recal exampl import part network learn lie dynam involv process word sequenc inde one might think network dynam encod grammat knowledg certain sequenc word move network welldefin permiss intern state sequenc move network permiss state sequenc permit ungrammat might therefor wish abl directli inspect intern state repres hidden unit activ vector network process word sequenc order see state trajectori encod network grammat knowledg unfortun high dimension hidden unit activ vector in simul here dimens make impract view state space directli furthermor guarante dimens interest us sens pick region import network solut task correl dimens code hidden unit inde mean represent distribut dimens variat cut across degre dimens pick hidden unit howev reason assum dimens variat exist tri identifi use princip compon analysi pca pca allow us find anoth set dimens a rotat axe along maximum variat occur it may addit reduc number variabl effect remov linearli depend set axe new axe permit us visual state space way hope allow us see network solv task shortcom pca linear howev combin pca factor next level may nonlinear represent inform may give incomplet pictur actual comput dimens eigenvector associ eigen valu magnitud indic amount varianc account di mension allow one focu dimens may particular signific also allow post hoc estim number hidden unit might actual requir task figur show graph eigenvalu eigenvector extract insert figur agreement sentenc present network hidden unit pattern captur word process sequenc boy hear boy c boy boy chase chase boy d boy boy chase chase boy these sentenc chosen minim differ due lexic content make possibl focu differ grammat structur a b contain train data c d novel never present network learn examin trajectori state space along variou dimens appar second princip compon play import role mark number main claus subject figur show trajectori a b trajectori overlaid differ readili seen path similar practic term anaylsi involv pass train set train network with weight frozen save hidden unit pattern produc respons input covari matrix result set hidden unit vector calcul eigenvector covari matrix found eigenvector order magnitud eigenvalu use basi describ origin hidden unit vector new set dimens effect give somewhat local descript hidden unit pattern new dimens correspond locat meaning activ defin term varianc hyperspac sinc dimens order term varianc account for may wish look select dimens start largest eigenvalu see fluri detail explan pca gonzalez wintz detail descript algorithm diverg first word indic differ number initi noun differ slight elimin main ie second chase verb input appar becaus two sentenc and grammar number inform relev task main verb receiv insert figur difficult imagin sentenc number inform may retain interven constitu sentenc c d exampl sentenc ident rel claus follow initi noun which differ regard number two sentenc materi boy chase irrelev far agreement requir main claus verb trajectori state space two sentenc overlaid shown figur seen differ two trajectori maintain main claus verb reach point state converg insert figur verb argument structur represent verb argument structur examin probe sentenc contain instanc three differ class verb sampl sentenc shown boy walk boy see boy c boy chase boy first contain verb may take direct object second take option direct object third requir direct object movement state space three sentenc process shown figur insert figur figur illustr network encod sever aspect grammat structur noun distinguish role subject noun three sentenc appear upper right portion space object noun appear them princip compon shown here encod distinct verb noun collaps across case verb differenti regard argument structur chase requir direct object see take option direct object walk preclud object differ reflect systemat displac plane princip compon rel claus presenc rel claus introduc complic grammar represent number verb argument structur must clausespecif would use network way repres constitu structur sentenc train network given follow sentenc a boy chase boy b boy chase boy chase boy c boy chase boy chase boy d boy chase boy chase boy chase boy first sentenc simpl three instanc embed sentenc contain train data sentenc c d e novel present network learn phase trajectori state space four sentenc princip compon shown figur panel a show basic pattern associ fact matrix sentenc four sentenc comparison figur panel b c show trajectori matrix sentenc appear follow for matrix subject noun lower left region state space matrix verb appear left matrix object noun near upper middl region recal look dimens along dimens nounverb distinct preserv categor rel claus appear involv replic basic pattern displac toward left move slightli down ward rel matrix constitu moreov exact posit rel claus element indic matrix noun modifi thu rel claus modifi subject noun closer it rel claus modifi object noun closer it trajectori pattern found sentenc grammat form pattern thu systemat insert figur figur d show happen multipl level embed success embed repres manner similar way first embed claus distinguish main claus basic patter claus replic region state space displac matrix materi displac provid systemat way network encod depth embed current state howev reliabl encod limit precis state repres turn depend factor number hidden unit precis numer valu current simula tion represent degrad three level embed consequ degrad perform in predict task differ differ type sentenc sentenc involv center embed eg c d level embed crucial maintain correct agreement advers affect sentenc involv socal tailrecurs eg d latter sentenc syntact structur principl involv recurs practic level embed relev task ie affect agreement verb argument structur way figur interest anoth respect given natur predict task actual necessari network carri forward inform prior claus would suffici network repres success rel claus iter previou pattern yet two rel claus differenti similarli servanschreib cleereman mcclelland in press found simpl recurr network taught predict input gener finit state automaton network develop intern represent correspond fsa state howev also redundantli made finergrain distinct encod path state achiev even though inform use task thu seem properti network abl encod state way minim context far behavior concern nonlinear natur allow remain sensit context level intern represent discuss basic question address paper whether connectionist model capabl complex represent possess intern structur product estens question particularli interest regard gener issu use connectionist paradigm framework cognit model context natur represent interact number close relat issu order understand signific present result may use first consid briefli two issu first statu rule whether exist whether explicit implicit second notion comput power whether suffici whether appropri sometim suggest connectionist model differ classic model latter reli rule wherea connectionist model typic rule sy tem although first glanc appear reason distinct actual clear distinct get us far basic problem obviou meant rule gener sens rule map take input yield output clearli sinc mani although all neural network function inputoutput system bulk machineri implement transform difficult see could thought rulesystem perhap meant form rule differ classic model connectionist network one suggest rule state explicitli former wherea implicit network slipperi issu unfortun ambigu meant implicit explicit one sens explicit rule physic present system form rule furthermor physic presenc import correct function system howev kirsh point intuit count physic presenc highli unreli sometim contradictori seem realli stake speed inform made avail true kirsh argu point persuas qualiti explicit belong data structur alon one must also take account natur process system involv sinc inform form may easili access one process system inaccess anoth unfortun understand inform process capac neural network quit preliminari strong tendenc analyz network view tradit lens suppos inform contain form familiar comput system inform somehow bur i inaccess implicit consid instanc network success learn complic map say text pronunci sejnowski rosenberg inspect result network immedi obviou explain map work even character map precis way case tempt say network learn implicit set rule realli mean map complic difficult formu late even unknown rather descript failur understand mechan rather descript mechan itself need new techniqu network analysi princip compon analysi use present work contribut analysi sanger weight matrix decomposit mc millan smolenski skeleton mozer smolenski success analys connectionist network may provid us new vocabulari understand inform process wemay learn new way inform explicit implicit may learn new notat express rule underli cognit notat new connectionist rule may look differ use in exampl product rule may expect notat lend describ type regular equal facil thu potenti import differ connectionist model classic model whether one system contain rule whether one system encod inform explicitli encod implicitli differ lie natur rule kind inform count explicitli present potenti differ bring us second issu comput power issu divid two consider connectionist model provid suffici comput power to account cognit phenomena provid appropri sort comput power first question answer affirm import qualif shown multilay feedforward network one hidden layer squash output arbitrari nonlinear activ function hidden layer capabl arbitrarili accur approxim arbitrari map thu belong class univers approxim hornik stinchcomb white press stinchcomb white pollack also proven ture equival neural network principl then network capabl implement function classic system implement import qualif result suffici mani hidden unit provid or case pollack proof weight infinit precis current known effect limit resourc comput power sinc human cognit carri system rel fix limit resourc question paramount interest limit provid critic constraint natur function map import empir question whether constraint explain specif form human cognit context question appropri comput power becom interest given limit resourc relev ask whether kind oper represent natur made avail like figur human cognit one theori cognit requir sort randomli order inform eg word frequenc list forster model lexic access becom extrem import comput framework provid effici support sort oper hand one believ inform store associ abil system fast sort irrelev instead import model provid associ storag retriev cours thing work direct avail certain type oper may encourag one build model type impract framework need work inappropri comput mechan may blind us see thing realli are let us return current work would like discuss first way work preliminari limit discuss see posit contribut work final would like relat work connectionist research gener question rais outset discuss viabl connectionist model understand cognit result preliminari number way first one imagin number exampl suggest norman addit test could perform test represent capac simpl recurr network memori capac remain unprob but see servan schreiber cleereman mcclelland press gener test limit way mani test involv novel sentenc one would like know whether network inferenti extend know type noun phrase encount second simul simpl noun rel claus noun phrase differ structur second true agreement verb argument structur fact contain present grammar import challeng bare scratch surfac term rich linguist phenomena character natur languag third natur languag contain far complex regard syntact structur also semant aspect inde langack other argu persuas fruit consid syntax semant autonom aspect languag rather form mean languag close entwin although may thing learn studi artifici languag present one pure syntact natur languag process crucial attempt retriev mean linguist form present work address issu all pdp model made progress problem eg st john mcclelland press current work contribut notion represent capac connectionist model variou writer eg fodor pylyshyn express concern regard abil connectionist represent encod composit structur provid openend gener capac network use simul report two import properti relev concern first network make possibl develop intern represent distribut hinton hinton mcclelland rumelhart un bound distribut represent less rigidli coupl resourc localist represent strict map concept individu node also greater flexibl determin dimens import model second network studi build sensit context import result current work suggest sensit context characterist mani connectionist model builtin architectur network use here preclud abil captur gener high level abstract paradox sensit context precis mechan underli abil abstract gener fact network exhibit behavior highli regular learn context insensit rather learn respond context abstractli de fine recal even network behavior seem ignor context eg figur d servanschreib cleereman mcclelland press intern represent reveal contextu inform still retain behavior strike contrast tradit symbol model represent system natur contextinsensit insensit make possibl express gener fulli regular highest possibl level represent eg pure syntact requir addit apparatu account regular reflect interact mean form contextu defin connectionist model hand begin task abstract end continuum emphas import context interact form mean current work demonstr characterist lead quit natur gener high level abstract appro priat behavior remain everroot represent contextu ground simul report capit subtl distinct con text ampl demonstr model eg kawamoto mcclelland kawamoto miikkulainen dyer st john mcclelland press final wish point current approach suggest novel way think mental represent construct languag input convent wisdom hold word heard listen retriev lexic rep resent although represent may indic context word accept occur represent contextfre exist canon form constant across occurr lexic form use assist construct complex represent form in sert one imagin complet result elabor structur word visibl also depict abstract grammat structur bind word account process build mental structur unlik process build physic structur bridg hous word and whatev represent element involv play role build block true bridg hous build block unaffect process construct differ imag suggest approach taken here word process separ stage lexic retriev represent word isol represent word the intern state follow input word alway reflect input taken togeth prior state scenario word build block much cue guid network differ grammat state word distinct virtu differ causal properti ametaphor captur characterist approach combin lock metaphor role word analog role play number combin number causal properti advanc lock differ state effect number depend context enter correct sequenc number move lock open state open state may said function composit van gelder press sens reflect particular sequenc event number present insofar respons final state still physic present limit combin lock cours one correct combin network studi complex causal properti word highli structuredepend network allow mani open ie gram matic state view languag comprehens emphas function import represent similar spirit approach describ bate macwhinney mcclelland st john taraban mani other stress function natur languag represent languag construct order accomplish behavior where obvious behavior may rang daydream ing verbal duel ask direct compos poetri represent proposit inform content chang constantli time accord demand current task word serv guidepost help establish mental state support behavior represent snapshot mental state acknowledg grate mani use discuss topic jay mcclelland dave rumelhart elizabeth bate steve stich member ucsd pdpnlp research group thank mcclelland mike jordan mari hare ken baldwin two anonym review critic comment earlier version paper research support contract nk offic naval research contract daabch armi avion ft monmouth request reprint sent center research languag univers california san diego author reach via electron mail elmancrlucsdedu r sytntact theori project problem functionalist approach grammar mean structur languag syntact transform distribut represent center research concept cognit syntact structur spread activ theori retriev sentenc product symbol schemata connectionist memori role bind evolut structur univers california implement connectionist product system use tensor product represent structur connectionist model find structur time mental space connectionist model properti cognit scienc frame semant common princip compon relat multivari model languag thought connection cognit architectur critic analysi level process structur languag processor network learn phonolog syntax functionaltypolog introduct spoken word recognit process gate paradigm knowledg represent connectionist network role similar hungarian vowel harmoni connectionist account connectionist perspect prosod structur repres partwhol hierarchi connectionist network technic report crgtr distribut represent transit grammar discours serial order parallel distribut process approach institut cognit scienc report distribut represent ambigu word resolut connectionist network function syntax anaphora read senseless sentenc brain potenti reflect semant incongru foundat cognit grammar theoret perspect usagebas model languag learn cue rule tempor structur spoken languag understand analyz connectionist model system soft rule ca morgan kaufmann publish focus backpropag algorithm tempor pattern recognit skeleton techniqu trim fat network via relev assess semant constraint judg prefer interpret ambigu sentenc learnabl cognitiion acquisit argument structur recurs autoassoci memori decis composit distribut represent philosoph implic connection learn intern represent error propag interact knowledg sourc spoken word identif contribut analysi techniqu assign respons hidden unit connectionist network linguist compet parallel network learn pronounc english text connectionist system rule base reason multiplac predic variabl proper treatment connection lexicon model languag product univers approxim use feedforward network nonsigmoid hidden layer activ function studi abil decod grammat novel sentenc journal verbal learn verbal behavior reconcil connection recurs natur stack tree rule map connectionist symbol process technic report cmuc mani map symbol among neuron detail connectionist infer architectur connectionist implement cognit phonolog graph network predict follow sequenc boy live graph network predict word sentenc boy mari chase feed dog graph eigenvalu order eigenvector extract simul trajectori state space sentenc a b trajectori state space process c d trajectori state space sentenc a trajectori state space sentenc ad boy mari chase feed cat tr ctr jame henderson peter lane connectionist architectur learn pars proceed th intern confer comput linguist august montreal quebec canada jame henderson segment state entiti implic learn emerg neural comput architectur base neurosci toward neuroscienceinspir comput springerverlag new york inc new york ny imran maqsood muhammad riaz khan ajith abraham intellig weather monitor system use connectionist model neural parallel scientif comput v n p june matthew h tong adam d bickett eric m christiansen garrison w cottrel special issu learn grammat structur echo state network neural network v n p april m k m rahman wang pi yang tommi w s chow sitao wu flexibl multilay selforgan map gener process treestructur data pattern recognit v n p may jame henderson neural network parser handl spars data new develop pars technolog kluwer academ publish norwel ma kathrin hammervold sentenc gener neural network proceed first intern confer natur languag gener june mitzp ramon israel michael gasser acquir recept morpholog connectionist model proceed nd annual meet associ comput linguist p june la cruce new mexico junghua wang yiwei yu jiahorng tsai intern represent product unit neural process letter v n p dec marcin chadi model higher cognit function hebbian cell assembl emerg neural comput architectur base neurosci toward neuroscienceinspir comput springerverlag new york inc new york ny heejin lim yoonsuck choe facilit neural dynam delay compens predict evolutionari neural network proceed th annual confer genet evolutionari comput juli seattl washington usa peter c r lane jame b henderson increment syntact pars natur languag corpora simpl synchroni network ieee transact knowledg data engin v n p march hinrich schtze partofspeech induct scratch proceed st annual meet associ comput linguist p june columbu ohio symbolicconnectionist systemfor word sens disambigu appli intellig v n p januari xindi cai nian zhang ganesh k venayagamoorthi donald c wunsch ii time seri predict recurr neural network train hybrid psoea algorithm neurocomput v n p august stephen jo hanson michiro negishi emerg rule neural network neural comput v n p septemb paul rodriguez simpl recurr network learn contextfre contextsensit languag count neural comput v n p septemb imran maqsood ajith abraham weather analysi use ensembl connectionist learn paradigm appli soft comput v n p june samuel w k chan integr linguist primit learn contextdepend represent ieee transact knowledg data engin v n p march steve lawrenc c lee gile sandiway fong natur languag grammat infer recurr neural network ieee transact knowledg data engin v n p januari ahmad emami frederick jelinek neural syntact languag model machin learn v n p septemb bechtel compat complex system reduct case analysi memori research mind machin v n p novemb w f g haselag j f h van rappard connection systemat frame problem mind machin v n p novemb sheila garfield stefan wermter call classif use recurr neural network support vector machin finit state automata knowledg inform system v n p februari sheila garfield stefan wermter siobhan devlin spoken languag classif use hybrid classifi combin intern journal hybrid intellig system v n p januari stephan k chalup alan d blair increment train first order recurr neural network predict contextsensit languag neural network v n p septemb stefan c kremer spatiotempor connectionist network taxonomi review neural comput v n p februari stefan wermter knowledg extract transduc neural network appli intellig v n p januaryapril