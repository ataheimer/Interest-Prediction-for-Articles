t coevolut success learn backgammon strategi a follow tesauro work tdgammon use paramet feedforward neural network develop competit backgammon evalu function play proce roll dice applic network legal move select posit highest evalu howev backpropag reinforc tempor differ learn method employ instead appli simpl hillclimb rel fit environ start initi champion zero weight proceed simpli play current champion network slightli mutat challeng chang weight challeng win surprisingli work rather well investig peculiar dynam domain enabl previous discard weak method succeed prevent suboptim equilibria metagam selflearn b introduct took great chutzpah gerald tesauro start wast comput cycl tempor differ learn game backgammon tesauro let machin learn program play hope becom expert inde all dream comput master domain selfplay introspect around sinc earli day ai form part samuel checker player samuel use donald michi menac tictacto learner michi selfcondit system later gener abandon field due problem scale weak nonexist intern represent moreov self play learner usual develop eccentr brittl strategi appear clever fare poorli expert human comput player yet tesauro result show selfplay approach could power refin million iter selfplay tdgammon program becom one best backgammon player world tesauro deriv weight view corpor signific enough intellectu properti keep trade secret except leverag sale minor oper system intern busi machin other replic td result backgammon research purpos boyan commerci purpos reinforc learn limit success area zhang dietterich crite barto walker et al respect goal selforgan learn machin start minim specif rise great sophist tdgammon stand alon success understood explain replic domain hypothesi success tdgammon princip due backpropag reinforc temporaldiffer technolog inher bia dynam game backgammon coevolutionari setup train task dynam chang learn progress test hypothesi use much simpler coevolutionari learn method backgammon name hillclimb implement detail use standard feedforward neural network two layer sigmoid set fashion tesauro unit repres number player piec point plu unit indic mani bar board addit ad one unit report whether game reach endgam race situat make total input unit fulli connect hidden unit connect one output unit judg posit includ bia hidden unit make total weight game play gener legal move convert proper network input pick posit judg best network start weight set zero initi algorithm hillclimb add gaussian nois weight play network mutant number game mutant win half game select next gener nois set step would rm distanc which euclidean distanc divid surprisingli work reason well network evolv improv rapidli first sank mediocr problem perceiv compar two close backgammon player like toss bias coin repeatedli may take dozen even hundr game find sure better replac welltest champion danger without enough inform prove challeng realli better player lucki novic rather burden system much comput instead introduc follow modif algorithm avoid buster dougla effect firstli game play pair order play revers random seed use gener dice roll game wash unfair due dice roll two network close particular ident result would alway one win though admittedli make differ move earli game good dice roll particular move one game may turn bad roll correspond move parallel game secondli challeng win contest rather replac champion challeng instead make small adjust direct champion idea similar inertia term backpropag rumelhart et al introduc assumpt small chang weight would lead small chang decisionmak evalu function so bite ear challeng ad champion current decis preserv would less like catastroph replac champion lucki novic challeng initi stage evolut two pair parallel game play challeng requir win game although would like rank player player use neurogammon gammontool avail us figur show first player rate pubev moder good publicdomain player train tesauro use human expert prefer three thing note percentag win pubev increas gener frequenc success challeng increas time player improv epoch eg start perform pubev begin falter first fact show simpl self buster dougla world heavyweight box champion month play hillclimb capabl learn second fact quit counterintuit expect player improv would harder challeng it true respect uniform sampl dimension weight space true sampl neighborhood given player player good part weight space small chang weight lead mostli similar strategi one make mostli move situat howev game use determin rel fit increas rate chang allow system drift may account subsequ degrad performanceto counteract drift decid chang rule engag evolut proce accord follow anneal schedul gener number game challeng requir win increas gener increas of cours bout abandon soon champion one game make averag number game per gener consider less number chosen ad hoc basi observ frequenc success challeng buster dougla effect particular run later experi show determin anneal schedul principl manner see section below game use simpl hillclimb develop surpris player capabl win game pubev network sampl everi gener order test perform network gener extract use benchmark figur show percentag win sampl player three benchmark network note three curv cross line respect show gener improv time endgam backgammon call bearoff use anoth yardstick progress learn bearoff occur player piec home board first point dice roll use remov piec figur percentag win first gener player pubev match consist game gener win board test network abil endgam set race board two piec player point one piec point graph figur show averag number roll bearoff network play use fix set random dicestream note pubev stronger roll discuss strength tesauro result section figur percentag win benchmark network upper middl lower show noisi nearli monoton increas player skill evolut proce win gener gener figur averag number roll bearoff gener sampl dicestream pubev averag roll task analysi learnabl unlearn learnabl formal defin time constraint search space hard randomli pick floatingpoint weight make good backgammon evalu simpli imposs hard find weight better current initi weight random quit easi play improv would expect get harder harder perhap similar probabl tornado construct junkyard howev search neighborhood current weight find mani similar player make mostli move capit other slightli differ choic expos weak tournament note differ point tesauro origin made feedforward neural network could exploit similar posit although set paramet initi run involv guesswork larg set player examin tri understand phe nomenon take champion network gener run sampl random player neighborhood differ rm distanc find like find win challeng thousand random neighbor differ rm distanc play game correspond champion figur plot fraction game challeng function rm distanc graph show player improv time probabl find good challeng neighborhood increas account frequenc success challeng goe up success challeng requir number good challeng neighborhood go up so algorithm falter nonetheless sever factor requir studi may due gener growth weight less variabl strategi among matur player less abil simpli tell expert player apart game figur distanc versu probabl random challeng win champion gener distanc champion k win challeng take small step chang move champion order beat it hope coevolut appar unlearn becom learnabl convert singl question continu stream question one depend previou answer replic experi first success run tri evolv ten player use paramet anneal schedul found one ten player even competit closer examin suggest nine run fail anneal earli frequenc success challeng reach appropri level prematur anneal made task challeng even harder challeng success rate fell even lower therefor abandon fix anneal schedul instead anneal whenev challeng success rate exceed averag gener ten player evolv regim competit though quit good origin player appar benefit extra induct bia due tailormad anneal schedul refin heurist schedul could lead superior player goal rel versu absolut expertis backgammon allow rel expertis absolut optim strategi theoret exist perfect polici backgammon would deliv minimax optim move posit perfect polici could exactli rate everi player linear scale practic especi without run game verifi seem mani rel cycl help prevent earli converg cellular studi iter prison dilemma follow axelrod stabl popul tit tat invad all cooper allow exploit all defect kind relativeexpertis dynam seen clearli simpl game rockpaperscissor littman might initi seem bad selfplay learn look like advanc might actual lead cycl mediocr small group champion domin circl aris hold tempor oligopoli prevent advanc hand may basic form instabl prevent format suboptim oligopoli allow learn progress problem specif nonzerosum game zero sum game appropri use selfplay shown converg optim play parti discuss believ evid success learn backgammon use simpl hillclimb rel fit environ indic reinforc tempor differ methodolog use tesauro paper led tdgammon provid advantag essenti success rather major contribut came coevolutionari learn environ dynam back gammon result thu similar bia found mitchel et al packard evolut cellular automata edg chao packard mitchel et al obvious suggest hillclimb advanc machin learn techniqu other bring mani task without intern cognit oppon behavior coevolut usual requir popul therefor must someth domain help permit td learn hillclimb succeed selfplay would clearli fail problemsolv task scale section discuss issu coevolutionari learn dynam backgammon may critic learn success evolut versu coevolut tdgammon major mileston kind evolutionari machin learn initi specif model far simpler expect learn environ specifi implicitli emerg result coevolut learn system train environ learner embed environ respond improv hope neverend spiral though elus goal achiev practic coevolutionari effect seen popul model complet unexpect hillclimb evolut coevolut explor sort network problem hilli tictacto strategi game angelin pollack rosin belew schraudolph et al predatorprey game cliff miller reynold classif problem intertwin spiral problem juill pollack howev besid tesauro tdgammon date view instanc coevolutionari learn sim artifici robot game sim domain complex backgammon substanti success sinc weak player sometim defeat strong one theori possibl network learn backgammon static evolutionari environ play fix oppon rather coevolutionari one play itself cours interest acheiv learn without expert hand tdgammon simpli learn neurogammon startl result order isol contribut coevolutionari learn modifi train setup origin algorithm appropri selfplay new setup current champion mutant play number game oppon call foil dicestream weight adjust champion lose game mutant win them number pair game initi set increment whenev challeng success rate exceed averag gener lower three plot figur track perform algorithm three benchmark network origin experi act foil seem show relationship learn rate probabl win weak foil k learn fast initi probabl win around taper probabl increas strong foil k learn slow initi probabl win small speed increas toward evolutionari run outperform coevolutionari version foil algorithm coev champion network play role foil coevolut seem maintain high learn rate throughout run automat provid new gener player oppon appropri skill level keep probabl win near moreov weak foil less like bia learn process automat correct coevolut proce see also section dynam backgammon gener problem learn selfplay discov repeatedli earli ai ml learner could keep play kind game over explor narrow region strategi space miss critic area game would vulner program human expert problem particularli preval determinist game chess tictacto tesauro point featur backgammon make suitabl approach involv selfplay random initi condit unlik chess draw imposs game play untrain network make random move eventu termin though may take much longer game compet player moreov random dice roll lead selfplay much larger part search space would like explor determinist game work use popul get around limit selfplay angelin pollack schraudolph et al ad nondetermin game go choos move accord boltzmann distribut statist mechan other fogel expand explor forc initi move epstein studi mix train use selfplay random test play expert order better understand aspect game learn gener figur perform pubev player evolv play benchmark network origin run gener k k k compar coevolutionari variant algorithm plot averag four run perform origin algorithm includ comparison origin coev k believ enough add random game forc explor altern train paradigm someth critic dynam backgammon set apart game random element like monopoli name outcom game continu uncertain contact broken one side clear advantag monopoli earli advantag purchas properti lead accumul return mani observ find excit backgammon help novic sometim overcom expert number situat one dice roll improb sequenc dramat revers player expect win order quantifi revers effect collect statist game play th gener network itself n collect differ game still contact move n and n game reach race stage move n but still move number standard deviat move number contact race game probabl figur a standard deviat probabl win contact posit race posit contact race figur b probabl game still contact race stage move n figur smooth distribut probabl win function move number contact posit left race posit right densiti densiti probabl win move number move probabl progress estim probabl win posit play differ dicestream figur show standard deviat probabl assum mean function n well probabl game still contact race stage move n figur show distribut probabl win function move number symmetr smooth convolut gaussian function data indic probabl win tend hover near earli stage game gradual move play proce typic remain within rang long still contact thu allow reason chanc revers number could differ player less revers stronger player perhap weaker one believ effect remain integr part game dynam regardless expertis conjectur dynam facilit learn process provid almost everi situat nontrivi chanc win nontrivi chanc lose therefor potenti learn consequ current move deep contrast mani domain earli blunder could lead hopeless situat learn virtual imposs reward alreadi becom effect unat tainabl seem featur backgammon may also share task tdlearn success zhang dietterich crite barto walker et al avoid suboptim equilibria metagam learn learn system view interact teacher student teacher goal expos student weak correct them student goal placat teacher avoid correct build model teacherstud interact formal game call metagam learn mgl avoid confus game learn metagam teacher present student sequenc question prompt respons r student in backgammon domain question respons would legal posit roll move receiv payoff process attempt maxim choic question answer limit abil selfmodif gener assum goal learn prepar student interact complex environ e provid object measur perfor manc e thu play similar role assum ident question is find payoff matrix enabl perform continu improv as measur e reward close correl s may tempt ask question easi anticorrel for exampl te question might difficult either case hard learn see section gener theori evolut selforgan e necessari attract solut problem two student play role teacher other inde singl student act teacher thu provid question alway appropri level difficulti dynam mgl selfteach coevolutionari situat would hope lead continu spiral improv may instead get bog antagonist collus dynam depend payoff structur hillclimb setup may think mutant teacher tri gain advantag adjust weight exploit weak champion champion student tri avoid adjust allow weak exploit sinc student teacher approxim equal abil advantag student narrow scope search thu limit domain within teacher abl look weak game chess tictacto student could achiev aim draw instead win alway play particular style game draw allow teacher student may figur way collud exampl throw altern game angelin make suboptim sequenc earli move effect selflearn system may appear earli converg evolutionari algorithm narrow scope draw collus teacher student fact nash equilibria mgl call mediocr stabl state hypothesi certain featur backgammon oper format mediocr stabl state mgl backgammon ergod sens posit reach posit sequenc move dice roll appar creat enough random prevent either player follow strategi narrow scope game appreci moreov earli suboptim move unlik provid oppon easi win see section collus throw altern game prevent mediocr stabl state also aris human educ system exampl student get answer right reward teacher posit teach evalu ask harder question work hope appli kind mgl equilibrium analysi issu human educ conclus tdgammon remain tremend success machin learn caus success well understood fundament research tesauro paper basi tdgammon reportedli beat sun gammontool time depend number hidden unit achiev pariti neurogammon follow semin paper tesauro incorpor number handcraft expertknowledg featur eventu engin network achiev world mss follow maynard smith ess maynard smith except race situat posit piec play master level play tesauro featur includ concept like exist prime probabl blot hit probabl escap behind oppo nent barrier evalu function also improv use multipl pli search best player weve abl evolv win time pubev believ level tesauro network tesauro never compar network pubev use gammontool heurist endgam rate level play achiev player somewhat murki the test procedur play game network becom race use gammontool algorithm move side end also penal td net learn rather poorli race phase gamep compar network perform pubev must note use network weak endgam rather substitut much stronger expert system like gammontool gerald tesauro commentari issu gracious clear matter compar pubev result differ somewhat conclus below two phenomena fom paper relev work perform posit race test set reach thi substanti wors race specialist describ previou section p the train time were order train game network game hidden unit net game hidden unit net p achiev similar level skill observ phenomena train endgam weak converg believ achiev result substanti similar tesauro result without advanc learn algorithm could make stronger player tune learn paramet ad input featur point claim th gener player anywher near good current enhanc version tdgammon readi challeng best human surprisingli good consid humbl origin hillclimb rel fit measur tune paramet ad input featur would make power player point studi also claim anyth wrong td learn hillclimb good reinforc learn gener cours isnt point environ represent refin work well machin learn method benchmark weakest possibl algorithm credit learn power properli distribut notic sever weak player stem train yet reward punish doubl tripl cost associ sever loss gammon backgammon take account gambl process doubl continu develop player sensit issu game interest player challeng th network use web browser home page at conclus replic tesauro tdgammon success much simpler learn paradigm find reinforc tempor differ method primari caus success rather dynam backgammon combin power coevolutionari learn isol featur backgammon domain enabl coevolutionari reinforc learn work well may lead better understand condit nece sari gener complex selforgan acknowledg work support onr grant n krasnow foundat postdoctor fellowship thank gerri tesauro provid pubev subsequ mean calibr it jack laurenc pablo fune develop www front end evolv player comment brandei demo group anonym refere justin boyan tom dietterich lesli kaelbl brendan kitt michael littman andrew moor rich sutton wei zhang r competit environ evolv better solut complex task altern interpret iter prison dilemma evolut nonmutu cooper evolut cooper modular neural network learn contextdepend game strategi track red queen measur adapt progress coevolutionari simul improv elev perform use reinforc learn massiv parallel genet program markov game framework multiag reinforc learn algorithm sequenti decis make revisit edg chao evolv cellular automata perform comput adapt toward edg chao studi machin learn use game checker tempor differ learn posit evalu game go evolv morpholog behavior competit learn predict method tempor differ connectionist learn expert prefer comparison train practic issu tempor differ learn tempor differ learn tdgammon tempor differ tr ctr gerald tesauro comment coevolut success learn backgammon strategi machin learn v n p sept david b fogel beyond samuel evolv nearli expert checker player advanc evolutionari comput theori applic springerverlag new york inc new york ny ji grim petr somol pavel pudil probabilist neural network play learn tictacto pattern recognit letter v n p septemb multiag system integr reinforc learn bid genet algorithm web intellig agent system v n p decemb multiag system integr reinforc learn bid genet algorithm web intellig agent system v n p march gerald tesauro program backammon use selfteach neural net artifici intellig v n p januari elizabeth sklar mathew davi multiag simul learn environ proceed fourth intern joint confer autonom agent multiag system juli netherland yeo keun kim jae yun kim yeongho kim tournamentbas competit coevolutionari algorithm appli intellig v n p mayjun elizabeth sklar mathew davi min san tan co sime simul educ multi agent system proceed third intern joint confer autonom agent multiag system p juli new york new york edwin de jong maxsolv algorithm coevolut proceed confer genet evolutionari comput june washington dc usa jordan b pollack hod lipson gregori hornbi pablo fune three gener automat design robot artifici life v n p summer pablo fune jordan pollack evolutionari bodi build adapt physic design robot artifici life v n p octob fran a oliehoek edwin d de jong niko vlassi parallel nash memori asymmetr game proceed th annual confer genet evolutionari comput juli seattl washington usa jordan b pollack hod lipson sevan ficici pablo fune greg hornbi richard a watson evolutionari techniqu physic robot creativ evolutionari system morgan kaufmann publish inc san francisco ca edwin d de jong monoton archiv paretocoevolut evolutionari comput v n p spring john cartlidg seth bullock combat coevolutionari disengag reduc parasit virul evolutionari comput v n p june stephan k chalup alan d blair increment train first order recurr neural network predict contextsensit languag neural network v n p septemb edwin d de jong jordan b pollack ideal evalu coevolut evolutionari comput v n p june cooper multiag learn state art autonom agent multiag system v n p novemb dars bill lourd pea jonathan schaeffer duan szafron learn play strong poker machin learn play game nova scienc publish inc commack ny