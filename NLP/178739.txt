t extract refin rule knowledgebas neural network a neural network despit empir proven abil littl use refin exist knowledg task requir threestep process first knowledg must insert neural network second network must refin third refin knowledg must extract network previous describ method first step process standard neural learn techniqu accomplish second step articl propos empir evalu method final possibl difficult step method effici extract symbol rule train neural network four major result empir test method extract rule close reproduc accuraci network extractedsemi superior rule produc method directli refin symbol rulessemi superior produc previou techniqu extract rule train neural networkssemi human comprehens thu method demonstr neural network use effect refin symbol knowledg moreov ruleextract techniqu develop herein contribut understand symbol connectionist approach artifici intellig profit integr b introduct artifici neural network ann proven power gener techniqu machin learn fisher mckusick shavlik et al howev ann sever wellknown shortcom perhap signific train ann essenti black box is determin exactli ann make particular decis daunt task signific shortcom without abil produc understand decis hard confid reliabl network address realworld problem also fruit train neural network difficult transfer neural network pratt et al amelior problem imposs directli transfer nonneur learn system henc train neural network analog pierr de fermat comment last theorem like fermat network tell discov someth wonder tell discov paper shed light neuralnetwork black box combin symbol rulebas reason neural learn approach form threelink chain illustr figur symbol knowledg revis correct use neural network thu approach present make possibl use neural network empir learn algorithm underli rulerefin system figur approxim here first link threelink chain insert knowledg need neither complet correct neural network use kbann towel et al here after network creat use kbann refer knowledgebas neural network knn step chang represent rule symbol neurallybas therebi make rule refin standard neural learn method second link chain train knn use set classifi train exampl standard neural learn algorithm backpropag rumelhart et al method weight optim feedforward neural network do rule upon knn base correct consist train exampl final link extract rule train knn extrem difficult task arbitrarilyconfigur network somewhat less daunt knn due properti stem initi comprehens take advantag properti develop method effici extract intellig rule network evalu two realworld test problem term abil correctli classifi exampl seen train method produc set rule close approxim network came moreov extract rule equal superior rule result rulerefin method act directli rule rather rerepresent neural network also show method superior previou algorithm extract rule gener neural network eg saito nakano fu next section contain brief overview method insert rule neural network subsequ section describ method best report method extract rule train knn section present seri empir test ruleextract method section use two realworld learn problem taken molecular biolog determin strength ruleextract method section use artifici domain character close possibl use realworld domain abil ruleextract method final section paper relat approach other extract rule train neural network discuss futur research plan kbann rulestonetwork translat kbann translat symbol knowledg neural network defin topolog connect weight network creat use knowledg base domainspecif infer rule repres proposit horn claus defin initi known topic detail explan procedur use kbann translat rule knn given towel et al towel provid brief summari procedur follow exampl consid sampl knowledg base figur a defin membership categori a figur b repres hierarch structur rule solid dot line repres necessari prohibitori depend respect figur c repres knn result translat knowledg base neural network unit x figur c introduc knn repres disjunct unit basic process element neural network receiv realnumb signal unit weight connect refer link mathemat transform signal realnumb output sent unit see tabl gener unit divid three categori input receiv signal environ output send signal environ hidden connect environ rule set otherwis unit knn correspond consequ anteced knowledg base thick line figur c repres heavilyweight link knn correspond depend knowledg base thin line repres link ad network allow addit refin knowledg base figur approxim here exampl illustr use procedur initi knn two princip benefit first algorithm indic input featur believ import exampl classif second specifi import deriv featur eg b c figur therebi guid choic number connect hidden unit knn rule extract section present detail explan approach previous report approach extract rule train knn first algorithm present comparison second algorithm introduc section focu work assumpt rule extract method present make two assumpt train network first assumpt underli method extract rule train neural network unit either maxim activ ie activ near one inact ie activ near zero assumpt particularli restrict commonlyus logist activ function slightli modifi ensur unit approxim step function make assumpt noninput unit train knn interpret step function boolean rule therefor rule extract problem determin situat rule true second assumpt train significantli alter mean unit make assumpt method abl attach label extract except gener includ method propos bochereau bourgin method extract fuzzi rule eg berenji w ij activ unit w ij weight link unit j unit bia unit i paramet affect slope sigmoid except explicitli state tabl logist activ function use backpropag rule correspond consequ symbol knowledg upon knn base therebi enhanc comprehens rule examin train network indic mean usual quit stabl although sutton suggest assumpt may gener true common method introduc extract rule neural network well previous describ eg saito nakano fu tri find combin input valu unit result activ near one henc section describ mathemat underli neural network use unit backpropagationtrain neural network normal activ defin equat tabl rephras equat activ unit function sum weight input unit less bia broadli speak result equat sum weight input exceed bia activ unit near one otherwis activ near zero henc ruleextract method search constraint input set weight sum guarante exceed bia first assumpt unit train network activ near zero one simplifi search ensur link carri signal equal weight signal all result equat simplifi equat state ruleextract method need concern weight link enter unit reduc rule extract search unit set incom link whose sum weight exce guarante unit bia exceed regardless activ carri incom link rule extract simplifi equat guarante noninput unit alway nonneg activ in problem investig input unit alway activ f g therefor negativelyweight link give rise negat anteced positivelyweight link give rise nonneg anteced consider reduc size search space fu final note short exactli copi unit link way limit kind differ extract rule network reason complex is extract rule may make error omiss commiss respect network error gener result cumul effect lowweight link appear extract rule one chief problem rule extract minim error without simpli rewrit network subset algorithm first method rule extract describ fundament similar approach describ saito nakano well fu howev particular implement own call gener approach subset method explicitli search subset incom weight exceed bia unit paper use subset algorithm straw man show effect new method rule extract present next section subset algorithm repres state art publish literatur simpl breadthfirst subset algorithm start determin whether set contain singl link suffici guarante bia exceed ye set rewritten rule search proce increas size subset possibl subset explor final algorithm remov subsum overlygener rule exampl given link weight bia shown figur a subset algorithm would initi find five rule elimin one subsum rule algorithm return four rule list figur b assum unit activ near zero one tabl specif subset algorithm hidden output unit a extract fi p subset positivelyweight incom link whose sum weight greater bia unit b subset p fi p subset found step a extract fi n minim subset negativelyweight link whose sum weight greater sum p less bia unit let z new predic use nowher els subset n fi n subset found step b form rule if n z form rule if p z name unit figur approxim here major problem subset algorithm cost find subset grow size power set link unit henc approach expect exactli reproduc behavior simpl network work small problem avoid otherwis prohibit combinator implement subset algorithm use heurist instanc saito nakano establish ceil number anteced extract rule establish priori ceil number anteced sever shortcom ming instanc ceil that one domain set accept tradeoff number extract rule differ extract rule network may accept anoth domain seriou problem occur properti problem studi suggest rule requir larg number anteced instanc initi rule one realworld domain studi indic smallest bound number anteced safe set could requir consid set therefor rather set bound number anteced implement use branchandbound algorithm limit term number rule may find subset algorithm present pseudocod tabl see fu complet descript subset algorithm briefli algorithm iter everi noninput unit train knn unit use branchandbound algorithm positivelyweight link find fi p posit subset whose sum weight exceed unit bia then posit subset make new branchandbound search negativelyweight link find minim neg subset whose sum weight greater magnitud differ sum weight posit subset unit bia final algorithm form rule result consequ satisfi anteced posit subset true none neg subset associ posit subset contain anteced true is neg subset suffici prevent node activ henc must ensur minim subset contain least one unsatisfi anteced algorithm may discov fi p rule noninput unit network translat describ abov tradeoff number extract rule accur reproduct network behavior henc set fi p fi n find reasonablys set rule approxim network came set use result find rule realworld domain studi gener accur reproduct knn requir mani rule subset extract larg set rule smaller mani handcraft expert system eg mcdermott henc subset deliv set rule are least potenti tractabl howev rule tend hide signific structur train network instanc figur link b c weight link e neg weight look problem way suggest rule figur b could rewritten follow rule provid much clearer statement condit a f b c d noteg a recogn structur share among sever conjunct rule led develop algorithm describ next focu paper mofn method algorithm call mofn address combinatori present problem inher subset algorithm differ subset algorithm explicitli search rule form m follow n anteced true suggest previous method aros notic rule set discov tabl mofn approach rule extract hidden output unit form group similarlyweight link set link weight group member averag group elimin group significantli affect whether unit activ inact hold link weight constant optim bias hidden output unit use backpropag algorithm form singl rule hidden output unit rule consist threshold given bia weight anteced specifi remain link possibl simplifi rule elimin superflu weight threshold ere subset often contain mofn style concept support method come experi indic neural network good learn mofn concept well experi variant id show bia toward mofn style concept use murphi pazzani final note pure conjunct rule result set disjunct rule result use mofn rule restrict gener idea underli mofn abstract version appear tabl individu anteced link uniqu import rather group anteced form equival class anteced import as interchang with member class equival class idea key mofn algorithm allow algorithm consid group link without worri particular link within group mofn algorithm section contain detail descript ruleextract algorithm illustr algorithm exampl follow section step cluster backpropag train tend group link knn loos cluster rather equival class assum mofn algorithm henc first step mofn creat equival class cluster link use standard cluster method join algorithm hartigan method oper success combin two closest cluster start cluster hold singl link cluster stop pair cluster closer set distanc mofn use step averag group form second step algorithm set weight link group averag group weight thu first two step forc link network equival class requir rest algorithm step elimin equival class place procedur next attempt identifi elimin group unlik bear calcul consequ group gener low link weight member elimin proce via two path one algorithm one heurist first elimin procedur algorithm attempt find cluster link cannot effect whether total incom activ exce bia done calcul total possibl activ cluster send total possibl activ compar level activ reachabl given link weight network cluster cannot chang whether net input exce bia elimin note procedur similar subset howev cluster link weight consider reduc combinator problem heurist elimin procedur base explicitli upon whether net input receiv cluster ever necessari correct classif train exampl procedur oper present train exampl cluster network sequenti zero input cluster result qualit chang activ unit receiv activ cluster cluster mark necessari cluster mark necessari elimin nowlan hinton neuralnetwork train algorithm draw link weight cluster reduc elimin problem one futur research plan combin train algorithm knowledgeinsert ruleextract method step optim unimport group elimin fourth step mofn optim bia unit step necessari first three step chang time unit activ result alter network may error rate significantli higher end train optim done freez weight link group stay intact retrain bias network use backpropag reflect rulelik natur network activ function slightli modifi moreclos resembl step function step extract step mofn algorithm form rule exactli reexpress network rule creat directli translat bia incom weight unit rule weight anteced rule true sum weight anteced exce bia note equival class elimin group rule consider simpler origin train network fewer anteced anteced tend weight class step simplifi sixth final step rule simplifi whenev possibl elimin weight threshold mofn simplifi rule scan determin possibl combin anteced exceed rule threshold ie bia scan may result one rule henc tradeoff simplif procedur complex individu rule complex result number syntact simpler rule exampl consid rule simplif rewrit rule follow three rule b c d e b c d e x y z x y z elimin weight bias requir rewrit singl rule five rule rule left origin state function numbertru return number anteced follow set true exampl mofn figur illustr process singl unit seven incom link transform mofn procedur rule requir two three anteced true first two step group link two cluster one four link weight one three link weight third step algorithm elimin cluster weight situat link affect unit fourth step bia optim unnecessari exampl averag elimin procedur significantli chang properti unit fifth sixth step simpl singl cluster remain henc final mofn written inspect figur approxim here complex analysi mofn complex mofn cannot precis analyz biasoptim phase use backpropag but note problem address bia optim consider simpler initi train network usual network order magnitud fewer link bia optim initi train moreov bias allow chang result step take reason short time initi cluster requir ou theta l time u number unit l averag number link receiv unit cluster elimin requir on theta u theta l time n number train exampl step use ou theta l time subset mofn summari ruleextract algorithm strength respect other exampl individu rule return subset often easili understood return mofn howev subset gener mani rule which repetit mofn rule set return mofn usual easier understand subset moreov measur time respect number link unit subset exponenti algorithm wherea mofn train simpl class neural network proven npcomplet judd hinton suggest that practic backpropag usual run ou theta l time approxim cubic final result present later paper indic rule set deriv mofn approxim equal accuraci network extract rule extract subset significantli wors next section contain seri empir test demonstr differ two algorithm experi realworld dataset dataset test efficaci ruleextract procedur realworld problem studi two problem domain molecular biolog use dataset member small collect realworld problem exist approximatelycorrect domain theori set classifi exampl also dataset previous studi theori revis literatur eg towel et al ourston mooney thompson et al noordewi et al make possibl comparison perform section notat dataset special notat use simplifi specifi locat dna sequenc dna sequenc linear string nucleotid nucleotid drawn fa g t cg idea number locat respect fix biologicallymeaning refer point neg number indic site preced to left of refer point posit number indic site follow refer point henc rule anteced refer input featur first state locat rel refer point sequenc vector dna nucleotid sequenc nucleotid must occur eg a biolog convent posit number zero use rule specif indic nucleotid suffic exampl first rule conform tabl say must a nucleotid refer locat anoth a must posit two nucleotid appear final must a locat final use standard ambigu code given tabl refer accept altern particular locat tabl ambigu code dna nucleotid code mean code mean code mean c r g w c g c k g v c g h c g b c g x g c problem promot recognit first problem investig prokaryot promot recognit origin describ towel et al promot short dna sequenc initi express gene basic promot site protein rna polymeras bind dna accord rule tabl two site bind must occur minu minu region addit conform rule attempt captur twist dna helix therebi ensur bind site spatial align set rule deriv straightforward manner biolog literatur harley reynold hawley mcclure koudelka et al consensu sequenc promot consensu sequenc describ probabl nucleotid given locat howev nucleotid appear everi promot instanc minu rule probabl nucleotid t t also rule deriv multipl sourc prune subsum rule extract rule strictli less gener other figur approxim here rule set translat kbann neural network topolog shown figur recal kbann add addit lowweight link not shown addit sequenc inform relev algorithm captur inform train input featur promot recognit sequenti dna nucleotid each locat dna sequenc translat input unit one nucleotid henc promot network input unit problem refer point site gene transcript would begin exampl contain promot point locat nucleotid preced seven follow tabl initi rule promot recognit promot contact conform contact minu minu conform aaa conform aa ttaat t conform at tattg a conform caattac gtc gcgcccc refer point thu posit exampl contain first seven nucleotid transcrib gene set exampl contain sampl promot nonpromot sequenc sampl promot obtain compil produc hawley mcclure deriv neg train exampl randomli select contigu substr kilobas sequenc provid prof t record univers wisconsin chemistri depart sequenc fragment e coli bacteriophag isol restrict enzym haeiii virtu fact fragment bind rna polymeras believ contain promot site record person commun prior train rule tabl classifi exampl promot result rule use just say no problem splicejunct determin second problem examin primat splicejunct determin origin describ learn problem noordewi et al splice junction point dna sequenc superflu dna remov process protein creation higher organ problem pose dataset recogn given sequenc dna boundari exon ie part dna sequenc retain splice intron ie part dna sequenc splice out problem consist two subtask recogn exonintron boundari recogn intronexon boundari dataset problem contain exampl approxim exonintron boundari intronexon boundari remain neither exampl consist nucleotid long dna sequenc categor accord type boundari center sequenc the center sequenc refer locat use number nucleotid experi present paper randomli select exampl exampl avail addit exampl inform splicejunct includ set rule deriv standard biolog textbook the rule set shown appear noordewi et al towel promot recognit success rate splice junction rule due larg tendenc just say no rule correctli classifi ie ei exampl experi section present set experi design determin rel strength weak two ruleextract method describ section compar ruleextract techniqu use two measur qualiti measur accuraci rule fidel network extract comprehens measur character whole set rule look individu rule final part section examin mean individu rule includ sampl rule extract train knn subset mofn system methodolog addit compar mofn algorithm subset compar mofn three symbol algorithm either ourston mooney c quinlan linu dzeroski lavrac first algorithm either ourston mooney method empir adapt set proposit rule correct train exampl c quinlan distinct algorithm compar build decis tree without use background knowledg howev extract rule tree like system consid final result c set rule final algorithm linu augment set input featur boolean featur repres truth valu consequ rule set henc promot domain linu featur avail origin plu rule use c induct compon linu henc result linu set rule may includ consequ origin rule train test methodolog neural network train network either a train exampl correct within desir output activ b everi exampl present time c improv classif occur five present everi train exampl the last termin criterion base upon fahlman lebier patienc metric follow hinton suggest improv network interpret weight subject gentl decay train addit network train use crossentropi error function hinton experi indic better abl handl type error occur knn standard error function rumelhart et al test exampl consid correctli classifi output within correct train test methodolog linu c c train use default code provid r quinlan specif use ten trial window procedur train set build ten decis tree tree transform ten rule set final optim set rule deriv ten rule set optim rule set use assess gener train test methodolog either neither train test either rather number report deriv ourston thesi either unabl work domain theori includ negat report result either splicejunct domain qualiti issu overrid import work qualiti extract rule measur qualiti least two dimension first rule must accur categor exampl seen train rule lose advantag accuraci kbann provid symbol learn algorithm towel et al littl valu rule extract would simpler use all symbol method is standard weight chang function term oe ad thu weight standard weight adjust rumelhart et al weight chang exampl present use gentl develop rule use kbann develop highlyaccur understand abl classifi second extract rule must captur inform contain knn necessari extract rule use gain understand exactli knn learn train measur show mofn superior subset also show accuraci rule extract mofn equal superior symbol algorithm importantli show mofn method extract rule equival network classifi test exampl accuraci assess accuraci system use ten repetit fold crossvalid weiss kulikowski figur plot averag tenfold crossvalid run comparison figur includ accuraci train knn prior rule extract the bar label network figur approxim here recal initi rule set promot recognit splicejunct determin correctli categor respect exampl henc system plot figur superior initi rule promot problem c linu either subset approxim equival testset accuraci method lag significantli behind mofn method somewhat surprisingli outperform linu although differ statist signific while accuraci rule extract either subset approxim equal method achiev accuraci quit differ wherea either perfect train set subset margin better train test set final rule extract mofn significantli superior with least confid rule extract method investig moreov differ accuraci rule extract mofn network came statist signific pattern result somewhat differ splice junction problem larg result rel improv c linu domain result c linu mofn origin network statist indistinguish rule gener subset method much wors perhap interest result dataset mofn rule outperform network came term train set accuraci earlier test towel shavlik show error tabl fidel extract rule train knn train exampl rule overal probabl agreement extract percent knn extract rule given method agreement knn correct knn incorrect splice junction subset mofn promot subset mofn rate extract rule promot problem also network rule extract howev alter train method to reduc overfit improv accuraci network without significantli affect accuraci extract rule section analyz result error rate subset rule test exampl statist wors rule learn method fidel fidel mean abil extract rule mimic behavior network extract fidel import two circumst extract rule tool understand behavior network extract rule use method transfer knowledg contain network tabl indic mofn superior subset reproduc behavior network exampl seen train these result obtain trial use previou section instanc splice junction data rule extract use mofn give answer train knn time rule extract subset match time addit tabl show method rule extract much better mimick behavior network network correct incorrect comprehens use extract rule must accur also must understand abl illdefin concept sever way understand might measur one approach look statist describ whole set rule altern examin whether individu rule meaning follow section present result measur global comprehens first dimens along character comprehens set rule ruleset size size concern set larg number rule difficult imposs understand figur address issu ruleset size plot ruleextract method space span number extract rule total number anteced rule the data figur repres averag crossvalid studi report figur unfortun count rule anteced mofn network straightforward mofn simplif phase may increas number rule requir reus anteced data figur blith ignor complic reflect rule anteced count unsimplifi rule set train network count anteced includ link whose weight within two order magnitud bia unit receiv link weight lesser size count littl effect final rule anteced count linu includ anteced deriv featur linu use rule deriv featur count singl anteced rule set extract linu would size extract c figur approxim here take initi rule set domain standard interpret rule refin symbol method like easi understand recal howev rule significantli less accur promot domain rule set extract mofn also like easili understood contain fewer rule approxim number anteced initi rule set hand rule subset extract much less like comprehens second import global statist number anteced per rule valu larg individu rule unlik understand bruner et al furthermor negat anteced add difficulti evalu rule nessier ween howev effect negat anteced difficult quantifi weight anteced appear mofn rule implicitli appear train network cloud pictur further rather arbitrarili assign difficulti rank type anteced figur simpli show number neg posit anteced averag rule figur approxim here measur ruleset size symbol method clear winner mofn rule slightli larger subset rule contain neg an teced still method return rule well within limit human comprehens miller recal mofn extract mani fewer rule individu comprehens global statist discuss suffici indic whether whole rule set like comprehens determin rule set potenti comprehens necessari look individu rule assess mean make assess examin rule set extract mofn subset method train knn entir set exampl problem domain tabl present rule mofn subset extract network promot recognit the rule extract splicejunct domain paper much charact promot domain appear towel rule set extract subset larg set fi p fi n valu small deliv reason accur rule set result rule tabl error rate train set rule extract mofn tabl somewhat murki vastli comprehens network link induc moreov rule rewritten form similar one use biolog commun name weight matric stormo one major pattern appar rule extract mofn subset specif knn learn disregard conform conform rule also drop either often use linu suggest drop rule artifact method rather dna nucleotid outsid minu minu region less import conform hypothesi koudelka et al suggest henc demonstr machin learn method provid valuabl evid confirm refut biolog theori gener rule mofn extract confirm import base identifi initi rule howev wherea initi rule requir match everi base extract rule allow less perfect match addit extract rule point tabl promot rule extract mofn promot minu minu cat rb x nt ac minu ctgac x nt ta minu ttdca x nt at tabl mean letter a g t c nt return number name anteced match given sequenc so nt c g would return match sequenc aaacaaaaa place chang sequenc import instanc final minu rule t posit strong indic rule true howev replac t g prevent rule ever satisfi difficult get clear pictur promot subset rule tabl three minu rule left column encod simpl of concept rule approxim of concept note pattern support idea implement mofn method bia toward mofn style concept use discuss result present section indic mofn method abl extract good set rule train network particular data support content mofn method abl extract comprehens rule train knn reproduc behavior knn extract extract rule equival superior rule obtain neurallybas symbol rulerefin method rule set produc mofn algorithm tabl promot rule extract subset promot minu minu minu minusb minusd minu tta minu minusa minusb minu tta minu minusa minusd minu gca minu tc minusb aca minusd ttc minusd tgc minusd tac minusd gac minusd tac abbrevi set rule extract subset test set accuraci set whose statist report previous section contain rule slightli larger produc all symbol approach mofn rule set small enough comprehens domain expert much ac curat henc although weigh tradeoff accuraci understand problem userspecif mofn algorithm networktorul translat offer appeal mixtur two result section deserv addit consider superior mofn rule obtain symbol rulerefin techniqu occasion superior mofn rule network extract first glanc might seem power mofn algorithm deriv use express languag rulerefin system true anteced consequ mofn rule boolean henc mofn rule written disjunct conjunct rule great increas number rule so hypothesi must reject still two hypothes explain superior mofn rulerefin method directli modifi rule first rerepresent rule set neural network allow finegrain refin cast neural network rule modifi small step may make possibl close fit target concept take larg step requir direct rule refin second hypothesi explain rel superior mofn symbol method rule refin mofn may better fit natur problem hand instanc promot problem sever potenti site hydrogen bond form dna protein enough bond form promot activ occur symbol method investig easili express mofn rule henc advantag mofn method may result output languag better fit natur languag dna sequenceanalysi prob lem gener viewpoint problem may natur languag parsimoni solv languag use learn system similar natur languag learn system abl effect learn solv problem hypothesi correct expect problem close fit induct bia symbol rulerefin system outperform mofn algorithm observ mofn rule superior network extract cannot attribut languag bia mofn style rule subset languag express use neural network instead advantag mofn rule like occur ruleextract process reduc overfit train exampl sever piec evid support hypothesi first note previous revis network train procedur reduc overfit promot domain elimin advantag mofn rule network extract is reduc degre network fit train data elimin advantag mofn rule network extract second differ abil correctli categor test train exampl smaller mofn rule train knn word rule mofn method extract slightli better classifi train exampl classifi test exampl while differ train test set perform smaller statist signific confid use onetail pairedsampl ttest rule subset extract also properti much wors train set mofn rule train knn test set asid expect subset algorithm abl exceed perform mofn two problem investig howev subset algorithm might expect equal accuraci mofn problem whose solut match bia toward set conjunct rule third piec evid support overfit hypothesi come work prune neural network elimin superflu part mozer smolenski le cun et al rule extract extrem form prune link unit prune action taken remain network transform network set rule prune effort also led gain test set perform gener research attribut gain reduc overfit train exampl test artifici problem previou section explor util mofn method context two realworld problem advantag realworld problem selfevid disadvantag realworld problem particular difficult close control studi investig abil algorithm instanc test previou section left unaddress question concern robust mofn method flaw initi domain theori know way domain theori incorrect therefor section step away real world look two artifici problem monk problem thrun et al do gain control distanc correct theori theori provid learn system control allow us make addit predict abil ruleextract algorithm monk problem chose monk problem test domain wide test thoroughli document problem afford easi replic monk problem origin describ thrun et al report author describ test machin learn algorithm monk problem consist popul exampl defin six also larg bodi literatur symbol machin learn suggest method reduc overfit train set improv gener eg quinlan featur appear top tabl first monk problem learn classifi exampl accord domain theori appear middl tabl domain theori simpli disjunct four conjunct theori easili express rule extract knn use either subset mofn second monk problem given rule near bottom tabl consider complex express concept disjunct conjunct requir rule six anteced altern concept express singl conjunct rule two claus express mofn concept rule appear bottom tabl addit complex second problem signific effect abil algorithm test thrun et al learn concept first problem test algorithm suppli train exampl nine system test problem correctli classifi whole popul overal system averag correct despit suppli exampl second problem four system test correctli classifi popul overal system averag correct system better second problem first experi question address experi section how difficult recov correct domain theori provid theori quit correct defin difficulti averag size train set need correctli identifi entir popul thi definit difficulti similar teach dimens goldman kearn except teach dimens learningsystem specif experi compar abil knn learn concept abil mofn subset extract rule express concept modifi domain theori three way first delet anteced rule test robust miss anteced second add negat unneg anteced rule test robust rule contain unnecessari anteced third swap unnecessari anteced correct anteced test abil simultan add delet anteced modifi everi rule theori instanc ad one anteced rule first monk problem see tabl creat rule set three rule three anteced one rule two anteced addit three type chang modifi domain theori accor featur name valu smile fye nog hold fsword balloon flagg jacketcolor fred yellow green blueg featur valu monk problem headshap round bodyshap round monk headshap squar bodyshap squar monk headshap octagon bodyshap octagon monk jacketcolor red monk correct theori first monk problem exactli two headshap round bodyshap round smile ye hold sword jacketcolor red hasti ye monk correct theori second monk problem two headshap round bodyshap round smile ye hold sword jacketcolor red hasti ye three headshap round bodyshap round smile ye hold sword jacketcolor red hasti ye monk reformul second monk problem tabl domain correct theori monk problem danc represent first domain theori negat anteced case system must learn anteced effect exactli opposit effect indic provid domain theori second domain theori alter requir number present absent anteced instanc rather requir exactli two anteced provid domain theori requir exactli anteced n f g also provid domain theori requir n anteced n f g ie match anteced would satisfi rule all examin five variant first monk problem fifteen variant second monk problem figur result result obtain creat knn base corrupt domain theori copi knn train use small percentag popul learn correctli classifi whole train set rule extract knn use mofn subset knn two set extract rule test entir popul three correctli classifi popul trial finish otherwis procedur repeat use new copi knn slightli larger train set which chosen includ member previous train set size train set increas three system correctli identifi entir popul entir popul use train result procedur size smallest train set requir knn two set extract rule correctli classifi entir popul figur plot averag repetit procedur five corrupt first monk theori eight corrupt second monk theori figur use data trial figur plot averag size term number anteced rule set extract subset mofn note figur short bar prefer knn unabl complet learn train data second monk problem sever nois condit describ abov particular knn fail even singl requir anteced swap unnecessari anteced knn also fail learn second problem told exact number match anteced three told n suffici total seven fifteen corrupt second domain theori result knn unabl learn train data seven case plot figur figur approxim here figur approxim here discuss signific trend figur that one case mofn learn concept fewer exampl knn requir result support suggest made section effect mofn attribut action postprun method network make suggest becaus case mofn learn concept knn not knn perfect train exampl knn problem classifi full popul spuriou correl among lowlyweight link impact categor exampl seen train ruleextract process use mofn act elimin link caus knn problem hand subset explicitli prune network mere attempt reproduc behavior network use boolean logic henc unsurpris that problem subset requir popul correctli identifi concept either mofn knn yet subset occasion quit well sever problem requir fewer train exampl knn one problem fewer mofn although occasion success often spectacularli bad one case complet unabl learn first problem despit knn reliabl acquir concept see popul look size concept identifi plot figur clear case mofn exactli identifi concept first problem mofn extract origin rule four five trial fifth trial mofn includ sever useless anteced extract rule interestingli one problem subset fail everi case mofn abl learn second problem extract correct rule final moder surpris knn unabl learn second problem corrupt rule set none corrupt particularli sever hope network would simpli resort knowledgefre start point would expect perform along line standard neural network fullyconnect randomlyiniti neural network singl layer hidden unit train use backpropag requir dataset reliabl learn first problem percent data reliabl learn second problem instead problem knn unabl learn fell local minima unabl escap observ prior knowledg hinder learn signific observ previous made pazzani focu paper not surprisingli knn unabl learn concept mofn subset rare extract rule express concept conclus experi show knn capabl learn rule underli concept mofn method abl extract set rule close approxim thereof knn relat work two distinct set work close relat ruleextract method present paper first set contain all symbol method learn rule exampl eg ourston mooney thompson et al dzeroski lavrac method avoid extract rule learn perform manipul directli rule method appeal requir shift symbol neural represent result present figur indic accur problem investig mofn method present here second set relat research attempt extract rule randomlyweight ann singl layer hidden unit saito nakano fu report method similar subset algorithm saito nakano look inputoutput behavior train network form rule map directli input output domain theori provid name hidden unit limit combinator inher algorithm like subset saito nakano limit rule four anteced howev even limit extract rule one output unit ann output thu method potenti use understand network may drown research sea rule sever group report attempt extract rule network that like knn welldefin architectur sestito dillon avoid combinatori problem approach rule extract transform network j input k output network j input train look link origin j input similar weight pattern one k addit input method discov hierarch rule set discov relationship robin isa bird isa anim network must output robin bird anim anoth method extract rule speciallyconfigur network mcmillan mozer smolenski connectionist scientist game use neural network iter learn set proposit rule method similar mofn algorithm except assum two group one larg posit weight one zero weight mani problem includ monk problem studi section assumpt quit use significantli constrain search space howev realworld problem assumpt may prove overli restrict final recent attempt extract fuzzi rule neural network instanc berenji describ method much like kbann except begin end fuzzi rule sever techniqu extract fuzzi rule neural network also report hayashi masuoka et al bochereau bourgin limit futur work result present section indic mofn method abl effect extract rule train knn therebi make kbann excel method refin exist rule howev method also sever limit heretofor briefli mention signific limit along brief discuss plan address limit are ffl mofn method requir network knowledg base is network must initi comprehens investig differ method train network knowledgebas yield network upon mofn method effect instanc nowlan hinton train method group link loos cluster may result network amen mofn ffl larg shift mean unit result train make extract rule difficult comprehend minimum system flag rule review better solut would give kbann way analyz extract rule ffl domain theori may provid sufficientlyrich vocabulari allow knn accur learn concept knn miss term requir express concept modifi exist term cover vocabulari shortfal often lead larg shift mean term discuss previou point case necessari augment knn addit hidden unit howev ad hidden unit open mani issu rais section extract rule network initi domain theori ffl system yet test broad rang problem discuss abov sequenc analysi problem often contain aspect mofnlik so mofn method may ideal suit sequenceanalysi problem two problem also share aspect relat sequenc analysi exampl initi domain theori problem overli specif empir test suggest kbann slightli effect domain theori overli specif towel henc test broader rang dataset need prove gener method addit extend kbann mofn method address limit current work ruleextract algorithm oper train knn rather allow link weight freeli take arbitrari valu algorithm period cluster link weight train thu consist altern cycl a standard weight adjust b round thi quit similar approach rule extract taken mcmillan mozer smolenski form rule produc method similar mofn rule howev search path weight space taken algorithm quit differ path taken mofn algorithm train instead undergo transit interpret set rule blackboxish knn back interpret set rule onlin cluster algorithm preserv comprehens knowledg base train also expect insight train process gain abl inspect knn knowledg base variou point train lastli investig way enhanc comprehens rule return mofn rule extract network mofn much comprehens network extract complet satisfi comprehens hope altern form present enhanc mofn algorithm differ network train method improv comprehens result rule conclus paper present empir valid mofn method extract rule knowledgebas neural network shown mofn method part kbann system form rulerefin algorithm result rule gener better exampl seen train rule produc allsymbol rule refin algorithm attribut gener abil shift represent initi domain theori symbol neurallybas shift alter bia system way enhanc abil accur refin initi rule particular neural represent natur admit mofn style concept addit neural represent allow gradat import anteced difficult achiev symbol learn system represent shift one use kbann system difficult effect pay handsom improv perform easiest represent shift involv train exampl rel eas shift result plethora comparison among empir learn system domainspecif knowledg much difficult shift represent initi work kbann provid method shift domainspecif knowledg form proposit horn claus neural network towel et al shift made knowledg avail neural learn algorithm backpropag result initi effort classifi accur obtain use train exampl towel et al noordewi et al one sens earlier result dead end refin knowledg train network inaccess previou paper provid method shift knowledg symbol neural provid method shift back symbol henc paper present method complet symbol circl do open dead end make highlyaccur neural classifi access humaninspect learn symbol orient system experiment result indic mofn method extract concis intellig rule train knn without seriou loss accuraci fact extract rule accur classifi test exampl network came moreov extract rule show util machin learn techniqu method valid refin realworld in case biolog theori final extra work requir system comparison all symbol rulerefin method shown worthwhil method provid superior rule small cost comprehens henc work show valu shift finegrain represent detail correct back commun correct acknowledg work partial support offic naval research grant nj nation scienc foundat grant iri depart energi grant de fger wish thank michiel noordewi construct two biolog rule data set gener comment work comment richard maclin mark craven deni kibler three anonym review also grate acknowledg final thank ross quinlan provid code c promot recognit splicejunct determin dataset part collect dataset ucirvin avail via anonym ftp icsuciedu directori pubmachinelearningdatabas r refin approxim reasoningbas control reinforc learn extract semant featur logic rule multilay neural network studi think learn relat noisi exampl empir comparison linu foil cascadecorrel learn architectur empir comparison id back propag rule learn search adapt net complex teach analysi e cluster algorithm compil analysi escherichia coli promot dna sequenc neural expert system autom extract fuzzi ifthen rule advanc neural inform process system vol connectionist learn procedur complex load shallow neural network effect noncontact base affin oper repressor cro neurofuzzi system fuzzi infer use structur neural network r rulebas configur comput system connectionist scientist game rule extract refin neural network magic number seven skeleton techniqu trim fat network via relev assess hierarchi concept attain train knowledgebas neural network recogn gene dna sequenc simplifi neural network soft weightshar advanc neural inform process system vol use explanationbas empir method theori revis phd thesi chang rule comprehens approach theori refin prior knowledg hinder learn direct transfer learn inform among neural network simplifi decis tree medic diagnost expert system base pdp model use multilay neural network learn symbol knowledg world scientif symbol neural net learn algorithm empir comparison consensu pattern dna two problem backpropag steepest descent learn procedur network use background knowledg concept format monk problem perform comparison differ learn algorithm symbol knowledg neural network insert interpret artifici neural network map knowledgebas neural network rule refin approxim correct domain theori knowledgebas neural network comput system learn tr ctr koji fujimoto sampei nakabayashi appli gmdh algorithm extract rule exampl system analysi model simul v n p octob milan zorman peter kokol bruno stiglic transform backpropag neural network decis tree use nndt cascad method second intern workshop intellig system design applic p august atlanta georgia khosrow kaikhah sandesh doddameti discov trend larg dataset use neural network appli intellig v n p februari rudi setiono huan liu symbol represent neural network comput v n p march petra povalej mitja leni peter kokol combin multipl specialist opinion cellular automata improv medic decis make proceed th wsea intern confer appli informat commun p decemb tenerif canari island spain rudi setiono wee kheng leow fernn algorithm fast extract rule fromneur network appli intellig v n p januaryapril marco muselli diego liberati binari rule gener via ham cluster ieee transact knowledg data engin v n p novemb steffen hlldobler yvonn kalink hanspet strr approxim semant logic program recurr neural network appli intellig v n p julyaugust gari w flake eric j glover steve lawrenc c lee gile extract queri modif nonlinear svm proceed th intern confer world wide web may honolulu hawaii usa witold pedrycz neural network handbook data mine knowledg discoveri oxford univers press inc new york ny o l mangasarian set contain character journal global optim v n p decemb yaochu jin bernhard sendhoff extract interpret fuzzi rule rbf network neural process letter v n p april ron sun knowledg extract reinforc learn new learn paradigm soft comput physicaverlag gmbh heidelberg germani rudi setiono extract rule neural network prune hiddenunit split neural comput v n p jan johan huysman bart baesen jan vanthienen new approach measur rule set consist data knowledg engin v n p octob sankar k pal sushmita mitra pabitra mitra roughfuzzi mlp modular evolut rule gener evalu ieee transact knowledg data engin v n p januari toni a plate joel a bert john a grace pierr a band visual function comput feedforward neural network neural comput v n p june judi goldsmith robert h sloan theori revis queri extend abstract proceed thirtysecond annual acm symposium theori comput p may portland oregon unit state amit gupta sang park siuwa m lam gener analyt rule extract feedforward neural network ieee transact knowledg data engin v n p novemb glenn fung sathyakama sandilya r bharat rao rule extract linear support vector machin proceed eleventh acm sigkdd intern confer knowledg discoveri data mine august chicago illinoi usa shlomo argamonengelson mosh koppel hillel walter maxim theori accuraci select reinterpret machin learn v n p novemb peter haddawi vu ha angelo restificar benjamin geisler john miyamoto prefer elicit via theori refin journal machin learn research zhihua zhou rule extract use neural network neural network journal comput scienc technolog v n p march hongjun lu rudi setiono huan liu neurorul connectionist approach data mine proceed th intern confer larg data base p septemb robert h sloan gyrgi turn theori revis queri proceed twelfth annual confer comput learn theori p juli santa cruz california unit state warodom geamsakul tetsuya yoshida kouzou ohara hiroshi motoda hideto yokoi katsuhiko takabayashi construct decis tree graphstructur data applic fundamenta informatica v n p januari judi goldsmith robert h sloan new horn revis algorithm journal machin learn research p judi goldsmith robert h sloan gyrgi turn theori revis queri dnf formula machin learn v n p mayjun kazumi saito ryohei nakano extract regress rule neural network neural network v n p decemb boonserm kijsirikul boonserm kijsirikul lerdlamnaochai firstord logic neural network intern journal hybrid intellig system v n p decemb anna l buczak wojciech ziarko neural rough set base data mine method engin handbook data mine knowledg discoveri oxford univers press inc new york ny artur s avila garcez gerson zaverucha connectionist induct learn logic program system appli intellig v n p julyaugust samuel h huang hao xing extract intellig concis fuzzi rule neural network fuzzi set system v n p decemb s c tan c p lim m v c rao hybrid neural network model rule gener applic process fault detect diagnosi engin applic artifici intellig v n p march volker tresp jrgen hollatz subutai ahmad repres probabilist rule network gaussianbasi function machin learn v n p may ioanni hatzilygeroudi jim prentza neurosymbol approach knowledg represent expert system intern journal hybrid intellig system v n p decemb zhihua zhou yuan jiang shifu chen extract symbol rule train neural network ensembl ai commun v n p januari zhihua zhou yuan jiang shifu chen extract symbol rule train neural network ensembl ai commun v n p may ismail a taha joydeep ghosh symbol interpret artifici neural network ieee transact knowledg data engin v n p may andrea nrnberger witold pedrycz rudolf kruse data mine task method classif neural network approach handbook data mine knowledg discoveri oxford univers press inc new york ny zijian zheng construct xofn attribut decis tree learn machin learn v n p juli martin holea piecewiselinear neural network relationship rule extract data neural comput v n p novemb ron sun todd peterson edward merril hybrid architectur situat learn reactiv sequenti decis make appli intellig v n p julyaugust henrik jacobsson rule extract recurr neural network taxonomi review neural comput v n p june russel greiner christian darken n iwan santoso effici reason acm comput survey csur v n p march