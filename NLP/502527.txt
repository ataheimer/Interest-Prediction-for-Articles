t proxim support vector machin classifi a instead standard support vector machin svm classifi point assign one two disjoint halfspac point classifi assign closest two parallel plane in input featur space push apart far possibl formul also interpret regular least squar consid much gener context regular network lead extrem fast simpl algorithm gener linear nonlinear classifi mere requir solut singl system linear equat contrast standard svm solv quadrat linear program requir consider longer comput time comput result publicli avail dataset indic propos proxim svm classifi compar test set correct standard svm classifi consider faster comput time order magnitud faster linear proxim svm easili handl larg dataset indic classif million point attribut set second comput result base line matlab code b introduct standard support vector machin svm power tool data classif classifi point assign one two disjoint halfspac halfspac either origin input space problem linear classifi higher dimension featur space nonlinear classifi standard svm requir solut either quadrat linear program requir special code contrast propos proxim svm psvm permiss make digit hard copi part work person classroom use grant without fee provid copi made distribut profit commerci advantag copi bear notic full citat first page copi otherwis republish post server redistribut list requir prior specif permiss andor fee kdd san francisco ca usa classifi point depend proxim one two parallel plane push far apart possibl fact geometr motiv proxim formul consid much gener context regular network result give extens theoret statist justif proxim approach contain extens comput implement result given here furthermor specif formul lead strongli convex object function alway case strong convex play key role simpl proxim code provid well fast comput time obtain obtain linear nonlinear psvm classifi requir noth sophist solv singl system linear equat effici fast linear equat solver freeli avail part standard commerci packag matlab solv larg system fast briefli summar content paper now section introduc proxim linear support vector machin give linear proxim algorithm explicit express leaveoneoutcorrect term problem data section introduc proxim kernelbas nonlinear support vector machin correspond nonlinear classifi nonlinear proxim algorithm section contain mani numer test result linear nonlinear classifi base extrem simpl matlab code line linear nonlinear psvm result surpass algorithm compar speed give compar test set correct word notat background materi vector column vector unless transpos row vector prime superscript vector x ndimension real space r n step function stepx defin n scalar inner product two vector x ndimension real space r n denot x norm x denot x matrix r mn ith row row vector r n j jth column a column vector one arbitrari dimens denot e r mn b r nk kernel kab map r mn r nk r mk particular x column vector r n then kx y real number kx row vector r kaa mm matrix base natur logarithm denot make use follow gaussian kernel frequent use svm literatur r mn b r nk posit constant ident matrix arbitrari dimens denot i linear proxim support vector consid problem depict figur classifi point ndimension real space r n repres n matrix a accord membership point class a a specifi given mm diagon matrix plu one minu one along diagon problem standard support vector machin linear kernel given follow quadrat program paramet min wyr nm depict figur w normal bound plane bound set a a respect constant determin locat rel origin two class strictli linearli separ error variabl which case shown figur plane x class a point plane x class a point follow consequ plane midway bound plane separ plane separ a a complet approxim depict figur quadrat term twice reciproc squar norm distanc w two bound plane see figur maxim distanc often call margin maxim margin enhanc gener capabl support vector machin class linearli insepar case shown figur two plane bound two class soft margin ie bound approxim error determin nonneg error variabl y is norm error variabl minim parametr weight result approxim separ plane depict figur plane act linear classifi follow x a point departur similar optim problem replac follow problem min wyr nm note explicit nonneg constraint need y compon neg object function decreas set still satisfi correspond inequ constraint note norm error vector minim instead norm margin bound plane maxim respect orient w rel locat origin extens comput experi indic formul good classic formul ad advantag strong convex object function key idea present paper make simpl fundament chang formul name replac inequ constraint equal follow min wyr nm modif even though simpl chang natur optim problem significantli fact turn write explicit exact solut problem term problem data show below wherea imposs previou formul combinatori natur geometr formul depict figur interpret follow plane x w bound plane anymor thought proxim plane around point class cluster push far apart possibl term w object function noth reciproc norm distanc squar two plane w space r n x a x x x x x x x psfrag replac w separ plane x figur standard support vector machin classifi wspace r n approxim bound plane equat soft ie error margin w plane equat approxim separ a a x x x x x a x x x x x x x psfrag replac separ plane x w figur proxim support vector machin classifi w space r n plane point set a a cluster push apart optim problem note formul also interpret regular least squar solut system linear equat daw e find approxim solut w least norm similarli standard svm formul interpret use linear program perturb theori least norm approxim solut system linear inequ e neither interpret howev base idea maxim margin distanc parallel plane key featur support vector machin karushkuhntuck kkt necessari sucient optim condit p equal constrain problem obtain set equal zero gradient respect w y u lagrangian lw y here u lagrang multipli associ equal constraint set gradient l equal zero give follow kkt optim condit first three equat give follow express origin problem variabl w y term lagrang multipli u substitut express last equal allow us obtain explicit express u term problem data follow h defin as u explicit solut w y problem given solut u entail invers possibl massiv mm matrix make immedi use shermanmorrisonwoodburi formula p matrix invers done result in express well anoth simpl express below involv invers much smaller dimension matrix order n complet solv classif problem concret explicitli state simpl algorithm algorithm linear proxim svm given data point r n repres n matrix diagon matrix label denot class row a gener linear classifi follow i defin h e vector one comput u posit typic chosen mean tune valid set ii determin w iii classifi new x use standard svm support vector consist data point complement data point drop problem without chang separ plane thu standard svm formul support vector correspond data point lagrang multipli nonzero becaus solv data point give answer solv entir dataset proxim formul howev lagrang multipli u mere multipl error vector y y given con sequent compon typic nonzero sinc none data point usual lie proxim plane x concept support vector need modifi follow w r n given linear function follow basi theorem linear equat theorem lemma appli last equal fix valu error vector y n linearli independ data point need determin basic nonzero compon w r n guid fact small number data point character specif w defin concept support vector data point error vector less absolut valu typic pick small enough data support vector resolv proxim svm problem data point adjust typic upward tune set give test set correct essenti ident obtain use entir dataset note explicit express w y u term problem data given abl get also explicit express leaveoneoutcorrect looc fraction correctli classifi data point point turn left psvm formul classifi classifi omit algebra follow leaveoneoutcorrect step function defin introduct here h defin h denot row h h denot h row h remov h u defin h replac h similarli denot row d extend result nonlinear proxim support vector machin nonlinear proxim support vector machin obtain nonlinear proxim classifi modifi equal constrain optim problem replac primal variabl w dual equival du obtain min e object function also modifi minim weight norm sum problem variabl u y replac linear kernel aa nonlinear kernel defin introduct obtain min use shorthand notat lagrangian written similarli as lu y here v r lagrang multipli associ equal constraint set gradient lagrangian respect u y v equal zero give follow kkt optim condit first three equat give follow express u y term lagrang multipli v substitut express last equal give explicit express v term problem data follow e g defin as note similar g h defin similar allow us obtain g express replac k taken advantag matlab code algorithm written linear classifi thu gener nonlinear classifi algorithm mere replac k algorithm solut v solut u y problem given unlik situat linear kernel shermanmorrisonwoodburi formula useless kernel matrix squar invers must take place potenti highdimension r howev reduc kernel techniqu util reduc m dimension kernel much smaller m dimension rectangular kernel small random submatrix a reduc kernel make larg problem tractabl also often lead improv gener avoid data overfit eectiv reduc kernel demonstr mean numer test problem next section paper nonlinear separ surfac correspond kernel equat deduc linear separ surfac follow replac x correspond kernel express substitut u obtain nonlinear separ surfac correspond nonlinear classifi nonlinear separ surfac then x a give explicit statement nonlinear classifi algorithm algorithm nonlinear proxim svm given data point r n repres m n matrix diagon matrix label denot class row a gener nonlinear classifi follow i choos kernel function kaa typic gaussian kernel ii defin g vector one comput v posit typic chosen mean tune set iii nonlinear surfac comput v constitut nonlinear classifi classifi new point x nonlinear classifi direct gener linear classifi work quit eectiv indic numer exampl present next section numer implement comparison comput perform univers wisconsin data mine institut locop machin util mhz pentium ii allow maximum gigabyt memori process comput run window nt server matlab instal even though locop multiprocessor machin one processor use experi sinc matlab singl thread applic distribut load across processor algorithm requir solut singl squar system linear equat size number input attribut n linear case size number data point nonlinear case use rectangular kernel size problem reduc k k nonlinear case simplic algo rithm give actual matlab implement use experi consist line nativ matlab code figur spiral dataset consist black point white point intertwin two spiral dimension space psvm gaussian kernel gener sharp nonlinear spiralshap separ code psvm matlab code function psvmlinear nonlinear classif note command line matlab code abov comput directli factor much econom stabl comput invers explicitli multipli h e calcul h e involv transpos typic larg matric time consum instead calcul rsumh wsa respect transpos vector note matlab code work linear classifi also nonlinear classifi well nonlinear case matrix kaa use input instead a equat pair return instead w nonlinear separ surfac given as rectangular kernel also handl code input rectangular matrix ka r mk k given output pair u u u associ reduc matrix a final note regard simplif psvm substitut express u obtain algebra follow simpl express w term problem data e direct explicit solut psvm problem written follow singl line matlab code also perform explicit matrix invers e slightli faster matlab code here accord matlab command diagd m vector gener diagon matrix d comput test result use onelin matlab code slightli better obtain code one report tabl below comment solut also obtain directli use equal constraint elimin problem solv result unconstrain minim problem variabl w set zero gradient respect w turn comput dataset use numer test follow seven publicli avail dataset uci machin learn repositori wpbc ionospher cleveland heart pima indian bupa liver mush room tictacto censu dataset version us censu bureau adult dataset publicli avail silicon graphic websit galaxi dim dataset use galaxi discrimin neural network two larg dataset million point attribut creat use david music ndc data gener spiral dataset propos alexi wieland mitr corpor avail cmu artifici intellig repositori outlin comput result five group follow tabl comparison seven dierent method adult dataset experi compar perform seven dierent method linear classif dierent size version adult dataset report result sor smo svm light result lsvm result comput use locop wherea ssvm rlp smo experi run mhz pentium ii processor window nt use microsoft visual c compil sor experi run mhz pentium pro megabyt ram also window nt use visual c svm light experi run hardwar sor solari oper system bold type indic best result dash indic result avail although time comparison approxim dierent machin use indic psvm distinct edg speed eg solv largest problem second much faster method time tenfold test correct shown tabl time tenfold tabl compar perform lsvm psvm larg dataset two larg dataset consist million point attribut creat use ndc data gener one call ndceasi highli linearli separ around one call ndchard sinc linear separ around shown tabl linear classifi obtain use method perform almost ident despit million size dataset psvm solv problem second compar lsvm time second contrast svm light fail problem tabl comparison psvm ssvm lsvm svm light use linear classifi experi compar four method psvm ssvm lsvm svm light seven publicli avail dataset uci machin learn repositori shown tabl correct four method similar execut time includ tenfold cross valid psvm smaller much one order magnitud three method test sinc lsvm ssvm psvm base similar formul classif problem valu use them svm light tradeo trade error margin repres paramet c valu c chosen tune pair ttest confid level perform compar perform psvm algorithm test pvalu obtain show signific dierenc psvm method test figur psvm spiral dataset use gaussian kernel order classifi spiral dataset dataset consist black white point intertwin shape spiral synthet dataset howev appar di cult test case data mine algorithm known give neural network sever problem con trast sharp separ obtain use psvm seen figur tabl nonlinear classifi comparison use psvm ssvm lsvm experi chose four dataset uci machin learn repositori known nonlinear classifi perform significantli better linear classifi use psvm ssvm lsvm order find gaussiankernelbas nonlinear classifi classifi data dataset test three method perform similarli far tenfold cross valid concern howev execut time psvm much smaller two method note mushroom dataset consist point attribut each squar kernel matrix fit memori order address prob lem use rectangular kernel r instead describ gener algorithm perform particularli well rectangular kernel sinc system solv size k k k k much smaller number row a contrast full squar kernel matrix system solv size m pair ttest confid level perform compar perform psvm algorithm test pvalu obtain show signific differ psvm method test far tenfold test correct concern conclus futur work propos extrem simpl procedur gener linear nonlinear classifi base proxim one two parallel plane push far apart po sibl procedur proxim support vector machin psvm requir noth sophist solv simpl nonsingular system linear equat either linear nonlinear classifi contrast standard support vector machin classifi requir costli solut linear quadrat program linear classifi need psvm invers small matrix order input space dimens typic order less even million data point cla sifi nonlinear classifi linear system equat order number data point need solv allow us easili classifi dataset mani thousand point larger dataset data select reduct method util indic numer result subject futur work comput result demonstr psvm classifi obtain test set correct statist compar standard svm classifi fraction time sometim order magnitud less anoth avenu futur research increment classif larg dataset appear particularli promis view simpl explicit solut linear nonlinear psvm classifi updat increment new data point come stream in sum up princip contribut work ecient classifi requir special softwar psvm easili incorpor sort data mine applic requir fast simpl eectiv classifi acknowledg research describ data mine institut report februari support nation scienc foundat grant ccr cda air forc oce scientif research grant f microsoft corpor grate professor cj lin nation taiwan univers point refer upon read origin version paper least squar also use construct svm explicit requir mercer posit definit condit need here fur thermor object function quadrat program strongli convex like our import featur psvm influenc speed evidenc mani numer comparison given r lapack user guid robust linear program discrimin two linearli insepar set massiv data discrimin via linear support vector machin us censu bureau tutori support vector machin pattern recognit learn data concept cplex optim inc regular network support vector machin regular network support vector machin interior point method massiv support vector machin data select support vector machin classif theori linear econom model matrix comput data mine spars grid make largescal support vector machin learn practic rsvm reduc support vector machin ssvm smooth support vector machin nonlinear program gener support vector machin nonlinear perturb linear program success overrelax support vector machin activ support vector machin classif lagrangian support vector machin lipschitz continu solut linear inequ mathwork machin learn uci repositori machin learn databas ndc normal distribut cluster dataset autom stargalaxi discrimin neural network sequenti minim optim fast algorithm train support vector machin advanc larg margin classifi least squar support vector machin classifi solut illpos problem natur statist learn theori natur statist learn theori twin spiral dataset tr lipschitz continu solut linear inequ program complementar problem natur statist learn theori matrix comput rd ed make largescal support vector machin learn practic fast train support vector machin use sequenti minim optim least squar support vector machin classifi data select support vector machin classifi machin learn learn data tutori support vector machin pattern recognit lagrangian support vector machin ctr weny li kinhong lee kwongsak leung largescal rlsc learn without agoni proceed th intern confer machin learn p june corvali oregon soumen chakrabarti shourya roy mahesh v soundalgekar fast accur text classif via multipl linear discrimin project proceed th intern confer larg data base p august hong kong china tsong song hwang tsungju lee yuhjy lee threetier id via data mine approach proceed rd annual acm workshop mine network data june san diego california usa simon i hill arnaud doucet adapt twoclass support vector classif method mani class problem proceed nd intern confer machin learn p august bonn germani thorsten joachim train linear svm linear time proceed th acm sigkdd intern confer knowledg discoveri data mine august philadelphia pa usa glenn fung sathyakama sandilya r bharat rao rule extract linear support vector machin proceed eleventh acm sigkdd intern confer knowledg discoveri data mine august chicago illinoi usa hwanjo yu jiong yang jiawei han xiaolei li make svm scalabl larg data set use hierarch cluster index data mine knowledg discoveri v n p novemb kristin p bennett michinari momma mark j embrecht mark boost algorithm heterogen kernel model proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli edmonton alberta canada hwanjo yu jiong yang jiawei han classifi larg data set use svm hierarch cluster proceed ninth acm sigkdd intern confer knowledg discoveri data mine august washington dc tonatiuh pea centeno neil d lawrenc optimis kernel paramet regularis coeffici nonlinear discrimin analysi journal machin learn research p yang ali r hurson contentawar search multimedia data ad hoc network proceed th acm intern symposium model analysi simul wireless mobil system octob montral quebec canada bin li mingmin chi jianp fan xiangyang xue support cluster machin proceed th intern confer machin learn p june corvali oregon dacheng tao xuelong li xindong wu weim hu stephen j maybank supervis tensor learn knowledg inform system v n p septemb hwanjo yu xiaoqian jiang jaideep vaidya privacypreserv svm use nonlinear kernel horizont partit data proceed acm symposium appli comput april dijon franc brian whitman deb roy barri verco learn word mean descript paramet space music proceed hltnaacl workshop learn word mean nonlinguist data p may soumen chakrabarti shourya roy mahesh v soundalgekar fast accur text classif via multipl linear discrimin project vldb journal intern journal larg data base v n p august glenn fung murat dundar jinbo bi bharat rao fast iter algorithm fisher discrimin use heterogen kernel proceed twentyfirst intern confer machin learn p juli banff alberta canada glenn m fung o l mangasarian multicategori proxim support vector machin classifi machin learn v n p may deepak k agarw shrinkag estim gener proxim support vector machin proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli edmonton alberta canada glenn m fung olvi l mangasarian alexand j smola minim kernel classifi journal machin learn research p w a chaovalitwongs p m pardalo time seri support vector machin use dynam time warp kernel brain activ classif cybernet system analysi v n p januari yuhjy lee wenfeng hsieh chienm huang epsilonssvr smooth support vector machin epsiloninsensit regress ieee transact knowledg data engin v n p may ryan rifkin aldebaro klautau defens onevsal classif journal machin learn research p rolando grave de peralta menendez quentin noirhomm febo cincotti donatella mattia fabio alois sara gonzlez andino modern electrophysiolog method braincomput interfac comput intellig neurosci v n p april rolando grave de peralta menendez quentin noirhomm febo cincotti donatella mattia fabio alois sara gonzlez andino modern electrophysiolog method braincomput interfac comput intellig neurosci v n p august