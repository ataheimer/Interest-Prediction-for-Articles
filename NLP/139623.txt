t converg tdmyampersandlambda gener myampersandlambda a method tempor differ td one way make consist predict futur paper use analysi watkin extend converg theorem due sutton case use inform adjac time step involv inform arbitrari onesit also consid version td behav face linearli depend represent statesdemonstr still converg differ answer least mean squar algorithm final adapt watkin theorem cal qlearn close relat predict action learn method converg probabl one demonstr strong form converg slightli modifi version td b introduct mani system oper tempor extend circumst whole sequenc state rather individu one import system may frequent predict futur outcom base potenti stochast relationship current state furthermor often import abl learn predict base experi consid simpl version problem task predict expect ultim termin valu start state absorb markov process random process gener termin valu absorb state one way make predict learn transit matrix chain expect valu absorb state solv simultan equat one fell swoop simpler altern learn predict directli without first learn transit method tempor differ td first defin sutton fall simpler categori given parametr way predict expect valu state alter paramet reduc inconsist estim one state estim next state state learn happen increment system observ state termin valu sutton prove result converg particular case td method mani control problem formalis term control absorb markov pro cess polici ie map state action defin absorb markov chain engin method dynam program dp use predict expect termin valu way judg henc improv polici td method also extend accomplish thi discuss extens watkin barto sutton watkin td actual close relat dp way significantli illumin work paper use watkin insight extend sutton theorem special case td consid inconsist adjac state gener case arbitrari state import weight exponenti less accord tempor distanc also consid td converg represent adopt state linearli depend prove one version td predict converg probabl one cast form qlearn earliest work tempor differ method due samuel checker draught play program tri learn consist function evalu board posit use discrep predict valu state base limit depth gamestre search subsequ predict valu number move elaps mani propos along similar line made sutton acknowledg influenc klopf discuss holland bucket brigad method classifi system procedur witten hampson present empir result quit similar navig task one describ barto sutton watkin barto sutton anderson describ earli td system learn balanc upend pole problem introduc relat paper michi chamber watkin also gave refer next section defin td show use watkin analysi relationship dp extend sutton theorem make comment unhelp state represent section look qlearn use version watkin converg theorem demonstr particular case strongest guarante known behaviour td sutton develop rational behind td method predict prove td special case time horizon one step converg mean observ absorb markov chain although theorem appli gener illustr case point anexampl simpl random walkshown figur here chain alway start state d move left right equal probabl state reach left absorb barrier right absorb barrier g problem face td estim probabl absorb right hand barrier rather left hand one given state current locat insert figur raw inform avail system collect sequenc state termin locat gener random walk initi knowledg transit probabl sutton describ supervis least mean squar lm techniqu work make estim probabl place visit sequenc closer sequenc end right hand barrier closer end left hand one show techniqu exactli td one special case td contrast td particularli td tri make estim probabl one state closer estim next without wait see sequenc might termin discount paramet td determin exponenti weight futur state base tempor distanc smoothli interpol next state relev lm case state equal weight describ introduct obeis tempor order sequenc mark td follow subsect describ sutton result td separ algorithm vector represent state show watkin analysi provid wherewith extend tdand final reincorpor origin represent converg theorem follow sutton consid case absorb markov chain defin set valu termin state nontermin state vector repres nontermin state expect termin valu state j probabl start state i p payoff structur chain shown figur degener sens valu termin state g determinist respect make expect valu state probabl absorb g estim system fed complet sequenc x observ vector togeth scalar termin valu z gener everi nontermin state predict expect valu ezji start state transit matrix markov chain complet known predict could comput as again follow sutton let m ab denot ab th entri matrix m u denot th compon vector u q denot squar matrix compon q ab denot vector whose compon h n equat sutton show exist limit equat follow fact q transit matrix nontermin state absorb markov chain which probabl one ultim termin learn phase linear td gener success vector w chang complet observ sequenc predict subsequ superscript use indic tdbase estim termin valu start state i stage n learn then one sequenc intermedi predict termin valu and abus notat somewhat defin also z observ termin valu note sutton use p n accord to ff learn rate sutton show td normal lm estim also prove follow theorem theorem absorb markov chain distribut start probabl inaccess state outcom distribut finit expect valu z j linearli independ set observ vector fx ji ng exist ffl that posit ff ffl initi weight vector predict linear td with weight updat sequenc converg expect valu ideal predict is w n denot weight vector n sequenc experienc lim true case paper prove theorem gener localist represent equat conflat two issu underli td algorithm represent predict function v n even though remain tangl ultim proof converg benefici separ out sinc make oper algorithm clearer consid repres v n lookup tabl one entri state equival choos set vector x one compon other state two state represent trivial satisfi condit sutton theorem also make wn easi interpret compon predict one state use also prevent generalis represent term rwn v sum reduc count number time chain visit state exponenti weight recenc case full linear case term depend n state chain visit defin characterist function state j predict function v n i entri lookup tabl state stage n learn equat reduc element piec valu state updat separ illustr process consid punctat represent state b c d e f figur observ sequenc d c d e f e f g sum step are compon sum clearli time t state g absorb repres contract map watkin show fruit way look td estim dynam program associ contract map method start current predict function vn i n show defin whole collect statist better estim vn i n base observ sequenc use td linear combin estim except explicitli note section follow watkin exactli equat develop exact analogu linear represent seen subsect imagin chain start state run forward state ultim absorb defin rstep estim either estim vn i r state r chain absorb r step r n observ termin valu z sequenc chain absorb time formal defin random variabl vn i z otherwis vn z otherwis vn i r z otherwis first state access markov chain one particular sequenc start second on z observ termin valu chain get absorb time step r reach random variabl sinc depend particular sequenc state observ natur also depend valu vn i point chain absorb complet step v r r base termin valu provid world rather one deriv bootstrap vn i v r therefor averag accur vn use increment improv it shown look differ e ezji ideal predict here trt vn i r wherea easili shown trt therefor watkin actual treat slightli differ case target valu predictor base discount futur valu whose contribut diminish exponenti time happen case easier see reduct error brought about analogu equat wa discount factor sinc p q matrix markov chain watkin could guarante provid weak guarante error v r n less vn nondiscount case differ here initi state nonzero probabl chain absorb finish r step case valu v r z unbias provid error reduct even chain absorb valu inaccur compon vn although error reduct due fl guarante inequ state possibl absorb within r step ensur sinc maximum could achiev patholog state fromwhich imposs absorb r step howev estim state within r step absorpt will averag improv should averag filter back state watkin demonstr td base weight averag v consid also valid estim termin valu start point choos valu trade bia caus error vn varianc real termin valu z higher signific v r higher valu r effect unbias termin valu have lead higher varianc lower bia convers lower less signific contribut higher valu r less effect unbias termin valu lead smaller varianc greater bia remain shown td inde base combin estim expand sum equat vn i vn i vn i vn i defin vn i whole point defin v use make v accur obviou increment updat rule achiev vn i vn i vn i equat appar chang vn i involv sum futur valu vn i t vn i weight power follow watkin differ calcul activ trace base characterist function t defin earlier way count often recent chain enter particular state use index member observ sequenc onlin version td rule problem sutton treat chang vn appli offlin complet sequenc chain therefor state chain pass one sequenc absorb termin valu vn i vn new estim experienc sequenc vn i vn i ff vn i t vn i vn i vn i ff vn i t vn i vn i vn i vn i sum term note express exactli td weight chang formula equat thu actual td algorithm base exponenti weight sum defin equat outcom v r random variabl themean contract properti variabl therefor determin mean contract properti overal td estim linear represent previou subsect consid td algorithm isol represent sutton use although number differ represent might employ simplest linear one adopt identifi vector x state repres vn wn x wn weight vector stage n learn basic algorithm concern v predictor random variabl rather valu use chang initi predictor vn new represent equat longer make sens sinc state cannot separ appropri manner rather inform error use updat weight depend appropri formula deriv deltarul vn i rwn vn i weight error due state vector represent equival equat sutton main td equat sophist represent kdtree see review cmac may lead faster learn better generalis requir separ converg proof compar qualiti certain differ represent barto sutton watkin grid task proof theorem strategi prove theorem follow sutton consid expect valu new predict weight vector given observ complet sequenc follow watkin split chang compon due equival v r random variabl sum them mean error reduct iter assur equival equat linear represent defin v r random variabl equat z otherwis x identifi state observ sequenc w r n current weight vector defin estim termin valu z actual valu then observ whole sequenc w r n updat as visit vn i rwn vn i visit exact parallel sutton proof procedur turn appli w r defin j ij number time sstep transit occur intermedi state x kt n sum equat regroup term sourc destin state transit ff z z j indic termin valu gener distribut due state j extra term gener possibl that visit x n chain absorb take r step take expect valu sequenc n ik q kj ik q kj expect number time markov chain state one sequenc absorb markov chain known depend probabl start variou state is substitut equat take expect side note depend ew r n n linear use w denot expect valu close relat equat emerg linear represent z defin x matrix whose column x x ab x diagon ab ffi ab kroneck delta rememb h convert matrix form sinc x cover possibl option rgammastep move state i defin correct predict e also equat e sum converg sinc chain absorb anoth way write equat multipli equat left x subtract e side equat note equat give updat rule equival equat e e e watkin construct td develop equat previou section reveal that start w r therefor sinc e io h e e w expect weight td procedur sum converg sinc truth theorem shown demonstr ffl e estim tend correct almost sutton proof appli mutati mutandi case alway provid crucial condit hold x full rank complet entir proof given appendix overal impli expect valu estim converg desir valu sequenc observ condit state theorem t nonindepend x move watkin representationfre proof sutton treatment linear case one assumpt x vector repres state indepen dent not matrix x full rank proof break down still posit howev x xd longer full set eigenvalu posit real part sinc null subspac empti nonzero member eigenvector eigenvalu say happen expect valu weight turn easier understand it choos basi basi y proof appendix appli exactli b exist lim also h definit y write e e xd e help understand result consid equival lm rule td xd e so sinc symmetr e e e e equat weight w squar error state expect number visit one sequenc therefor quadrat form e e load squar error predict state desir valu load factor expect frequenc markov chain hit state condit equat impli expect valu weight tend minimis error happen gener intuit tradeoff bia varianc return case x full rank sutton show harmless use inaccur estim next state x t w criticis estim current state x w x full rank success estim becom bias account might deem share represent amount extra bia relat amount share frequenc transit happen one state next formalis lead second issu interact two statist process calcul mean weight calcul expect number transit compar equat one might expect lim e howev key step prove equat transit equat reli symmetri d sinc q gener symmetr happen defin w e e e actual happen g although behaviour describ equat satisfactori describ equat reveal consid happen one attempt arrang hold achiev complet deriv ie learn rule whose effect e e q term effect arrang backward well forward learn occur would state adjust estim make like state t also state would adjust estim make like state werbo sutton person commun discuss point context gradient descent td rather converg nonindepend x werbo present exampl base learn techniqu similar td complet deriv manner make rule converg away true solut fault procedur introduc unhelp correl learn rule random move one state next mention abov point converg term function g equat w weight fix sutton present exampl help explain result first sight augment td seem quit reason could quit easili happen random chanc train sequenc predict one state accur predict next point therefor train second like first would help howev sutton point time choic alway move forward backward imagin case shown figur number arrow repres transit probabl number termin node repres termin absorb valu insert figur here valu state reason probabl end either z valu state b though chain certain end y train forward give thi train backward make valu b tend werbo term correl weight possibl transit count augment term incident result affect td train valu termin valu sequenc bear relat transit themselv number time state visit come back case x full rank td still converg away best valu degre determin matrix converg probabl one sutton proof proof previou section accomplish nadir stochast converg viz converg mean rather zenith viz converg probabl one watkin prove converg probabl one form predict action learn call qlearn section show result appli almost directli discount predict version td albeit without linear represent provid first strong proof tempor differ method like dynam program dp qlearn combin predict control consid control discount nonabsorb markovprocess ie one state finit set possibl action a take one action lead immedi reward random variabl r a whose distribut depend a stochast transit accord markov matrix p ij a j n agent polici i a determin action would perform state defin valu v i satisfi fl discount factor defin q valu state action polici as valu take action follow polici thereaft theori dp impli polici least good take action state bg follow state fact lie util q valu discount problem turn least one optim polici defin q a qlearn method determin q henc optim polici base explor effect action state consid sequenc observ i n process state n probe action take state j n give reward z n defin recurs qn i a otherwis start valu q i a un j n bg ff n set learn rate obey standard stochast converg criteriax a k th time a watkin prove if addit reward bound then probabl one lim consid degener case control markov process one action possibl everi state case q v similarli defin u valu exactli equal q equat exactli onlin form td case nonabsorb chain reward ie termin valu discuss context absorb markov chain arriv everi state rather particular set absorb state therefor condit watkin theorem onlin version td converg correct predict probabl one although clearli td procedur variou differ one describ previou section here learn onlin v q valu chang everi observ also learn need proceed along observ sequenc requir j uncoupl disembodi move use condit equat consequ everi state must visit infinit often also note sutton proof sinc confin show converg mean work fix learn rate ff wherea watkin common stochast converg proof requir ff n tend also state qlearn theorem appli discount nonabsorb markov chain rather absorb one previou section one watkin main motiv allow system learn effect action believ suboptim import r ole watkin proof bound effect earli qn valu fairli easi modifi proof case absorb markov chain ever increas probabl absorpt achiev effect also condit sutton theorem impli everi nonabsorb state visit infinit often suffic one set ff satisfi condit appli sequenti visit state normal run chain conclus paper use watkin analysi relationship tempor differ td estim dynam program extend sutton theorem td predict converg mean case theorem t td gener also demonstr vector repres state linearli independ td converg differ solut least mean squar algorithm further appli special case watkin theorem qlearn method increment dynam program converg probabl one show td use localist state represent also converg probabl one leav open question whether td punctat distribut represent also converg manner appendix exist appropri ff defin necessari show ffl case for formula remain correct x full rank sutton prove page show success di gamma q posit full set eigenvalu whose real part posit final ff thu chosen eigenvalu gamma ffx xdi gamma q less modulu proof requir littl alter case path follow exactli equival di gamma q posit definit accord lemma varga observ sutton shown strictli diagon domin posit diagon entri part proof differ sutton even here structur rather similar sinc q matrix absorb markov chain q r diagon element therefor r posit diagon element also j sinc element q henc also q r posit case r strictli diagon domin if if p strict inequ i equat follow equat equat hold sinc equat hold sinc p chain absorb q also exist least one inequ strict i strictli diagon domin r strictli diagon domin too therefor posit definit next stage show x xd full set eigenvalu whose real part posit x x non singular ensur set full let u eigenvalueeigenvector pair indic conjug transpos impli xv xv equival b sinc right side by posit definit xv xv strictli posit real part must strictli posit too furthermor u must also eigenvector sinc therefor eigenvalu gamma ffx xd posit ae take eigenvalu eigenvalu gamma ff iter matrix guarante modulu less one anoth theorem varga lim r new approach manipul control cerebellar model articul control cmac neuronlik element solv difficult learn problem learn sequenti decis make appli dynam program reinforc connection learn statist way neural model adapt behavior connectionist problem solv comput aspect biolog learn escap brittl possibl generalpurpos learn algorithm appli parallel rulebas system brain function adapt system heterostat theori hedonist neuron theori memori box experi adapt control effici memorybas learn robot control effici algorithm neural network behaviour studi machin learn use game checker studi machin learn use game checker ii recent progress tempor credit assign reinforc learn learn predict method tempor differ matrix iter analysi learn delay reward consist hdp appli simpl reinforc learn problem adapt signal process adapt optim control discretetim markov environ tr ctr claudenicola fiechter effici reinforc learn proceed seventh annual confer comput learn theori p juli new brunswick new jersey unit state fernando j pineda meanfield theori batch td lgr neural comput v n p oct vladislav b tadi asymptot analysi temporaldiffer learn algorithm constant stepsiz machin learn v n p may satind singh peter dayan analyt mean squar error curv tempor differencelearn machin learn v n p juli vladislav tadi converg analysi temporaldiffer learn algorithm linear function approxim proceed twelfth annual confer comput learn theori p juli santa cruz california unit state satind singh tommi jaakkola michael l littman csaba szepesvri converg result singlestep onpolicyreinforcementlearn algorithm machin learn v n p march vladislav tadi converg temporaldiffer learn linear function approxim machin learn v n p march peter auer philip m long structur result onlin learn model without queri machin learn v n p sept kazunori iwata kazushi ikeda hideaki sakai asymptot equipartit properti reinforc learn relat return maxim neural network v n p januari john w sheppard colearn differenti game machin learn v n p novdec david choi benjamin roy gener kalman filter fix point approxim effici temporaldiffer learn discret event dynam system v n p april craig boutili plan learn coordin multiag decis process proceed th confer theoret aspect ration knowledg march netherland florentin wrgtter bernd porr tempor sequenc learn predict control review differ model relat biolog mechan neural comput v n p februari