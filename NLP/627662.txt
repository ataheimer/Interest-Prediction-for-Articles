t unifi integr explicit knowledg learn exampl recurr network a abstractw propos novel unifi approach integr explicit knowledg learn exampl recurr network explicit knowledg repres automaton rule directli inject connect network accomplish use techniqu base linear program instead learn random initi weight learn conceiv refin process mainli respons uncertain inform manag present preliminari result problem automat speech recognit b introduct resurg interest connectionist model led sever research investig applic build intellig system unlik symbol model propos artifici intellig learn play central role connectionist model mani success applic mainli concern perceptu task see eg research partial support murst cnr grant ct author dipartimento di sistemi e informatica universita di firenz via di santa itali tel telex unf fax discov explicit rule seem either natur easi connectionist model appear better suit low level task symbol one like human reli learn perceptu task hand learn exampl paradigm cannot stress much emul intellig behavior mani case intellig behavior follow explicit rule matter fact machin conceiv situat ignor knowledg order prove potenti power learn exampl paradigm problem learn sequenc research recent shown explicit rule also discov learn tabula rasa configur particular cleereman elman william demonstr full connect recurr network capabl learn small automata investig interest sinc show connectionist model learn rule reli present exampl howev closer investig show cannot stress much learn exampl paradigm problem complex task may give rais local minima ordinari gradient descent learn algorithm like fail case least feedforward net analysi problem carri allow us understand success backpropag sever problem pattern recognit howev use theori easili proven simpl exampl exist learn algorithm fail discov optim solut integr explicit knowledg learn exampl appear natur way evolv intellig system base connectionist model hypothesi model effect integr uniform consequ explicit learn rule repres way weight connect neural network paper address problem learn sequenc assum explicit knowledg problem avail term automaton rule basic assumpt implement automata reli state equat do effort focuss find method inject automaton rule connect recurr network section ii demonstr automaton state code neuron activ and section iii automaton rule realiz term constraint weight particular automaton rule translat set inequ accord linear program framework basi remark section iv propos unifi approach integr explicit knowledg learn exampl paradigm recurr neural network propos architectur compos two cooper subnet first one design order inject avail explicit knowledg wherea second one mainli respons uncertain inform effect propos model current evalu problem automat speech recognit section v report preliminari result problem isol word recognit chosen test base italian speech databas quit difficult sinc word compos nasal vowel purpos experi mainli provid materi discuss behavior propos model practic unlik mani suggest solut propos literatur base learn exampl propos model like scale well increas lexicon ii inform latch let n u set neuron extern network input respect neuron receiv input n u recurr network model consid base follow equat network statu contain output neuron also denot w vector weight toward neuron feed network sequenc input statu repres codif inform extract sequenc let us investig possibl latch inform given state show next section use order investig automaton realiz definit say given dynam hidden neuron latch inform repres activ follow inequ hold concept inform latch introduc discuss properti local feedback multilay network definit suggest interpret figur graphic interpret inform latch neuron output boolean statu x b relev henceforth refer state state transit network assum tacitli x b t involv actual output x t theorem given gener neuron i follow fact hold latch occur provid w ii f w ii latch condit also hold ji tj w ii state transit occur finit number step low high transit high low transit proof let us consid gener neuron n follow equat hypothesi w ii equat three equilibrium point see line fig one correspond point asymptot stabl prove fact point satisfi let us defin lyapunov function pp v a hypothesi w ii follow ga result first factor posit consequ therefor first factor neg deltav again henc stabil similar proof provid stabil non null solut equilibrium point fact start point neighborhood zero state trajectori goe one two stabl point accord initi sign proof also valid neuron receiv constant input suchthatji effect translat input line fig ji line becom tangent curv fa situat correspond degener two equilibrium point straightforward analysi allow us check relationship given second statement theorem let us consid effect ad timevari forc term t bound modul constant previous done let us limit analysi posit solut previou discuss follow system stabl equilibrium point ff easili prove activ t system satisfi inequ assum null initi state eq obvious valid us suppos valid t then previou consider stabil ff see eq activ ff t therefor t cannot chang sign inform latch occur rememb thatf a no step neuron input tabl relationship transient durat l neuron input differ valu w ii exampl w use lead state transit three step order prove third theorem statement let us consid case neuron latch high state input gammai appli input line one intersect curv fa see fig line therefor ts evolut follow attract trajectori toward uniqu equilibrium point see dot line fig correspond low state boolean valu similar proof given low high transit theorem indic condit inform latch occur make clear local weight increas latch relat satur configur moreov theorem s second statement defin condit current state latch indic limit condit guarante inform latch consequ state transit increas w ii increas thu indic robust latch inform valu w ii also affect transient durat l state transit occur greater w ii longer transient behavior summar tabl case low high transit tabl creat assum transient durat evalu assum column valu belong interv extrem given two subsequ row valu determin number step specifi first row valu iii k algorithm learn linear program point introduct intellig behavior often follow rule explicit extent order limit complex learn phase intellig system exploit rule show section v input inform sometim repres continu signal howev case deriv symbol represent inform mean input quanti zation string obtain way may contain subsequ repetit symbol eg nnuuummaaa problem automat speech recognit repetit relat phonem durat sinc consid uncertain inform number repetit help detect low level error assum sequenc futg belong certain class c accept particular automaton c repres class c order understand automaton oper think machin cascad two block first one task model durat provid sort filter input sequenc produc instanc symbol provid repeat least given number step eg number step process nnmnuumummaaa would produc numa second block simpli finit state automaton fsa repres basic knowledg assum problem notic that unlik mention fsa cascad two block may regard nondeterminist automaton section demonstr automaton rule realiz network term weight boundari turn use integr rule learn exampl first step choos proper code automaton state mean boolean state x b t neuron recurr network assum that pair present nextstat fsa ham distanc correspond codif one thereaft neuron straightforward deriv set r neuron switch rule automaton rule rule r r denot x b ir x b ir respect present next boolean state neuron i neuron switch rule implement use result contain theorem let vector weight rule r hold input neuron i fulfil rule r is ir sequel index may omit sake simplic code assumpt constant state transit result directli appli theorem follow linear constraint weight must hold ir ir oe boolean state switch requir otherwis oe gamma exampl let us consid rule r requir low high switch boolean state neuron i case x b equat becom ir accord theorem s result equat framework linear program feasibl solut point w weight space lie convex region bound set hyperplan h ir w solut satisfi requir arisen fsa import rememb network state transit may need one step number step depend strictli relationship fact shown clearli tabl consider make clear evalu region weight space automaton rule valid import parametr weight represent space quit difficult achiev although restrict spheric subset space easili determin chang equat basic idea reli comput distanc ir weight solut w hyperplan distanc written as ir ir c r put togeth equat setup follow optim problem still solv framework linear program ffl solv neuron i follow set equat ir ir obtain optim spheric region weight space center coordin describ procedur refer k algorithm recurr network weight belong sphere actual nondeterminist automaton weight specifi automaton becom determinist section b input symbol neuron a figur a chain automaton exampl b neural implement iv determin weight propos use supervis learn exampl let us consid simpl automaton order state chain structur see fig a basic state transit nextstat permit gener state code follow neural realiz base recurr network compos dynam neuron w ii worth mention that particular codif adopt network fig b use instead full connect net equat case follow gammaw exclus binari code chosen input neuron receiv one bit input code determin maximum sphere includ weight space solv equat term w found sphere radiu ae center latch condit impos choos w iv integr rule learn output network input rule learn rule priori figur kl network shown previou section neural realiz nondeterminist automaton lead network whose weight belong specif region weight space choic particular point space associ model symbol durat moreov must rememb explicit knowledg defin automaton base input quantiz inform convey continu signal quantiz repres approxim view origin problem model durat use supervis learn scheme base present exampl learn scheme also prove use deal continu natur input inform mani problem howev prioriknowledg inject network connect may limit possibl learn new rule specifi explicit model reason propos kl prioriknowledg learn architectur shown fig base two cooper subnet nk nl devot explicit learn rule represent respect third subnet take input subset nk nl neuron provid extern output simplest case consist singl output neuron see exampl section v weight first subnet nk quickli initi thank method shown section iii permit begin learn configur alreadi repres problem explicit knowledg learn uncertain inform mainli accomplish second subnet kl architectur fullconnect recurr network randomli initi task discov hidden rule weight optim carri mean modifi version pearlmutt learn algorithm adapt discret time formal definit procedur may found exampl algorithm discov solut optim cost function ino flag oe mean supervis request take place neuron time t length input sequenc ordinari gradient descent accomplish order optim weight relev differ nk weight constrain spheric region describ section iii guarante automaton rule destroy propos model learn exampl essenti conceiv refin process reliev problem discov complex determinist rule case use learn exampl paradigm like fail presenc local minima failur understood framework complex theori where least feedforward net proven load problem npcomplet particular class automata consequ recurr net interest applic go propos follow net refer chainlik net next section discuss chainlik net bear mind applic speech recognit v applic automat speech recognit order valid theoret hypothes better understand propos model carri sever preliminari experi automat speech recognit one primari goal applic area demonstr capabl propos model deal isol word recognit iwr larg lexicon far mani attempt build neuralbas classifi iwr assum small lexicon see eg neural classifi succeed problem acoust featur extract exhibit signific result applic larg lexicon basic due intrins limit method reli learn exampl although solut propos build modular architectur scale larg lexicon appear seriou problem order overcom difficulti propos model word given dictionari kl net one must detect word built reject word dictionari recognit phase word recogn present net simpl decis criteria choos highest output valu use perform word predict experi isol word recognit henceforth propos experi discrimin italian word compos vowel nasal order accomplish task select hierarch network architectur first net n p devot perform phonem hypothes u u figur automaton devot detect italian word numa tabl show codif automaton state net nw fed n p s output use model word indic section iv detail descript phonet network n p found net nw devot detect word dictionari highest network output criterion use perform word predict fig b show particular net chosen model italian word numa subnet priori rule represent chainlik structur conceiv repres automaton fig state subsequ occurr phonet symbol produc state transit automaton capabl deal phonem skip behav like string parser whose final accept state reach right phonem string appli basic automata kind solv directli problem insert delet phonet symbol import iwr practic want kl net consid state transit speech frame order avoid sever noisi predict phonem net n p see fig a featur particularli use decreas crosstalk word moreov forgotten net nw deal analog valu repres evid given phonem fullconnect network compos two neuron adopt net nl investig effect learn particularli nl s neuron expect theoret consider rule includ nk automaton net automat figur a phonem output word numa b network model word numa fed word numa input level activ neuron proport gray level black high valu figur a phonem output word inumano b network model word numa fed word inumano learn exampl fact clearli understood inspect behavior network associ word numa word numa inumano present input respect worth mention discrimin word possibl consid first subnet sinc inumanocontain numa substr fact come also inspect network state first subnet howev learn exampl make possibl develop intern rep resent neuron subnet nl permit discrimin two word quick glanc fig b fig b suggest word discrimin gain thank differ inform code creat nl s neuron explicit exampl show new rule discov includ net nk initi prioriknowledg obvious case discrimin word could attain also directli use complex automata inject nk sinc differ quit explicit practic want learn process develop rule appear explicit affect heavili uncertainti preliminari speaker independ small test base word perform maximum output decis criterion adopt found recognit rate high task simpl sinc word consid compos vowel nasal notic although dictionari small onli word model propos like scale much better other suggest literatur mainli due subnet nk accept acoust string correspond word model worth mention learn exampl approach use model word guarante provid ensur given word net react word vi conclus paper propos novel method integr prioriknowledg learn exampl recurr network show behavior nondeterminist automata inject network connect behavior difficult learn use learn exampl approach presenc local minima propos model optim procedur must discov solut begin tabula rasa must rather produc refin find addit regular captur explicit rule preliminari applic problem automat speech recognit promis importantli unlik mani propos iwr neural net propos model scale well increas lexicon dimens final worth mention that although mainli conceiv speech recognit understand task model turn use applic well r approxim boolean function sigmoid network part i xor twovari function speech pattern discrimin multilay perceptron finit state automata simpl recurr network on use neural network speaker independ isol word recognit find structur time learn hidden structur speech an unifi approach integr explicit knowledg learn exampl recurr network local feedback multilay network recurr network continu speech recognit bp learn algorithm captur dynam natur speech on problem local minima backpropag neural network design complex learn design hierarch perceptron structur applic task isol word recognit stabil motion a logic calculu idea imman nervou activ learn state space trajectori recurr neural net work the multilay perceptron tool speech pattern process research learn intern represent error propag formal languag relat automata phonem recognit use timedelay neural network modular neural network speech recognit a learn algorithm continu run fulli recurr network an effici gradientbas algorithm onlin train recurr network trajectori tr ctr ben choi appli learn exampl digit design autom appli intellig v n p mayjun christian w omlin c lee gile rule revis recurr neural network ieee transact knowledg data engin v n p februari barbara hammer peter tio recurr neural network small weight implement definit memori machin neural comput v n p august pasqual foggia roberto genna mario vento symbol vs connectionist learn experiment comparison structur domain ieee transact knowledg data engin v n p march steve lawrenc c lee gile sandiway fong natur languag grammat infer recurr neural network ieee transact knowledg data engin v n p januari stefan c kremer spatiotempor connectionist network taxonomi review neural comput v n p februari michael berthold david j hand refer intellig data analysi springerverlag new york inc new york ny