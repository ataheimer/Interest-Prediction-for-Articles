t tune compil optim simultan multithread a compil optim often driven specif assumpt underli architectur implement target machin exampl target sharedmemori multiprocessor parallel program compil minim share order decreas highcost interprocessor commun paper reexamin sever compil optim context simultan multithread smt processor architectur issu instruct multipl thread function unit cycl unlik sharedmemori multiprocessor smt provid benefit finegrain share processor memori system resourc unlik current multiprocessor smt expos benefit interthread instructionlevel parallel hide latenc therefor optim appropri convent machin may inappropri smt revisit three optim light loopiter schedul softwar specul execut loop tile result show three optim appli differ context smt architectur thread parallel cyclic rather block algorithm nonloop program softwar specul compil longer need concern precis size tile match cach size follow new guidelin compil gener code improv perform program execut smt machin b introduct compil optim typic driven specif assumpt underli architectur implement target machin exampl compil schedul longlat oper earli minim critic path order instruct base processor issu slot restrict maxim function unit util alloc frequent use variabl regist benefit fast access time new process paradigm chang architectur assumpt howev must reevalu machinedepend compil optim order maxim perform new machin simultan multithread smt multithread processor design alter sever architectur assumpt compil tradit reli smt processor instruct multipl thread issu function unit cycl take advantag simultan threadissu capabl processor resourc memori subsystem resourc dynam share among thread singl featur respons perform gain almost x wideissu superscalar roughli singlechip share memori multiprocessor multiprogram spec specint parallel splash specfp workload smt achiev improv limit slowdown singl execut thread simultan multithread present compil differ model hide oper latenc share code data oper latenc hidden instruct execut thread thread longlat oper addit multithread instruct issu increas instructionlevel parallel ilp level much higher sustain singl thread factor suggest reconsid uniprocessor optim copyright ieee publish proceed micro decemb research triangl park north carolina person use materi permit howev permiss reprintrepublish materi advertis promot purpos creat new collect work resal redistribut server list reus copyright compon work work must obtain ieee contact manag copyright permiss ieee servic center hoe lane po box piscataway nj hide latenc expos ilp expens increas dynam instruct count smt latencyhid benefit may need extra instruct may consum resourc could better util instruct concurr thread multipl thread resid within singl smt processor cheapli share common data incur penalti fals share fact benefit crossthread spatial local call question compilerdriven parallel techniqu origin develop distributedmemori multiprocessor partit data physic distribut thread avoid commun coher cost smt may benefici parallel program process contigu data paper investig extent simultan multithread affect use sever compil optim particular examin one parallel techniqu loopiter schedul compilerparallel applic two optim hide memori latenc expos instructionlevel parallel softwar specul execut loop tile result prescrib differ usag three optim compil smt processor found that block loop schedul may use distribut data distributedmemori multiprocessor cyclic iter schedul appropri smt architectur reduc tlb footprint parallel applic sinc smt thread run singl processor share memori hierarchi data share among thread improv local memori page softwar specul execut may incur addit instruct overhead convent wideissu superscalar instruct throughput usual low enough addit instruct simpli consum resourc would otherwis go unus howev smt processor simultan multithread instruct issu increas throughput roughli wide processor softwar specul execut degrad perform particularli nonloopbas applic simultan multithread also impact loop tile techniqu tile size select smt processor far less sensit variat tile size convent processor must find appropri balanc larg tile low instruct overhead small tile better cach reus higher hit rate processor elimin perform sweet spot hide extra miss larger tile addit threadlevel parallel provid multithread tile loop smt decompos thread comput tile rather creat separ tile thread done multiprocessor tile way rais perform smt processor moderatelys memori subsystem aggress design remaind paper organ follow section provid brief descript smt processor section discuss detail two architectur assumpt affect simultan multithread ramif compilerdirect loop distribut softwar specul execut loop tile section present experiment methodolog section examin compil optim provid experiment result analysi section briefli discuss compil issu rais smt relat work appear section conclud section microarchitectur simultan multithread processor smt design eightwid outoford processor hardwar context eight thread everi cycl instruct fetch unit fetch four instruct two thread fetch unit favor high throughput thread fetch two thread fewest instruct wait execut fetch instruct decod regist renam insert either integ float point instruct queue operand becom avail instruct from thread issu function unit execut final instruct retir perthread program order littl microarchitectur need redesign enabl optim simultan multithread compon integr part convent dynamicallyschedul superscalar major except larger regist file architectur regist per thread plu renam regist two addit pipelin stage access regist one read write instruct fetch scheme mention abov sever perthread mechan program counter return stack retir trap logic identifi tlb branch target buffer notabl miss list special perthread hardwar schedul instruct onto function unit instruct schedul done convent outoford superscalar instruct issu operand calcul load memori without regard thread renam hardwar elimin interthread regist name conflict map threadspecif architectur regist onto processor physic regist see detail larg hardwar data structur cach tlb branch predict tabl share among thread addit crossthread conflict cach branch predict hardwar absorb smt enhanc latencyhid capabl tlb interfer address techniqu describ section rethink compil optim explain abov simultan multithread reli novel featur attain greater processor perform coupl multithread wide instruct issu schedul instruct differ thread cycl new design prompt us revisit compil optim automat parallel loop enhanc memori perform andor increas ilp section discuss two factor affect smt uniqu design data share among thread avail instruct issu slot light three compil optim affect interthread data share convent parallel techniqu target multiprocessor thread physic distribut differ processor minim cach coher interprocessor commun overhead data loop distribut techniqu partit distribut data match physic topolog multiprocessor parallel compil attempt decompos applic minim synchron commun loop typic achiev alloc disjoint set data processor work independ contrast smt multipl thread execut processor affect perform two way first real fals interthread data share entail local memori access incur coher overhead smt share l cach consequ share even fals share benefici second share data among thread memori footprint parallel applic reduc result better cach tlb behavior factor suggest loop distribut polici cluster rather separ data multipl thread latencyhid capabl avail instruct issu slot workload wideissu processor typic cannot sustain high instruct throughput low instructionlevel parallel singl execut thread compil optim softwar specul execut loop tile or block tri increas ilp by hide reduc instruct latenc respect often side effect increas dynam instruct count despit addit instruct optim often profit instruct overhead accommod otherwis idl function unit issu instruct multipl thread smt processor fewer empti issu slot fact sustain instruct throughput rather high roughli time greater convent superscalar furthermor smt better job hide latenc singlethread processor use instruct one thread mask delay anoth environ aforement optim may less use even detriment overhead instruct compet use instruct hardwar resourc smt simultan multithread capabl natur toler high latenc without addit instruct overhead examin compil optim describ methodolog use experi chose applic spec spec splash benchmark suit tabl program compil multiflow trace schedul compil gener dec alpha object file multiflow chosen gener highqual code use aggress static schedul wide issu loop unrol ilpexpos optim implicitlyparallel applic the spec suit first parallel suif compil suif c output fed multiflow block loop distribut polici commonli use multiprocessor execut implement suif use applic compil latest version suif access sourc implement altern algorithm describ section hand suif also find tileabl loop determin appropri multiprocessorori tile size particular data set cach gener tile code experi tile size manual code specul execut enableddis modifi multiflow compil machin descript file specifi instruct move specul trace schedul experi static gener profiledriven trace latter profil inform gener instrument applic execut train input data set differ set use simul object file gener multiflow link version anl suif runtim librari creat execut smt simul process unmodifi alpha execut use emulationbas instructionlevel simul model detail processor pipelin hardwar support out oford execut entir memori hierarchi includ tlb usag memori hierarchi processor consist two level cach size latenc bandwidth characterist shown applic data set instruc tion simul f applu xx array iter x x mgrid sucor xxx vector len k iter b x x tomcatv x array iter fft k data point lu x matrix x water nsquar molecul timestep x water spatial molecul timestep x compress train input set x go train input set stone x li train input set x test input set dhryston x perl train input set scrabbl x mxm matrix multipli x x array gmt x gaussian elimin x adi integr stencil comput solv partial differenti equat tabl benchmark last three column identifi studi applic use specul execut l icach l dcach l cach cach size byte k k k line size byte bank transfer timebank cycl cycl cycl cach fill time cycl latenc next level tabl memori hierarchi paramet choic valu first the aggress repres forecast smt implement roughli three year futur use experi second set typic today memori subsystem use emul larger data set size use tile studi onli tabl model cach behavior well bank bu content two tlb size use loop distribut experi entri illustr perform loop distribut polici sensit tlb size larger tlb repres probabl configur futur generalpurpos smt smaller appropri less aggress design smt multimedia co processor page size typic rang mb tlb size miss requir two full memori access incur cycl penalti branch predict use mcfarlingstyl hybrid predictor entri way setassoci branch target buffer k entri selector choos global histori predictor histori bit local predictor a kentri local histori tabl index kentri bit local predict tabl length simul limit detail simul result parallel comput portion applic the norm simul parallel applic initi phase applic use fast simul mode simul cach warm main comput phase reach turn detail simul model loop distribut reduc commun coher overhead distributedmemori multiprocessor parallel compil employ block loop parallel polici distribut iter across processor block distribut assign thread processor continu array data iter manipul figur figur present smt speedup applic parallel use block distribut two tlb size good speedup obtain mani applic as number thread increas smaller tlb perform sever program hydrod swim tomcatv degrad thread thread case particularli import applic parallel exploit hardwar context smt analysi simul bottleneck metric indic slowdown result thrash data tlb indic tlb miss rate tabl tlb thrash direct result block partit increas total work set applic thread work disjoint data set sever case thread requir mani tlb entri loop stride sever larg array onc sinc primari data set usual larger typic kb page size least one tlb entri requir array swim benchmark specfp illustr extrem exampl one loop larg array access iter loop loop parallel use block distribut data tlb footprint array exclud entri requir data size less signific thrash occur parallel profit lesson tlb share resourc need manag effici smt least three approach consid use fewer thread parallel increas data tlb size parallel loop differ first altern unnecessarili limit use thread hardwar context neither exploit smt parallel applic fullest potenti second choic incur cost access time hardwar although increas chip densiti futur processor may abl accommod even larger tlb found entri solv problem howev entri data tlb avoid tlb thrash figur b indic achiev speedup least specfp data set applic number thread applu hydrod mgrid sucor tomcatv tabl tlb miss rate miss rate shown block distribut entri data tlb bold entri correspond decreas perform see figur number thread increas howev desir reduc tlb footprint smt true smt workload would multiprogram exampl multipl parallel applic could execut togeth compris thread hardwar context thread schedul could schedul thread first parallel applic context switch run second later switch back first type environ would performancewis minim data tlb footprint requir applic as exampl tlb footprint multiprogram workload consist swim hydrod would greater entri third desir solut reli compil reduc data tlb footprint rather distribut loop iter block organ could use cyclic distribut cluster access multipl thread onto fewer page with cyclic partit swim would consum rather tlb entri cyclic partit also requir less instruct overhead calcul array partit bound non neglig although much less import factor compar block cyclic loop distribut code data figur figur illustr speedup attain cyclic distribut block tabl contain correspond chang data tlb miss rate entri tlb applic better cyclic distribut case signific decreas data tlb miss coupl long cycl tlb miss penalti major factor cyclic increas tlb conflict tomcatv thread but number miss low overal program perform suffer thread tomcatv a origin loop block parallel c cyclic parallel figur block cyclic loop distribut exampl code exampl loop nest shown a use block distribut code structur b cyclic version shown c right d e illustr portion array access thread two polici for clariti assum thread assum row array kb doubl precis element block distribut d thread access differ kb page memori cyclic e howev loop decompos manner allow four thread access singl kb page time thu reduc tlb footprint dimens dimens thread thread thread thread d block a entri data tlb figur speedup one thread block parallel number thread applu hydrod mgrid sucor swim tomcatv averag b entri data tlb applu hydrod mgrid sucor swim tomcatv averagespeedup block data tlb miss rate jump caus correspond hike speedup cyclic absolut miss rate larger data tlb low enough usual except applu sucor reach chang produc littl benefit cyclic contrast sucor saw degrad cyclic schedul increas loop unrol instruct overhead perform degrad seen smaller tlb size cyclic improv tlb hit rate offset overhead mgrid saw larg perform improv tlb size reduct dynam instruct count figur b c illustr cyclic parallel requir fewer comput longlat divid summari result suggest use cyclic loop distribut smt rather tradit block distribut parallel applic larg data footprint cyclic distribut increas program speedup we saw speedup high even smallish specfp refer data set applic smaller data footprint cyclic broke even one applic odd interact loop unrol factor cyclic worsen perform multiprocessor smt processor cyclic distribut would still appropri within node applic entri tlb entri tlb number thread number thread applu hydrod mgrid sucor tomcatv tabl improv decreas tlb miss rate cyclic distribut block applu hydrod mgrid sucor swim tomcatv meanspeedup versu block b entri data tlb applu hydrod mgrid sucor swim tomcatv meanspeedup versu block a entri data tlb thread thread thread thread figur speedup attain cyclic block parallel applic execut time block normal number thread thu bar compar speedup cyclic block number thread hybrid parallel polici might desir though block distribut across processor minim interprocessor commun softwar specul execut today optim compil reli aggress code schedul hide instruct latenc global schedul techniqu trace schedul hyperblock schedul instruct predict branch path may move condit branch execut becom specul runtim branch path taken specul instruct useless potenti wast processor resourc inord superscalar vliw machin softwar specul necessari hardwar provid schedul assist smt processor whose execut core outoford superscalar instruct dynam schedul specul execut hardwar multithread also use hide latenc as number smt thread increas instruct throughput also increas therefor latencyhid benefit softwar specul execut may need less even unnecessari addit instruct overhead introduc incorrect specul may degrad perform experi design evalu appropri softwar specul execut smt processor result highlight two factor determin effect smt static branch predict accuraci instruct throughput correctlyspecul instruct instruct overhead incorrectlyspecul instruct howev add dynam instruct count therefor specul execut benefici applic high specul accuraci eg loopbas program either profiledriven stateoftheart static branch predict tabl compar dynam instruct count profiledriven specul nonspecul version applic small increas dynam instruct count indic compil with assist profil inform abl accur predict path execut consequ specul may incur penalti higher increas dynam instruct count hand mean wrongpath specul probabl loss smt perform instruct overhead influenc effect specul factor level instruct throughput program without specul also import determin easili specul overhead absorb suffici instruct issu bandwidth low ipc incorrect specul may caus harm higher use profiledriven specul provid bestcas comparison smt without profil mispredict would occur overhead instruct would gener consequ softwar specul would wors perform report make absenc appear even benefici smt specfp program radix splash compress specint loopbas small increas dynam instruct count specul increas specint increas splash increas applu compress fft hydrod go lu mgrid li radix sucor mksim waternsquar tomcatv tabl percentag increas dynam instruct count due profiledriven softwar specul execut data shown thread one thread number ident close applic bold high specul instruct overhead high ipc without specul ital former spec specint spec spec splash spec spec applu compress fft hydrod go lu mgrid li radix sucor mksim water nsquar tomcatv spatial tabl throughput instruct per cycl without profiledriven softwar specul thread program bold high ipc without specul plu high specul overhead ital former perthread ilp thread softwar specul less profit incorrectlyspecul instruct like compet use instruct processor resourc in particular fetch bandwidth function unit issu tabl contain instruct throughput applic program ipc higher softwar specul indic degre absorpt specul overhead other lower addit hardwar resourc conflict notabl l cach miss specul instruct overhead relat static branch predict accuraci instruct throughput togeth explain speedup or lack thereof illustr figur factor high the nonloop base fft li lu speedup without softwar specul greatest rang one factor low moder speedup minim nonexist the specfp applic radix waternsquar high ipc go mksim perl specul overhead without either factor softwar specul help perform reason benefit architectur hid latenc execut specul instruct applic and other well thread use advantag turn specul gener becom even larger addit thread provid parallel therefor specul instruct like compet use instruct processor resourc applu hydrod tomcatv mgrid sucor swimspeedup specul a specfp thread thread thread thread lu go fft li perl specul b splash spec int nsquar spatial figur speedup applic execut without softwar specul specul specul execut cycl specul execut cycl bar greater indic specul better otherwis idl function unit bottom line that loopbas applic compil softwar specul execut nonloop applic compil without it either improv smt program perform maintain current level perform never hurt loop tile order improv cach behavior loop tile take advantag data reus section examin two tile issu tile size select distribut tile thread tile size chosen appropri reduct averag memori access time compens tile overhead instruct the code figur b c illustr sourc overhead smt howev tile may less benefici first smt enhanc latencyhid capabl may render tile unnecessari second addit tile instruct may increas execut time given smt higher multithread throughput these factor influenc whether softwar specul address issu examin tileabl loop nest differ memori access characterist execut smt processor benefit tile vari size cach chang smaller cach requir smaller tile natur introduc instruct overhead hand smaller tile also produc lower averag memori latenc ie fewer conflict miss latenc reduc benefit tile better therefor vari tile size measur perform impact rang tile overhead also simul two memori hierarchi gaug interact cach size memori latenc tile size larger memori configur repres probabl smt memori subsystem machin product approxim year futur see section configur smaller model today memori hierarchi design provid appropri ratio data set cach size model loop larger ie realist data set benchmark experi thread given separ tile the tile norm figur present perform total execut cycl averag memori access time dynam instruct count rang tile size larger memori configur thread smt execut applic compar singlethread run even though float point comput waterspati high ipc without specul therefor specul instruct bottleneck integ unit execut without specul profit approxim execut superscalar result indic tile profit smt convent processor mxm may seem except sinc tile bring improv except show harm appli optim program execut smt appear insensit tile size almost tile size examin smt abl hide memori latenc as indic flat amat curv still absorb tile overhead therefor smt less depend static algorithm determin optim tile size particular cach work set contrast convent processor like tile size sweet spot even outoford execut modern processor well altern singledi processor architectur lack suffici latencyhid abil consequ requir exact tile size calcul compil tile size also perform determin less aggress memori subsystem result shown indic tile smt robust across keep mind specul without runtim support the pro file rel benefit specul versu specul would higher exampl thread waternsquar break even profiledriven specul howev reli multiflow static branch predict give specul slight edg speedup nevertheless gener conclus still hold good branch predict low multithread ipc need softwar specul benefit applic execut smt figur tile result larger memori subsystem separ tilesthread horizont axe tile size tile size mean tile size greater one dimens tile measur array element vertic axe metric evalu tile dynam instruct count total execut cycl amat mxm dynam instruct count million total execut cycl million averag memori access time cycl amat total execut cycl million averag memori access time cycl amat adi thread gmt thread memori hierarchi or altern rang data set size execut time is cours higher perform depend amat paramet rather tile overhead adi becam slightli less toler tile size chang largest tile size measur x amat increas sharpli interthread interfer small cach loop nest either tile size fit cach altern tile techniqu describ below use second loop tile issu distribut tile thread parallel loop multiprocessor differ tile alloc processor thread maxim reus reduc interprocessor commun smt howev tile manner could detriment privat perthread tile discourag interthread tile share increas total thread tile footprint singleprocessor smt the factor make block loop iter schedul inappropri smt rather give thread tile call block tile singl tile share thread loop iter distribut cyclic across thread cyclic tile see figur code explan block cyclic tile figur effect perthread data layout tile share cyclic tile optim increas tile size reduc overhead c larger tile cyclic tile drop execut time applic execut small memori smt closer smt aggress memori hierarchi or put anoth way perform program larg data set a origin loop block tile jtlb jt ub jtjtsize it m itits jjt j minnjtjtsizej kmax kt iit minmititsizei c cyclic tile kmax kt figur code block cyclic version tile loop nest approach smaller exampl figur c illustr larger tile size greater array element per dimens cyclic tile reduc mxm amat enough decreas averag execut time smaller cach hierarchi compar block figur b within block tile memori subsystem sever time size figur a smallest tile size increas tile overhead overwhelm smt abil hide memori latenc cyclic tile still appropri multiprocessor smt hierarch hybrid tile approach might effect cyclic tile could use maxim local processor block tile could distribut tile across processor minim interprocessor thread thread thread dimens c optim cyclic a block dimens b cyclici dimens dimens figur comparison block cyclic tile techniqu multipl thread block tile shown a tile x array element number repres order tile access thread cyclic tile tile still x array tile share thread exampl thread get one row tile shown b cyclic tile thread work smaller chunk data time tile overhead greater c tile size increas x reduc overhead within tile thread respons element origin block exampl total execut time million cycl averag memori access time cycl amat dynam instruct count million b c a figur tile perform thread mxm tile size along xaxi result shown a block tile larger memori subsystem b block tile smaller memori subsystem c cyclic tile also smaller memori subsystem compil optim addit optim studi paper compilerdirect prefetch predic execut softwar pipelin also reevalu context smt processor convent processor compilerdirect prefetch use toler memori latenc long prefetch overhead due prefetch instruct addit memori bandwidth andor cach interfer minim smt overhead detriment interfer thread prefetch also compet thread predic execut architectur model instruct execut guard boolean predic determin whether instruct execut nullifi compil use ifconvers transform control depend data depend therebi expos ilp like softwar specul execut aggress predic incur addit instruct overhead execut instruct either nullifi produc result never use softwar pipelin improv instruct schedul overlap execut multipl loop iter rather pipelin loop smt execut parallel separ hardwar context allevi increas regist pressur normal associ softwar pipelin multithread could also combin softwar pipelin necessari optim discuss paper origin design increas singlethread ilp intrathread parallel still import smt processor simultan multithread reli multipl thread provid use parallel throughput often becom import perform metric smt rais issu compil throughput singlethread exampl perspect singl run thread optim tradit appli may desir reduc thread run time global perspect greater throughput and therefor use work achiev limit amount specul work relat work three compil optim discuss paper wide investig nonsmt architectur loop iter schedul sharedmemori multiprocessor evalu wolf lam carr mckinley tseng anderson amarasingh lam cierniak li among other studi focu schedul minim commun synchron overhead restructur loop data layout improv access local processor particular anderson et al discuss block cyclic map scheme present heurist choos them global schedul optim like trace schedul superblock hyperblock allow code motion includ specul motion across basic block therebi expos ilp staticallyschedul vliw wideissu superscalar studi ilp limit lam wilson found specul provid greater speedup loopbas numer applic nonnumer code studi includ effect wrongpath instruct previou work code transform improv local propos variou framework algorithm select appli rang loop transform studi illustr effect tile also propos loop transform enabl better tile lam rothberg wolf coleman mckinley carr et al show applic perform sensit tile size present techniqu select tile size base problems cach paramet rather target fixeds fixedcach occup conclus paper examin compil optim context simultan multithread architectur smt architectur differ previou parallel architectur sever signific way first smt thread share processor memori system resourc singl processor finegrain basi even within singl cycl optim smt therefor seek benefit finegrain share rather avoid it done convent sharedmemori multiprocessor second smt hide intrathread latenc use instruct activ thread optim expos ilp may need third instruct throughput smt high therefor optim increas instruct count may degrad perform effect compil strategi simultan multithread processor must recogn uniqu characterist result show specif case smt processor benefit chang compil optim strategi particular show cyclic iter schedul as oppos block schedul appropri smt abil reduc tlb footprint softwar specul execut bad smt decreas use instruct throughput loop tile algorithm less concern determin exact tile size smt perform less sensit tile size loop tile increas rather reduc interthread tile share appropri smt increas benefit share memori system resourc acknowledg would like thank john odonnel equat technolog inc tryggv fossum digit equip corp sourc alpha axp version multiflow compil jennif anderson dec western research laboratori provid us suifparallel copi benchmark also would like thank jeffrey dean dec wrl refere whose comment help improv paper research support washington technolog center nsf grant mip ccr ccr darpa grant f onr grant n j n dec wrl fellowship intel corpor r optim loop parallel convers control depend data depend data comput transform multiprocessor portabl program parallel processor compil blockabl numer algo rithm compil optim improv data local hierarch tile improv superscalar perform approach scientif array process architectur design apbfp famili unifi data control transform distribut sharedmemori machin tile size select use cach organ data layout new cpu benchmark suit spec simultan multithread platform nextgener processor strategi cach local memori manag global program transform maxim multiprocessor perform suif compil highli concurr scalar process maxim loop parallel improv data local via loop fusion distribut softwar pipelin effect schedul techniqu vliw machin limit control flow parallel cach perform optim block algorithm convert threadlevel parallel instructionlevel parallel via simultan multithread multiflow trace schedul compil effect compil support predic execut use hyperblock combin branch predictor superblock effect techniqu vliw superscalar compil design evalu compil algorithm prefetch schedul techniqu easili schedul horizont architectur high perform scientif comput cydra department supercomput scale parallel program multiprocessor methodolog exampl exploit choic instruct fetch issu implement simultan multithread processor simultan multi thread maxim onchip parallel data local optim algorithm loop transform theori algorithm maxim parallel splash program character methodolog consider tr highli concurr scalar process strategi cach local memori manag global program transform optim loop parallel softwar pipelin effect schedul techniqu vliw machin cydra department supercomput cach perform optim block algorithm data local optim algorithm new cpu benchmark suit spec limit control flow parallel design evalu compil algorithm prefetch effect compil support predic execut use hyperblock compil blockabl numer algorithm multiflow trace schedul compil superblock compil optim improv data local unifi data control transform distribut sharedmemori machin tile size select use cach organ data layout splash program simultan multithread exploit choic compilerdirect page color multiprocessor convert threadlevel parallel instructionlevel parallel via simultan multithread convers control depend data depend portabl program parallel processor scale parallel program multiprocessor maxim multiprocessor perform suif compil simultan multithread loop transform theori algorithm maxim parallel hierarch tile improv superscalar perform maxim loop parallel improv data local via loop fusion distribut schedul techniqu easili schedul horizont architectur high perform scientif comput ctr mark n yankelevski constantin d polychronopoulo coral multigrain multithread processor architectur proceed th intern confer supercomput p june sorrento itali nichola mitchel larri carter jeann ferrant dean tullsen ilp versu tlp smt proceed acmiee confer supercomput cdrom pe novemb portland oregon unit state jack l lo luiz andr barroso susan j egger kourosh gharachorloo henri m levi sujay s parekh analysi databas workload perform simultan multithread processor acm sigarch comput architectur new v n p june alex settl joshua kihm andrew janiszewski dan connor architectur support enhanc smt job schedul proceed th intern confer parallel architectur compil techniqu p septemb octob evangelia athanasaki niko anastopoulo kornilio kourti nectario koziri explor perform limit simultan multithread memori intens applic journal supercomput v n p april gari m zoppetti gagan agraw lori pollock jose nelson amar xinan tang guang gao automat compil techniqu thread coarsen multithread architectur proceed th intern confer supercomput p may santa fe new mexico unit state steven swanson luke k mcdowel michael m swift susan j egger henri m levi evalu specul instruct execut simultan multithread processor acm transact comput system toc v n p august calin cacav david a padua estim cach miss local use stack distanc proceed th annual intern confer supercomput june san francisco ca usa jame burn jeanluc gaudiot smt layout overhead scalabl ieee transact parallel distribut system v n p februari joshua a redston susan j egger henri m levi analysi oper system behavior simultan multithread architectur acm sigplan notic v n p nov joshua a redston susan j egger henri m levi analysi oper system behavior simultan multithread architectur acm sigarch comput architectur new v n p dec luke k mcdowel susan j egger steven d gribbl improv server softwar support simultan multithread processor acm sigplan notic v n octob