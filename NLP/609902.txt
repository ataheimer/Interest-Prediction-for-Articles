t pac learn nasti nois a introduc new model learn presenc nois call nasti nois model model gener previous consid model learn nois learn process model variant pac model proce follow suppos learn algorithm execut ask exampl exampl algorithm get gener nasti adversari work accord follow step first adversari choos exampl independ accord fix but unknown learn algorithm distribut pacmodel power adversari upon see specif exampl chosen and use knowledg target function distribut learn algorithm allow remov fraction exampl choic replac exampl number arbitrari exampl choic modifi exampl given learn algorithm restrict adversari number exampl adversari allow modifi distribut accord binomi distribut paramet the nois rate mon neg side prove algorithm achiev accuraci learn nontrivi class function also give lower bound sampl complex requir achiev accuraci posit side show polynomi in usual paramet number exampl suffic learn class finit vcdimens accuraci algorithm may effici howev also show fairli wide famili concept class effici learn presenc nasti nois b introduct valiant pac model learn one import model learn exampl although extrem eleg model pac model drawback particular assum learn algorithm access perfect sourc random exampl name upon request learn algorithm ask random exampl return get pair x c x xs point input space distribut ident independ accord fix probabl distribut d c x correct classif x accord target function c algorithm tri learn sinc valiant semin work sever attempt relax assumpt introduc model nois first nois model call random classif nois model introduc extens studi eg model adversari provid exampl x c x learn algorithm toss bias coin whenev coin show h happen probabl j classif exampl flip algorithm provid the wrongli classifi exampl stronger model call malici nois model introduc revisit studi model adversari whenev jbias coin show h replac exampl x c x arbitrari pair point input space b boolean valu note particular give adversari power distort distribut d work present new model call nasti sampl nois model model adversari get see whole sampl exampl request learn algorithm give algorithm modifi e exampl choic e random variabl distribut binomi distribut paramet j m size sampl distribut make number exampl modifi determin independ toss jbias coin howev allow adversari choic depend sampl drawn modif appli adversari arbitrari as malici nois model intuit speak new adversari power previou one examin whole sampl remov inform exampl replac less use even mislead exampl wherea malici nois model instanc adversari also may insert sampl mislead exampl freedom choos exampl remov relationship variou model shown tabl random noiseloc adversari noiseloc label nois random classif nois nasti classif nois point label nois malici nois nasti sampl nois tabl summari model paclearn noisi data argu newli introduc model gener previou nois model includ variant decatur cam model cpcn model also mani realworld situat assumpt previou model made nois seem unjustifi exampl train data result physic experi nois may tend stronger boundari area rather uniformli distribut input special model also consid weaker variant model call nasti classif nois model adversari may modifi classif chosen point as random classif nois model devis describ situat exactlearn set for exampl incomplet boundari queri model blum et al may regard special case nasti nois adversari choos provid unreli answer sampl point near boundari target concept or remov point sampl anoth situat model relat set agnost learn model concept class given instead learn algorithm need minim empir error use hypothesi predefin hypothes class see exampl definit model assum best hypothesi classifi input j fraction may altern see problem learn hypothes class nasti nois rate j howev note success criterion agnost learn literatur differ one use pacbas set show two type result section show inform theoret result sect show algorithm result first result present section lower bound qualiti learn possibl nasti adversari result show learn algorithm cannot learn nontrivi concept class accuraci better j sampl contain nasti nois rate j show learn concept class vc dimens accuraci requir exampl complement match posit result section show class finit vcdimens learn use sampl polynomi size accuraci ffl j size sampl requir polynomi usual pac paramet delta margin request accuraci ffl mention lower bound main quit surpris result present section anoth posit result show effici learn algorithm still possibl spite power adversari specif present composit theorem analog nastynois learn model show concept class construct compos concept class paclearn hypothesi class fix vcdimens effici learnabl use sampl subject nasti nois includ instanc class concept form boolean combin halfspac constant dimens euclidean space complex is again polynomi usual paramet delta algorithm use proof result adapt model pac algorithm present result may compar similar result avail malici nois model model cesabianchi et al show accuraci learn malici nois lower bound match algorithm learn class similar present malici nois present random classif nois model learn arbitrari small accuraci even nois rate close half possibl again techniqu present may use learn type class examin work random classif nois preliminari section provid basic definit relat learn pac model without nois learn task specifi use concept class denot c boolean concept defin instanc space denot x boolean concept c function c x f g concept class c set boolean concept c f g x throughout paper sometim treat concept set point instead boolean function set correspond concept c simpli g use c denot function correspond set interchang specif probabl distribut defin x use notat dc refer probabl point x drawn x accord classic pac model probabl approxim correct pac model origin present valiant model learn algorithm access oracl pac return call label exampl accord fix distribut x unknown learn algorithm c c target function learn algorithm learn definit class c boolean function paclearn use hypothesi class h polynomi time exist algorithm that c c input paramet distribut x given access pac oracl run time polynomi log jx j ffi ffl probabl least output function h h pr model learn presenc nois next defin model paclearn presenc nasti sampl nois nsn short model learn algorithm concept class c given access adversari oracl nsn cj m learn algorithm allow call oracl singl run learn algorithm pass singl natur number oracl specifi size sampl need get return label sampl x theta f g it assum simplic algorithm know advanc number exampl need extens model scenario bound avail advanc given section sampl requir learn algorithm construct follow pac model distribut instanc space x defin target concept c c chosen adversari draw sampl g point x accord distribut d full knowledg learn algorithm target function c distribut d sampl drawn adversari choos point sampl es g random variabl e point chosen adversari remov sampl replac pointandlabel pair adversari chosen adversari remain unchang label correct label accord c modifi sampl point denot s given learn algorithm limit adversari number exampl may modifi distribut accord binomi distribut paramet j name probabl taken first choos g choos e accord correspond random variabl es g definit algorithm said learn class c nasti sampl nois rate j accuraci paramet ffl confid paramet access oracl nsn cj m distribut target c c output hypothesi h x f g that probabl least pr also interest restrict model call nasti classif nois learn model ncn short differ ncn nsn model ncn adversari allow modifi label e chosen samplepoint cannot modifi e point themselv previou model learn presenc nois also readili shown restrict nasti sampl nois model malici nois model correspond nasti nois model adversari restrict introduc nois point chosen uniformli random probabl j origin sampl random classif nois model correspond nasti classif nois model adversari restrict nois introduc point chosen uniformli random probabl j origin sampl point chosen get label flip vc theori basic vcdimens wide use learn theori measur complex concept class vcdimens class c denot vcdimc maxim integ exist subset x size possibl behavior present class c subset exist natur d well known eg that two class c h over x class negat fcjx n c cg vcdimens class c class union fc hjc c h hg vcdimens vcdimcvcdimh follow defin dual concept class definit dual h f g h class h f g x defin set defin x view concept class h boolean matrix row repres concept column point instanc space x matrix correspond h transpos matrix correspond h follow claim give tight bound vc dimens dual class everi class h log follow discuss limit instanc space x finit cardin main use make vcdimens construct ffnet follow definit theorem definit set point x ffnet concept class h f g x distribut x everi h h dh ff h theorem class h f g x vcdimens d distribut x ae ff log ff log ff oe exampl drawn iid x accord distribut d constitut ffnet h probabl least gamma ffi talagrand prove similar result definit set point x ffsampl concept class h f g x distribut x hold everi h h theorem constant c class h f g x vcdimens d distribut x ff exampl drawn iid x accord distribut d constitut ffsampl h probabl least consist algorithm let p n subset point x say function h x f g consist posit point x p neg point x n consist algorithm see pair class c h both instanc space x c h receiv input two subset instanc space run time tjp n j satisfi follow function c consist p n algorithm output ye h h consist p n algorithm output no consist exist there restrict output case consist function h c given subset point instanc space q x interest set possibl partit q posit neg exampl function h h function c c consist partit may formul as con consist algorithm c h follow base sauer lemma lemma set point q furthermor effici algorithm gener set partit along correspond function h present assum c paclearn h constant vc dimens algorithm output denot h consist inform theoret lower bound section show learn algorithm not even ineffici one learn non trivial concept class accuraci ffl better j nsn model fact prove imposs result hold even ncn model also give result size sampl requir learn nsn model accuraci ffl j definit class c instanc space x call nontrivi exist two point theorem let c nontrivi concept class j nois rate ffl j accuraci paramet then algorithm learn concept class c accuraci ffl ncn model with rate j proof base proof method induc distribut introduc theorem show two concept distribut adversari forc label exampl shown learn algorithm distribut ident c target c target let c c two concept whose exist guarante fact c nontrivi class let x two point satisfi c defin probabl distribut dx g clearli inde prd c now defin nasti adversari strategi with respect probabl distribut d let size sampl ask learn algorithm adversari start draw sampl g point accord distribut then occurr x sampl adversari label correctli accord c occurr x adversari toss coin probabl label point correctli ie c flip label to result sampl exampl given adversari learn algorithm first argu number exampl modifi adversari inde distribut accord binomi distribut paramet j m thi view adversari pick independ point decid as abov whether flip label henc suffic show exampl label incorrectli probabl j independ exampl inde exampl independ probabl label incorrectli equal probabl choos x accord time probabl adversari choos flip label x exampl ie j delta need we emphas binomi distribut obtain known adversari next observ that matter whether target c c exampl given learn algorithm after modifi nasti adversari distribut accord follow probabl distribut therefor accord sampl learn algorithm see imposs differenti case target function c case target function c note proof inde take advantag nasti adversari unlik malici adversari adversari focu power point x caus suffer rel high error rate exampl point x suffer nois also took advantag fact e the number modifi exampl allow depend sampl in case depend number time x appear origin sampl allow adversari focu destruct power sampl otherwis good learn algorithm final sinc ncn adversari also nsn adversari theorem impli follow corollari let c nontrivi concept class j nois rate ffl j accuraci paramet algorithm learn concept class c accuraci ffl nsn model nois rate j settl j lower bound accuraci possibl nasti adversari error rate j turn question number exampl necessari learn concept class accuraci again section consid informationtheoret issu result similar present cesabianchi et al malici nois model note howev definit margin delta use rel lower bound differ one use proof result use follow claim see provid lower bound probabl random variabl binomi distribut deviat expect standard deviat fact let snp random variabl distribut binomi distribut paramet n p let p n pq pr ki pr ki theorem nontrivi concept class c nois rate j confid paramet sampl size need pac learn c accuraci confid toler nasti classif nois rate j least omega proof let c c two concept whose exist guarante fact c nontrivi class let x two point satisfi c let us defin distribut give weight ffl point x weight gamma ffl x make f target function either c c nasti classif adversari use follow strategi pair form sampl probabl jffl revers label ie present learn algorithm pair instead rest sampl all pair form unmodifi note exampl probabl classif chang therefor exactli ffl delta j number point suffer nois inde distribut accord binomi distribut paramet j m induc probabl distribut sampl learn algorithm see is contradict let possibl random algorithm learn c accuraci ffl use sampl gener oracl whose size p m error hypothesi h output use exampl let b bay strategi output c major instanc x label c clearli strategi minim probabl choos wrong hypothesi impli defin follow two event run b sampl size m let n denot number exampl show point x bad event least dne corrupt bad event n jj answer incorrectli exampl show x wrong label exampl show x correct label examin probabl bad occur note n random variabl distribut binomi distribut paramet ffl and recal delta interest in sinc probabl n larg higher larger upper bound j gamma may bound use hoeffd inequ least therefor have hand assum bad hold name n jj addit assum n j delta jj delta then claim with use follow inequ s follow prbad see inequ equat inde hold bad hold note impli by is turn impli two condit verifi two condit hold take n rang assum optim strategi henc wors strategi ignor sampl point error decreas point shown x therefor result hold remov lower bound n thu prbad second type lower bound number requir exampl base vc dimens class learn similar result and proof techniqu standard pac model condit delta must least one integ rang assum n theorem concept class c vcdimens ffl sampl size requir learn c accuraci ffl confid ffi use sampl gener nasti classif adversari error rate delta greater omega set point shatter c defin probabl distribut follow assum contradict d gamma delta exampl use learn algorithm let nasti adversari behav follow revers label exampl x dgamma probabl independ sampl point make label x dgamma appear random nois also note probabl exampl corrupt adversari exactli j delta j thu probabl point x dgamma misclassifi learner hypothesi rest sampl left unmodifi denot bad event least half point x seen learn algorithm given bad denot set d gamma unseen point lowest indic defin bad event algorithm hypothesi misclassifi least d gamma point up final let bad denot event x dgamma misclassifi easi see bad bad bad impli hypothesi error least ffl impli hypothesi err d gamma point point weight deltad gamma point x whose weight j make total error least delta therefor algorithm learn class confid ffi must hold prbad bad bad note befor x dgamma appear label random nois henc prbad independ bad bad thu event sinc d gamma delta exampl seen expect number point x learn algorithm see d gamma markov inequ follow that probabl least d gamma point seen henc everi unseen point misclassifi learn algorithm probabl least half sinc point adversari may set target label point label lower probabl given algorithm thu prbad jbad probabl fair coin flip d gamma time show head least d gamma time use fact probabl shown least thu have complet proof sinc learn nasti sampl nois easier learn nasti classif nois result theorem also hold learn nasti sampl nois oracl inform theoret upper bound section provid posit result complement neg result section result show that given suffici larg sampl hypothesi perform suffici well sampl even sampl subject nasti nois satisfi pac learn condit formal analyz follow gener algorithm learn class c vcdimens d whose input certainti paramet ffi nasti error rate paramet requir algorithm nastyconsist request sampl output h c if h exist choos h c arbitrarili theorem let c class vcdimens d then for constant c algorithm nasti consist pac learn algorithm nasti sampl nois rate j proof theorem as well analysi algorithm next section use conveni slightli weaker definit pac learnabl one use definit requir algorithm output probabl least pr rather strict inequ howev use algorithm give slightli smaller accuraci paramet eg ffl ffl get algorithm learn use origin criterion definit proof first argu high probabl number sampl point modifi adversari mj delta random variabl e distribut accord binomi distribut expect jm may use hoeffd inequ get pr by choic c event happen probabl ffi now note target function c err e point sampl shown learn algorithm as complet accur nonmodifi sampl g thu probabl least nastyconsist abl choos function h c err j deltam point sampl shown it howev worst case error function h occur point modifi adversari addit h may erron point adversari modifi therefor guarante case hypothesi h err e point origin sampl g theorem exist constant c that probabl take g size least c result sampl g delta sampl class symmetr differ function c union bound therefor that probabl least deltam mean js deltam g deltasampl class symmetr differ so pr requir composit theorem learn nasti nois follow defin notion composit class let c class boolean function defin class c set boolean function f x repres fg boolean function g c defin size fg k given vector hypothes follow set wh set subdomain w ag possibl vector f g show variat algorithm present learn class c nasti sampl adversari assum class c paclearn class h constant vc dimens d algorithm build fact consist algorithm con c h construct given algorithm pac learn c h algorithm learn concept class c confid paramet ffi accuraci ffl arbitrarili close lower bound j prove previou section sampl complex comput complex polynomi k ffi delta algorithm base follow idea request larg sampl oracl randomli pick smaller subsampl sampl retriev randomli pick subsampl algorithm neutral power adversari ha sinc adversari cannot know exampl one inform us use consist algorithm c h find one repres h possibl behavior smaller subsampl hypothes h defin divis instanc space cell cell character specif behavior hypothes pick final hypothes simpli base take major vote among complet sampl insid cell demonstr algorithm let us consid inform specif rel simpl case class learn class k interv straight line see figur algorithm given sampl input proce follow algorithm use rel small random subsampl divid line subinterv two adjac point subsampl defin subinterv subinterv algorithm calcul major vote complet sampl result hypothesi number point which specif case number subinterv algorithm choos first step depend k intuit want total weight subinterv contain target endpoint rel small thi call bad part formal analysi follow natur k bad subinterv larger k target concept subsampl interv bad bad bad bad algorithm hypothesi figur exampl nastylearn interv is larger subsampl need except bad subinterv subinterv algorithm err least half point modifi adversari thu total error roughli j plu weight bad subinterv now proceed formal descript learn algorithm given constant d size k target function bound error rate j paramet ffi delta two addit paramet mn to specifi below algorithm proce follow algorithm nastylearn request sampl size n choos uniformli random subsampl r size use consist algorithm c h comput output hypothes hh comput follow w wh empti set h major label w w empti set h x w theorem let log log k constant then algorithm nastylearn learn class c accuraci confid ffi time polynomi k theorem theorem refer modifi pac criterion requir algorithm output probabl least gamma ffi function h pr techniqu mention algorithm nastyconsist may use modifi algorithm pac learn algorithm sens definit commenc actual proof present technic lemma lemma assum n set statement theorem probabl least number point error introduc e j deltan proof lemma note that definit model e distribut accord binomi distribut paramet j n thu e behav number success independ bernoulli experi hoeffd inequ may use bound valu pr therefor take n lnffi have probabl least e j deltan note valu chosen n statement theorem clearli larg enough readi present proof theorem proof analyz error made hypothesi algorithm gener let us denot adversari strategi follow gener sampl request size n accord distribut d label target concept f denot sampl g choos subset g size random variabl as defin section choos malici set point x theta f g size e hand learn algorithm sampl assum target function f form hypothesi algorithm chosen step exhibit behavior g point r from definit scon guarante hypothesi exist definit point r h j vcdimens class c g s class h h s d class possibl symmetr differ also vcdimens od see section appli theorem view r sampl taken accord uniform distribut choos statement theorem r ffnet with respect uniform distribut s class symmetr differ least gamma ffi note may still point h j g henc let use get probabl least gamma ffi simultan i everi subdomain b wh n b js bj word nb n simpli stand size restrict origin noisefre sampl g noisi exampl introduc adversari subdomain b rest definit base distinct good part b g h j behav same bad part present due fact g h j exhibit behavior smaller subsampl r rather complet sampl s use n ff b denot number sampl point bad part b n outg b denot number sampl point remov adversari good bad part b respect sinc learn algorithm decid classif subdomain major vote hypothesi err domain b number exampl left untouch b less number exampl b modifi adversari plu misclassifi h j with respect g s may formul follow condit n therefor total error algorithm may experi most b nbn calcul bound two term separ bound second term note theorem choic n guarante g delta sampl domain probabl least gamma ffi note definit wh sauer lemma jwh choic n inde guarante probabl least b nbn b nbn n from choic n follow g also delta sampl class symmetr differ form h j g thu probabl least gamma ffi have total error made hypothesi assum none four bad event happen therefor bound by pr n requir bound hold certainti least gamma ffi conclus present model pac learn nasti nois gener previou model prove neg informationtheoret result show learn algorithm learn nontrivi class accuraci better j pair posit result show bound tight complement result lower bound sampl size requir learn accuraci j delta also shown wide varieti interest concept class effici learn algorithm model exist neg result gener case learn algorithm use random hypothes coin rule as defin case get inform theoret lower bound j achiev accuraci compar lower bound j prove learn malici nois rate j partit two separ variant nsn ncn model seem intuit wellmotiv remain open problem come result actual separ two model neg posit result present work appli equal nsn ncn model final note definit nasti nois model requir learn algorithm know advanc sampl size or upper bound it model howev extend deal scenario bound known learn algorithm sever scenario kind exampl sampl complex may depend certain paramet such size target function known algorithm adversari know learn algorithm know target function and gener know paramet hidden learn algorithm thu plan ahead draw advanc sampl g size suffici larg satisfi high probabl request learn algorithm make modifi g defin reorder result sampl randomli now learn algorithm simpli ask one exampl time as pac model adversari suppli next exampl randomlyord set s sampl exhaust which may happen case expect samplecomplex guarante say learn algorithm fail howev use larg enough sampl with respect ffi happen suffici small probabl r gener bound statist queri learn pac learn nois via hypothesi boost learn noisi exampl a composit theorem learn algorithm applic geometr concept class combinatori variabl vapnikchervonenki class applic sampl compress scheme learn unreli boundari queri weakli learn dnf character statist queri learn use fourier analysi learnabl vapnikchervonenki dimens a new composit theorem learn algorithm noisetoler distributionfre learn gener geometr concept sampleeffici strategi learn presenc nois learn hybrid nois environ use statist queri pac learn constantpartit classif nois applic decis tree induct on learn noisi incomplet exampl probabl inequ sum bound random variabl effici noisetoler learn statist queri learn presenc malici toward effici agnost learn on densiti famili set the design analysi effici learn algorithm sharper bound gaussian empir process a theori learnabl learn disjunct conjunct on uniform converg rel frequenc event probabl tr theori learnabl learnabl vapnikchervonenki dimens design analysi effici learn algorithm learn presenc malici error effici noisetoler learn statist queri weakli learn dnf character statist queri learn use fourier analysi toward effici agnost learn learn unreli boundari queri learn noisi incomplet exampl noisetoler distributionfre learn gener geometr concept composit theorem learn algorithm applic geometr concept class new composit theorem learn algorithm combinatori variabl vapnikchervonenki class applic sampl compress scheme sampleeffici strategi learn presenc nois learn noisi exampl ctr marco barreno blain nelson russel sear anthoni d joseph j d tygar machin learn secur proceed acm symposium inform comput commun secur march taipei taiwan