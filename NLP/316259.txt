t multicategori classif support vector machin a examin problem discrimin object three class specif investig twoclass discrimin method extend multiclass case show linear program lp approach base work mangasarian quadrat program qp approach base vapnik support vector machin svm combin yield two new approach multiclass problem lp multiclass discrimin singl linear program use construct piecewiselinear classif function propos multiclass svm method singl quadrat program use construct piecewisenonlinear classif function piec function take form polynomi radial basi function even neural network k class problem svm method origin propos requir construct twoclass svm separ class remain class similarili k twoclass linear program use multiclass problem perform empir studi origin lp method propos k lp method propos singl qp method origin k qp method discuss advantag disadvantag approach b introduct investig problem discrimin larg realworld dataset two class given exampl point known come k class construct function discrimin class goal select function ecient correctli classifi futur point classif techniqu use data mine pattern recognit exampl unit state postal servic interest ecient yet accur method classifi zipcod actual handwritten digit zipcod collect unit state postal servic use studi digit repres pixel grayscal map result attribut sampl number given enorm quantiti mail postal servic sort day accuraci ecienc evalu extrem import paper combin two independ relat research direct develop solv twoclass linear discrimin problem first linear program lp method stem multisurfac method mangasarian method later extens robust linear program rlp approach use highli success breast cancer diagnosi system second direct quadrat program qp method base vapnik statist learn theori statist learn theori address mathemat problem best construct function gener well futur point problem construct best linear twoclass discrimin pose convex quadrat program linear constraint result linear discrimin known support vector machin svm function subset train data known support vector specif implement gener optim plane gop method proven perform well practic throughout paper refer two dierent approach rlp svm primari focu paper two research direct dier approach solv problem k class origin svm method multiclass problem find k separ twoclass discrimin discrimin construct separ singl class other process requir solut k quadrat program appli k classifi origin multicategori dataset multipli classifi point unclassifi point may occur ambigu avoid choos class point correspond classif function maxim point lp approach directli construct k classif function point correspond class function maxim multicategori discrimin method construct piecewiselinear discrimin k class problem use singl linear program call method mrlp sinc direct extens rlp approach show two dierent approach combin two yield two new method krlp msvm section provid background exist rlp svm method kclass case quit dierent twoclass linear discrimin method svm rlp almost ident dier regular term use object use regular form rlp propos equival svm except dierent norm use regular term twoclass linear discrimin rlp gener equal well comput ecient svm rlp exploit fact stateoftheart lp code far ecient reliabl qp code primari appeal svm simpli elegantli appli nonlinear discrimin minor chang svm method construct wide class twoclass nonlinear discrimin solv singl qp basic idea point map nonlinearli higher dimension space dual svm problem use construct linear discrimin higher dimension space nonlinear origin attribut space use kernel function dual svm problem svm ecient eectiv construct mani type nonlinear discrimin function includ polynomi radial basi function machin neural net work success polynomialtim nonlinear method base lp use multistep approach method roy et al use cluster conjuct lp gener neural network polynomi time anoth approach recurs construct piecewiselinear discrimin use seri lp approach could also use svm limit discuss nonlinear discrimin construct use svm kerneltyp approach introduct exist multiclass method mrlp k svm show idea use mrlp adapt construct multiclass svm use singl quadrat program adapt problem formul similar twoclass case twoclass case initi problem construct linear discrimin data point transform higher dimension featur space linear discrimin construct higher dimens space result nonlinear classif function origin featur space section k class case begin construct piecewiselinear discrimin function regular term ad avoid overfit method extend piecewis nonlinear classif function section variabl map higher dimension space piecewiselinear discrimin function construct new space result piecewisenonlinear discrimin origin space section extend method piecewis insepar dataset call final approach multicategori support vector machin msvm depend choic transform piec may polynomi radial basi function neural network etc concentr research polynomi classifi leav comput investig classif function futur work figur show piecewisesecond degre polynomi separ three class two dimens msvm requir solut larg quadrat program transform data point higher dimens featur space number figur piecewisepolynomi separ three class two dimens variabl grow exponenti exampl second degre polynomi classifi two dimens requir origin variabl x x well variabl x x x primal problem problem size explod degre polynomi increas dual problem howev remain tractabl number dual variabl k time number point regardless transform select dual problem transform appear inner product high dimension space inexpens techniqu exist comput inner product dual variabl correspond point origin featur space point correspond posit dual variabl refer support vector goal maintain high accuraci use small number support vector minim number support vector import gener also reduc comput time requir evalu new exampl section contain comput result compar two lp approach k rlp mrlp two qp approach ksvm msvm method compar term gener test set accuraci number support vector comput time follow notat use throughout paper mathemat abstract problem follow given element set k ndimension real space r n construct discrimin function determin separ point distinct region region contain point belong almost class let j set point ndimension real space r n cardin j let j j n matrix whose row point j th point j th row j denot j let e denot vector one appropri dimens scalar vector zero repres thu x r n x impli x similarli n set minim fx set denot arg min xs fx vector x r n x denot vector r n compon x n step function x denot vector n compon n vector x r n matrix r nm transpos x denot x respect dot product two vector x denot x background section contain brief overview rlp svm method cla sific first discuss twoclass problem use linear classifi svm two class defin rlp review final piecewiselinear function use multicategori classif mrlp review two class linear discrimin commonli method discrimin two class point involv determin linear function consist linear combin attribut given set simplest case linear function use separ two set shown figur function separ plane x psfrag replac figur two linearli separ set separ plane w normal plane distanc origin let two set point ndimension real space r n cardin respect let n matrix whose row point let n matrix whose row point let x r n point classifi follow two set point linearli separ e vector one appropri dimens two class linear separ infinit mani plane separ two class goal two choos plane gener best futur point mangasarian vapnik chervonenki conclud best plane separ case one minim distanc closest vector class separ plane separ case formul mangasarian multisurfac method pattern recognit vapnik optim hyperplan similar concentr optim hyperplan problem sinc basi svm valid theoret statist learn theori accord statist learn theori optim hyperplan construct linear psfrag replac class class figur two support plane result optim separ plane discrimin high dimension space without overfit reader consult full detail statist learn theori cover paper problem canon form vapnik becom determin two parallel plane margin distanc two plane maxim margin seper two support plane w exampl plane shown figur problem find maximum margin becom min gener alway possibl singl linear function complet separ two given set point thu import find linear function discrimin best two set accord error minim criterion bennett mangasarian minim averag magnitud misclassif error construct follow robust linear program problem rlp min subject z a w misclassif cost avoid null solut cardin respect rlp method eectiv practic function gener rlp gener well mani realworld problem addit comput time reason small solut involv singl linear program note howev rlp method longer includ notion maxim margin statist learn theori indic maxim margin essenti good gener svm approach multiobject quadrat program minim absolut misclassif error maxim separ margin minim w min fix constant note problem equival rlp addit regular term linear program version construct replac norm use minim weight w recal svm object minim squar norm w w norm w w use instead absolut valu function remov introduc variabl constraint s w s svm object modifi substitut e w w optim k result lp is min wyz refer problem rlp sinc yield origin rlp method svm method rlp method minim averag distanc misclassifi point relax support plane maximum classif error main advantag rlp method svm problem rlp linear program solvabl use robust algorithm simplex method svm requir solut quadrat program typic much comput costli size problem rlp method found gener well linear svm much less comput cost ecient comput solv dual rlp svm prob lem dual rlp problem min uv e paper use may posit weight misclassif cost dual svm problem extens nonlinear discrimin given next section nonlinear classifi use support vector machin primari advantag svm rlp dual form use construct nonlinear discrimin use polynomi separ radial basi function neural network etc basic idea map origin problem higher dimension space construct linear discrimin higher dimension space correspond linear discrimin origin space exampl construct quadrat discrimin two dimension problem input attribut x x map linear discrimin function construct new fivedimension space two exampl possibl polynomi classifi given figur dual svm appli map point regular term primal object help avoid overfit higher dimension space dual svm provid practic comput approach use gener inner product kernel figur two exampl second degre polynomi separ two set dual svm follow follow min formul nonlinear case conveni rewrit problem summat notat let set point defin total number point let x construct nonlinear classif function origin data point x transform higher dimens featur space function x n dot product origin vector x replac dot product transform vector x first term object function written sum use notat simplifi problem becom min st support vector machin svm vapnik replac inner product inner product hilbert space kx x symmetr function kx x must satisfi theorem theorem ensur inner product featur space choic kx x determin type classifi construct possibl choic includ polynomi classifi figur kx x degre polynomi radial basi function machin k xx x x distanc two vector width param ter twolay neural network kx x sigmoid function variant svm proven quit success paractic note number variabl program remain constant increas dimension addit object function remain quadrat thu complex problem increas fact size problem depend number nonzero dual variabl point x correspond variabl call support vector accord statist learn theori best solut given misclassif error use minimum number support vector final classif function gener kernel function kx x is support vector psfrag replac figur piecewiselinear separ set convex piecewiselinear function fx multicategori discrimin multicategori classif piecewiselinear separ use discrimin point examin two method accomplish thi first use svm two construct discrimin function separ one class remain k class process repeat k time separ case linear discrimin class must satisfi follow set inequ find w classifi new point x comput f one clearli point belong class one f x class ambigu thu gener rule class point x determin w find maxim figur show piecewiselinear function r separ three set note either svm rlp use construct k twoclass discrimin clariti call method use svm k svm denot method use rlp ksvm advantag ksvm use piecewisenonlinear discrimin krlp limit piecewiselinear discrimin ksvm krlp attain perfect train set accuraci follow inequ must satisfi inequ use definit piecewiselinear separ definit piecewiselinear separ set point k repres matric piecewis linearli separ exist w equival definit find piecewiselinear separ involv solv equat w e rewritten a w e figur show exampl piecewiselinear separ three class two dimens linear separ function repres quantiti psfrag replac figur three class separ piecewiselinear function w k mrlp method propos investig use find w min mrlp optim object valu zero dataset piecewiselinearli separ dataset piecewis linearli separ posit valu variabl ij l proport method origin call multicategori discrimin magnitud misclassifi point plane x w program gener twoclass rlp linear program multicategori case like origin rlp mrlp includ term maxim margin directli permit use gener inner product kernel allow extens nonlinear case next section show mrlp svm combin includ margin maxim gener inner product mrlp formul msvm piecewiselinear separ case propos construct piecewiselinear piecewisenonlinear svm use singl quadrat program analog two class case start formul optim piecewiselinear separ separ case assum k set point piecewiselinearli separ ie exist class point x determin w find maxim piecewiselinearli separ problem infinit mani w exist satisfi intuit optim w provid largest margin classif approach analog two class support vector machin svm approach add regular term dash line figur repres margin piec w piecewiselinear separ function margin separ class j ie distanc so would like minim w also add regular term k object piecewiselinearli separ problem get follow min st w simplifi notat formul piecewiselinear svm rewrit matrix notat see appendix complet matrix definit gener k three class problem follow matric let psfrag replac w w w w w figur piecewiselinear separ margin three class r nn ident matrix let vector one use notat fix k program becom min w k dual problem written as u elimin variabl w problem first show matrix c nonsingular proposit nonsingular c invers matrix i c k nk n nk n nk n nk n n indic n n ident matrix proof show c nonsingular k calcul invers matrix c defin appendix size n i kn recal n indic dimens featur space in in in in k i n size kn kn therefor kn kin in in in in in in kin simpl calcul shown invers matrix nk n nk n nk n nk n use proposit follow relationship result follow problem equat u use relationship elimin w dual problem addit remov simplif new dual problem becom u construct multicategori support vector machin conveni problem summat notat let dual vector u k u kk result dual problem piecewiselinear dataset is l li l l l number point class i recal piecewiselinear classif function class point x determin find maxim equat u solv w summat notat get therefor formul msvm piecewisenonlinearli separ case like twoclass case msvm gener piecewis nonlinear function construct separ function f x higher dimens featur space origin data point x transform function f x relat sum dot product vector higher dimens featur space accord symmetr function kx x theorem replac dot product x x mercer theorem guarante eigenvalu j expans kx x posit sucient condit function kx x defin dot product higher dimens featur space therefor let kx x return dual problem object function contain sum dot product j two point origin featur space transform point j p higher dimens featur space replac dot product result msvm piecewiselinearli separ dataset is l li l l l l point l correspond nonzero dual variabl u ij l refer support vector possibl l correspond figur piecewisepolynomi separ three class two dimens support vector indic circl one nonzero variabl l figur support vector repres circl around point point doubl circl indic two dual variabl u ij l complementar within kkt condit l l w consequ support vector locat closest separ func tion fact remaind point support vector necessari construct separ function result nonlinear classif problem point x find classif function support vector support vector maxim formul msvm piecewis insepar case proceed section provid formul piecewiselinearli piecewisenonlinear separ case construct classif function piecewis linearli insepar dataset must first choos error minim crite rion techniqu use preceed section formul msvm piecewiselinearli separ dataset combin norm error criterion use problem bennett mangasarian result msvm piecewiselinearli insepar problem use matrix notat section add term object problem result primal problem follow min wy solv dual substitut u simplifi produc follow problem u shown proposit problem maxim concav quadrat object bound polyhedr set thu exist local optim solut global optim proposit concav object function u e u concav proof matrix alway posit semidefinit symmetr thu hessian matrix neg semidefinit therefor object concav function problem ident problem piecewiselinearli separ case except dual variabl bound therefor transform data point l proceed ident section use function denot dot product featur space final msvm result l li l l section class point x determin find maximum function support vector support vector determin threshold valu solv primal problem w fix aw transform higher dimens featur space problem follow min y l st r l l r li r r l l r r l right side constraint constant thu problem linear program easili solv comput experi section present comput result compar msvm m rlp ksvm use svm krlp use rlp sever experi realworld dataset report descript dataset follow paragraph method implement use mino solver quadrat program problem m svm ksvm solv use nonlinear solver implement mino solver use reducedgradi algorithm conjunct quasinewton method msvm ksvm mrlp select valu given better solut may result dierent choic addit alli necessari valu use method kernel function piecewisenonlinear msvm ksvm method degre desir polynomi wine recognit data wine dataset use chemic analysi wine determin cultivar point featur three class dataset distribut follow point class point class point class dataset avail via anonym file transfer protocol ftp uci repositori machin learn databas domain theori ftpftpicsuciedupubmachinelearningdatabas glass identif databas glass dataset use identifi origin sampl glass chemic analysi dataset compris six class point featur distribut point class follow float process build window float process vehicl window nonfloat process build window contain tablewar headlamp dataset avail via anonym file transfer protocol ftp uci repositori machin learn databas domain theori ftpftpicsuciedupubmachinelearningdatabas us postal servic databas usp databas contain zipcod sampl actual mail databas compris separ train test set sampl train set sampl test set sampl belong one ten class integ sampl repres featur two experi perform first dataset normal fold cross valid use estim gener futur data second experi conduct two subset unit state postal servic usp data data contain handwrit sampl integ object dataset quickli eectiv interpret zipcod data separ train test set consist integ class compil two individu train subset usp train data first subset contain exampl belong class call set usp train data second subset contain exampl belong class call set usp train data similarli two subset creat test data dataset data valu scale test set accuraci report four method total number uniqu support vector result classif function msvm ksvm method given tabl contain result mrlp krlp msvm ksvm wine glass dataset anticip ad regular term msvm glass mrlp ksvm tabl percent test set accuraci total number support vector msvm ksvm krlp msvm ksvm degre one problem msvm produc better test gener mrlp wine dataset wine dataset piecewiselinearli separ therefor mrlp method infinit mani optim solut how ever test accuraci msvm degre one glass data much lower mrlp accuraci may indic choic larg howev degre increas accuraci msvm method improv exce mrlp result ksvm method gener surprisingli well test accuraci report ksvm wine dataset higher msvm linear krlp method perform well quadrat ksvm program wine dataset better msvm mrlp method glass data degre in creas method msvm ksvm improv dramat test accuraci use higher degre polynomi msvm ksvm method surpass accuraci mrlp krlp demonstr potenti polynomi piecewisepolynomi classif function linear piecewiselinear function tabl contain result four method usp data subset similar observ made dataset piecewis linearli separ solut mrlp found dataset test significantli lower method ksvm method gener slightli better msvm krlp method report similar accuraci ksvm method addit solv linear program rather quadrat program comput train time significantli smaller method chang paramet may improv gener aliz msvm method consist find classif function use fewer support vector ksvm fewer support vector sam msvm ksvm msvm ksvm tabl percent test set accuraci total number support vector msvm svm ksvm degre tabl total comput train time in second mrlpkrlp msvm ksvm usp ple classifi quickli sinc dotproduct sampl support vector must comput thu msvm would good method choos classif time critic cpu time train four method usp dataset report tabl time dataset list program run use batch system cluster machin time reliabl howev trend clear krlp method significantli faster method msvm ksvm method degre increas comput time would decreas certain degre reach would increas degre polynomi start increas vari dataset surprisingli usp dataset ksvm method faster mrlp method case wine glass dataset mrlp method faster train time ksvm dataset time report ibm rs model workstat mb ram conclus examin four method solut multicategori discrimin problem base lp method mangasarian qp method svm vapnik twoclass method rlp svm dier norm regular term past two dierent approach use k class case method call ksvm construct k twoclass discrimin use k quadrat program result classifi piecewiselinear piecewis nonlinear discrimin function depend kernel function use svm origin multicategori rlp k class construct piecewiselinear discrimin use singl linear program propos two new hybrid approach like ksvm method k rlp use lp construct k twoclass discrimin also formul new approach msvm began formul ad regular term mrlp like ksvm piecewisenonlinear discrimin nonlinear piec found map origin data point higher dimens featur space transform appear dual problem inner product two point higher dimens space gener inner product use make problem tractabl new msvm method requir solut singl quadrat program perform comput studi four method four dataset gener found k svm krlp gener howev msvm use fewer support vector counterintuit result sinc twoclass class statist learn theori predict fewer support vector result better gener theoret justif better gener ksvm krlp m svm mrlp open question krlp method provid accur ecient result piecewiselinear separ dataset ksvm also test surprisingli well requir solut k quadrat program thu provid solut smaller classif time piecewis linearli insepar dataset polynomi piecewisepolynomi classifi provid improv mrlp krlp method dataset krlp method found solut gener best nearli best less comput time matrix represent multicategori support vector machin appendix contain definit matric use gener kclass svm formul min let i r nn ident matrix matrix c n matrix vector one matrix r comparison classifi high dimension set decis tree construct via linear program geometri learn neural network train via linear program multicategori discrimin via linear program serial parallel multicategori discrimin support vector network method mathemat physic rule induct forens scienc linear nonlinear separ pattern linear program nonlinear program mathemat program machin learn uci repositori machin learn databas mino user guid algorithm gener radial basi function rbflike net classif problem polynomi time algorithm construct train class multilay perceptron pattern classif use linear program ming incorpor invari support vector machin compar support vector machin gaussian kernel radial basi function classifi natur statist learn theori natur statist learn theori theori pattern recognit multisurfac method pattern separ medic diagnosi appli breast cytolog tr polynomi time algorithm construct train class multilay perceptron algorithm gener radial basi function rbflike net classif problem natur statist learn theori network featur minim within decis tree featur select via concav minim support vector machin incorpor invari support vector learn machin comparison viewbas object recognit algorithm use realist model compar support vector machin gaussian kernel radial basi function classifi ctr tieyan liu yime yang hao wan huajun zeng zheng chen weiy ma support vector machin classif largescal taxonomi acm sigkdd explor newslett v n p june kobi crammer yoram singer algorithm implement multiclass kernelbas vector machin journal machin learn research rong jin jian zhang multiclass learn smooth boost machin learn v n p june glenn m fung o l mangasarian multicategori proxim support vector machin classifi machin learn v n p may ryan rifkin aldebaro klautau defens onevsal classif journal machin learn research p yiguang liu zhisheng lipe cao novel quick svmbase multiclass classifi pattern recognit v n p novemb ping zhong masao fukushima secondord cone program formul robust multiclass classif neural comput v n p januari andrea albrecht chakkuen wong approxim boolean function local search comput optim applic v n p januari isabel guyon jason weston stephen barnhil vladimir vapnik gene select cancer classif use support vector machin machin learn v n p fabien lauer ching y suen grard bloch trainabl featur extractor handwritten digit recognit pattern recognit v n p june