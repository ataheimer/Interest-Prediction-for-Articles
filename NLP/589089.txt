t feasibl bfg interior point algorithm solv convex minim problem a propos bfg primaldu interior point method minim convex function convex set defin equal inequ constraint algorithm gener feasibl iter consist comput approxim solut optim condit perturb sequenc posit paramet mu converg zero prove converg qsuperlinearli fix mu also show global converg analyt center primaldu optim set mu tend strict complementar hold b introduct consid problem minim smooth convex function convex set defin inequ constraint problem written r function minim cx mean compon m c must nonneg solut simplifi present avoid complic notat case linear equal constraint present discuss end paper sinc assum compon c concav feasibl set problem convex algorithm propos paper converg analysi requir f c dierenti least one function f c c m strongli convex reason latter hypothesi clarifi below sinc algorithm belong class interior point ip method may well suit problem mani inequ constraint also ecient number variabl remain small medium say fewer updat n n matric quasinewton qn formula problem variabl limit memori bfg updat use consid issu paper motiv base practic consider last year much progress realiz ip method solv linear convex minim problem see monograph nonlinear convex problem algorithm assum second deriv function use defin problem avail see practic how receiv editor septemb accept public in revis form januari publish electron august httpwwwsiamorgjournalssiopthtml de scienc av a thoma limog cedex franc paularmand unilimfr inria rocquencourt bp le chesnay cedex franc jeancharlesgilbertinriafr mip ufr mig universit paul sabati rout de narbonn toulous cedex franc janmipupstlsefr p armand j ch gilbert s janj egou ever uncommon find situat requir cannot sati fie particular larg scale engin problem see exampl partli motiv studi deal estim paramet three phase flow porou medium despit possibl use comput dieren tiation techniqu comput time need evalu hessian hessianvector product may larg ip algorithm use second deriv may unattract situat familiar unconstrain optim case qn tech niqu use first deriv onli prove ecient even million variabl see exampl meteorolog fact motiv present paper explor possibl combin ip approach qn techniqu ambit remain modest howev sinc confin question whether eleg bfg theori unconstrain convex optim still valid inequ constraint present applic would desir qnip algorithm case f c nonlinear necessarili convex postpon dicult subject futur research see possibl approach provid constraint satisfi qualif assumpt karush kuhntuck kkt optim condit problem written see exampl follow exist vector multipli r fx gradient f x for euclidean scalar product cx matrix whose column gradient c i x diagon matrix whose diagon element compon c lagrangian function associ problem defin r n sinc f convex compon c i concav fix convex function r n r f c twice dierenti gradient hessian respect x given primaldu ip approach rather standard see comput iter approxim solut perturb optim system sequenc paramet converg zero vector one whose dimens clear context last inequ mean compon cx must posit perturb complementar equat kkt condit paramet bfg interior point algorithm combinatori aspect problem inher determin activ constraint zero multipli avoid use word inner qualifi iter use find approxim solut fix outer iter collect inner iter correspond valu newton step solv first two equat fix solut linear system fx cx xx x direct sometim call primaldu step sinc obtain linear primaldu system primal step newton direct minim primal variabl x barrier function log c i x associ the algorithm spirit two problem relat sinc elimin repres optim condit unconstrain barrier problem cx result approxim solut also approxim minim barrier problem howev algorithm use primaldu direct shown present better numer ecienc see exampl algorithm solv approxim search direct comput solut posit definit symmetr matrix approxim xx x updat bfg formula see materi qn techniqu elimin obtain sinc iter forc remain strictli feasibl ie cx posit definit impli x descent direct x therefor forc converg inner iter possibl could forc decreas iter howev sinc algorithm also gener dual variabl prefer add function see log i c i x control chang function also use potenti function nonlinear complementar problem even though map x vx necessarili convex show uniqu minim solut decreas along direct primaldu merit function use forc converg pair x solut use linesearch shown addit p armand j ch gilbert s janj egou function v prevent unit stepsiz accept asymptot import point ecienc algorithm let us stress fact algorithm standard bfg algorithm solv barrier problem sinc hessian lagrangian approxim updat matrix hessian motiv follow argument first dierenc involv first deriv onli sinc deriv consid avail need approxim second hessian xx approxim independ becom illcondit goe zero third approxim obtain end outer iter use start matrix next outer iter look attract also inconveni restrict approach strongli convex function explain comput new iter stepsiz given linesearch matrix updat bfg formula use two vector sinc want new matrix m approxim satisfi qn equat m a properti bfg formula make sens defin formula well defin gener stabl posit definit matric provid vector satisfi inequ known curvatur condit express strict monoton gradient lagrangian two success iter unconstrain optim alway satisfi use wolf linesearch provid function minim bound below reason assumpt unconstrain optim longer case constraint present sinc optim problem may perfectli well defin even unbound below now assum hypothesi bounded would less restrict assum strong convex satisfactori inde bound lagrangian curvatur condit satisfi wolf linesearch unconstrain optim near solut inform collect matrix could come region far optim point would prevent qsuperlinear converg it erat observ assum f one function c i strongli convex lagrangian becom strongli convex function x fix assumpt curvatur condit satisfi independ kind linesearch techniqu actual use algorithm question whether present theori adapt convex problem henc includ linear program puzzl come back issu discuss section larg part paper devot analysi qn algorithm solv perturb kkt condit fix algorithm detail next section converg speed analyz section particular shown that fix primaldu pair x converg qsuperlinearli toward solut tool use prove converg essenti bfg interior point algorithm bfg theori section overal algorithm present shown sequenc outer iter global converg sens bound accumul point primaldu solut problem if addit strict complementar hold whole sequenc outer iter converg analyt center primaldu optim set algorithm solv barrier problem euclidean norm denot recal function r n r said strongli convex modulu x y r n equival definit see exampl chapter iv minim assumpt follow assumpt i function f c i m convex dierenti r n r least one function f c c m strongli convex ii set strictli feasibl point problem nonempti ie exist x r n cx assumpt i motiv section assumpt ii also call strong slater condit necessari wellposed feasibl interior point method convex assumpt equival fact set multipli associ given solut nonempti compact see theorem vii exampl assumpt follow clear consequ lemma suppos assumpt hold then solut set problem nonempti bound lemma level set logarithm barrier function compact fact use frequent consequ lemma recal complet lemma let f r n r convex continu function c r n continu function concav compon suppos set x r cx nonempti solut set problem nonempti bound then r set log c i x compact and possibl empti let x first iter feasibl ip algorithm henc satisfi cx defin level set lemma suppos assumpt hold then barrier problem uniqu solut denot x proof assumpt lemma lemma l p nonempti compact barrier problem least one solut solut also uniqu sinc strictli convex x r inde assumpt i x given posit definit simplifi notat denot z x typic pair primaldu variabl z set strictli feasibl zs p armand j ch gilbert s janj egou algorithm gener sequenc pair z z z posit definit symmetr matrix given pair z next one z obtain follow first stepsiz uniqu solut uniqu come posit cx posit definit for unic x use next matrix updat m given formula give symmetr posit definit matrix m provid symmetr posit definit see latter condit satisfi strong convex assumpt inde sinc least one function f c i strongli convex fix function x x strongli convex is exist constant sinc size displac x merit function use estim progress solut must depend x follow idea anstreich vial add function forc take valu cx merit function defin z x z log i c i x note use merit function reason provid problem z z bfg interior point algorithm uniqu solut solut direct descent direct check lemma below lemma suppos assumpt hold then problem uniqu solut z x x uniqu solut barrier problem ith compon defin i c i x furthermor stationari point z proof optim uniqu solut x barrier problem x cx hand sinc log minim c i x i index i z z ad preced two inequ give z z z z henc z solut remain show z uniqu stationari point z stationari satisfi cancel first equal give fx cxcx thu x uniqu minim convex function now second equat system abov lemma suppos z z symmetr posit definit let solut descent direct point z z mean z proof z d use nonposit hand satisfi second equat one see also nonposit formula z given statement lemma follow calcul furthermor z z z state precis one iter algorithm use solv perturb kkt system constant given independ iter index p armand j ch gilbert s janj egou algorithm for solv one iter begin iter current iter suppos avail well posit definit matrix approxim hessian lagrangian xx x comput d x solut linear system comput stepsiz mean backtrack line search test sucient decreas condit satisfi choos new trial stepsiz go step satisfi set z updat bfg formula given lemma descent direct z stepsiz satisfi found linesearch implicitli assum satisfi z hold new iter z conclud section result give contribut linesearch converg sequenc gener algorithm spirit similar result given zoutendijk for proof see say function c lipschitz continu first deriv denot level set determin first iter z lemma c open convex neighborhood level set l pd posit constant k z l pd determin linesearch step algorithm one follow two inequ hold import mention result hold even though may defin posit stepsiz along d linesearch may reduc stepsiz first stage enforc feasibl global rlinear converg algorithm a converg analysi bfg path qsuperlinear converg tradit lead rlinear converg see section show iter gener algorithm converg z x solut converg speed use notat first result show that iter x remain level set l pd sequenc cx bound bound away zero bfg interior point algorithm lemma suppos assumpt hold then level set l pd compact exist posit constant k k proof sinc cx log i c i x bound m log constant k assumpt lemma level set l compact continu cl also compact cx bound bound away zero z l pd proven impli bound below constant k henc compon zs l pd bound bound away zero shown l pd includ compact set now compact continu next proposit crucial techniqu use prove global converg see claim proxim point z uniqu solut measur valu z norm gradient z unconstrain optim correspond result direct consequ strong convex here necessarili convex result still establish use lemma lemma function nonconvex exampl minim halflin nonneg real number proposit suppos assumpt hold then constant z l pdaz z proof let us show strongli convex neighborhood z use fact e hessian z written assumpt fix lagrangian strongli convex function variabl x follow hessian respect x posit definit us show matrix also posit definit multipli matrix side vector u v r n posit definit cx quantiti nonneg vanish one deduc next posit definit let us prove local version proposit exist constant open neighborhood n z z z z p armand j ch gilbert s janj egou inequ left come fact z strong convex near z inequ right first use local convex arbitrari z near z z z z cauchyschwarz inequ inequ left one get simplifi squar give inequ right extend valid z l pd suce note that virtu lemma ratio z z well defin continu compact set l pd z uniqu minim l pd ratio respect bound away zero bound l pd n posit constant k k conclus proposit follow take proof rlinear converg rest follow lemma part theori bfg updat state independ present context see byrd noced denot k angl k k roundup oper lemma let m k posit definit matric gener bfg formula use pair vector k k k satisfi k independ k then r exist posit constant b b b index k least rk indic j k assumpt made k k lemma satisfi context first one due strong convex one function f c c m fact bound away zero lemma f c c second one deduc lipschitz inequ bounded lemma first inequ theorem suppos assumpt hold f c c function then algorithm gener sequenc z k converg z rlinearli mean lim sup kz k z k particular z proof denot k posit constant independ iter index also use notat bfg interior point algorithm bound cx given lemma fact f c c impli c open convex neighborhood level set l pd exampl open bound convex set contain l pd thi set use c bound given neighborhood therefor linesearch lemma posit constant k either let us appli lemma fix r denot j set indic j hold use lemma bound lemma one let us denot k posit constant cx k x l pd use inequ a also d x p armand j ch gilbert s janj egou combin inequ give posit constant k and j j end proof standard see use proposit j j hand linesearch z k lemma k j rk rk last inequ give k k posit constant use inequ left one k rlinear converg z k follow qsuperlinear converg algorithm a rlinear converg result previou section readi establish qsuperlinear converg sequenc z k gener algorithm definit z k converg qsuperlinearli z follow estim hold z z mean z k z z k z assum z k z get result f c littl bit smoother name twice continu dierenti near x use notat start show unit stepsiz accept asymptot linesearch condit provid updat matrix k becom good or sucient larg sens specifi inequ provid iter z k sucient close solut z given two sequenc vector u k v k norm space posit number write u k ov k exist sequenc k r k u k k v k k proposit suppos assumpt hold f c twice continu dierenti near x suppos also sequenc z k gener algorithm converg z posit definit matric k satisfi estim d x k sucient decreas condit satisfi k sucient larg provid bfg interior point algorithm proof observ first posit definit impli d x posit constant k sucient larg k observ also k for x use therefor k larg enough z k z k near z one expand z k second order expans give lefthand side want show quantiti neg k larg first aim show z k smaller term order od k purpos one comput hand use one get lemma k estim fact lemma bounded c k becom d x d clear result proven show that posit constant k k larg z k k kd k show thi use p armand j ch gilbert s janj egou last express z k k upper bound d x k obtain cauchyschwartz inequ d x d k follow d x d k therefor use lemma one get posit constant k k larg proposit show particular function v ad get merit function right curvatur around z unit stepsiz x accept linesearch follow proposit establish necessari sucient condit qsuperlinear converg denni more type analysi assum unit stepsiz taken updat matrix k sucient good asymptot manner given estim slightli dierent proposit suppos assumpt hold f c twice dierenti x suppos sequenc z k gener algorithm converg z that k sucient larg unit stepsiz accept linesearch z k converg qsuperlinearli toward z proof let us denot nonsingular jacobian matrix perturb kkt condit solut z x first order expans righthand side z ident e give subtract md k side assum unit stepsiz obtain z bfg interior point algorithm suppos z k converg qsuperlinearli then righthand side order oz k z follow fact that qsuperlinear converg z k z k let us prove convers lefthand side od k due nonsingular m give z k z unit stepsiz z z k z final get z k z prove qsuperlinear converg sequenc z k need follow result bfg theori see theorem lemma let m k sequenc matric gener bfg formula given symmetr posit definit matrix pair k k vector verifi symmetr posit definit matrix then sequenc m k k bound use lemma see bfg formula give estim note estim impli qsuperlinear converg z k follow function twice dierenti neighborhood point x r n said local radial lipschitzian hessian x exist posit constant l x near x one theorem suppos assumpt hold f c c function twice continu dierenti near x local radial lipschitzian hessian x suppos linesearch algorithm use constant sequenc z k gener algorithm converg z x qsuperlinearli and k sucient larg unit stepsiz accept linesearch proof let us start show lemma appli first k k alreadi discuss lemma converg seri use taylor expans assum k larg enough f c c near p armand j ch gilbert s janj egou local radial lipschitz continu f c x bounded k exist posit constant k k z henc seri converg theorem therefor fact k parallel x estim proposit unit stepsiz accept k larg enough qsuperlinear converg z k follow proposit overal primaldu algorithm section consid overal algorithm solv problem recal lemma set primal solut problem nonempti bound slater condit as sumption ii set dual solut also nonempti bound let us denot primaldu solut problem also solut necessari sucient condit optim overal algorithm solv call algorithm a consist comput approxim solut perturb optim condit sequenc s converg zero primaldu algorithm use find approxim solut done socal inner iter next decreas process solv new valu repeat call outer iter collect inner iter solv fix valu index outer iter superscript j n algorithm for solv problem one outer iter begin jth outer iter approxim z j z solut z suppos avail well posit approxim hessian lagrangian valu given well precis threshold j start z j use algorithm z j choos new start iter z j next outer iter well posit definit matrix j set new paramet j j j j converg zero j bfg interior point algorithm start jth outer iter possibl take z j updat matrix obtain end jth outer iter far global converg concern z determin import therefor point algorithm leav user much freedom maneuv theorem give us global converg result gener algorithm theorem suppos assumpt hold f c c function algorithm gener bound sequenc z j limit point z j primaldu solut problem proof theorem outer iter algorithm termin iter z j satisfi stop criteria step therefor algorithm gener sequenc z j sinc sequenc j j converg zero limit point z j solut problem remain show z j bound let us first prove bounded x j convex lagrangian impli use posit j cx next stop criteria algorithm a follow x j unbound set j x j j x j one choos subsequ j lim last inequ deduc moreov sinc cx j c i follow see exampl proposit iv formula therefor solut set problem would unbound contradict claim lemma prove bounded multipli suppos algorithm gener unbound sequenc posit vector j subsequ j sequenc jj bound thu least one limit point say divid two inequ j take limit j deduc cx use concav compon c i one inequ right follow strict feasibl first iter multipli deduc cx contradict p armand j ch gilbert s janj egou rest section give condit whole sequenc converg particular point call analyt center primaldu optim set actual occur follow two condit hold strict complementar proper choic forc sequenc j algorithm a satisfi estim mean j j let us first recal notion analyt center optim set assumpt uniqu defin see monteiro zhou relat result denot optp optd set primal dual solut problem analyt center optp defin follow optp reduc singl point analyt center precis point otherwis optp convex set one point case f strongli convex and assumpt i least one constraint function c i say strongli convex follow index set nonempti it contain analyt center optp defin uniqu solut follow problem log c i x fact problem well defin uniqu solut matter lemma below similarli optd reduc singl point analyt center point case multipl dual solut index set nonempti otherwis optd would reduc analyt center optd defin uniqu solut follow problem log i lemma suppos assumpt hold optp resp optd reduc singleton problem resp uniqu solut proof consid first problem suppos optp singleton seen b nonempti convex set optp concav function c i exist therefor feasibl set nonempti hand let x point satisfi constraint set log c x ib log c x nonempti bound lemma close therefor problem solut final assumpt i know index bfg interior point algorithm c i strongli convex follow object strongli concav problem uniqu solut similar argument fact object function strictli concav follow problem uniqu solut complementar ie cx convex problem index set b n intersect may indic neither b n said problem strict complementar properti n equival exist primaldu solut satisfi strict complementar theorem suppos assumpt hold f c c function suppos also problem strict complementar properti sequenc j algorithm satisfi estim sequenc z j gener algorithm converg point z x analyt center primal optim set analyt center dual optim set proof let x arbitrari primaldu solut x minim use convex j stop criterion inner iter algorithm a one x theorem constant c ad correspond side two inequ lead pursu adapt idea use mclinden give properti limit point path x let us defin indic c i c i substitut divid j give c i x c i assumpt suppos x limit point x j j take limit preced estim provid c i x p armand j ch gilbert s janj egou necessarili that strict complementar exactli term lefthand side preced inequ henc arithmeticgeometr mean inequ c i x c i x one take inequ c i x c i x show x solut solut sinc problem uniqu solut sequenc x j converg x sequenc j converg discuss way conclus discuss result obtain paper give remark rais open question problem linear constraint algorithm present convex inequ constraint onli also use linear constraint present consid problem min fx obtain ad linear constraint problem p n matrix p n b r p given rang space a problem reduc problem use basi null space matrix a inde let x first iter suppos strictli feasibl sens let us denot z n q matrix whose column form basi null space a then point satisfi linear constraint written notat problem rewritten problem u r form thank transform deduc assumpt minim assumpt algorithm solv problem or equival problem converg bfg interior point algorithm assumpt i realvalu function f c i m convex dierenti ane subspac x b least one function f c c m strongli convex x ii exist x r n assumpt previou result appli particular algorithm converg rlinearli if f c also c qsuperlinearli if f c also c twice continu dierenti near x local radial lipschitzian hessian similarli conclus theorem appli f c also c feasibl algorithm qn techniqu framework qn method properti gener feasibl iter view restrict limit applic feasibl algorithm inde case problem sometim dicult find strictli feasibl initi iter matrix updat solv problem order q onli instead order n infeas algorithm solv problem directli q n qn updat approach reduc hessian lagrangian z z rapidli full hessian feasibl algorithm like converg rapidli strong convex hypothesi anoth issu concern extens present theori convex problem without strong convex assumpt assumpt i hypothesi class problem consid encompass linear program f c ane clear deal properli linear program algorithm need modif sinc bfg formula longer defin cours would ineect solv linear program qn techniqu propos paper m desir matrix problem almost linear near solut may encount techniqu deal situat k k interest accept look limit bfg formula possibl updat formula could updat matrix satisfi k posit semidefinit provid alreadi posit semidefinit fact k may singular rais diculti howev exampl search direct x may longer defin see formula matrix cxcx cx singular therefor present theori cannot extend straightforward manner hand strong convex assumpt may view import restrict fictiv strongli convex constraint alway ad obviou exampl fictiv constraint x x k constant k larg enough constraint inact solut solut origin problem alter new constraint present theori appli better control outer iter last least global converg result section independ updat rule paramet j practic howev choic decreas valu j j essenti ecienc algorithm would deserv detail numer studi theoret viewpoint would highli desir updat rule would allow outer iter algorithm converg qsuperlinearli along p armand j ch gilbert s janj egou line interest problem design algorithm barrier paramet would updat everi step qsuperlinear converg iter extens would involv dicult issu global converg result prove paper give us reason believ unreason tackl open question acknowledg would like thank refere valuabl com ment one shown us direct argument last part proof proposit one final chosen give paper refere brought mclinden paper attent led us theorem r converg infeas primaldu interiorpoint method convex program asymptot analysi penalti barrier method convex linear program comput di trust region interior point algorithm linearli constrain optim a trust region method base interior point techniqu tool analysi quasinewton method applic unconstrain minim primaldu algorithm minim nonconvex function subject bound linear equal constraint principl techniqu algorithm di interior point approach linear potenti reduct method class smooth convex program problem classic logarithm barrier function method class smooth convex program problem numer method unconstrain optim nonlinear equat formul theori newton interiorpoint method nonlinear program sequenti unconstrain minim techniqu practic method optim feasibl direct interiorpoint techniqu nonlinear optim interior point techniqu optimizationcomplementar method analyt center solv smooth convex problem practic interiorpoint method convex program unifi approach interior point algorithm linear complementar problem new continu method complementar problem uniform p limit behavior trajectori gener continu method monoton complementar problem limit memori bfg method larg scale optim project sumt method convex program problem analogu moreau proxim theorem interior point algorithm solv smooth convex program base newton method extens karmarkartyp algorithm class convex separ program problem global linear rate converg exist converg central path convex program dualiti result updat quasinewton matric limit storag converg variabl metric algorithm global converg properti variabl metric algorithm minim without exact line search theori algorithm linear optimizationan interior point approach analyt center interior point method mathemat program comput experi primaldu interiorpoint method smooth convex program pure primal newton barrier step may infeas superlinear quadrat converg primaldu interior point method constrain optim interior point algorithmstheori analysi integ nonlinear pro gram tr ctr richard h byrd jorg noced richard a waltz feasibl interior method use slack nonlinear optim comput optim applic v n p octob paul armand quasinewton penalti barrier method convex minim problem comput optim applic v n p octob dingguo pu weiwen tian revis dfp algorithm without exact line search journal comput appli mathemat v n p may