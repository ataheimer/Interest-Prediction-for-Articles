t dimension reduct unsupervis learn condit gaussian network a abstractthi paper introduc novel enhanc unsupervis learn condit gaussian network benefit featur select propos base assumpt that absenc label reflect cluster membership case databas featur exhibit low correl rest featur consid irrelev learn process thu suggest perform process use relev featur then everi irrelev featur ad learn model obtain explanatori model origin databas primari goal simpl and thu effici measur assess relev featur learn process present addit form measur allow us calcul relev threshold automat identifi relev featur experiment result report synthet realworld databas show abil propos distinguish relev irrelev featur acceler learn howev still obtain good explanatori model origin databas b introduct one basic problem aris great varieti eld includ pattern recognit machin learn statist socal data cluster problem despit dierent interpret expect give rise to gener data cluster problem involv assumpt that addit observ variabl also refer predict attribut or simpli featur hidden variabl last unobserv variabl would ect cluster membership everi case databas thu data cluster problem also refer exampl learn incomplet data due exist hidden variabl incomplet data repres special case miss data miss entri concentr singl variabl hidden cluster variabl is refer given databas incomplet case unlabel point view adopt paper data cluster problem may dene infer gener joint probabl densiti function given databas concret focu learn condit gaussian network data cluster roughli speak condit gaussian network graphic model encod condit gaussian distribut variabl domain then appli data cluster encod multivari normal distribut observ variabl condit state cluster variabl aim automat recov gener joint probabl densiti function given incomplet databas learn condit gaussian network paper concern understand data cluster descript task rather predict task thu order encod descript origin databas learnt model must involv origin featur instead subset them unsupervis learn algorithm focu predict task featur select proven valuabl techniqu increas predict abil elicit model paper demonstr that even focus descript featur select also known dimension reduct protabl tool improv perform unsupervis learn gener framework propos show unsupervis learn condit gaussian network benet featur select straightforward consist three step i ident relev featur learn ii unsupervis learn condit gaussian network databas restrict relev featur iii addit irrelev featur learnt network obtain explanatori model origin databas accord framework featur select consid preprocess step accompani postprocess step fulll object postprocess step consist addit everi irrelev featur learnt model nal model encod gener joint probabl densiti function origin data complet dene framework one decid automat dimension reduct scheme identifi relev featur learn paper introduc simpl relev measur assess relev featur learn process order select subset contain salient one addit propos heurist method automat qualifi everi featur complet relev irrelev learn process carri automat calcul relev threshold featur relev measur valu higher relev threshold consid relev learn pro cess wherea rest quali irrelev experiment result report paper show framework depict provid us good explanatori model origin databas reduc cost learn process relev featur use process addit eectiv simplic automat dimension reduct scheme propos repres valuabl advantag allow framework reduc dimension databas perform learn ecient besid scheme tie particular learn algorithm and therefor adapt them remaind paper organ follow section introduc condit gaussian network data cluster section dedic explain detail automat dimension reduct scheme present new relev measur well automat discov relev irrelev featur calcul relev threshold section also present propos unsupervis learn condit gaussian network framework alreadi outlin experiment result show abil propos identifi relev featur acceler learn process compil section final draw conclus section condit gaussian network data cluster ing section start introduc notat use throughout paper then give formal denit condit gaussian network also present bayesian structur em algorithm use explanatori purpos well experi present section due good perform unsupervis learn condit gaussian network notat follow usual convent denot variabl uppercas letter state letter lowercas use letter letter boldfac uppercas design set variabl boldfac lowercas letter letter denot assign state variabl given set gener joint probabl densiti function x repres x addit gener condit probabl densiti function x given y variabl x discret joint probabl mass function x thu denot condit probabl mass function x given y hand variabl x continu joint probabl densiti function x thu fx j y denot condit probabl densiti function x given y condit gaussian network alreadi mention face data cluster problem assum exist random variabl x partit ndimension continu variabl unidimension discret hidden cluster variabl c x said follow condit gaussian distribut distribut y condit state c multivari normal distribut is c ndimension mean vector c n n varianc matrix posit denit dene condit gaussian network cgn x graphic model encod condit gaussian distribut x essenti cgn belong class mix graphic model introduc rst time lauritzen wermuth develop class group model discret continu variabl present condit distribut continu variabl given discret variabl restrict multivari gaussian recent cgn success appli data cluster concret cgn dene direct acycl graph model structur determin condit independ among variabl y set local probabl densiti function multinomi distribut variabl c model structur yield factor gener joint probabl densiti function x follow denot congur parent consist x local probabl densiti function multinomi distribut previou equat assum depend nite set paramet therefor equat rewritten follow model structur multinomi distribut local probabl densiti function c c c c c c figur structur local probabl densiti function multinomi distribut cgn three continu variabl one binari cluster variabl c denot paramet local probabl densiti function h denot hypothesi condit independ assert impli hold true gener joint probabl densiti function x obtain equat that order encod condit gaussian distribut x local probabl densiti function cgn linearregress model thu normal distribut mean standard deviat given form miss arc j impli b c linearregress model local paramet c b c column vector loop run em algorithm comput map paramet b l given perform search model structur evalu model structur l l let l model structur highest score among encount search score l l figur schemat bsem algorithm interpret compon local paramet c follow given uncondit mean v c condit varianc given pa b c linear coecient ect strength relationship j see figur exampl cgn three continu variabl one binari cluster variabl note model structur independ valu cluster variabl c thu model structur valu c howev paramet local probabl densiti function depend valu c may dier distinct valu variabl c learn condit gaussian network incomplet data one method learn cgn incomplet data wellknown bayesian structur em bsem algorithm develop friedman due good perform algorithm receiv special attent literatur motiv sever variant use bsem algorithm explanatori purpos well experi present section appli bsem algorithm data cluster problem assum databas n case everi case repres assign n observ variabl involv problem domain so n n random variabl describ databas let denot set observ variabl is nn variabl assign valu similarli let h denot set hidden unobserv variabl is n variabl ect unknown cluster membership case d learn cgn incomplet data bsem algorithm perform search space cgn base wellknown em algorithm direct optim bayesian score shown figur bsem algorithm compris two step optim cgn paramet structur search model select concret bsem algorithm altern step nd maximum posteriori map paramet current cgn structur usual mean em algorithm step search cgn structur iter bsem algorithm attempt maxim expect bayesian score instead true bayesian score interest solv data cluster problem consider size direct applic bsem algorithm appear figur may unrealist ineci solut opinion reason possibl ineci comput score l impli huge comput expens take account everi possibl complet databas common use relax version present bsem algorithm consid like complet databas comput score l instead consid everi possibl complet thu relax version bsem algorithm compris iter parametr optim current model structur search databas complet like complet use best estim gener joint probabl densiti function data far current model is posterior probabl distribut cluster variabl c case databas l calcul then case assign cluster maximum posterior probabl distribut c reach use relax version experi section complet specifi bsem algorithm decid structur search procedur step figur usual approach perform greedi hillclimb search cgn structur consid possibl addit remov revers singl arc point search structur search procedur desir exploit decomposit properti cgn factor properti bayesian score complet data howev structur search procedur exploit properti use log margin likelihood expect complet data log d j h usual chosen score guid structur search make use experi accord assumpt i databas restrict cluster variabl c c multinomi sampl ii databas complet iii paramet multinomi distribut c independ follow dirichlet distribut that y c databas restrict continu variabl case set valu cluster variabl c take term pd correspond margin likelihood trivial bayesian network singl node c calcul close form reason assumpt accord moreov term form f c d y c j h c v alc repres margin likelihood domain contain continu variabl assumpt continu data sampl multivari normal distribut then term evalu factor close form reason assumpt accord automat dimension reduct unsupervis learn condit gaussian network section devot detail present new automat dimension reduct scheme appli unsupervis learn cgn section start introductori revis gener problem featur select brief discuss problem appear adapt supervis featur select unsupervis paradigm supervis unsupervis featur select mani data analysi applic size data larg larg due excess number featur huge number instanc both learn algorithm work ecient even sometim eectiv one may need reduc data size featur select proven valuabl techniqu achiev reduct dimension data select subset featur focu attent subsequ learn process gener form featur select consid problem search optim subset origin featur accord certain criterion criterion speci detail measur good featur subset well relev featur choic criterion uenc purpos featur select howev share dierent purpos desir improv perform subsequ learn algorithm usual term speed learn predict abil learnt model andor comprehens learnt model roughli speak featur select involv algorithm explor space potenti featur subset evalu function measur qualiti featur subset sinc space featur subset n featur size n featur select mechan typic perform nonexhaust search one popular techniqu use simpl hillclimb search known sequenti select may either forward backward former search start empti set select featur and time add best featur among unselect one accord evalu function process stop improv made similarli backward sequenti select begin full set featur and time remov worst featur base evalu function improv found address doak featur select mechan base sequenti select requir great deal process time databas larg number featur also complex eectiv search algorithm use explor space potenti featur subset main advantag algorithm sequenti select avoid get stuck local maxima mean random howev approach usual involv huge comput eort one recent work eld report paper author propos explor space featur subset accord evolutionari populationbas random search algorithm repres instanc estim distribut algorithm eda approach author distinguish two approach evalu function featur select wrapper lter wrapper approach impli search optim featur subset tailor perform function subsequ learn algorithm is consid feedback perform function particular subsequ learn algorithm part function evalu featur subset hand lter approach reli intrins properti data presum aect perform learn algorithm direct function perform then lter approach tri assess merit dierent featur subset data ignor subsequ learn algorithm appli supervis learn main object featur select improv classic accuraci class label predict accuraci model elicit subsequ learn algorithm consid relev featur task independ approach use lter wrapper approach requir class label present data order carri featur select filter approach evalu featur subset usual assess correl everi featur class label use dierent measur hand wrapper approach reli perform learn algorithm measur classic accuraci valid set evalu good dierent featur subset evid supervis featur select research wrapper approach outperform lter approach although featur select central problem data analysi suggest grow amount research area vast major research carri supervis learn paradigm supervis featur select pay littl attent unsupervis learn unsupervis featur select work exist address latter problem author present method rank featur accord unsupervis entropi measur algorithm work lter approach plu backward sequenti select search devaney ram propos wrapper approach combin either forward backward sequenti select search perform conceptu cluster talavera introduc lter approach combin search one step wrapper approach combin either forward backward sequenti select search featur select mechan hierarch cluster symbol data lter approach use featur depend measur dene fisher wherea perform criterion consid multipl predict accuraci measur averag accuraci predict valu featur present test data appli mechan compris lter approach search one step present featur select conceptu cluster symbol data consid class label predict accuraci perform criterion opinion two main problem translat supervis featur select unsupervis featur select firstli absenc class label ect membership everi case databas inher unsupervis paradigm make imposs use evalu function supervis featur select secondli standard accept perform task unsupervis learn due lack uni perform criterion mean optim featur subset may vari task task natur solut problem propos interpret perform task unsupervis learn multipl predict accuraci seem reason approach extend standard accept perform task supervis learn unsupervis learn wherea former learn compris predict one featur class knowledg mani latter aim predict mani featur knowledg mani hand evalu unsupervis featur select mechan measur class label predict accuraci learnt model case test set perform learn train set class label mask out speed learn comprehens learnt model also studi although consid less import perform criteria learn condit gaussian network data cluster benet featur select motiv perform unsupervis featur select dier motiv previous refer paper due distinct point view data cluster problem learnt model data cluster primarili evalu regard multipl class label predict accuraci occur featur select proven valuabl techniqu reduc dimension databas perform learn usual pursu improv perform learnt model consid relev featur task howev main goal data cluster happen paper descript rather predict learnt model must involv featur origin databas order encod descript databas wellknown unsupervis learn cgn solv data cluster problem dicult time consum task even focus descript origin featur usual consid learn process aim solv handicap propos framework learn cgn data cluster benet featur select framework straightforward consist three step i ident relev featur learn ii unsupervis learn cgn databas restrict relev featur iii addit irrelev featur learnt cgn obtain explanatori model origin databas thu featur select consid preprocess step accompani postprocess step achiev object postprocess step consist addit everi irrelev featur elicit model condit independ rest given cluster variabl make framework applic unsupervis learn cgn dene relev howev mean relev depend particular purpos dimension reduct due lack uni perform criterion data cluster concret case object reduc dimension databas learn cgn data cluster decreas cost learn process still obtain good explanatori model origin data achiev goal assess compar term explanatori power runtim learn process cgn learnt given origin databas cgn elicit use dimension reduct learn process assess achiev object lead us make follow assumpt consider featur either relev irrelev learn process absenc label ect cluster membership case databas featur exhibit low correl rest featur consid irrelev learn process implicitli assumpt dene relev accord purpos perform dimension reduct import note assumpt independ cluster data readili appli without requir previou cluster databas justic previou assumpt straightforward featur low correl rest like remain condit independ rest featur given cluster variabl learn cgn origin databas thu cgn elicit origin databas restrict featur highli correl rest like encod set condit depend assert cgn learnt origin databas paramet local probabl densiti function featur appear cgn similar well furthermor low correl featur ad cgn elicit restrict databas condit independ rest given cluster variabl nal cgn like encod set condit depend independ assert cgn learnt origin data thu explanatori power cgn almost model like similar work success made use similar assumpt although three work present assumpt gener form valid conceptu cluster symbol data paper rst knowledg veri continu domain relev measur order assess relev evalu follow simpl and thu ecient relev measur ijjrest n number featur databas n number case databas r ijjrest sampl partial correl j adjust remaind variabl last quantiti express term maximum likelihood estim element invers varianc matrix r ijjrest then relev measur valu featur averag likelihood ratio test statist exclud edg featur graphic gaussian model mean featur like remain condit independ rest given cluster variabl learn progress receiv low relev measur valu thu measur show reason behavior accord denit relev relev threshold calcul relev measur valu everi featur databas decreas relev rank featur obtain now would like know mani need perform learn appropri is would like identifi relev rank relev featur learn process knew k featur need could simpli choos rst k featur relev rank name k featur highest relev measur valu howev kind knowledg usual propos novel automat solut problem relev measur valu featur interpret averag valu likelihood ratio test statist exclud singl edg featur graphic gaussian model thu propos follow evalu relev measur featur calcul relev threshold let rel featur subset contain relev featur loop run em algorithm comput map paramet b rel l rel l given perform search model structur evalu model structur l rel l l rel l l let rel l model structur highest score among encount search exit loop score rel l l let final nal model obtain ad irrelev featur rel l calcul map paramet b final final return s final b figur schemat automat dimension reduct scheme bsem algorithm framework present heurist relev threshold calcul reject region boundari edg exclus test graphic gaussian model likelihood ratio test statist see detail heurist agre purpos perform dimension reduct quali irrelev featur like remain condit independ rest given cluster variabl learn progress shown distribut function likelihood ratio test statist follow distribut function x random variabl thu test reject region boundari which consid relev threshold given resolut follow equat simpl manipul resolut previou equat turn nding root equat newtonraphson method use experi exampl suitabl method solv equat featur exhibit relev measur valu higher relev threshold quali relev learn process rest featur treat irrelev fit automat dimension reduct learn subsect present automat dimension reduct scheme bsem algorithm gener framework previous introduc howev notic scheme coupl particular learn algorithm could adapt them figur show that preprocess step consist automat dimension reduct scheme bsem algorithm appli usual restrict origin databas relev featur rel hidden cluster variabl c is databas perform learn consist n case figur exampl tanb model structur seven predict attribut g everi case repres assign relev featur so r n random variabl describ databas r number relev featur denot set observ variabl restrict relev featur set hidden variabl rel jo rel respect obvious figur rel l repres model structur relev featur consid learn pro cess rel l denot hypothesi condit independ assert impli rel l hold true joint probabl densiti function rel learn end postprocess step compris addit everi irrelev featur model return bsem algorithm condit independ rest given cluster variabl result explanatori model origin databas local paramet node nal model associ irrelev featur easili estim complet origin databas last complet restrict databas rel experiment evalu section dedic show abil propos perform automat dimension reduct acceler unsupervis learn cgn without degrad explanatori power nal model order reach conclus perform sort experi synthet realworld databas rst evalu relev measur introduc section mean assess relev featur learn process second evalu abil relev threshold calcul appear section automat distinguish relev irrelev featur learn address use bsem algorithm unsupervis learn algorithm current experi limit bsem algorithm learn tree augment naiv bay tanb model sensibl usual decis reduc otherwis larg search space cgn moreov allow solv ecient data cluster problem consider size wellknown diculti involv learn dens connect cgn larg databas pain slow probabilist infer work these tanb model constitut class compromis cgn dene follow con dition predict attribut may have most one predict attribut parent figur show exampl tanb model structur tanb model cgn interest tradeo ecienc eectiv achiev is balanc cost learn process qualiti learnt cgn databas involv synthet realworld databas involv experiment evalu knowledg cgn use gener synthet databas allow us assess accur achiev object besid realworld databas provid us realist evalu framework obtain synthet databas construct tanb model dierent complex sampl rst tanb model involv predict continu attribut valu cluster variabl rst predict attribut relev rest irrelev arc relev attribut randomli chosen uncondit mean everi relev attribut xed rst valu cluster variabl second third linear coecient randomli gener interv condit varianc xed see equat multinomi distribut cluster variabl c uniform everi irrelev attribut follow univari normal distribut mean varianc valu cluster variabl second tanb model involv predict continu attribut valu cluster variabl rst predict attribut relev rest irrelev arc relev attribut randomli chosen uncondit mean everi relev attribut xed rst valu cluster variabl second third linear coecient randomli gener interv condit varianc xed see equat multinomi distribut cluster variabl c uniform everi irrelev attribut follow univari normal distribut mean varianc valu cluster variabl second model consid complex rst due higher degre overlap probabl densiti function cluster higher number irrelev attribut tanb model sampl case learn databas case test databas forthcom learn databas sampl tanb model refer synthet synthet respect obvious discard entri correspond cluster variabl learn databas test databas anoth sourc data evalu consist wellknown realworld databas uci repositori machin learn databas waveform artici databas consist predict featur last predict attribut nois attribut turn irrelev describ underli cluster use data set gener uci repositori obtain case learn case test pima real databas contain case predict featur cluster use rst case learn last case test rst databas chosen due interest work databas consider size thousand case ten featur addit thi repres opportun evalu eectiv approach true irrelev featur known beforehand second databas consider shorter number case number featur chosen get feedback scalabl dimension reduct scheme obvious delet cluster entri learn databas test databas perform criteria exist essenti purpos focu explanatori power generaliz learnt model rst purpos summar given databas learnt model second purpos elicit model abl predict unseen instanc thu explanatori power learnt cgn assess evalu achiev purpos log margin likelihood sc nal multipl predict accuraci ltest learnt cgn seem sensibl perform measur rst second purpos respect multipl predict accuraci measur logarithm score rule good jd test j yd test log fy test set test case jd test j number test case higher valu criterion higher multipl predict accuraci learnt cgn note ltest primari perform measur measur assess explanatori power learnt cgn focus descript ltest extrem necessari detect model that suer overt high sc nal valu although abl gener learn data unseen instanc note equat repres kind probabilist approach standard multipl predict accuraci understand latter averag accuraci predict valu featur present test data data cluster problem consid infer gener joint probabl densiti function learn data via unsupervis learn cgn probabilist approach present equat appropri standard multipl predict accuraci illustr simpl exampl let us imagin dierent cgn exhibit standard multipl predict accuraci dierent multipl predict accuraci measur logarithm score rule good would ect gener joint probabl densiti function encod cgn dierent moreov would impli cgn gener learn data unseen instanc better ie likelihood unseen instanc higher other although standard multipl predict accuraci same thu standard multipl predict accuraci would appropri perform criterion context would unabl distinguish model work made use logarithm score rule good assess multipl predict accuraci runtim overal learn process runtim also consid valuabl inform everi runtim report includ runtim preprocess step dimension reduct learn algorithm postprocess step addit irrelev featur result report averag independ run synthet synthet waveform databas independ run pima databas due shorter size experi run pentium mhz comput featur syntheticrelevancefeatur synthet relevancefeatur waveformrelevancefeatur pima figur relev measur valu featur databas use dash line correspond relev threshold result relev rank figur plot relev measur valu featur databas consid addit show relev threshold dash line databas case synthet databas true irrelev featur synthet databas synthet databas clearli appear lowest relev measur valu case waveform databas may interest compar graph figur graph report databas caution use detail comparison advis due fact relev dene dierent way depend particular purpos work moreov work talavera limit conceptu cluster symbol data then origin waveform databas previous discret howev notic true irrelev featur appear plot low relev valu graph although shape graph restrict relev featur vari work report agre graph consid rst last relev featur less import rest shape graph slightli closer appear one plot then conclud relev measur propos exhibit desir behavior databas true irrelev featur known clearli assign low relev valu them follow subsect evalu valu low enough automat distinguish relev irrelev featur calcul relev threshold figur show log margin likelihood sc nal multipl predict accuraci number select featur syntheticsc_fin number select featur syntheticltest number select featur synthet sc_final number select featur synthet number select featur waveformsc_fin number select featur waveformltest number select featur pima sc_final number select featur pima figur log margin likelihood sc nal multipl predict accuraci ltest nal cgn databas use function number featur select relev decreas relev rank ltest nal cgn databas consid function number featur select relev learn addit thi figur report runtim need learn nal cgn function number featur select number select featur syntheticruntim number select featur synthet runtim secondsnumb select featur waveformruntim second number select featur pima runtim figur runtim need learn nal cgn databas use function number featur select relev decreas relev rank relev learn select k featur relev mean select k rst featur decreas relev rank obtain featur concret databas accord relev measur valu thu rst part experiment evalu perform automat dimension reduct instead aim studi perform function number featur involv learn allow us evalu abil relev measur assess relev featur learn process gener term figur conrm relev measur abl induc eectiv decreas relev rank featur databas consid is addit featur low relev measur valu last featur rank impli signic increas qualiti nal model even case hurt explanatori power thu gure conrm assumpt low correl featur irrelev learn process work well continu domain consid hand addit irrelev featur tend increas cost learn process measur runtim see figur particularli interest result synthet databas origin model known select true irrelev featur take part learn produc better model increas runtim learn process also known last featur waveform databas true irrelev featur accord relev measur valu featur waveform databas see figur true irrelev featur would appear last posit decreas relev rank furthermor appreci figur addit irrelev featur signicantli increas tabl comparison perform achiev learn cgn origin databas automat dimension reduct scheme appli featur origin dimension dimension reduct databas origin relev sc nal ltest runtim sc nal ltest runtim synthet explanatori power nal cgn result obtain pima databas knowledg exist true irrelev featur share fact use featur learn process degrad qualiti nal model well make learn process slower thu explanatori power nal cgn appear monoton respect addit featur relev learn henc need automat tool discov irrelev featur may degrad eectiv enlarg runtim learn result automat dimension reduct figur show relev threshold dash line calcul shown section databas consid featur exhibit relev measur valu higher relev threshold quali relev rest featur consid irrelev learn interest notic that synthet databas true irrelev featur identi independ complex sampl model rememb synthet databas sampl model complex one use gener synthet databas result obtain waveform databas also special appeal true irrelev featur correctli identi moreov scheme consid featur remaind featur also irrelev appear sensibl decis featur correspond rst last relev featur rememb agre point rst last relev featur less import rest relev featur tabl compar databas consid perform achiev dimension reduct carri perform achiev automat dimension reduct scheme appli learn cgn column relev indic number relev featur automat identi scheme databas see figur clearli appear tabl scheme abl automat set relev threshold induc save runtim still obtain good explanatori model applic scheme preprocess step bsem algorithm figur provid us save runtim origin bsem algorithm achiev synthet databas synthet databas moreov explanatori power cgn elicit origin synthet databas cgn obtain use automat dimension reduct scheme exactli same waveform databas automat dimension reduct scheme propos reduct number featur origin featur consid relev reduct induc gain term runtim wherea scheme signicantli hurt qualiti learnt model hand cgn learnt help automat dimension reduct scheme pima databas exhibit averag desir behavior cgn elicit origin pima databas higher log margin likelihood multipl predict accuraci wherea runtim learn process shorten conclus main contribut paper twofold first propos novel automat scheme perform unsupervis dimension reduct compris i simpl ecient measur assess relev everi featur learn process ii heurist calcul relev threshold automat distinguish relev irrelev featur second present framework unsupervis learn cgn benet propos scheme order obtain model describ origin databas framework propos perform learn take account relev featur identi automat dimension reduct scheme present then everi irrelev featur incorpor learnt model order obtain explanatori cgn origin databas experiment result synthet realworld domain suggest great advantag deriv use automat dimension reduct scheme unsupervis learn cgn huge decreas runtim learn process achiev nal model appear good and sometim even better model obtain use featur learn process addi tional experiment result proven assumpt made relev dene accord purpos perform dimension reduct work fairli well continu domain consid paper primarili focus gain ecienc without degrad explanatori power nal model deriv use refer scheme preprocess learn process howev worth notic identica tion relev irrelev featur learn process allow us reach better comprehens readabl problem domain elicit model work address problem unsupervis featur select preprocess step howev dier work wherea focu descript origin databas interest class label predict accuraci multipl predict accuraci imposs fair comparison dierent approach moreov automat dimension reduct scheme oer seri advantag exist mechan addit simplic ecienc scheme coupl particular learn algorithm could adapt them hand exist unsupervis featur select mechan base wrapper approach tailor perform criterion particular subsequ learn algorithm see and thu usual requir great deal process time larg databas furthermor propos featur select mechan base l ter approach provid user rank featur leav open problem determin mani featur use perform proper learn scheme abl automat distinguish relev irrelev featur relev rank then one line futur research could extens current contribut categor data order overcom problem determin number featur use subsequ learn algorithm awar contribut present paper unabl deal properli domain redund featur exist ie featur whose valu exactli determin rest featur reason relev measur introduc section score featur separ instead group featur thu redund featur would consid relev although would provid learn process addit inform true relev fea ture detect featur necessari eect runtim learn process one line research current explor concern extens gener framework depict paper case redund featur exist current work focus deriv new relev measur assess gain relev featur relat featur consid relev far acknowledg jm pena wish thank dr steve ellacott interest work use comment also made possibl visit school comput mathemat scienc univers brighton brighton unit kingdom author would also like thank two anonym review whose use comment previou version paper help us improv manuscript work support spanish ministri educ cultur min isterio de educacion cultura ap grant r analysi applic pattern classi cluster algorithm find group data estim distribut algorithm featur select knowledg discoveri data mine em algorithm extens uci repositori machin learn databas tr ctr martin h c law mario a t figueiredo anil k jain simultan featur select cluster use mixtur model ieee transact pattern analysi machin intellig v n p septemb lanc parson ehtesham haqu huan liu subspac cluster high dimension data review acm sigkdd explor newslett v n p june j m pea j a lozano p larraaga global multimod problem optim via estim distribut algorithm base unsupervis learn bayesian network evolutionari comput v n p januari