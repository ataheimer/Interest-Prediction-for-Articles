t elev group control use multipl reinforc learn agent a recent algorithm theoret advanc reinforc learn rl attract widespread interest rl algorithm appear approxim dynam program increment basi train basi real simul experi focus comput area state space actual visit control make comput tractabl larg problem member team agent employ one algorithm new collect learn algorithm emerg team whole paper demonstr collect rl algorithm power heurist method address largescal control problemselev group control serv testb difficult domain pose combin challeng seen multiag learn research date use team rl agent respons control one elev car team receiv global reward signal appear noisi agent due effect action agent random natur arriv incomplet observ state spite complic show result simul surpass best heurist elev control algorithm awar result demonstr power multiag rl larg scale stochast dynam optim problem practic util b introduct interest develop capabl learn system increas within multiag ai research commun eg weiss sen learn enabl system flexibl robust make better abl handl uncertainti chang circumst especi import multiag system design system often face extrem difficult task tri anticip possibl conting interact among agent ahead time much could said concern field decentr control polici control station develop global vantag point learn play role even though execut polici depend inform avail control station polici design central way access complet descript problem research focus constitut optim polici given inform pattern polici might learn constraint reinforc learn rl barto sutton forthcom bertseka tsitsik li appli natur case autonom agent receiv sensat input take action affect environ order achiev goal rl base idea tendenc produc action strengthen reinforc produc favor result weaken produc unfavor result framework appeal biolog point view sinc anim certain builtin prefer such pleasur alway teacher tell exactli action take everi situat member group agent employ rl algorithm result collect algorithm allow control polici learn decentr way even situat central inform avail may advantag develop control polici decentr way order simplifi search polici space although may possibl synthes system whose goal achiev agent conflict object paper focus team agent share ident object correspond directli goal system whole demonstr power multiag rl focu difficult problem elev group supervisori control elev system oper highdimension continu state space continu time discret event dynam system state fulli observ nonstationari due chang passeng arriv rate use team rl agent respons control one elev car agent use artifici neural network store action valu estim compar parallel architectur agent share network decentr architectur agent independ network either case team receiv global reinforc signal noisi perspect agent due part effect action agent despit difficulti system outperform heurist elev control algorithm known us also analyz polici learn agent show learn rel robust even face increasingli incomplet state inform result suggest approach decentr control use multiag rl consider promis follow section give addit background rl introduc elev domain describ detail multiag rl algorithm network architectur use present discuss result final draw conclus detail topic see crite reinforc learn symbol connectionist learn research focus primarili supervis learn teacher provid learn system set train exampl form inputoutput pair supervis learn techniqu use wide varieti problem involv pattern classif function approxim howev mani situat train exampl costli even imposs obtain rl applic difficult situa tion help avail critic provid scalar evalu output select rather specifi best output direct chang output rl one face difficulti supervis learn combin addit difficulti explor is determin best output given input rl task divid natur two type nonsequenti task agent must learn map situat action maxim expect immedi payoff sequenti task agent must learn map situat action maxim expect longterm payoff sequenti task difficult action select agent may influenc futur situat thu futur payoff case agent interact environ extend period time need evalu action basi longterm consequ perspect control theori rl techniqu way find approxim solut stochast optim control problem agent control environ system control object maxim perform measur time given model state transit probabl reward structur environ problem solv principl use dynam program dp algorithm howev even though dp requir time polynomi number state mani problem interest mani state amount time requir solut infeas recent rl algorithm design perform dp increment manner unlik tradit dp algorithm requir priori knowledg state transit probabl reward structur environ use improv perform onlin interact environ onlin learn focus comput area state space actual visit control thu algorithm comput tractabl way approxim dp larg problem focus phenomenon also achiev simul onlin train ing one often construct simul model without ever explicitli determin state transit probabl environ barto sutton forthcom crite barto for exampl simul model see section sever advantag use simul model suffici ac curat possibl gener huge amount simul experi quickli potenti speed train process mani order magnitud would possibl use actual experi addit one need concern perform level simul system train success exampl simul onlin train found tesauro tdgammon system use rl techniqu learn play strong masterlevel backgammon multiag reinforc learn varieti disciplin contribut studi multiag system mani research focus topdown approach build distribut system creat global vantag point one drawback topdown approach extraordinari complex design agent sinc extrem difficult anticip possibl interact conting ahead time complex system research recent taken opposit approach combin larg number rel unsophist agent bottomup manner see emerg put togeth group amount sort iter procedur design set agent observ group behavior repeatedli adjust design note effect group behavior although group simpl agent often exhibit interest complex dynam littl understand yet creat bottomup design achiev complex predefin goal multiag rl attempt combin advantag approach achiev simplic bottomup approach allow use rel unsophist agent learn basi experi time rl agent adapt topdown global reinforc signal guid behavior toward achiev complex predefin goal result robust system complex problem creat minimum human effort crite barto research multiag rl date back least work russian mathematician tsetlin other field learn automata see narendra thathachar number theoret result obtain context nonsequenti rl certain type learn automata converg equilibrium point zerosum nonzerosum repeat game see narendra thathachar detail team equilibrium point local maximum an element game matrix maximum row column howev gener nonzerosum game equilibrium point often provid poor payoff player good exampl prison dilemma equilibrium point produc lowest total payoff axelrod start approxim number research began investig appli sequenti rl algorithm multiag context although much work simplist domain grid world sever interest applic appear point promis sequenti multiag rl markey appli parallel qlearn problem control vocal tract model degre freedom discuss two architectur equival distribut parallel architectur describ section agent control one degre freedom action space distinguish qvalu base action select bradtk describ initi experi use rl decentr control flexibl beam task effici damp disturb beam appli forc discret locat time use independ adapt control distribut along beam control attempt minim local cost observ local portion state inform dayan hinton propos manageri hierarchi call feudal rl scheme higherlevel manag set task lower level manag reward see fit sinc reward may differ differ level hierarchi team furthermor singl action select lowest level actual affect environ sens hierarch architectur singl agent tan report simpl hunterprey experi multiag rl focu share sensori inform polici experi among agent shoham tennenholtz investig social behavior emerg agent simpl learn rule focu two simpl nkg iter game n agent meet k time randomli play game g littman boyan describ distribut reinforc learn algorithm packet rout base asynchron bellmanford algorithm scheme use singl qfunction state entri qfunction assign node network respons store updat valu entri differ work distribut rl entir qfunction singl entri must store node addit multiag rl research concern team problem signific amount work focus zerosum game singl agent learn play oppon one earliest exampl samuel checkerplay program recent exampl tesauro tdgammon program learn play strong master level backgam mon type program often train use selfplay gener view singl agent littman provid detail discuss rl appli zerosum game case agent altern action take simultan littl work done multiag rl gener nonzero sum game sandholm crite studi behavior multiag rl context iter prison dilemma show qlearn agent abl learn optim strategi fix oppon titfortat addit investig behavior result two qlearn agent face other elev group control section introduc problem elev group control serv testb multiag reinforc learn familiar problem anyon ever use elev system spite conceptu simplic pose signific difficulti elev system oper highdimension continu state space continu time discret event dynam system state fulli observ nonstationari due chang passeng arriv rate optim polici elev group control known use exist control algorithm standard comparison elev domain provid opportun compar parallel distribut control architectur agent control one elev car monitor amount degrad occur agent face increas level incomplet state inform button dn figur elev system schemat diagram schemat diagram elev system lewi present figur elev car repres fill box diagram repres hall call someon want enter car gamma repres car call someon want leav car left side shaft repres upward move car call right side shaft repres downward move car call car therefor move clockwis direct around shaft section consid natur differ passeng arriv pattern implic section review varieti elev control strategi literatur section describ particular simul elev system focu remaind paper passeng arriv pattern elev system driven passeng arriv arriv pattern vari cours day typic offic build morn rush hour bring peak level traffic peak traffic occur afternoon part day characterist pattern differ arriv pattern differ effect pattern requir analysi up peak downpeak elev traffic simpli equival pattern opposit direct one might initi guess downpeak traffic mani arriv floor singl destin uppeak traffic singl arriv floor mani destin distinct signific implic exampl light traffic averag passeng wait time kept low keep idl car lobbi immedi avail arriv passeng light traffic wait time longer sinc possibl keep idl car everi upper floor build therefor addit wait time incur car move servic hall call situat revers heavi traffic heavi traffic car may fill lobbi passeng desir stop mani differ upper floor larg number stop caus significantli longer roundtrip time heavi traffic car may fill stop upper floor reason downpeak handl capac much greater uppeak capac siikonen illustr differ excel graph obtain extens simul sinc uppeak handl capac limit factor elev system design predict heaviest like uppeak demand build determin configur accomod demand uppeak capac suffici downpeak gener also uppeak traffic easiest type analyz sinc passeng enter car lobbi destin floor servic ascend order empti car return lobbi standard capac calcul strakosch siikonen assum car leav lobbi passeng percent capac averag passeng likelihood select destin floor known probabl theori use determin averag number stop need round trip one estim averag round trip time repres averag amount time car arriv lobbi l number car assum car evenli space averag wait time one half interv realiti averag wait somewhat longer control decis pure traffic determin open close elev door lobbi decis affect mani passeng board elev lobbi door close realli choic next action car call regist passeng must servic ascend order empti car must return lobbi pepyn cassandra show optim polici handl pure traffic thresholdbas polici close door optim number passeng enter car optim threshold depend upon traffic intens may also affect number car call alreadi regist state car cours traffic seldom complet pure method must use assign hall call gener two way traffic come two varieti two way lobbi traffic upmov passeng arriv lobbi downmov passeng depart lobbi compar pure traffic round trip time longer passeng serv two way interfloor traffic passeng travel floor lobbi interfloor traffic complex lobbi traffic requir almost twice mani stop per passeng lengthen round trip time two way downpeak traffic pattern requir mani decis pure traffic leav lobbi car must decid high travel build turn floor make addit pickup decis requir wider varieti context control strategi also possibl two way downpeak traffic situat reason down peak traffic pattern chosen testb research describ testb detail review variou elev control strategi literatur elev control strategi oldest relaybas automat control use principl collect control strakosch siikonen car alway stop nearest call run direct one drawback scheme mean avoid phenomenon call bunch sever car arriv floor time make interv thu averag wait time much longer advanc electron includ advent microprocessor made possibl sophist control polici approach elev control discuss literatur gener fit follow categori often one categori unfortun descript proprietari algorithm often rather vagu sinc written market purpos specif intend benefit competitor reason difficult ascertain rel perform level mani algorithm accept definit current state art ovaska zone approach oti elev compani use zone start point deal variou traffic pattern strakosch car assign zone build ing answer hall call within zone park idl goal zone approach keep car reason well separ thu keep interv down approach quit robust heavi traffic give signific amount flexibl sakai kurosawa hitachi describ concept call area control relat zone possibl assign hall call car alreadi must stop floor due car call otherwis car within area ff hall call assign possibl area ff control paramet affect averag wait time power consumpt searchbas approach anoth control strategi search space possibl car assign select one optim criterion averag wait time greedi search strategi perform immedi call assign is assign hall call car first regist never reconsid assign ment nongreedi algorithm postpon assign reconsid light updat inform may receiv addit hall call passeng destin greedi algorithm give measur perform due lack flexibl also requir less comput time western countri arriv car gener signal wait passeng begin deceler si ikonen allow use nongreedi algorithm custom japan signal car assign immedi upon call registr type signal requir use greedi algorithm tobita et al hitachi describ system car assign occur hall button press assign car minim weight sum predict wait time travel time number rider fuzzi rulebas system use pick coeffici estim function simul use verifi effect reced horizon control exampl nongreedi searchbas approach everi event perform expens search best assign hall call assum new passeng arriv closedloop control achiev recalcul new openloop plan everi event weak approach comput demand lack consider futur arriv exampl reced horizon control finit intervisit minim empti system algorithm esa bao et al fim attempt minim squar wait time esa attempt minim length current busi period rulebas approach sens control polici could consid rulebas situat action howev narrowli consid type product system commonli use artifici intellig ujihara tsuji mitsubishi describ ai system use expertsystem fuzzylog technolog claim expert groupsupervisori control experi knowledg necessari shorten wait time variou traffic condit admit expert knowledg fragmentari hard organ difficult incorpor creat rule base compar decis made convent algorithm decis determin simul anneal discrep analyz expert whose knowledg solv problem use creat fuzzi control rule fuzzi lie part rule ujihara amano describ latest chang system previou version use fix evalu formula base current car posit call locat recent version consid futur car posit probabl futur hall call exampl one rule there hall call regist upper floor there larg number car ascend toward upper floor assign one ascend car basi estim time arriv note immedi call alloc algorithm consequ particular rule assign car basi estim time arriv bear similar greedi searchbas algorithm describ abov heurist approach longest queue first lqf algorithm assign upward move car longest wait queue highest unansw floor first huff algorithm assign upward move car highest queue peopl wait bao et al algorithm design specif downpeak traffic assign downward move car unassign hall call encount dynam load balanc dlb algorithm attempt keep car evenli space assign contigu nonoverlap sector car way balanc load lewi dlb nongreedi algorithm reassign sector everi event adapt learn approach imasaki et al toshiba use fuzzi neural network predict passeng wait time distribut variou set control paramet system adjust paramet evalu altern candid paramet neural network explain control algorithm actual use paramet are network train hitachi research fujino et al tobita et al use greedi control algorithm combin multipl object wait time travel time crowd ing power consumpt weight object accomplish use paramet tune onlin modul call learn function unit collect traffic statist attempt classifi current traffic pattern tune function unit gener paramet set current traffic pattern test use builtin simul best paramet use control system search entir paramet space would prohibit expens heurist use paramet set test levi et al use dynam program dp offlin minim expect time need complet current busi period discount factor use sinc assum valu finit major differ qlearn must perform offlin sinc use model transit probabl system perform sweep state space troubl use dp calcul optim polici state space larg requir drastic simplif levi et al use sever method keep size state space manag consid build car floor number button simultan restrict state button restrict binari valu ie elaps time discard car unlimit capac construct transit probabl matrix principl part procedur assum intens poisson arriv floor known valu iter polici iter perform obtain solut markon et al devis system train neural network perform immedi call alloc three phase train phase one system control exist control the flex fuzzyai group control system fujitec supervis learn use train network predict hall call servic time first phase train use learn appropri intern represent ie weight input layer hidden layer network end first phase train weight fix phase two output layer network retrain emul exist control phase three singl weight output layer network perturb result perform measur traffic sampl weight modifi direct improv perform view form nonsequenti reinforc learn singlestag reward determin measur system perform traffic sampl input represent use unit car output represent use one unit car hall call alloc car correspond output unit highest activ also describ clever way incorpor permut symmetri problem architectur network say if state two car interchang output also interchang done mani set hidden unit car explicitli link togeth appropri weight system test simul car floor typic build train passeng per hour small improv around second averag wait time exist control untyp build uniformli distribut origin destin floor passeng per hour improv averag wait time almost second one advantag system maintain adequ servic level begin sinc start preexist control hand clear whether also may trap control suboptim region polici space would interest use central immedi call alloc network architectur part sequenti reinforc learn algorithm elev testb particular elev system studi paper simul stori build elev car simul written lewi passeng arriv floor assum poisson arriv rate vari cours day simul use traffic profil bao et al dictat arriv rate everi minut interv typic afternoon down peak rush hour tabl show mean number passeng arriv floor minut interv head lobbi addit interfloor traffic vari traffic lobbi tabl downpeak traffic profil time system dynam system dynam approxim follow paramet ffl floor time the time move one floor maximum speed sec ffl stop time the time need deceler open close door acceler sec ffl turn time the time need stop car chang direct sec ffl load time the time one passeng enter exit car random variabl th order truncat erlang distribut rang sec mean sec ffl car capac passeng simul quit detail certainli realist enough purpos howev minor deviat realiti note simul car acceler full speed deceler full speed distanc one half floor distanc would somewhat longer real system thu simul acceler deceler time alway same real system vari depend speed elev exampl express car descend tenth floor top speed take longer deceler first floor car descend second floor simul also allow car commit stop floor one half floor away though realist car move top speed concept make decis regard next floor car could commit stop valid although elev car system homogen learn techniqu describ paper also use gener situat eg sever express car car servic subset floor state space state space continu includ elaps time sinc hall call regist realvalu even real valu approxim binari valu size state space still immens compon includ possibl combin button up button land except top bottom possibl combin car button possibl combin posit direct car round nearest floor part state fulli ob servabl exampl exact number passeng wait floor exact arriv time desir destin ignor everyth except configur hall car call button approxim posit direct car obtain extrem conserv estim size discret approxim continu state space state control action car small set primit action stop floor must either move up move down motion floor must either stop next floor continu past next floor due passeng expect two constraint action car cannot pass floor passeng want get cannot turn servic car button present direct also ad three addit heurist constraint attempt build primit prior knowledg car cannot stop floor unless someon want get there cannot stop pick passeng floor anoth car alreadi stop there given choic move down prefer move sinc downpeak traffic tend push car toward bottom build last constraint real choic left car stop continu action action elev car execut asynchron sinc may take differ amount time complet perform criteria perform object elev system defin mani way one possibl object minim averag wait time time arriv passeng entri car anoth possibl object minim averag system time sum wait time travel time third possibl object minim percentag passeng wait longer dissatisfact threshold usual second anoth common object minim averag squar wait time chose latter perform object sinc tend keep wait time low also encourag fair servic exampl wait time second averag second wait time second averag squar wait time differ versu algorithm network architectur section describ multiag reinforc learn algorithm appli elev group control scheme agent respons control one elev car agent use modif qlearn discreteev system togeth employ collect form reinforc learn begin describ modif need extend qlearn discreteev framework deriv method determin appropri reinforc signal face uncertainti exact passeng arriv time describ algorithm feedforward network use store qvalu distinct parallel distribut version algorithm discreteev reinforc learn elev system model discret event system cassandra signific event such passeng arriv occur discret time amount time event realvalu variabl system constant discount factor fl use discretetim reinforc learn algorithm inadequ problem approach use variabl discount factor depend amount time event bradtk duff case costtogo defin integr rather infinit sum c immedi cost discret time t c instantan cost continu time the sum squar wait time current wait pa senger fi control rate exponenti decay experi describ paper sinc wait time measur second scale instantan cost c factor keep costtogo valu becom exceedingli larg elev system event occur randomli continu time branch factor effect infinit complic use algorithm requir explicit lookahead therefor employ discret event version qlearn algorithm sinc consid event encount actual system trajectori requir model state transit probabl qlearn updat rule watkin take follow discret event form e gammafi gammat x action taken state x time x next decis requir state time ff learn rate paramet c fi defin abov e gammafit gammat x act variabl discount factor depend amount time event consid case c constant event extend formul case c quadrat sinc goal minim squar wait time integr qlearn updat rule take form e gammafi gammat x w p amount time passeng p wait time alreadi wait time x special care need handl passeng begin wait x see section integr solv part yield difficulti aris use formula sinc requir knowledg wait time wait passeng howev wait time passeng press hall call button known real elev system number subsequ passeng arriv exact wait time avail examin two way deal problem call omnisci onlin reinforc scheme simul access wait time passeng could use inform produc necessari reinforc signal call omnisci reinforc sinc requir inform avail real system note control receiv extra inform howev rather critic evalu control reason even omnisci reinforc use design phase elev control simul system result train control instal real system without requir extra knowledg possibl train use inform would avail real system onlin onlin reinforc assum wait time first passeng queue known which elaps button time poisson arriv rate queue known estim gamma distribut use estim arriv time subsequ passeng time n th subsequ arriv follow gamma distribut gamman queue subsequ arriv gener follow expect cost first b second hall button pressedx z bprob n th arriv occur time delta cost given arriv time d z bgamma z bz bgamma integr also solv part yield expect cost gener solut provid section describ section use onlin reinforc produc result almost good obtain omnisci reinforc collect discreteev qlearn elev system event divid two type event first type import calcul wait time therefor also reinforc includ passeng arriv transfer car omnisci case hall button event onlin case second type car arriv event potenti decis point rl agent control car car motion floor gener car arriv event reach point must decid whether stop next floor continu past next floor case car constrain take particular action exampl stop next floor passeng want get there agent face decis point unconstrain choic action calcul omnisci reinforc omnisci reinforc updat increment everi passeng arriv event when passeng arriv queue passeng transfer event when passeng get car car arriv event when control decis made increment updat natur way deal discontinu reinforc aris passeng begin end wait car decis eg anoth car pick wait passeng amount reinforc event car sinc share object function amount reinforc car receiv decis differ sinc car make decis asynchron there fore car associ storag locat ri total discount reinforc receiv sinc last decis at time di accumul time event follow comput perform let time last event time current event passeng p wait let w p w p total time passeng p wait respect car i calcul onlin reinforc onlin reinforc updat increment everi hall button event sig nale arriv first wait passeng queue arriv car pick wait passeng queue car arriv event when control decis made assum onlin reinforc caus passeng wait queue end immedi car arriv servic queue sinc possibl know exactli passeng board car poisson arriv rate queue estim reciproc last interbutton time queue ie amount time last servic button push again howev ceil passeng per second place estim arriv rate prevent small interbutton time creat huge penalti might destabil costtogo estim time event follow comput perform let time last event time current event hall call button b activ let w b w b elaps time button b respect car i f g make decis updat qvalu car motion floor gener car arriv event reach point must decid whether stop next floor continu past next floor case car constrain take particular action exampl stop next floor passeng want get there agent face decis point unconstrain choic action algorithm use agent make decis updat qvalu estim follow time x observ state x car arriv decis point select action use boltzmann distribut qvalu estim posit temperatur paramet anneal decreas train valu control amount random select action begin train qvalu estim inaccur high valu use give nearli equal probabl action later train qvalu estim accur lower valu use give higher probabl action thought superior still allow explor gather inform action discuss section choos slow enough anneal schedul particularli import multiag set let next decis point car time state y car includ car i updat rdelta valu describ last two section car adjust estim qx a toward follow target valu fstopcontg car reset reinforc accumul ri zero let x x go step network use store qvalu use lookup tabl store qvalu rule larg system in stead use feedforward neural network train error backpropag algorithm rumelhart et al network receiv state inform input produc qvalu estim output qvalu estim written qx a oe oe vector paramet weight network exact weight updat equat is fstopcontg ff posit learn rate stepsiz paramet gradient oe vector partial deriv qx a oe respect compon oe start train weight network initi uniform random number gamma experi paper use separ singleoutput network actionvalu estim other use one network multipl output unit one action basic network architectur pure traffic use input unit hidden sigmoid unit linear output unit input unit follow ffl unit two unit encod inform nine hall but ton realvalu unit encod elaps time button push binari unit button push unit unit repres possibl locat direct car whose decis requir exactli one unit given time note car differ egocentr view state system unit unit repres one floor car may locat car footprint depend direct speed exampl stop car caus activ unit correspond current floor move car caus activ sever unit correspond floor approach highest activ closest floor inform provid one car particular locat unit car whose decis requir highest floor wait passeng unit car whose decis requir floor passeng wait longest amount time unit bia unit alway on section introduc represent includ restrict state inform parallel distribut implement elev car control separ qlearn agent experi parallel decentr implement parallel implement agent use central set share network allow learn other experi forc learn ident polici total decentr implement agent network allow special control polici either case none agent given explicit access action agent cooper learn indirectli via global reinforc signal agent face ad stochast nonstationar environ contain learn agent result discuss basic result versu algorithm sinc optim polici elev group control problem unknown measur perform algorithm heurist algorithm includ best awar algorithm were sector sectorbas algorithm similar use mani actual elev system dlb dynam load balanc attempt equal load car huff highest unansw floor first give prioriti highest floor peopl wait lqf longest queue first give prioriti queue person wait longest amount time fim finit intervisit minim reced horizon control search space admiss car assign minim load function esa empti system algorithm reced horizon control search fastest way empti system assum new passeng arriv fim comput intens would difficult implement real time present form esa use queue length inform would avail real elev system esanq version esa use arriv rate inform estim queue length detail see bao et al rlp rld denot rl control parallel decentr rl control train hour simul elev time took four day mip workstat result algorithm averag hour simul elev time ensur statist signific averag wait time list train rl algorithm correct within sigma confid level averag squar wait time correct within sigma averag system time correct within sigma tabl show result traffic profil traffic onli tabl show result downpeak traffic profil traffic includ averag passeng per minut lobbi algorithm train downonli traffic yet gener well traffic ad upward move car forc stop upward hall call tabl show result downpeak traffic profil traffic includ averag passeng per minut lobbi time twice much traffic rl agent gener extrem well new situat tabl result downpeak profil traffic onli algorithm avgwait squaredwait systemtim percent sec dlb esa rld tabl result downpeak profil traffic algorithm avgwait squaredwait systemtim percent sec huff rld tabl result downpeak profil twice much traffic algorithm avgwait squaredwait systemtim percent sec basic huff fim esa rld one see rl system achiev good perform notabl measur system time the sum wait travel time measur directli minim surprisingli decentr rl system abl achiev good level perform parallel rl system analysi decentr result view outstand success decentr rl algorithm sever question suggest themselv similar polici agent learn one anoth polici learn parallel algorithm result improv use vote scheme happen one agent polici use control car section address question first simul modifi poll four decentr qnetwork agent well parallel qnetwork everi decis everi car compar action select one hour simul elev time total decis requir four agent unanim decis decis percent split evenli decis percent parallel network agre unanim decis percent reason parallel network tend favor stop action decentr network though appar littl impact overal perform complet result list tabl tabl amount agreement decentr agent agent say agent say number parallel parallel stop continu instanc say stop say cont result show consider agreement minor situat agent disagre next experi agent vote action select car case agent evenli split examin three way resolv tie favor stop rl favor continu rlc randomli rlr follow tabl show result vote scheme compar origin decentr algorithm rld result averag hour simul elev time pure traffic result show signific improv vote situat agent evenli split break tie randomli produc result almost ident origin decentr algorithm seem impli agent gener agre import decis tabl comparison sever vote scheme algorithm avgwait squaredwait systemtim percent sec rlc rl rlr rld disagre decis littl consequ action valu similar next experi agent singl car select action car rl use agent car control car rl use agent car on follow tabl compar control origin decentr algorithm rld result averag hour simul elev time pure traffic tabl let singl agent control four car algorithm avgwait squaredwait systemtim percent sec rld agent outperform agent agent perform well rel nonrl control discuss abov summari appear decentr parallel agent learn similar polici similar learn polici may caus part symmetri elev system input represent select distinguish among car futur work would interest see whether agent input represent distinguish among car would still arriv similar polici anneal schedul one import factor perform algorithm anneal schedul use control amount explor perform agent slower anneal process better final result illustr tabl figur show result one train run number anneal rate temperatur anneal accord schedul repres hour train complet again result measur hour simul elev time even though somewhat noisi due averag multipl train run trend still quit clear schedul test share start end temper atur although anneal process end time current qvalu estim use determin control polici amount time avail train known advanc one select anneal schedul cover full rang temperatur tabl effect vari anneal rate factor hour avgwait squaredwait systemtim pct sec gradual anneal import singleag rl even import multiag rl tradeoff explor exploit agent must also balanc need agent learn stationari environ agent best begin learn process agent extrem inept gradual anneal abl rais perform level parallel tesauro note slightli differ relat phenomenon context zerosum game train selfplay allow agent learn wellmatch oppon stage develop omnisci versu onlin reinforc section examin rel perform omnisci onlin reinforc describ section given network structur temperatur learn rate schedul shown tabl omnisci reinforc led slightli better perform onlin reinforc littl concern regard applic rl real elev system sinc one would want perform initi train simul case huge amount experi need also perform would poor earli stage train real elev system initi train could perform use simul network could finetun real system final averag squar wait hour train freez figur effect vari anneal rate tabl omnisci versu onlin reinforc avgwait squaredwait systemtim pct sec omnisci onlin level incomplet state inform parallel decentr rl implement real elev system would problem provid whatev state inform avail agent howev truli decentr control situat might possibl section look perform degrad agent receiv less state inform experi amount inform avail agent vari along two dimens inform hall call button inform locat direct statu car input represent hall call button were real consist input unit two unit encod inform nine hall button realvalu unit encod elaps time button push binari unit button push binari consist binari input unit correspond nine hall button quantiti consist two input unit measur number hall call current decisionmak car none input unit convey inform hall button input represent configur car were foot print consist input unit unit repres one floor car may locat car footprint depend direct speed exampl stop car caus activ unit correspond current floor move car caus activ sever unit correspond floor approach highest activ closest floor activ caus variou car addi quantiti consist input unit repres number upward downward move car decisionmak car none consist input unit convey inform hall button network also possess bia unit alway activ hidden unit output unit for stop continu action use decentr rl algorithm train hour simul elev time use downpeak profil omnisci reinforc temperatur anneal accord schedul hour train learn rate paramet decreas accord schedul result shown tabl measur term averag squar passeng wait time hour simul elev time consid fairli noisi averag multipl train run nevertheless show interest trend tabl averag squar wait time variou level incomplet state inform hall locat car button footprint quantiti none real binari quantiti none clearli inform hall call import inform configur car fact perform still remark good even without inform car technic speak inform alway avail car constraint prevent car stop pick passeng floor anoth car alreadi stop doubt constraint help perform consider hall call inform complet miss network weight increas tendenc becom unstabl grow without bound learn rate paramet lower case discuss network instabl see section way inform present import exampl suppli number hall call decisionmak car use network potenti inform binari button inform also appear inform along one dimens help util inform along dimens exampl footprint represent made perform much wors car inform absenc hall call inform time footprint outperform represent maximum amount hall call inform overal perform quit good except complet absenc hall call inform which signific handicap inde could improv slower anneal seem reason say algorithm degrad grace presenc incomplet state inform problem final experi two binari featur ad realfootprint input represent activ decisionmak car highest floor wait passeng floor longest wait pa senger respect addit featur averag squar wait time decreas appear valu practic issu one biggest difficulti appli rl elev control problem find correct temperatur learn rate paramet help start scale version consist car floor lookup tabl qvalu made easier determin rough valu temperatur learn rate schedul import focus experi learner appropri area state space cannot overstress train trajectori system import start ad reason constraint describ section also help evid support import focus given choic train heavier lighter traffic one expect face test better train heavier traffic type train give system experi state queue length long thu make correct decis crucial instabl weight neural network becom unstabl magnitud increas without bound two particular situat seem lead instabl first occur learn algorithm make updat larg happen learn rate larg network input larg which happen heavi traffic situat both second occur network weight initi random valu produc excess inconsist qvalu exampl learn rate gamma suitabl train random initi network moder traffic passengershour consist bring instabl heavi traffic passengershour howev learn rate gamma keep network stabl even heavi traffic train network way sever hundr hour elev time lead weight repres consist set qvalu learn rate safe rais back gamma without caus instabl linear network one may ask whether nonlinear function approxim feedforward sigmoid network necessari good perform elev control prob lem test run use linear network train delta rule linear network much greater tendenc unstabl order keep weight blow up learn rate lower sever order magnitud gamma gamma initi improv linear network unabl reduc averag td error result extrem poor perform failur linear network lend support content elev control difficult problem discuss parallel distribut multiag rl architectur abl outperform elev algorithm test against two architectur learn similar polici gradual anneal appear crucial factor success train accomplish effect use omnisci onlin reinforc algorithm robust easili gener new situat ad traffic final degrad grace face increas level incomplet state inform although network becam unstabl certain circumst techniqu discuss prevent instabl practic taken togeth result demonstr multiag rl algorithm power techniqu address larg scale stochast dynam optim problem crucial ingredi success multiag rl care control amount explor perform agent explor context mean tri action believ suboptim order gather addit inform potenti valu begin learn process rl agent choos action randomli without knowledg rel valu thu agent extrem inept howev spite nois reinforc signal caus action agent action begin appear better other gradual anneal or lower amount explor perform agent better action taken greater frequenc gradual chang environ agent continu explor rais perform level parallel even though rl agent team face ad stochast nonstationar due chang stochast polici agent team display except abil cooper one anoth learn maxim reward mani area research elev group control gener multiag rl deserv investig implement rl control real elev system would requir train sever traffic profil includ uppeak interfloor traffic pattern addit action would need order handl traffic pattern exampl uppeak traffic would use action specif open close door control dwell time lobbi interfloor traffic unconstrain up down action would need sake flexibl car also abil park variou floor period light traffic would interest tri someth uniform anneal schedul agent exampl coordin explor strategi roundrobin type anneal might way reduc nois gener agent howev coordin explor strategi may greater tendenc becom stuck suboptim polici theoret result sequenti multiag rl need supplement result nonsequenti multiag rl describ section anoth area need studi rl architectur reinforc tailor individu agent possibl use hierarchi advanc organiz structur local reinforc architectur potenti greatli increas speed learn requir much knowledg part whatev produc reinforc signal barto fi nalli import find effect method allow possibl explicit commun among agent conclus multiag control system often requir spatial geograph distribut situat central inform avail practic even distribut approach requir multipl agent may still provid excel way scale approxim solut larg problem streamlin search space possibl polici multiag rl combin advantag bottomup topdown approach design multiag system achiev simplic bottomup approach allow use rel unsophist agent learn basi experi time rl agent adapt topdown global reinforc signal guid behavior toward achiev complex specif goal result robust system complex problem creat minimum human effort rl algorithm train use actual simul experi allow focu comput area state space actual visit control make comput tractabl larg problem member team agent employ rl algorithm new collect algorithm emerg group whole type collect algorithm allow control polici learn decentr way even though rl agent team face ad stochast nonstationar due chang stochast polici agent team display except abil cooper one anoth maxim reward order demonstr power multiag rl focus difficult problem elev group supervisori control use team rl agent respons control one elev car result obtain simul surpass best heurist elev control algorithm awar perform also robust face increas level incomplet state inform acknowledg thank john mcnulti christo cassandra asif gandhi dave pepyn kevin markey victor lesser rod grupen rich sutton steve bradtk anw group assist simul help discuss research support air forc offic scientif research grant f r evolut cooper elev dispatch peak traffic chemotaxi cooper abstract exercis neuron learn strategi learn interact introduct modern reinforc learn distribut adapt optim control flexibl structur reinforc learn method continuoustim markov decis problem discret event system model perform analysi phd thesi form control polici simul model use reinforc learn improv elev perform use reinforc learn feudal reinforc learn fuzzi neural network applic elev group control optim control elev dynam load balanc approach control multiserv poll system applic elev system dispatch distribut reinforc learn scheme network rout technic report cmuc markov game framework multiag reinforc learn algorithm sequenti decis make effici learn multipl degreeoffreedom control problem quasiindepend qagent adapt optim elev group control use neural network learn automata introduct electron inform technolog highrang elev system optim dispatch control elev system uppeak traffic pdp research group develop elev supervisori group control system artifici intellig studi machin learn use game checker multiag reinforc learn iter prison dilemma elev traffic simul vertic transport elev escal neural comput tempor differ learn tdgammon elev character group supervisori control system automaton theori model biolog system latest elev groupcontrol system revolutionari ai elevatorgroup control system new intellig option seri learn delay reward adapt learn multiag system receiv date accept date final manuscript date tr ctr shingo mabu kotaro hirasawa jinglu hu graphbas evolutionari algorithm genet network program gnp extens use reinforc learn evolutionari comput v n p fall rajbala makar sridhar mahadevan mohammad ghavamzadeh hierarch multiag reinforc learn proceed fifth intern confer autonom agent p may montreal quebec canada shin ishii hajim fujita masaoki mitsutak tatsuya yamazaki jun matsuda yoichiro matsuno reinforc learn scheme partiallyobserv multiag game machin learn v n p may mohammad ghavamzadeh sridhar mahadevan learn commun act use hierarch reinforc learn proceed third intern joint confer autonom agent multiag system p juli new york new york theodor j perkin andrew g barto lyapunov design safe reinforc learn journal machin learn research shimon whiteson matthew e taylor peter stone empir studi action select reinforc learn adapt behavior anim animat softwar agent robot adapt system v n p march tadhg omeara ahm patel topicspecif web robot model base restless bandit ieee internet comput v n p march hajim fujita shin ishii modelbas reinforc learn partial observ game samplingbas state estim neural comput v n p novemb andrew g barto sridhar mahadevan recent advanc hierarch reinforc learn discret event dynam system v n p januaryapril andrew g barto sridhar mahadevan recent advanc hierarch reinforc learn discret event dynam system v n p octob philipp fries jrg rambau onlineoptim multielev transport system reoptim algorithm base setpartit model discret appli mathemat v n p august shimon whiteson peter stone evolutionari function approxim reinforc learn journal machin learn research p gang chen zhonghua yang hao kiah mok goh coordin multipl agent via reinforc learn autonom agent multiag system v n p may pasqual fiengo giovanni giamben edmondo trentin neuralbas downlink schedul algorithm broadband wireless network comput commun v n p januari dars bill lourd pea jonathan schaeffer duan szafron learn play strong poker machin learn play game nova scienc publish inc commack ny